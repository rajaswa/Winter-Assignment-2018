{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Code modified from PyTorch DCGAN examples: https://github.com/pytorch/examples/tree/master/dcgan\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "# compute the current classification accuracy\n",
    "def compute_acc(preds, labels):\n",
    "    correct = 0\n",
    "    preds_ = preds.data.max(1)[1]\n",
    "    correct = preds_.eq(labels.data).cpu().sum()\n",
    "    acc = float(correct) / float(len(labels.data)) * 100.0\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "IMG_EXTENSIONS = ['.jpg', '.jpeg', '.png', '.ppm', '.bmp', '.pgm']\n",
    "\n",
    "\n",
    "def is_image_file(filename):\n",
    "    \"\"\"Checks if a file is an image.\n",
    "\n",
    "    Args:\n",
    "        filename (string): path to a file\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the filename ends with a known image extension\n",
    "    \"\"\"\n",
    "    filename_lower = filename.lower()\n",
    "    return any(filename_lower.endswith(ext) for ext in IMG_EXTENSIONS)\n",
    "\n",
    "\n",
    "def find_classes(dir, classes_idx=None):\n",
    "    classes = [d for d in os.listdir(dir) if os.path.isdir(os.path.join(dir, d))]\n",
    "    classes.sort()\n",
    "    if classes_idx is not None:\n",
    "        assert type(classes_idx) == tuple\n",
    "        start, end = classes_idx\n",
    "        classes = classes[start:end]\n",
    "    class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
    "    return classes, class_to_idx\n",
    "\n",
    "\n",
    "def make_dataset(dir, class_to_idx):\n",
    "    images = []\n",
    "    dir = os.path.expanduser(dir)\n",
    "    for target in sorted(os.listdir(dir)):\n",
    "        if target not in class_to_idx:\n",
    "            continue\n",
    "        d = os.path.join(dir, target)\n",
    "        if not os.path.isdir(d):\n",
    "            continue\n",
    "\n",
    "        for root, _, fnames in sorted(os.walk(d)):\n",
    "            for fname in sorted(fnames):\n",
    "                if is_image_file(fname):\n",
    "                    path = os.path.join(root, fname)\n",
    "                    item = (path, class_to_idx[target])\n",
    "                    images.append(item)\n",
    "\n",
    "    return images\n",
    "\n",
    "\n",
    "def pil_loader(path):\n",
    "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
    "    with open(path, 'rb') as f:\n",
    "        with Image.open(f) as img:\n",
    "            return img.convert('RGB')\n",
    "\n",
    "\n",
    "def accimage_loader(path):\n",
    "    import accimage\n",
    "    try:\n",
    "        return accimage.Image(path)\n",
    "    except IOError:\n",
    "        # Potentially a decoding problem, fall back to PIL.Image\n",
    "        return pil_loader(path)\n",
    "\n",
    "\n",
    "def default_loader(path):\n",
    "    from torchvision import get_image_backend\n",
    "    if get_image_backend() == 'accimage':\n",
    "        return accimage_loader(path)\n",
    "    else:\n",
    "        return pil_loader(path)\n",
    "\n",
    "\n",
    "class ImageFolder(data.Dataset):\n",
    "    \"\"\"A generic data loader where the images are arranged in this way: ::\n",
    "\n",
    "        root/dog/xxx.png\n",
    "        root/dog/xxy.png\n",
    "        root/dog/xxz.png\n",
    "\n",
    "        root/cat/123.png\n",
    "        root/cat/nsdf3.png\n",
    "        root/cat/asd932_.png\n",
    "\n",
    "    Args:\n",
    "        root (string): Root directory path.\n",
    "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        target_transform (callable, optional): A function/transform that takes in the\n",
    "            target and transforms it.\n",
    "        loader (callable, optional): A function to load an image given its path.\n",
    "\n",
    "     Attributes:\n",
    "        classes (list): List of the class names.\n",
    "        class_to_idx (dict): Dict with items (class_name, class_index).\n",
    "        imgs (list): List of (image path, class_index) tuples\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root, transform=None, target_transform=None,\n",
    "                 loader=default_loader, classes_idx=None):\n",
    "        self.classes_idx = classes_idx\n",
    "        classes, class_to_idx = find_classes(root, self.classes_idx)\n",
    "        imgs = make_dataset(root, class_to_idx)\n",
    "        if len(imgs) == 0:\n",
    "            raise(RuntimeError(\"Found 0 images in subfolders of: \" + root + \"\\n\"\n",
    "                               \"Supported image extensions are: \" + \",\".join(IMG_EXTENSIONS)))\n",
    "\n",
    "        self.root = root\n",
    "        self.imgs = imgs\n",
    "        self.classes = classes\n",
    "        self.class_to_idx = class_to_idx\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.loader = loader\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is class_index of the target class.\n",
    "        \"\"\"\n",
    "        path, target = self.imgs[index]\n",
    "        img = self.loader(path)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _netG(nn.Module):\n",
    "    def __init__(self, ngpu, nz):\n",
    "        super(_netG, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.nz = nz\n",
    "\n",
    "        # first linear layer\n",
    "        self.fc1 = nn.Linear(110, 768)\n",
    "        # Transposed Convolution 2\n",
    "        self.tconv2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(768, 384, 5, 2, 0, bias=False),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        # Transposed Convolution 3\n",
    "        self.tconv3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(384, 256, 5, 2, 0, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        # Transposed Convolution 4\n",
    "        self.tconv4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 192, 5, 2, 0, bias=False),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        # Transposed Convolution 5\n",
    "        self.tconv5 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(192, 64, 5, 2, 0, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        # Transposed Convolution 5\n",
    "        self.tconv6 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 3, 8, 2, 0, bias=False),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 1:\n",
    "            input = input.view(-1, self.nz)\n",
    "            fc1 = nn.parallel.data_parallel(self.fc1, input, range(self.ngpu))\n",
    "            fc1 = fc1.view(-1, 768, 1, 1)\n",
    "            tconv2 = nn.parallel.data_parallel(self.tconv2, fc1, range(self.ngpu))\n",
    "            tconv3 = nn.parallel.data_parallel(self.tconv3, tconv2, range(self.ngpu))\n",
    "            tconv4 = nn.parallel.data_parallel(self.tconv4, tconv3, range(self.ngpu))\n",
    "            tconv5 = nn.parallel.data_parallel(self.tconv5, tconv4, range(self.ngpu))\n",
    "            tconv5 = nn.parallel.data_parallel(self.tconv6, tconv5, range(self.ngpu))\n",
    "            output = tconv5\n",
    "        else:\n",
    "            input = input.view(-1, self.nz)\n",
    "            fc1 = self.fc1(input)\n",
    "            fc1 = fc1.view(-1, 768, 1, 1)\n",
    "            tconv2 = self.tconv2(fc1)\n",
    "            tconv3 = self.tconv3(tconv2)\n",
    "            tconv4 = self.tconv4(tconv3)\n",
    "            tconv5 = self.tconv5(tconv4)\n",
    "            tconv5 = self.tconv6(tconv5)\n",
    "            output = tconv5\n",
    "        return output\n",
    "\n",
    "\n",
    "class _netD(nn.Module):\n",
    "    def __init__(self, ngpu, num_classes=10):\n",
    "        super(_netD, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "\n",
    "        # Convolution 1\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.5, inplace=False),\n",
    "        )\n",
    "        # Convolution 2\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, 3, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.5, inplace=False),\n",
    "        )\n",
    "        # Convolution 3\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.5, inplace=False),\n",
    "        )\n",
    "        # Convolution 4\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.5, inplace=False),\n",
    "        )\n",
    "        # Convolution 5\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 3, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.5, inplace=False),\n",
    "        )\n",
    "        # Convolution 6\n",
    "        self.conv6 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, 3, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.5, inplace=False),\n",
    "        )\n",
    "        # discriminator fc\n",
    "        self.fc_dis = nn.Linear(13*13*512, 1)\n",
    "        # aux-classifier fc\n",
    "        self.fc_aux = nn.Linear(13*13*512, num_classes)\n",
    "        # softmax and sigmoid\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input):\n",
    "        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 1:\n",
    "            conv1 = nn.parallel.data_parallel(self.conv1, input, range(self.ngpu))\n",
    "            conv2 = nn.parallel.data_parallel(self.conv2, conv1, range(self.ngpu))\n",
    "            conv3 = nn.parallel.data_parallel(self.conv3, conv2, range(self.ngpu))\n",
    "            conv4 = nn.parallel.data_parallel(self.conv4, conv3, range(self.ngpu))\n",
    "            conv5 = nn.parallel.data_parallel(self.conv5, conv4, range(self.ngpu))\n",
    "            conv6 = nn.parallel.data_parallel(self.conv6, conv5, range(self.ngpu))\n",
    "            flat6 = conv6.view(-1, 13*13*512)\n",
    "            fc_dis = nn.parallel.data_parallel(self.fc_dis, flat6, range(self.ngpu))\n",
    "            fc_aux = nn.parallel.data_parallel(self.fc_aux, flat6, range(self.ngpu))\n",
    "        else:\n",
    "            conv1 = self.conv1(input)\n",
    "            conv2 = self.conv2(conv1)\n",
    "            conv3 = self.conv3(conv2)\n",
    "            conv4 = self.conv4(conv3)\n",
    "            conv5 = self.conv5(conv4)\n",
    "            conv6 = self.conv6(conv5)\n",
    "            flat6 = conv6.view(-1, 13*13*512)\n",
    "            fc_dis = self.fc_dis(flat6)\n",
    "            fc_aux = self.fc_aux(flat6)\n",
    "        classes = self.softmax(fc_aux)\n",
    "        realfake = self.sigmoid(fc_dis).view(-1, 1).squeeze(1)\n",
    "        return realfake, classes\n",
    "\n",
    "\n",
    "class _netG_CIFAR10(nn.Module):\n",
    "    def __init__(self, ngpu, nz):\n",
    "        super(_netG_CIFAR10, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.nz = nz\n",
    "\n",
    "        # first linear layer\n",
    "        self.fc1 = nn.Linear(110, 384)\n",
    "        # Transposed Convolution 2\n",
    "        self.tconv2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(384, 192, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        # Transposed Convolution 3\n",
    "        self.tconv3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(192, 96, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(96),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        # Transposed Convolution 4\n",
    "        self.tconv4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(96, 48, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(48),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        # Transposed Convolution 4\n",
    "        self.tconv5 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(48, 3, 4, 2, 1, bias=False),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 1:\n",
    "            input = input.view(-1, self.nz)\n",
    "            fc1 = nn.parallel.data_parallel(self.fc1, input, range(self.ngpu))\n",
    "            fc1 = fc1.view(-1, 384, 1, 1)\n",
    "            tconv2 = nn.parallel.data_parallel(self.tconv2, fc1, range(self.ngpu))\n",
    "            tconv3 = nn.parallel.data_parallel(self.tconv3, tconv2, range(self.ngpu))\n",
    "            tconv4 = nn.parallel.data_parallel(self.tconv4, tconv3, range(self.ngpu))\n",
    "            tconv5 = nn.parallel.data_parallel(self.tconv5, tconv4, range(self.ngpu))\n",
    "            output = tconv5\n",
    "        else:\n",
    "            input = input.view(-1, self.nz)\n",
    "            fc1 = self.fc1(input)\n",
    "            fc1 = fc1.view(-1, 384, 1, 1)\n",
    "            tconv2 = self.tconv2(fc1)\n",
    "            tconv3 = self.tconv3(tconv2)\n",
    "            tconv4 = self.tconv4(tconv3)\n",
    "            tconv5 = self.tconv5(tconv4)\n",
    "            output = tconv5\n",
    "        return output\n",
    "\n",
    "\n",
    "class _netD_CIFAR10(nn.Module):\n",
    "    def __init__(self, ngpu, num_classes=10):\n",
    "        super(_netD_CIFAR10, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "\n",
    "        # Convolution 1\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.5, inplace=False),\n",
    "        )\n",
    "        # Convolution 2\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.5, inplace=False),\n",
    "        )\n",
    "        # Convolution 3\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.5, inplace=False),\n",
    "        )\n",
    "        # Convolution 4\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.5, inplace=False),\n",
    "        )\n",
    "        # Convolution 5\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, 3, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.5, inplace=False),\n",
    "        )\n",
    "        # Convolution 6\n",
    "        self.conv6 = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.5, inplace=False),\n",
    "        )\n",
    "        # discriminator fc\n",
    "        self.fc_dis = nn.Linear(4*4*512, 1)\n",
    "        # aux-classifier fc\n",
    "        self.fc_aux = nn.Linear(4*4*512, num_classes)\n",
    "        # softmax and sigmoid\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input):\n",
    "        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 1:\n",
    "            conv1 = nn.parallel.data_parallel(self.conv1, input, range(self.ngpu))\n",
    "            conv2 = nn.parallel.data_parallel(self.conv2, conv1, range(self.ngpu))\n",
    "            conv3 = nn.parallel.data_parallel(self.conv3, conv2, range(self.ngpu))\n",
    "            conv4 = nn.parallel.data_parallel(self.conv4, conv3, range(self.ngpu))\n",
    "            conv5 = nn.parallel.data_parallel(self.conv5, conv4, range(self.ngpu))\n",
    "            conv6 = nn.parallel.data_parallel(self.conv6, conv5, range(self.ngpu))\n",
    "            flat6 = conv6.view(-1, 4*4*512)\n",
    "            fc_dis = nn.parallel.data_parallel(self.fc_dis, flat6, range(self.ngpu))\n",
    "            fc_aux = nn.parallel.data_parallel(self.fc_aux, flat6, range(self.ngpu))\n",
    "        else:\n",
    "            conv1 = self.conv1(input)\n",
    "            conv2 = self.conv2(conv1)\n",
    "            conv3 = self.conv3(conv2)\n",
    "            conv4 = self.conv4(conv3)\n",
    "            conv5 = self.conv5(conv4)\n",
    "            conv6 = self.conv6(conv5)\n",
    "            flat6 = conv6.view(-1, 4*4*512)\n",
    "            fc_dis = self.fc_dis(flat6)\n",
    "            fc_aux = self.fc_aux(flat6)\n",
    "        classes = self.softmax(fc_aux)\n",
    "        realfake = self.sigmoid(fc_dis).view(-1, 1).squeeze(1)\n",
    "        return realfake, classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'cifar10'\n",
    "dataroot = './root'\n",
    "workers = 32\n",
    "batchSize = 64\n",
    "imageSize = 32\n",
    "nz = 110\n",
    "ngf = 64\n",
    "ndf = 64\n",
    "niter = 25\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "cuda = False\n",
    "ngpu = 1\n",
    "netG = ''\n",
    "netD = ''\n",
    "outf = '.'\n",
    "manualSeed = 1\n",
    "num_classes = 10\n",
    "gpu_id = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the gpu id if using only 1 gpu\n",
    "if ngpu == 1:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'if manualSeed is None:\\n    manualSeed = random.randint(1, 10000)\\nprint(\"Random Seed: \", manualSeed)\\nrandom.seed(manualSeed)\\ntorch.manual_seed(manualSeed)\\nif cuda:\\n    torch.cuda.manual_seed_all(manualSeed)'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''if manualSeed is None:\n",
    "    manualSeed = random.randint(1, 10000)\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed_all(manualSeed)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajaswa-pc/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/transforms/transforms.py:188: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset = dset.CIFAR10(\n",
    "        root=dataroot, download=True,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.Scale(imageSize),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert dataset\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batchSize,\n",
    "                                         shuffle=True, num_workers=int(workers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some hyper parameters\n",
    "ngpu = int(ngpu)\n",
    "nz = int(nz)\n",
    "ngf = int(ngf)\n",
    "ndf = int(ndf)\n",
    "num_classes = int(num_classes)\n",
    "nc = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_netD_CIFAR10(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (2): Dropout(p=0.5)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (3): Dropout(p=0.5)\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (3): Dropout(p=0.5)\n",
       "  )\n",
       "  (conv4): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (3): Dropout(p=0.5)\n",
       "  )\n",
       "  (conv5): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (3): Dropout(p=0.5)\n",
       "  )\n",
       "  (conv6): Sequential(\n",
       "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (3): Dropout(p=0.5)\n",
       "  )\n",
       "  (fc_dis): Linear(in_features=8192, out_features=1, bias=True)\n",
       "  (fc_aux): Linear(in_features=8192, out_features=10, bias=True)\n",
       "  (softmax): Softmax()\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netG = _netG_CIFAR10(ngpu, nz)\n",
    "netG.apply(weights_init)\n",
    "\n",
    "netD = _netD_CIFAR10(ngpu, num_classes)\n",
    "netD.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss functions\n",
    "dis_criterion = nn.BCELoss()\n",
    "aux_criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor placeholders\n",
    "input = torch.FloatTensor(batchSize, 3, imageSize, imageSize)\n",
    "noise = torch.FloatTensor(batchSize, nz, 1, 1)\n",
    "eval_noise = torch.FloatTensor(batchSize, nz, 1, 1).normal_(0, 1)\n",
    "dis_label = torch.FloatTensor(batchSize)\n",
    "aux_label = torch.LongTensor(batchSize)\n",
    "real_label = 1\n",
    "fake_label = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if using cuda\n",
    "if cuda:\n",
    "    netD.cuda()\n",
    "    netG.cuda()\n",
    "    dis_criterion.cuda()\n",
    "    aux_criterion.cuda()\n",
    "    input, dis_label, aux_label = input.cuda(), dis_label.cuda(), aux_label.cuda()\n",
    "    noise, eval_noise = noise.cuda(), eval_noise.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0000]],\n",
       "\n",
       "         [[ 0.0000]],\n",
       "\n",
       "         [[ 1.0000]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.6634]],\n",
       "\n",
       "         [[-1.6777]],\n",
       "\n",
       "         [[-0.7255]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000]],\n",
       "\n",
       "         [[ 0.0000]],\n",
       "\n",
       "         [[ 0.0000]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.9469]],\n",
       "\n",
       "         [[-1.3862]],\n",
       "\n",
       "         [[-0.0978]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000]],\n",
       "\n",
       "         [[ 0.0000]],\n",
       "\n",
       "         [[ 0.0000]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.2930]],\n",
       "\n",
       "         [[-1.0074]],\n",
       "\n",
       "         [[ 0.3345]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[ 0.0000]],\n",
       "\n",
       "         [[ 0.0000]],\n",
       "\n",
       "         [[ 0.0000]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0825]],\n",
       "\n",
       "         [[-0.8512]],\n",
       "\n",
       "         [[ 1.4252]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000]],\n",
       "\n",
       "         [[ 0.0000]],\n",
       "\n",
       "         [[ 0.0000]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.5785]],\n",
       "\n",
       "         [[ 0.3623]],\n",
       "\n",
       "         [[ 0.8861]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0000]],\n",
       "\n",
       "         [[ 0.0000]],\n",
       "\n",
       "         [[ 0.0000]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.4978]],\n",
       "\n",
       "         [[ 0.8109]],\n",
       "\n",
       "         [[-0.2708]]]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define variables\n",
    "input = Variable(input)\n",
    "noise = Variable(noise)\n",
    "eval_noise = Variable(eval_noise)\n",
    "dis_label = Variable(dis_label)\n",
    "aux_label = Variable(aux_label)\n",
    "# noise for evaluation\n",
    "eval_noise_ = np.random.normal(0, 1, (batchSize, nz))\n",
    "eval_label = np.random.randint(0, num_classes, batchSize)\n",
    "eval_onehot = np.zeros((batchSize, num_classes))\n",
    "eval_onehot[np.arange(batchSize), eval_label] = 1\n",
    "eval_noise_[np.arange(batchSize), :num_classes] = eval_onehot[np.arange(batchSize)]\n",
    "eval_noise_ = (torch.from_numpy(eval_noise_))\n",
    "eval_noise.data.copy_(eval_noise_.view(batchSize, nz, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup optimizer\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_loss_D = 0.0\n",
    "avg_loss_G = 0.0\n",
    "avg_loss_A = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rajaswa-pc/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:272: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/rajaswa-pc/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:66: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/home/rajaswa-pc/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:67: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/home/rajaswa-pc/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:75: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/25][0/782] Loss_D: 1.3390 (1.3390) Loss_G: 0.7419 (0.7419) D(x): 0.4662 D(G(z)): 0.5029 / 0.4509 Acc: 10.9375 (10.9375)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[0/25][1/782] Loss_D: 1.2310 (1.2850) Loss_G: 0.6641 (0.7030) D(x): 0.4897 D(G(z)): 0.4767 / 0.4794 Acc: 6.2500 (8.5938)\n",
      "[0/25][2/782] Loss_D: 1.1786 (1.2495) Loss_G: 0.6075 (0.6712) D(x): 0.4977 D(G(z)): 0.4679 / 0.4916 Acc: 4.6875 (7.2917)\n",
      "[0/25][3/782] Loss_D: 1.2894 (1.2595) Loss_G: 0.6547 (0.6671) D(x): 0.4730 D(G(z)): 0.4882 / 0.4841 Acc: 12.5000 (8.5938)\n",
      "[0/25][4/782] Loss_D: 1.2981 (1.2672) Loss_G: 0.6809 (0.6698) D(x): 0.4767 D(G(z)): 0.4964 / 0.4734 Acc: 10.9375 (9.0625)\n",
      "[0/25][5/782] Loss_D: 1.1291 (1.2442) Loss_G: 0.7082 (0.6762) D(x): 0.5121 D(G(z)): 0.4445 / 0.4677 Acc: 9.3750 (9.1146)\n",
      "[0/25][6/782] Loss_D: 1.1675 (1.2332) Loss_G: 0.7148 (0.6817) D(x): 0.5188 D(G(z)): 0.4812 / 0.4654 Acc: 14.0625 (9.8214)\n",
      "[0/25][7/782] Loss_D: 1.0803 (1.2141) Loss_G: 0.7224 (0.6868) D(x): 0.5469 D(G(z)): 0.4548 / 0.4521 Acc: 7.8125 (9.5703)\n",
      "[0/25][8/782] Loss_D: 1.1829 (1.2106) Loss_G: 0.6148 (0.6788) D(x): 0.4745 D(G(z)): 0.4412 / 0.4961 Acc: 4.6875 (9.0278)\n",
      "[0/25][9/782] Loss_D: 1.1135 (1.2009) Loss_G: 0.6263 (0.6736) D(x): 0.5288 D(G(z)): 0.4360 / 0.5103 Acc: 9.3750 (9.0625)\n",
      "[0/25][10/782] Loss_D: 1.2011 (1.2009) Loss_G: 0.7815 (0.6834) D(x): 0.5332 D(G(z)): 0.5016 / 0.4358 Acc: 9.3750 (9.0909)\n",
      "[0/25][11/782] Loss_D: 1.1331 (1.1953) Loss_G: 0.7559 (0.6894) D(x): 0.5515 D(G(z)): 0.4818 / 0.4376 Acc: 4.6875 (8.7240)\n",
      "[0/25][12/782] Loss_D: 1.2083 (1.1963) Loss_G: 0.8440 (0.7013) D(x): 0.5335 D(G(z)): 0.4995 / 0.4088 Acc: 12.5000 (9.0144)\n",
      "[0/25][13/782] Loss_D: 1.1502 (1.1930) Loss_G: 0.7978 (0.7082) D(x): 0.4866 D(G(z)): 0.4216 / 0.4282 Acc: 9.3750 (9.0402)\n",
      "[0/25][14/782] Loss_D: 1.2018 (1.1936) Loss_G: 0.7594 (0.7116) D(x): 0.4871 D(G(z)): 0.4474 / 0.4622 Acc: 9.3750 (9.0625)\n",
      "[0/25][15/782] Loss_D: 1.2305 (1.1959) Loss_G: 0.7465 (0.7138) D(x): 0.5164 D(G(z)): 0.4994 / 0.4475 Acc: 7.8125 (8.9844)\n",
      "[0/25][16/782] Loss_D: 1.1975 (1.1960) Loss_G: 0.7744 (0.7174) D(x): 0.5083 D(G(z)): 0.4787 / 0.4314 Acc: 6.2500 (8.8235)\n",
      "[0/25][17/782] Loss_D: 1.1971 (1.1960) Loss_G: 0.9049 (0.7278) D(x): 0.5158 D(G(z)): 0.4724 / 0.3974 Acc: 12.5000 (9.0278)\n",
      "[0/25][18/782] Loss_D: 1.2431 (1.1985) Loss_G: 0.8107 (0.7321) D(x): 0.4589 D(G(z)): 0.4311 / 0.4331 Acc: 12.5000 (9.2105)\n",
      "[0/25][19/782] Loss_D: 1.2160 (1.1994) Loss_G: 0.6901 (0.7300) D(x): 0.4921 D(G(z)): 0.4622 / 0.4809 Acc: 9.3750 (9.2188)\n",
      "[0/25][20/782] Loss_D: 1.1562 (1.1973) Loss_G: 0.7806 (0.7324) D(x): 0.5179 D(G(z)): 0.4493 / 0.4430 Acc: 9.3750 (9.2262)\n",
      "[0/25][21/782] Loss_D: 1.2237 (1.1985) Loss_G: 0.8303 (0.7369) D(x): 0.5178 D(G(z)): 0.4971 / 0.4170 Acc: 10.9375 (9.3040)\n",
      "[0/25][22/782] Loss_D: 1.2020 (1.1987) Loss_G: 0.8414 (0.7414) D(x): 0.5276 D(G(z)): 0.4905 / 0.4278 Acc: 7.8125 (9.2391)\n",
      "[0/25][23/782] Loss_D: 1.0789 (1.1937) Loss_G: 0.8443 (0.7457) D(x): 0.4977 D(G(z)): 0.4118 / 0.4091 Acc: 17.1875 (9.5703)\n",
      "[0/25][24/782] Loss_D: 1.1323 (1.1912) Loss_G: 0.7469 (0.7458) D(x): 0.4859 D(G(z)): 0.4080 / 0.4457 Acc: 6.2500 (9.4375)\n",
      "[0/25][25/782] Loss_D: 1.0215 (1.1847) Loss_G: 0.7963 (0.7477) D(x): 0.5519 D(G(z)): 0.4285 / 0.4334 Acc: 7.8125 (9.3750)\n",
      "[0/25][26/782] Loss_D: 0.9171 (1.1748) Loss_G: 0.8325 (0.7509) D(x): 0.5894 D(G(z)): 0.4376 / 0.4050 Acc: 7.8125 (9.3171)\n",
      "[0/25][27/782] Loss_D: 1.0305 (1.1696) Loss_G: 0.8209 (0.7534) D(x): 0.5344 D(G(z)): 0.4320 / 0.4217 Acc: 15.6250 (9.5424)\n",
      "[0/25][28/782] Loss_D: 1.1285 (1.1682) Loss_G: 0.8790 (0.7577) D(x): 0.5296 D(G(z)): 0.4705 / 0.3907 Acc: 9.3750 (9.5366)\n",
      "[0/25][29/782] Loss_D: 1.0096 (1.1629) Loss_G: 0.7417 (0.7572) D(x): 0.5382 D(G(z)): 0.3960 / 0.4621 Acc: 4.6875 (9.3750)\n",
      "[0/25][30/782] Loss_D: 0.9921 (1.1574) Loss_G: 0.8141 (0.7590) D(x): 0.5699 D(G(z)): 0.4416 / 0.4332 Acc: 14.0625 (9.5262)\n",
      "[0/25][31/782] Loss_D: 1.0736 (1.1548) Loss_G: 0.8589 (0.7621) D(x): 0.5546 D(G(z)): 0.4475 / 0.4149 Acc: 12.5000 (9.6191)\n",
      "[0/25][32/782] Loss_D: 1.1322 (1.1541) Loss_G: 0.8109 (0.7636) D(x): 0.4938 D(G(z)): 0.4097 / 0.4357 Acc: 4.6875 (9.4697)\n",
      "[0/25][33/782] Loss_D: 1.2034 (1.1556) Loss_G: 0.7947 (0.7645) D(x): 0.5238 D(G(z)): 0.4713 / 0.4328 Acc: 6.2500 (9.3750)\n",
      "[0/25][34/782] Loss_D: 1.0985 (1.1539) Loss_G: 0.8252 (0.7662) D(x): 0.5486 D(G(z)): 0.4599 / 0.4211 Acc: 7.8125 (9.3304)\n",
      "[0/25][35/782] Loss_D: 1.1214 (1.1530) Loss_G: 0.8752 (0.7693) D(x): 0.5241 D(G(z)): 0.4428 / 0.4164 Acc: 9.3750 (9.3316)\n",
      "[0/25][36/782] Loss_D: 1.1390 (1.1527) Loss_G: 0.7635 (0.7691) D(x): 0.5216 D(G(z)): 0.4574 / 0.4527 Acc: 12.5000 (9.4172)\n",
      "[0/25][37/782] Loss_D: 1.1020 (1.1513) Loss_G: 0.8057 (0.7701) D(x): 0.5445 D(G(z)): 0.4622 / 0.4371 Acc: 12.5000 (9.4984)\n",
      "[0/25][38/782] Loss_D: 1.1710 (1.1518) Loss_G: 0.7684 (0.7700) D(x): 0.4832 D(G(z)): 0.4360 / 0.4437 Acc: 9.3750 (9.4952)\n",
      "[0/25][39/782] Loss_D: 1.2489 (1.1543) Loss_G: 0.8442 (0.7719) D(x): 0.5291 D(G(z)): 0.5078 / 0.4233 Acc: 10.9375 (9.5312)\n",
      "[0/25][40/782] Loss_D: 1.2375 (1.1563) Loss_G: 0.8127 (0.7729) D(x): 0.4860 D(G(z)): 0.4445 / 0.4419 Acc: 9.3750 (9.5274)\n",
      "[0/25][41/782] Loss_D: 1.2776 (1.1592) Loss_G: 0.9020 (0.7760) D(x): 0.4843 D(G(z)): 0.4581 / 0.4142 Acc: 15.6250 (9.6726)\n",
      "[0/25][42/782] Loss_D: 1.1972 (1.1601) Loss_G: 0.8465 (0.7776) D(x): 0.5106 D(G(z)): 0.4907 / 0.4133 Acc: 14.0625 (9.7747)\n",
      "[0/25][43/782] Loss_D: 1.1420 (1.1597) Loss_G: 0.9328 (0.7811) D(x): 0.4832 D(G(z)): 0.4120 / 0.3980 Acc: 15.6250 (9.9077)\n",
      "[0/25][44/782] Loss_D: 1.1287 (1.1590) Loss_G: 0.8313 (0.7822) D(x): 0.4968 D(G(z)): 0.4521 / 0.4074 Acc: 17.1875 (10.0694)\n",
      "[0/25][45/782] Loss_D: 1.1139 (1.1580) Loss_G: 0.9253 (0.7853) D(x): 0.5028 D(G(z)): 0.4393 / 0.3847 Acc: 12.5000 (10.1223)\n",
      "[0/25][46/782] Loss_D: 1.1347 (1.1575) Loss_G: 0.9813 (0.7895) D(x): 0.5148 D(G(z)): 0.4444 / 0.3746 Acc: 15.6250 (10.2394)\n",
      "[0/25][47/782] Loss_D: 1.0676 (1.1556) Loss_G: 1.0190 (0.7943) D(x): 0.5034 D(G(z)): 0.3996 / 0.3609 Acc: 21.8750 (10.4818)\n",
      "[0/25][48/782] Loss_D: 0.9653 (1.1517) Loss_G: 0.9721 (0.7979) D(x): 0.5521 D(G(z)): 0.3930 / 0.3585 Acc: 9.3750 (10.4592)\n",
      "[0/25][49/782] Loss_D: 1.0005 (1.1487) Loss_G: 0.8882 (0.7997) D(x): 0.5447 D(G(z)): 0.4055 / 0.4144 Acc: 20.3125 (10.6562)\n",
      "[0/25][50/782] Loss_D: 1.1530 (1.1488) Loss_G: 0.9884 (0.8034) D(x): 0.5451 D(G(z)): 0.4798 / 0.3708 Acc: 17.1875 (10.7843)\n",
      "[0/25][51/782] Loss_D: 0.9398 (1.1448) Loss_G: 0.9512 (0.8063) D(x): 0.5763 D(G(z)): 0.4431 / 0.3833 Acc: 23.4375 (11.0276)\n",
      "[0/25][52/782] Loss_D: 1.0647 (1.1433) Loss_G: 0.9229 (0.8085) D(x): 0.4965 D(G(z)): 0.3940 / 0.3946 Acc: 17.1875 (11.1439)\n",
      "[0/25][53/782] Loss_D: 1.0288 (1.1411) Loss_G: 0.9744 (0.8115) D(x): 0.5433 D(G(z)): 0.4228 / 0.3747 Acc: 15.6250 (11.2269)\n",
      "[0/25][54/782] Loss_D: 1.0353 (1.1392) Loss_G: 0.8500 (0.8122) D(x): 0.5139 D(G(z)): 0.4268 / 0.4067 Acc: 21.8750 (11.4205)\n",
      "[0/25][55/782] Loss_D: 1.0353 (1.1374) Loss_G: 0.8731 (0.8133) D(x): 0.5143 D(G(z)): 0.4047 / 0.3759 Acc: 10.9375 (11.4118)\n",
      "[0/25][56/782] Loss_D: 1.0366 (1.1356) Loss_G: 0.8304 (0.8136) D(x): 0.5331 D(G(z)): 0.4149 / 0.4236 Acc: 12.5000 (11.4309)\n",
      "[0/25][57/782] Loss_D: 0.9819 (1.1329) Loss_G: 0.8194 (0.8137) D(x): 0.5192 D(G(z)): 0.3815 / 0.3968 Acc: 7.8125 (11.3685)\n",
      "[0/25][58/782] Loss_D: 0.9615 (1.1300) Loss_G: 1.1284 (0.8191) D(x): 0.6053 D(G(z)): 0.4598 / 0.3437 Acc: 15.6250 (11.4407)\n",
      "[0/25][59/782] Loss_D: 0.9281 (1.1267) Loss_G: 1.0713 (0.8233) D(x): 0.5644 D(G(z)): 0.3948 / 0.3453 Acc: 14.0625 (11.4844)\n",
      "[0/25][60/782] Loss_D: 1.0563 (1.1255) Loss_G: 1.0903 (0.8276) D(x): 0.5003 D(G(z)): 0.3449 / 0.3418 Acc: 6.2500 (11.3986)\n",
      "[0/25][61/782] Loss_D: 1.0680 (1.1246) Loss_G: 0.9605 (0.8298) D(x): 0.4924 D(G(z)): 0.3730 / 0.3786 Acc: 20.3125 (11.5423)\n",
      "[0/25][62/782] Loss_D: 0.9313 (1.1215) Loss_G: 1.2141 (0.8359) D(x): 0.6006 D(G(z)): 0.4369 / 0.3187 Acc: 20.3125 (11.6815)\n",
      "[0/25][63/782] Loss_D: 1.0905 (1.1210) Loss_G: 1.0981 (0.8400) D(x): 0.5231 D(G(z)): 0.4416 / 0.3114 Acc: 12.5000 (11.6943)\n",
      "[0/25][64/782] Loss_D: 0.9412 (1.1183) Loss_G: 1.2520 (0.8463) D(x): 0.5413 D(G(z)): 0.3708 / 0.2954 Acc: 9.3750 (11.6587)\n",
      "[0/25][65/782] Loss_D: 1.0360 (1.1170) Loss_G: 1.1378 (0.8507) D(x): 0.4989 D(G(z)): 0.3548 / 0.3313 Acc: 18.7500 (11.7661)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/25][66/782] Loss_D: 0.8870 (1.1136) Loss_G: 1.2205 (0.8563) D(x): 0.5436 D(G(z)): 0.3492 / 0.3220 Acc: 18.7500 (11.8703)\n",
      "[0/25][67/782] Loss_D: 1.0121 (1.1121) Loss_G: 1.0663 (0.8594) D(x): 0.5396 D(G(z)): 0.3872 / 0.3515 Acc: 14.0625 (11.9026)\n",
      "[0/25][68/782] Loss_D: 1.1275 (1.1123) Loss_G: 0.9963 (0.8613) D(x): 0.5422 D(G(z)): 0.4397 / 0.3834 Acc: 14.0625 (11.9339)\n",
      "[0/25][69/782] Loss_D: 0.8887 (1.1091) Loss_G: 1.3281 (0.8680) D(x): 0.6031 D(G(z)): 0.3820 / 0.2753 Acc: 14.0625 (11.9643)\n",
      "[0/25][70/782] Loss_D: 0.8533 (1.1055) Loss_G: 1.4325 (0.8760) D(x): 0.5946 D(G(z)): 0.3894 / 0.2620 Acc: 15.6250 (12.0158)\n",
      "[0/25][71/782] Loss_D: 0.9417 (1.1033) Loss_G: 1.1380 (0.8796) D(x): 0.5690 D(G(z)): 0.3938 / 0.3185 Acc: 17.1875 (12.0877)\n",
      "[0/25][72/782] Loss_D: 0.9341 (1.1009) Loss_G: 1.2594 (0.8848) D(x): 0.5681 D(G(z)): 0.4056 / 0.2988 Acc: 12.5000 (12.0933)\n",
      "[0/25][73/782] Loss_D: 0.9043 (1.0983) Loss_G: 1.1942 (0.8890) D(x): 0.5550 D(G(z)): 0.3812 / 0.3059 Acc: 12.5000 (12.0988)\n",
      "[0/25][74/782] Loss_D: 1.0270 (1.0973) Loss_G: 1.3297 (0.8949) D(x): 0.5511 D(G(z)): 0.4039 / 0.2815 Acc: 12.5000 (12.1042)\n",
      "[0/25][75/782] Loss_D: 0.9784 (1.0958) Loss_G: 1.2788 (0.8999) D(x): 0.5472 D(G(z)): 0.3788 / 0.2828 Acc: 12.5000 (12.1094)\n",
      "[0/25][76/782] Loss_D: 0.8498 (1.0926) Loss_G: 1.3594 (0.9059) D(x): 0.5392 D(G(z)): 0.3459 / 0.2587 Acc: 20.3125 (12.2159)\n",
      "[0/25][77/782] Loss_D: 0.9039 (1.0901) Loss_G: 1.4238 (0.9125) D(x): 0.4998 D(G(z)): 0.2883 / 0.2633 Acc: 14.0625 (12.2396)\n",
      "[0/25][78/782] Loss_D: 0.7037 (1.0853) Loss_G: 1.3843 (0.9185) D(x): 0.5715 D(G(z)): 0.2785 / 0.2596 Acc: 14.0625 (12.2627)\n",
      "[0/25][79/782] Loss_D: 0.6171 (1.0794) Loss_G: 1.3492 (0.9239) D(x): 0.5969 D(G(z)): 0.2415 / 0.2778 Acc: 12.5000 (12.2656)\n",
      "[0/25][80/782] Loss_D: 0.5721 (1.0731) Loss_G: 1.4728 (0.9306) D(x): 0.6686 D(G(z)): 0.2566 / 0.2520 Acc: 12.5000 (12.2685)\n",
      "[0/25][81/782] Loss_D: 0.5941 (1.0673) Loss_G: 1.5772 (0.9385) D(x): 0.6303 D(G(z)): 0.2367 / 0.2188 Acc: 7.8125 (12.2142)\n",
      "[0/25][82/782] Loss_D: 0.4853 (1.0603) Loss_G: 1.7126 (0.9479) D(x): 0.7094 D(G(z)): 0.2899 / 0.2000 Acc: 18.7500 (12.2929)\n",
      "[0/25][83/782] Loss_D: 0.4423 (1.0529) Loss_G: 1.8275 (0.9583) D(x): 0.7177 D(G(z)): 0.2379 / 0.1825 Acc: 10.9375 (12.2768)\n",
      "[0/25][84/782] Loss_D: 0.4609 (1.0460) Loss_G: 2.0201 (0.9708) D(x): 0.7094 D(G(z)): 0.2158 / 0.1573 Acc: 10.9375 (12.2610)\n",
      "[0/25][85/782] Loss_D: 0.4233 (1.0387) Loss_G: 1.8121 (0.9806) D(x): 0.7547 D(G(z)): 0.2715 / 0.1879 Acc: 15.6250 (12.3001)\n",
      "[0/25][86/782] Loss_D: 0.5351 (1.0329) Loss_G: 1.5731 (0.9874) D(x): 0.6533 D(G(z)): 0.2394 / 0.2435 Acc: 21.8750 (12.4102)\n",
      "[0/25][87/782] Loss_D: 0.7104 (1.0293) Loss_G: 1.6296 (0.9947) D(x): 0.6718 D(G(z)): 0.3813 / 0.2304 Acc: 20.3125 (12.5000)\n",
      "[0/25][88/782] Loss_D: 0.7753 (1.0264) Loss_G: 1.9256 (1.0052) D(x): 0.6588 D(G(z)): 0.3692 / 0.1772 Acc: 9.3750 (12.4649)\n",
      "[0/25][89/782] Loss_D: 0.7966 (1.0239) Loss_G: 1.9677 (1.0159) D(x): 0.5557 D(G(z)): 0.3100 / 0.1571 Acc: 25.0000 (12.6042)\n",
      "[0/25][90/782] Loss_D: 0.9162 (1.0227) Loss_G: 1.8435 (1.0250) D(x): 0.5132 D(G(z)): 0.2641 / 0.1780 Acc: 10.9375 (12.5859)\n",
      "[0/25][91/782] Loss_D: 0.5170 (1.0172) Loss_G: 1.8447 (1.0339) D(x): 0.6140 D(G(z)): 0.2194 / 0.1702 Acc: 21.8750 (12.6868)\n",
      "[0/25][92/782] Loss_D: 0.5475 (1.0121) Loss_G: 1.7267 (1.0413) D(x): 0.5833 D(G(z)): 0.2075 / 0.1950 Acc: 25.0000 (12.8192)\n",
      "[0/25][93/782] Loss_D: 0.4954 (1.0066) Loss_G: 1.8371 (1.0498) D(x): 0.6926 D(G(z)): 0.2428 / 0.1729 Acc: 12.5000 (12.8158)\n",
      "[0/25][94/782] Loss_D: 0.3800 (1.0000) Loss_G: 2.0774 (1.0606) D(x): 0.7145 D(G(z)): 0.2040 / 0.1512 Acc: 20.3125 (12.8947)\n",
      "[0/25][95/782] Loss_D: 0.4267 (0.9941) Loss_G: 1.8841 (1.0692) D(x): 0.7140 D(G(z)): 0.2477 / 0.1746 Acc: 17.1875 (12.9395)\n",
      "[0/25][96/782] Loss_D: 0.6303 (0.9903) Loss_G: 1.8846 (1.0776) D(x): 0.7340 D(G(z)): 0.3417 / 0.2085 Acc: 14.0625 (12.9510)\n",
      "[0/25][97/782] Loss_D: 0.9470 (0.9899) Loss_G: 1.8323 (1.0853) D(x): 0.7169 D(G(z)): 0.5025 / 0.2032 Acc: 17.1875 (12.9943)\n",
      "[0/25][98/782] Loss_D: 1.2726 (0.9927) Loss_G: 2.2194 (1.0967) D(x): 0.5982 D(G(z)): 0.4824 / 0.1481 Acc: 10.9375 (12.9735)\n",
      "[0/25][99/782] Loss_D: 0.8663 (0.9915) Loss_G: 2.2749 (1.1085) D(x): 0.5672 D(G(z)): 0.2766 / 0.1443 Acc: 21.8750 (13.0625)\n",
      "[0/25][100/782] Loss_D: 0.6931 (0.9885) Loss_G: 2.3947 (1.1213) D(x): 0.5761 D(G(z)): 0.1804 / 0.1224 Acc: 12.5000 (13.0569)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[0/25][101/782] Loss_D: 0.5551 (0.9843) Loss_G: 2.1103 (1.1310) D(x): 0.6276 D(G(z)): 0.1701 / 0.1652 Acc: 17.1875 (13.0974)\n",
      "[0/25][102/782] Loss_D: 0.4608 (0.9792) Loss_G: 1.5498 (1.1350) D(x): 0.7145 D(G(z)): 0.2885 / 0.2383 Acc: 18.7500 (13.1523)\n",
      "[0/25][103/782] Loss_D: 0.4692 (0.9743) Loss_G: 2.0159 (1.1435) D(x): 0.7712 D(G(z)): 0.3200 / 0.1887 Acc: 10.9375 (13.1310)\n",
      "[0/25][104/782] Loss_D: 0.5720 (0.9704) Loss_G: 1.7706 (1.1495) D(x): 0.7053 D(G(z)): 0.3587 / 0.2038 Acc: 20.3125 (13.1994)\n",
      "[0/25][105/782] Loss_D: 0.8379 (0.9692) Loss_G: 1.9783 (1.1573) D(x): 0.6274 D(G(z)): 0.3679 / 0.1704 Acc: 10.9375 (13.1781)\n",
      "[0/25][106/782] Loss_D: 0.5995 (0.9657) Loss_G: 2.0877 (1.1660) D(x): 0.6145 D(G(z)): 0.2573 / 0.1621 Acc: 20.3125 (13.2447)\n",
      "[0/25][107/782] Loss_D: 0.6657 (0.9630) Loss_G: 1.7773 (1.1716) D(x): 0.6488 D(G(z)): 0.2769 / 0.2059 Acc: 12.5000 (13.2378)\n",
      "[0/25][108/782] Loss_D: 0.8711 (0.9621) Loss_G: 1.5432 (1.1750) D(x): 0.6327 D(G(z)): 0.3658 / 0.2557 Acc: 20.3125 (13.3028)\n",
      "[0/25][109/782] Loss_D: 0.8270 (0.9609) Loss_G: 1.6008 (1.1789) D(x): 0.6204 D(G(z)): 0.3476 / 0.2382 Acc: 14.0625 (13.3097)\n",
      "[0/25][110/782] Loss_D: 0.7477 (0.9590) Loss_G: 1.4486 (1.1813) D(x): 0.5965 D(G(z)): 0.3445 / 0.2643 Acc: 20.3125 (13.3727)\n",
      "[0/25][111/782] Loss_D: 0.8309 (0.9578) Loss_G: 1.5312 (1.1845) D(x): 0.6061 D(G(z)): 0.3389 / 0.2781 Acc: 20.3125 (13.4347)\n",
      "[0/25][112/782] Loss_D: 0.8261 (0.9567) Loss_G: 1.6317 (1.1884) D(x): 0.6002 D(G(z)): 0.3523 / 0.2497 Acc: 17.1875 (13.4679)\n",
      "[0/25][113/782] Loss_D: 1.2626 (0.9593) Loss_G: 1.1515 (1.1881) D(x): 0.5364 D(G(z)): 0.4337 / 0.3784 Acc: 12.5000 (13.4594)\n",
      "[0/25][114/782] Loss_D: 1.1361 (0.9609) Loss_G: 1.1800 (1.1880) D(x): 0.5862 D(G(z)): 0.4579 / 0.3656 Acc: 20.3125 (13.5190)\n",
      "[0/25][115/782] Loss_D: 1.0907 (0.9620) Loss_G: 1.3020 (1.1890) D(x): 0.5919 D(G(z)): 0.4411 / 0.3237 Acc: 9.3750 (13.4833)\n",
      "[0/25][116/782] Loss_D: 1.0608 (0.9628) Loss_G: 1.1598 (1.1888) D(x): 0.5886 D(G(z)): 0.4028 / 0.3589 Acc: 15.6250 (13.5016)\n",
      "[0/25][117/782] Loss_D: 1.2474 (0.9653) Loss_G: 0.9454 (1.1867) D(x): 0.5454 D(G(z)): 0.4928 / 0.4179 Acc: 17.1875 (13.5328)\n",
      "[0/25][118/782] Loss_D: 1.1515 (0.9668) Loss_G: 0.7813 (1.1833) D(x): 0.5669 D(G(z)): 0.4777 / 0.4703 Acc: 17.1875 (13.5636)\n",
      "[0/25][119/782] Loss_D: 1.4114 (0.9705) Loss_G: 0.8448 (1.1805) D(x): 0.5326 D(G(z)): 0.5330 / 0.4589 Acc: 9.3750 (13.5286)\n",
      "[0/25][120/782] Loss_D: 1.0987 (0.9716) Loss_G: 0.9062 (1.1782) D(x): 0.6116 D(G(z)): 0.5031 / 0.4166 Acc: 12.5000 (13.5201)\n",
      "[0/25][121/782] Loss_D: 1.2133 (0.9736) Loss_G: 0.9582 (1.1764) D(x): 0.5812 D(G(z)): 0.5332 / 0.4384 Acc: 18.7500 (13.5630)\n",
      "[0/25][122/782] Loss_D: 1.1347 (0.9749) Loss_G: 0.9392 (1.1745) D(x): 0.5360 D(G(z)): 0.4383 / 0.4287 Acc: 17.1875 (13.5925)\n",
      "[0/25][123/782] Loss_D: 1.3150 (0.9776) Loss_G: 0.7728 (1.1712) D(x): 0.5219 D(G(z)): 0.5074 / 0.4660 Acc: 12.5000 (13.5837)\n",
      "[0/25][124/782] Loss_D: 1.2419 (0.9797) Loss_G: 0.7254 (1.1677) D(x): 0.4890 D(G(z)): 0.4892 / 0.4602 Acc: 9.3750 (13.5500)\n",
      "[0/25][125/782] Loss_D: 1.0568 (0.9803) Loss_G: 1.0717 (1.1669) D(x): 0.5694 D(G(z)): 0.4344 / 0.3975 Acc: 23.4375 (13.6285)\n",
      "[0/25][126/782] Loss_D: 1.1266 (0.9815) Loss_G: 0.9326 (1.1651) D(x): 0.5277 D(G(z)): 0.3925 / 0.3980 Acc: 12.5000 (13.6196)\n",
      "[0/25][127/782] Loss_D: 1.1183 (0.9826) Loss_G: 0.7799 (1.1621) D(x): 0.6319 D(G(z)): 0.5037 / 0.4610 Acc: 18.7500 (13.6597)\n",
      "[0/25][128/782] Loss_D: 0.8757 (0.9817) Loss_G: 0.8973 (1.1600) D(x): 0.6139 D(G(z)): 0.4508 / 0.3957 Acc: 18.7500 (13.6991)\n",
      "[0/25][129/782] Loss_D: 1.2059 (0.9835) Loss_G: 0.8114 (1.1573) D(x): 0.5645 D(G(z)): 0.4594 / 0.4674 Acc: 9.3750 (13.6659)\n",
      "[0/25][130/782] Loss_D: 1.2648 (0.9856) Loss_G: 0.8819 (1.1552) D(x): 0.5810 D(G(z)): 0.4868 / 0.4234 Acc: 14.0625 (13.6689)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/25][131/782] Loss_D: 1.1694 (0.9870) Loss_G: 0.8168 (1.1527) D(x): 0.6284 D(G(z)): 0.5363 / 0.4504 Acc: 14.0625 (13.6719)\n",
      "[0/25][132/782] Loss_D: 1.5805 (0.9915) Loss_G: 0.6307 (1.1487) D(x): 0.5134 D(G(z)): 0.5175 / 0.5073 Acc: 12.5000 (13.6631)\n",
      "[0/25][133/782] Loss_D: 1.3908 (0.9944) Loss_G: 0.6050 (1.1447) D(x): 0.5055 D(G(z)): 0.5293 / 0.5217 Acc: 23.4375 (13.7360)\n",
      "[0/25][134/782] Loss_D: 1.2744 (0.9965) Loss_G: 0.6107 (1.1407) D(x): 0.5651 D(G(z)): 0.5439 / 0.4959 Acc: 17.1875 (13.7616)\n",
      "[0/25][135/782] Loss_D: 1.1338 (0.9975) Loss_G: 0.8139 (1.1383) D(x): 0.6586 D(G(z)): 0.5541 / 0.4426 Acc: 21.8750 (13.8212)\n",
      "[0/25][136/782] Loss_D: 1.2571 (0.9994) Loss_G: 0.6298 (1.1346) D(x): 0.5130 D(G(z)): 0.5127 / 0.4959 Acc: 21.8750 (13.8800)\n",
      "[0/25][137/782] Loss_D: 1.2818 (1.0015) Loss_G: 0.7060 (1.1315) D(x): 0.5300 D(G(z)): 0.5175 / 0.4863 Acc: 20.3125 (13.9266)\n",
      "[0/25][138/782] Loss_D: 1.0374 (1.0017) Loss_G: 0.7153 (1.1285) D(x): 0.5856 D(G(z)): 0.5019 / 0.4747 Acc: 15.6250 (13.9388)\n",
      "[0/25][139/782] Loss_D: 1.1154 (1.0025) Loss_G: 0.7347 (1.1257) D(x): 0.6604 D(G(z)): 0.5591 / 0.4722 Acc: 14.0625 (13.9397)\n",
      "[0/25][140/782] Loss_D: 1.0112 (1.0026) Loss_G: 0.7892 (1.1233) D(x): 0.5781 D(G(z)): 0.4782 / 0.4558 Acc: 18.7500 (13.9738)\n",
      "[0/25][141/782] Loss_D: 1.0557 (1.0030) Loss_G: 0.7846 (1.1209) D(x): 0.6078 D(G(z)): 0.4863 / 0.4400 Acc: 15.6250 (13.9855)\n",
      "[0/25][142/782] Loss_D: 1.1736 (1.0042) Loss_G: 0.8988 (1.1194) D(x): 0.6021 D(G(z)): 0.5123 / 0.4137 Acc: 12.5000 (13.9751)\n",
      "[0/25][143/782] Loss_D: 0.9926 (1.0041) Loss_G: 0.9015 (1.1179) D(x): 0.5903 D(G(z)): 0.4735 / 0.4282 Acc: 17.1875 (13.9974)\n",
      "[0/25][144/782] Loss_D: 0.9322 (1.0036) Loss_G: 0.8266 (1.1158) D(x): 0.6036 D(G(z)): 0.4736 / 0.4424 Acc: 28.1250 (14.0948)\n",
      "[0/25][145/782] Loss_D: 1.1106 (1.0043) Loss_G: 0.7367 (1.1132) D(x): 0.5725 D(G(z)): 0.5136 / 0.4677 Acc: 23.4375 (14.1588)\n",
      "[0/25][146/782] Loss_D: 1.0674 (1.0048) Loss_G: 0.5939 (1.1097) D(x): 0.5956 D(G(z)): 0.5084 / 0.5132 Acc: 15.6250 (14.1688)\n",
      "[0/25][147/782] Loss_D: 1.2865 (1.0067) Loss_G: 0.6688 (1.1067) D(x): 0.5711 D(G(z)): 0.5568 / 0.5022 Acc: 18.7500 (14.1997)\n",
      "[0/25][148/782] Loss_D: 1.2161 (1.0081) Loss_G: 0.7148 (1.1041) D(x): 0.5604 D(G(z)): 0.5431 / 0.4961 Acc: 21.8750 (14.2513)\n",
      "[0/25][149/782] Loss_D: 1.0637 (1.0084) Loss_G: 0.6913 (1.1014) D(x): 0.5953 D(G(z)): 0.5024 / 0.4796 Acc: 20.3125 (14.2917)\n",
      "[0/25][150/782] Loss_D: 1.0748 (1.0089) Loss_G: 0.7346 (1.0989) D(x): 0.5465 D(G(z)): 0.4548 / 0.4809 Acc: 23.4375 (14.3522)\n",
      "[0/25][151/782] Loss_D: 1.1832 (1.0100) Loss_G: 0.7081 (1.0964) D(x): 0.5854 D(G(z)): 0.5137 / 0.4759 Acc: 9.3750 (14.3195)\n",
      "[0/25][152/782] Loss_D: 1.1459 (1.0109) Loss_G: 0.6619 (1.0935) D(x): 0.5830 D(G(z)): 0.4989 / 0.4844 Acc: 14.0625 (14.3178)\n",
      "[0/25][153/782] Loss_D: 1.1742 (1.0120) Loss_G: 0.6151 (1.0904) D(x): 0.5613 D(G(z)): 0.5096 / 0.5072 Acc: 17.1875 (14.3364)\n",
      "[0/25][154/782] Loss_D: 1.2215 (1.0133) Loss_G: 0.7160 (1.0880) D(x): 0.5761 D(G(z)): 0.5165 / 0.4691 Acc: 12.5000 (14.3246)\n",
      "[0/25][155/782] Loss_D: 1.1447 (1.0142) Loss_G: 0.7568 (1.0859) D(x): 0.5901 D(G(z)): 0.5243 / 0.4536 Acc: 18.7500 (14.3530)\n",
      "[0/25][156/782] Loss_D: 1.0651 (1.0145) Loss_G: 0.8198 (1.0842) D(x): 0.5737 D(G(z)): 0.4764 / 0.4252 Acc: 15.6250 (14.3611)\n",
      "[0/25][157/782] Loss_D: 0.9659 (1.0142) Loss_G: 0.6975 (1.0817) D(x): 0.6077 D(G(z)): 0.4901 / 0.4737 Acc: 28.1250 (14.4482)\n",
      "[0/25][158/782] Loss_D: 1.0650 (1.0145) Loss_G: 0.7562 (1.0797) D(x): 0.5769 D(G(z)): 0.4966 / 0.4469 Acc: 23.4375 (14.5047)\n",
      "[0/25][159/782] Loss_D: 0.9473 (1.0141) Loss_G: 0.5942 (1.0766) D(x): 0.5849 D(G(z)): 0.4867 / 0.4594 Acc: 20.3125 (14.5410)\n",
      "[0/25][160/782] Loss_D: 1.1823 (1.0151) Loss_G: 0.6938 (1.0743) D(x): 0.5961 D(G(z)): 0.5017 / 0.4868 Acc: 12.5000 (14.5283)\n",
      "[0/25][161/782] Loss_D: 1.0771 (1.0155) Loss_G: 0.8081 (1.0726) D(x): 0.5983 D(G(z)): 0.4739 / 0.4505 Acc: 10.9375 (14.5062)\n",
      "[0/25][162/782] Loss_D: 0.9953 (1.0154) Loss_G: 0.8811 (1.0714) D(x): 0.5380 D(G(z)): 0.4069 / 0.3925 Acc: 17.1875 (14.5226)\n",
      "[0/25][163/782] Loss_D: 1.0537 (1.0156) Loss_G: 0.6483 (1.0689) D(x): 0.5577 D(G(z)): 0.5027 / 0.4689 Acc: 21.8750 (14.5675)\n",
      "[0/25][164/782] Loss_D: 1.2093 (1.0168) Loss_G: 0.7476 (1.0669) D(x): 0.5822 D(G(z)): 0.5253 / 0.4644 Acc: 14.0625 (14.5644)\n",
      "[0/25][165/782] Loss_D: 0.9675 (1.0165) Loss_G: 0.8013 (1.0653) D(x): 0.6507 D(G(z)): 0.5069 / 0.4298 Acc: 12.5000 (14.5520)\n",
      "[0/25][166/782] Loss_D: 1.1789 (1.0175) Loss_G: 0.7238 (1.0633) D(x): 0.5775 D(G(z)): 0.4961 / 0.4679 Acc: 12.5000 (14.5397)\n",
      "[0/25][167/782] Loss_D: 0.7893 (1.0161) Loss_G: 0.6940 (1.0611) D(x): 0.6139 D(G(z)): 0.4680 / 0.4510 Acc: 29.6875 (14.6298)\n",
      "[0/25][168/782] Loss_D: 1.0321 (1.0162) Loss_G: 0.7266 (1.0591) D(x): 0.5972 D(G(z)): 0.4881 / 0.4567 Acc: 20.3125 (14.6635)\n",
      "[0/25][169/782] Loss_D: 1.0030 (1.0161) Loss_G: 0.6879 (1.0569) D(x): 0.6291 D(G(z)): 0.4902 / 0.4620 Acc: 10.9375 (14.6415)\n",
      "[0/25][170/782] Loss_D: 1.0023 (1.0160) Loss_G: 0.8111 (1.0555) D(x): 0.6546 D(G(z)): 0.4885 / 0.4453 Acc: 12.5000 (14.6290)\n",
      "[0/25][171/782] Loss_D: 0.9770 (1.0158) Loss_G: 0.8003 (1.0540) D(x): 0.6024 D(G(z)): 0.4626 / 0.4490 Acc: 23.4375 (14.6802)\n",
      "[0/25][172/782] Loss_D: 0.9340 (1.0153) Loss_G: 0.7474 (1.0522) D(x): 0.6147 D(G(z)): 0.4482 / 0.4432 Acc: 12.5000 (14.6676)\n",
      "[0/25][173/782] Loss_D: 0.9347 (1.0149) Loss_G: 0.6936 (1.0502) D(x): 0.6345 D(G(z)): 0.4540 / 0.4867 Acc: 12.5000 (14.6552)\n",
      "[0/25][174/782] Loss_D: 0.9227 (1.0144) Loss_G: 0.7419 (1.0484) D(x): 0.6431 D(G(z)): 0.4895 / 0.4317 Acc: 14.0625 (14.6518)\n",
      "[0/25][175/782] Loss_D: 0.9468 (1.0140) Loss_G: 0.7452 (1.0467) D(x): 0.6310 D(G(z)): 0.4624 / 0.4469 Acc: 14.0625 (14.6484)\n",
      "[0/25][176/782] Loss_D: 0.7834 (1.0127) Loss_G: 0.8688 (1.0457) D(x): 0.6634 D(G(z)): 0.4729 / 0.4239 Acc: 25.0000 (14.7069)\n",
      "[0/25][177/782] Loss_D: 1.0112 (1.0127) Loss_G: 0.8247 (1.0444) D(x): 0.5952 D(G(z)): 0.4479 / 0.4323 Acc: 15.6250 (14.7121)\n",
      "[0/25][178/782] Loss_D: 0.7927 (1.0114) Loss_G: 0.8730 (1.0435) D(x): 0.6654 D(G(z)): 0.4153 / 0.4123 Acc: 7.8125 (14.6735)\n",
      "[0/25][179/782] Loss_D: 0.9238 (1.0109) Loss_G: 0.8657 (1.0425) D(x): 0.6403 D(G(z)): 0.4187 / 0.4319 Acc: 10.9375 (14.6528)\n",
      "[0/25][180/782] Loss_D: 0.9260 (1.0105) Loss_G: 0.8140 (1.0412) D(x): 0.6399 D(G(z)): 0.4438 / 0.4242 Acc: 17.1875 (14.6668)\n",
      "[0/25][181/782] Loss_D: 0.9467 (1.0101) Loss_G: 0.7623 (1.0397) D(x): 0.6200 D(G(z)): 0.4670 / 0.4258 Acc: 14.0625 (14.6635)\n",
      "[0/25][182/782] Loss_D: 1.0603 (1.0104) Loss_G: 0.8622 (1.0387) D(x): 0.6061 D(G(z)): 0.4557 / 0.4353 Acc: 15.6250 (14.6687)\n",
      "[0/25][183/782] Loss_D: 0.8304 (1.0094) Loss_G: 0.9091 (1.0380) D(x): 0.6732 D(G(z)): 0.4724 / 0.4109 Acc: 20.3125 (14.6994)\n",
      "[0/25][184/782] Loss_D: 0.9905 (1.0093) Loss_G: 0.7830 (1.0366) D(x): 0.6067 D(G(z)): 0.4881 / 0.4176 Acc: 15.6250 (14.7044)\n",
      "[0/25][185/782] Loss_D: 1.0313 (1.0094) Loss_G: 0.7428 (1.0351) D(x): 0.5845 D(G(z)): 0.4808 / 0.4507 Acc: 17.1875 (14.7177)\n",
      "[0/25][186/782] Loss_D: 0.9550 (1.0091) Loss_G: 0.7405 (1.0335) D(x): 0.6766 D(G(z)): 0.5149 / 0.4456 Acc: 15.6250 (14.7226)\n",
      "[0/25][187/782] Loss_D: 1.0472 (1.0093) Loss_G: 0.8280 (1.0324) D(x): 0.6337 D(G(z)): 0.4790 / 0.4402 Acc: 14.0625 (14.7191)\n",
      "[0/25][188/782] Loss_D: 0.8258 (1.0084) Loss_G: 0.9892 (1.0322) D(x): 0.6698 D(G(z)): 0.4768 / 0.3881 Acc: 17.1875 (14.7321)\n",
      "[0/25][189/782] Loss_D: 1.1737 (1.0092) Loss_G: 1.0865 (1.0324) D(x): 0.5444 D(G(z)): 0.4582 / 0.3646 Acc: 17.1875 (14.7451)\n",
      "[0/25][190/782] Loss_D: 1.0030 (1.0092) Loss_G: 0.9376 (1.0320) D(x): 0.6052 D(G(z)): 0.4665 / 0.3813 Acc: 12.5000 (14.7333)\n",
      "[0/25][191/782] Loss_D: 0.7147 (1.0077) Loss_G: 0.8438 (1.0310) D(x): 0.6632 D(G(z)): 0.4372 / 0.4115 Acc: 23.4375 (14.7786)\n",
      "[0/25][192/782] Loss_D: 0.9978 (1.0076) Loss_G: 0.8795 (1.0302) D(x): 0.5894 D(G(z)): 0.4340 / 0.3925 Acc: 15.6250 (14.7830)\n",
      "[0/25][193/782] Loss_D: 0.8597 (1.0069) Loss_G: 1.0211 (1.0301) D(x): 0.6313 D(G(z)): 0.4655 / 0.3683 Acc: 25.0000 (14.8357)\n",
      "[0/25][194/782] Loss_D: 1.2478 (1.0081) Loss_G: 0.9109 (1.0295) D(x): 0.5608 D(G(z)): 0.4910 / 0.4060 Acc: 10.9375 (14.8157)\n",
      "[0/25][195/782] Loss_D: 0.9962 (1.0080) Loss_G: 0.9521 (1.0291) D(x): 0.6861 D(G(z)): 0.5057 / 0.4153 Acc: 15.6250 (14.8198)\n",
      "[0/25][196/782] Loss_D: 0.9479 (1.0077) Loss_G: 1.0384 (1.0292) D(x): 0.5978 D(G(z)): 0.4632 / 0.3736 Acc: 21.8750 (14.8556)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/25][197/782] Loss_D: 1.0469 (1.0079) Loss_G: 0.8152 (1.0281) D(x): 0.5740 D(G(z)): 0.4815 / 0.4308 Acc: 15.6250 (14.8595)\n",
      "[0/25][198/782] Loss_D: 1.0983 (1.0084) Loss_G: 0.6866 (1.0264) D(x): 0.5993 D(G(z)): 0.5413 / 0.4698 Acc: 25.0000 (14.9105)\n",
      "[0/25][199/782] Loss_D: 0.9535 (1.0081) Loss_G: 0.7013 (1.0248) D(x): 0.6075 D(G(z)): 0.4790 / 0.4692 Acc: 21.8750 (14.9453)\n",
      "[0/25][200/782] Loss_D: 1.0535 (1.0083) Loss_G: 0.8383 (1.0238) D(x): 0.6270 D(G(z)): 0.5373 / 0.4392 Acc: 20.3125 (14.9720)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[0/25][201/782] Loss_D: 1.0870 (1.0087) Loss_G: 0.8242 (1.0228) D(x): 0.5798 D(G(z)): 0.5251 / 0.4566 Acc: 25.0000 (15.0217)\n",
      "[0/25][202/782] Loss_D: 1.0303 (1.0088) Loss_G: 0.8169 (1.0218) D(x): 0.6015 D(G(z)): 0.4883 / 0.4528 Acc: 21.8750 (15.0554)\n",
      "[0/25][203/782] Loss_D: 0.9627 (1.0086) Loss_G: 0.8991 (1.0212) D(x): 0.6305 D(G(z)): 0.4711 / 0.4301 Acc: 10.9375 (15.0352)\n",
      "[0/25][204/782] Loss_D: 1.0843 (1.0090) Loss_G: 0.8239 (1.0203) D(x): 0.5946 D(G(z)): 0.4595 / 0.4739 Acc: 14.0625 (15.0305)\n",
      "[0/25][205/782] Loss_D: 1.0882 (1.0094) Loss_G: 0.8676 (1.0195) D(x): 0.5918 D(G(z)): 0.4595 / 0.4188 Acc: 10.9375 (15.0106)\n",
      "[0/25][206/782] Loss_D: 1.0634 (1.0096) Loss_G: 0.7098 (1.0180) D(x): 0.5822 D(G(z)): 0.4899 / 0.4575 Acc: 17.1875 (15.0211)\n",
      "[0/25][207/782] Loss_D: 1.0028 (1.0096) Loss_G: 0.7657 (1.0168) D(x): 0.5632 D(G(z)): 0.4599 / 0.4463 Acc: 25.0000 (15.0691)\n",
      "[0/25][208/782] Loss_D: 1.1491 (1.0103) Loss_G: 0.6614 (1.0151) D(x): 0.5367 D(G(z)): 0.4816 / 0.4920 Acc: 15.6250 (15.0718)\n",
      "[0/25][209/782] Loss_D: 1.1354 (1.0109) Loss_G: 0.7423 (1.0138) D(x): 0.6290 D(G(z)): 0.5801 / 0.4420 Acc: 23.4375 (15.1116)\n",
      "[0/25][210/782] Loss_D: 0.9634 (1.0106) Loss_G: 0.8575 (1.0131) D(x): 0.5880 D(G(z)): 0.4928 / 0.4053 Acc: 17.1875 (15.1214)\n",
      "[0/25][211/782] Loss_D: 1.0127 (1.0106) Loss_G: 0.9122 (1.0126) D(x): 0.5618 D(G(z)): 0.4383 / 0.3986 Acc: 14.0625 (15.1165)\n",
      "[0/25][212/782] Loss_D: 1.0723 (1.0109) Loss_G: 0.8696 (1.0119) D(x): 0.5571 D(G(z)): 0.4531 / 0.4133 Acc: 17.1875 (15.1262)\n",
      "[0/25][213/782] Loss_D: 0.9930 (1.0108) Loss_G: 0.7454 (1.0107) D(x): 0.6094 D(G(z)): 0.4685 / 0.4454 Acc: 7.8125 (15.0920)\n",
      "[0/25][214/782] Loss_D: 0.8158 (1.0099) Loss_G: 0.9000 (1.0102) D(x): 0.6699 D(G(z)): 0.4718 / 0.3887 Acc: 17.1875 (15.1017)\n",
      "[0/25][215/782] Loss_D: 0.7843 (1.0089) Loss_G: 0.7879 (1.0091) D(x): 0.6244 D(G(z)): 0.4415 / 0.4346 Acc: 18.7500 (15.1186)\n",
      "[0/25][216/782] Loss_D: 0.8119 (1.0080) Loss_G: 0.9059 (1.0087) D(x): 0.6024 D(G(z)): 0.4374 / 0.3848 Acc: 20.3125 (15.1426)\n",
      "[0/25][217/782] Loss_D: 0.9759 (1.0078) Loss_G: 0.9804 (1.0085) D(x): 0.5737 D(G(z)): 0.4241 / 0.3851 Acc: 17.1875 (15.1519)\n",
      "[0/25][218/782] Loss_D: 0.7601 (1.0067) Loss_G: 0.8432 (1.0078) D(x): 0.6372 D(G(z)): 0.4155 / 0.4141 Acc: 21.8750 (15.1826)\n",
      "[0/25][219/782] Loss_D: 1.0569 (1.0069) Loss_G: 0.8046 (1.0069) D(x): 0.5842 D(G(z)): 0.4444 / 0.4326 Acc: 6.2500 (15.1420)\n",
      "[0/25][220/782] Loss_D: 1.0292 (1.0070) Loss_G: 0.8162 (1.0060) D(x): 0.5953 D(G(z)): 0.5191 / 0.4214 Acc: 18.7500 (15.1584)\n",
      "[0/25][221/782] Loss_D: 0.9674 (1.0069) Loss_G: 0.7718 (1.0049) D(x): 0.5863 D(G(z)): 0.4293 / 0.4386 Acc: 12.5000 (15.1464)\n",
      "[0/25][222/782] Loss_D: 1.0620 (1.0071) Loss_G: 0.7900 (1.0040) D(x): 0.6061 D(G(z)): 0.5063 / 0.4326 Acc: 12.5000 (15.1345)\n",
      "[0/25][223/782] Loss_D: 1.1469 (1.0077) Loss_G: 0.9049 (1.0035) D(x): 0.5844 D(G(z)): 0.5216 / 0.3865 Acc: 15.6250 (15.1367)\n",
      "[0/25][224/782] Loss_D: 1.0520 (1.0079) Loss_G: 1.0009 (1.0035) D(x): 0.5646 D(G(z)): 0.4552 / 0.3737 Acc: 12.5000 (15.1250)\n",
      "[0/25][225/782] Loss_D: 0.9981 (1.0079) Loss_G: 1.0606 (1.0038) D(x): 0.5765 D(G(z)): 0.4266 / 0.3530 Acc: 15.6250 (15.1272)\n",
      "[0/25][226/782] Loss_D: 0.9942 (1.0078) Loss_G: 0.9853 (1.0037) D(x): 0.5606 D(G(z)): 0.4160 / 0.3673 Acc: 9.3750 (15.1019)\n",
      "[0/25][227/782] Loss_D: 0.9838 (1.0077) Loss_G: 0.9943 (1.0036) D(x): 0.5084 D(G(z)): 0.3915 / 0.3980 Acc: 17.1875 (15.1110)\n",
      "[0/25][228/782] Loss_D: 0.9612 (1.0075) Loss_G: 0.8349 (1.0029) D(x): 0.5921 D(G(z)): 0.4542 / 0.3999 Acc: 7.8125 (15.0791)\n",
      "[0/25][229/782] Loss_D: 0.9043 (1.0071) Loss_G: 0.9700 (1.0028) D(x): 0.6338 D(G(z)): 0.4479 / 0.4177 Acc: 20.3125 (15.1019)\n",
      "[0/25][230/782] Loss_D: 0.6983 (1.0057) Loss_G: 0.8574 (1.0021) D(x): 0.5932 D(G(z)): 0.3953 / 0.4020 Acc: 26.5625 (15.1515)\n",
      "[0/25][231/782] Loss_D: 0.7462 (1.0046) Loss_G: 0.8478 (1.0015) D(x): 0.6614 D(G(z)): 0.4186 / 0.4125 Acc: 20.3125 (15.1738)\n",
      "[0/25][232/782] Loss_D: 0.8469 (1.0039) Loss_G: 0.9367 (1.0012) D(x): 0.5886 D(G(z)): 0.4057 / 0.3788 Acc: 17.1875 (15.1824)\n",
      "[0/25][233/782] Loss_D: 0.9885 (1.0039) Loss_G: 0.9435 (1.0009) D(x): 0.5946 D(G(z)): 0.4265 / 0.4125 Acc: 14.0625 (15.1776)\n",
      "[0/25][234/782] Loss_D: 0.9824 (1.0038) Loss_G: 0.9664 (1.0008) D(x): 0.6660 D(G(z)): 0.4926 / 0.3799 Acc: 15.6250 (15.1795)\n",
      "[0/25][235/782] Loss_D: 0.8722 (1.0032) Loss_G: 1.0241 (1.0009) D(x): 0.6104 D(G(z)): 0.3858 / 0.3786 Acc: 17.1875 (15.1880)\n",
      "[0/25][236/782] Loss_D: 0.6737 (1.0018) Loss_G: 1.0793 (1.0012) D(x): 0.6555 D(G(z)): 0.3674 / 0.3557 Acc: 20.3125 (15.2097)\n",
      "[0/25][237/782] Loss_D: 0.7721 (1.0009) Loss_G: 1.1795 (1.0020) D(x): 0.6370 D(G(z)): 0.4096 / 0.3236 Acc: 17.1875 (15.2180)\n",
      "[0/25][238/782] Loss_D: 0.7987 (1.0000) Loss_G: 1.0901 (1.0023) D(x): 0.6352 D(G(z)): 0.4006 / 0.3304 Acc: 20.3125 (15.2393)\n",
      "[0/25][239/782] Loss_D: 0.8192 (0.9993) Loss_G: 1.1161 (1.0028) D(x): 0.6801 D(G(z)): 0.4048 / 0.3308 Acc: 10.9375 (15.2214)\n",
      "[0/25][240/782] Loss_D: 0.6921 (0.9980) Loss_G: 1.2489 (1.0038) D(x): 0.6554 D(G(z)): 0.3553 / 0.2979 Acc: 17.1875 (15.2295)\n",
      "[0/25][241/782] Loss_D: 0.8371 (0.9973) Loss_G: 1.3325 (1.0052) D(x): 0.6460 D(G(z)): 0.3925 / 0.2723 Acc: 17.1875 (15.2376)\n",
      "[0/25][242/782] Loss_D: 0.7134 (0.9962) Loss_G: 1.2956 (1.0064) D(x): 0.6136 D(G(z)): 0.3380 / 0.2810 Acc: 15.6250 (15.2392)\n",
      "[0/25][243/782] Loss_D: 0.6459 (0.9947) Loss_G: 1.1914 (1.0072) D(x): 0.6458 D(G(z)): 0.3733 / 0.2943 Acc: 17.1875 (15.2472)\n",
      "[0/25][244/782] Loss_D: 0.6954 (0.9935) Loss_G: 1.1746 (1.0078) D(x): 0.6510 D(G(z)): 0.3611 / 0.3169 Acc: 15.6250 (15.2487)\n",
      "[0/25][245/782] Loss_D: 0.9416 (0.9933) Loss_G: 1.4126 (1.0095) D(x): 0.6729 D(G(z)): 0.4959 / 0.2662 Acc: 21.8750 (15.2757)\n",
      "[0/25][246/782] Loss_D: 0.7399 (0.9923) Loss_G: 1.4213 (1.0112) D(x): 0.6466 D(G(z)): 0.3716 / 0.2423 Acc: 10.9375 (15.2581)\n",
      "[0/25][247/782] Loss_D: 0.7709 (0.9914) Loss_G: 1.3282 (1.0124) D(x): 0.6278 D(G(z)): 0.3603 / 0.2891 Acc: 18.7500 (15.2722)\n",
      "[0/25][248/782] Loss_D: 0.9811 (0.9913) Loss_G: 1.1268 (1.0129) D(x): 0.5800 D(G(z)): 0.3706 / 0.3274 Acc: 4.6875 (15.2297)\n",
      "[0/25][249/782] Loss_D: 0.9318 (0.9911) Loss_G: 1.2324 (1.0138) D(x): 0.6323 D(G(z)): 0.3972 / 0.3063 Acc: 7.8125 (15.2000)\n",
      "[0/25][250/782] Loss_D: 0.8507 (0.9905) Loss_G: 1.4788 (1.0156) D(x): 0.7083 D(G(z)): 0.4632 / 0.2618 Acc: 12.5000 (15.1892)\n",
      "[0/25][251/782] Loss_D: 0.7553 (0.9896) Loss_G: 1.2698 (1.0166) D(x): 0.6261 D(G(z)): 0.3922 / 0.3232 Acc: 21.8750 (15.2158)\n",
      "[0/25][252/782] Loss_D: 0.8718 (0.9891) Loss_G: 1.1198 (1.0170) D(x): 0.5652 D(G(z)): 0.3770 / 0.3522 Acc: 23.4375 (15.2483)\n",
      "[0/25][253/782] Loss_D: 0.9631 (0.9890) Loss_G: 0.9372 (1.0167) D(x): 0.5988 D(G(z)): 0.4566 / 0.3974 Acc: 26.5625 (15.2928)\n",
      "[0/25][254/782] Loss_D: 1.2033 (0.9899) Loss_G: 1.1892 (1.0174) D(x): 0.6239 D(G(z)): 0.5359 / 0.3254 Acc: 9.3750 (15.2696)\n",
      "[0/25][255/782] Loss_D: 1.0360 (0.9900) Loss_G: 1.0156 (1.0174) D(x): 0.5630 D(G(z)): 0.4285 / 0.3592 Acc: 15.6250 (15.2710)\n",
      "[0/25][256/782] Loss_D: 1.3385 (0.9914) Loss_G: 0.8534 (1.0168) D(x): 0.4818 D(G(z)): 0.5141 / 0.4312 Acc: 14.0625 (15.2663)\n",
      "[0/25][257/782] Loss_D: 1.0716 (0.9917) Loss_G: 0.8153 (1.0160) D(x): 0.5805 D(G(z)): 0.4664 / 0.4339 Acc: 17.1875 (15.2737)\n",
      "[0/25][258/782] Loss_D: 1.1091 (0.9922) Loss_G: 0.8633 (1.0154) D(x): 0.5708 D(G(z)): 0.4984 / 0.4143 Acc: 15.6250 (15.2751)\n",
      "[0/25][259/782] Loss_D: 1.2454 (0.9931) Loss_G: 1.1351 (1.0158) D(x): 0.4854 D(G(z)): 0.4495 / 0.3435 Acc: 15.6250 (15.2764)\n",
      "[0/25][260/782] Loss_D: 1.1871 (0.9939) Loss_G: 1.0266 (1.0159) D(x): 0.5273 D(G(z)): 0.4079 / 0.3992 Acc: 10.9375 (15.2598)\n",
      "[0/25][261/782] Loss_D: 1.1414 (0.9944) Loss_G: 0.7594 (1.0149) D(x): 0.5703 D(G(z)): 0.4338 / 0.4907 Acc: 10.9375 (15.2433)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/25][262/782] Loss_D: 1.0623 (0.9947) Loss_G: 0.9016 (1.0145) D(x): 0.6173 D(G(z)): 0.5422 / 0.4090 Acc: 23.4375 (15.2745)\n",
      "[0/25][263/782] Loss_D: 1.0215 (0.9948) Loss_G: 1.0608 (1.0147) D(x): 0.6182 D(G(z)): 0.4446 / 0.3666 Acc: 10.9375 (15.2580)\n",
      "[0/25][264/782] Loss_D: 1.1239 (0.9953) Loss_G: 1.2819 (1.0157) D(x): 0.5922 D(G(z)): 0.5178 / 0.2888 Acc: 15.6250 (15.2594)\n",
      "[0/25][265/782] Loss_D: 0.8543 (0.9948) Loss_G: 1.1755 (1.0163) D(x): 0.5381 D(G(z)): 0.3056 / 0.3109 Acc: 9.3750 (15.2373)\n",
      "[0/25][266/782] Loss_D: 0.9498 (0.9946) Loss_G: 1.1759 (1.0169) D(x): 0.6328 D(G(z)): 0.4448 / 0.3370 Acc: 14.0625 (15.2329)\n",
      "[0/25][267/782] Loss_D: 1.0742 (0.9949) Loss_G: 1.1475 (1.0173) D(x): 0.6223 D(G(z)): 0.4709 / 0.3523 Acc: 10.9375 (15.2169)\n",
      "[0/25][268/782] Loss_D: 1.1698 (0.9955) Loss_G: 1.3074 (1.0184) D(x): 0.6028 D(G(z)): 0.4995 / 0.3013 Acc: 10.9375 (15.2010)\n",
      "[0/25][269/782] Loss_D: 1.0275 (0.9957) Loss_G: 1.6785 (1.0209) D(x): 0.5588 D(G(z)): 0.4366 / 0.2278 Acc: 15.6250 (15.2025)\n",
      "[0/25][270/782] Loss_D: 1.3337 (0.9969) Loss_G: 1.4339 (1.0224) D(x): 0.5005 D(G(z)): 0.4611 / 0.2763 Acc: 12.5000 (15.1926)\n",
      "[0/25][271/782] Loss_D: 1.2190 (0.9977) Loss_G: 0.9958 (1.0223) D(x): 0.4787 D(G(z)): 0.3942 / 0.3962 Acc: 14.0625 (15.1884)\n",
      "[0/25][272/782] Loss_D: 1.2686 (0.9987) Loss_G: 1.2501 (1.0231) D(x): 0.5820 D(G(z)): 0.5378 / 0.3106 Acc: 17.1875 (15.1957)\n",
      "[0/25][273/782] Loss_D: 1.4610 (1.0004) Loss_G: 1.1371 (1.0235) D(x): 0.4147 D(G(z)): 0.4576 / 0.3462 Acc: 15.6250 (15.1973)\n",
      "[0/25][274/782] Loss_D: 1.2644 (1.0014) Loss_G: 0.8449 (1.0229) D(x): 0.5063 D(G(z)): 0.4488 / 0.3956 Acc: 6.2500 (15.1648)\n",
      "[0/25][275/782] Loss_D: 1.3476 (1.0026) Loss_G: 1.0232 (1.0229) D(x): 0.5082 D(G(z)): 0.5119 / 0.3862 Acc: 14.0625 (15.1608)\n",
      "[0/25][276/782] Loss_D: 1.3492 (1.0039) Loss_G: 0.9206 (1.0225) D(x): 0.4836 D(G(z)): 0.4759 / 0.4223 Acc: 20.3125 (15.1794)\n",
      "[0/25][277/782] Loss_D: 1.3853 (1.0052) Loss_G: 1.0026 (1.0225) D(x): 0.5789 D(G(z)): 0.5466 / 0.3876 Acc: 9.3750 (15.1585)\n",
      "[0/25][278/782] Loss_D: 1.3579 (1.0065) Loss_G: 0.9798 (1.0223) D(x): 0.5031 D(G(z)): 0.4970 / 0.3846 Acc: 17.1875 (15.1658)\n",
      "[0/25][279/782] Loss_D: 1.4753 (1.0082) Loss_G: 1.4867 (1.0240) D(x): 0.4499 D(G(z)): 0.5081 / 0.2597 Acc: 9.3750 (15.1451)\n",
      "[0/25][280/782] Loss_D: 1.1460 (1.0087) Loss_G: 1.4402 (1.0254) D(x): 0.4457 D(G(z)): 0.3247 / 0.2768 Acc: 12.5000 (15.1357)\n",
      "[0/25][281/782] Loss_D: 1.1022 (1.0090) Loss_G: 0.8919 (1.0250) D(x): 0.5229 D(G(z)): 0.3821 / 0.4193 Acc: 7.8125 (15.1097)\n",
      "[0/25][282/782] Loss_D: 0.9593 (1.0088) Loss_G: 1.0364 (1.0250) D(x): 0.6596 D(G(z)): 0.4618 / 0.3671 Acc: 12.5000 (15.1005)\n",
      "[0/25][283/782] Loss_D: 1.3260 (1.0099) Loss_G: 1.0808 (1.0252) D(x): 0.5644 D(G(z)): 0.5244 / 0.3699 Acc: 15.6250 (15.1023)\n",
      "[0/25][284/782] Loss_D: 1.3151 (1.0110) Loss_G: 1.2549 (1.0260) D(x): 0.5354 D(G(z)): 0.4894 / 0.3298 Acc: 12.5000 (15.0932)\n",
      "[0/25][285/782] Loss_D: 1.3907 (1.0123) Loss_G: 0.9609 (1.0258) D(x): 0.4791 D(G(z)): 0.4698 / 0.3913 Acc: 6.2500 (15.0623)\n",
      "[0/25][286/782] Loss_D: 1.4233 (1.0138) Loss_G: 0.9635 (1.0256) D(x): 0.5046 D(G(z)): 0.5307 / 0.3854 Acc: 17.1875 (15.0697)\n",
      "[0/25][287/782] Loss_D: 1.3956 (1.0151) Loss_G: 0.9465 (1.0253) D(x): 0.4831 D(G(z)): 0.4722 / 0.4006 Acc: 18.7500 (15.0825)\n",
      "[0/25][288/782] Loss_D: 1.2461 (1.0159) Loss_G: 0.7668 (1.0244) D(x): 0.5097 D(G(z)): 0.4932 / 0.4451 Acc: 17.1875 (15.0897)\n",
      "[0/25][289/782] Loss_D: 1.3155 (1.0169) Loss_G: 0.9973 (1.0243) D(x): 0.4900 D(G(z)): 0.4837 / 0.3885 Acc: 15.6250 (15.0916)\n",
      "[0/25][290/782] Loss_D: 1.3057 (1.0179) Loss_G: 0.8615 (1.0237) D(x): 0.4675 D(G(z)): 0.4503 / 0.4423 Acc: 14.0625 (15.0881)\n",
      "[0/25][291/782] Loss_D: 1.4494 (1.0194) Loss_G: 0.7806 (1.0229) D(x): 0.4526 D(G(z)): 0.4676 / 0.4484 Acc: 7.8125 (15.0631)\n",
      "[0/25][292/782] Loss_D: 1.1389 (1.0198) Loss_G: 0.9269 (1.0226) D(x): 0.6206 D(G(z)): 0.5469 / 0.3912 Acc: 17.1875 (15.0704)\n",
      "[0/25][293/782] Loss_D: 1.0060 (1.0198) Loss_G: 0.9065 (1.0222) D(x): 0.5278 D(G(z)): 0.4582 / 0.3992 Acc: 26.5625 (15.1095)\n",
      "[0/25][294/782] Loss_D: 1.1128 (1.0201) Loss_G: 1.0450 (1.0223) D(x): 0.5024 D(G(z)): 0.4030 / 0.3638 Acc: 15.6250 (15.1112)\n",
      "[0/25][295/782] Loss_D: 1.0440 (1.0202) Loss_G: 1.0176 (1.0223) D(x): 0.5714 D(G(z)): 0.4298 / 0.3750 Acc: 14.0625 (15.1077)\n",
      "[0/25][296/782] Loss_D: 1.0090 (1.0201) Loss_G: 1.0097 (1.0222) D(x): 0.5837 D(G(z)): 0.4196 / 0.3883 Acc: 15.6250 (15.1094)\n",
      "[0/25][297/782] Loss_D: 0.9555 (1.0199) Loss_G: 1.1028 (1.0225) D(x): 0.5893 D(G(z)): 0.4341 / 0.3613 Acc: 20.3125 (15.1269)\n",
      "[0/25][298/782] Loss_D: 1.0343 (1.0200) Loss_G: 0.8537 (1.0219) D(x): 0.5510 D(G(z)): 0.4553 / 0.4218 Acc: 14.0625 (15.1233)\n",
      "[0/25][299/782] Loss_D: 1.1130 (1.0203) Loss_G: 0.9633 (1.0217) D(x): 0.5373 D(G(z)): 0.4373 / 0.4052 Acc: 15.6250 (15.1250)\n",
      "[0/25][300/782] Loss_D: 1.1634 (1.0207) Loss_G: 0.9549 (1.0215) D(x): 0.5654 D(G(z)): 0.4794 / 0.4125 Acc: 9.3750 (15.1059)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[0/25][301/782] Loss_D: 1.2728 (1.0216) Loss_G: 0.7567 (1.0206) D(x): 0.5531 D(G(z)): 0.5276 / 0.4578 Acc: 18.7500 (15.1180)\n",
      "[0/25][302/782] Loss_D: 1.1883 (1.0221) Loss_G: 0.9015 (1.0202) D(x): 0.5439 D(G(z)): 0.5085 / 0.3973 Acc: 17.1875 (15.1248)\n",
      "[0/25][303/782] Loss_D: 1.0642 (1.0223) Loss_G: 1.0469 (1.0203) D(x): 0.5105 D(G(z)): 0.4219 / 0.3639 Acc: 23.4375 (15.1521)\n",
      "[0/25][304/782] Loss_D: 1.0966 (1.0225) Loss_G: 0.9962 (1.0202) D(x): 0.5154 D(G(z)): 0.4492 / 0.3944 Acc: 18.7500 (15.1639)\n",
      "[0/25][305/782] Loss_D: 1.2093 (1.0231) Loss_G: 0.9111 (1.0199) D(x): 0.5066 D(G(z)): 0.4619 / 0.4162 Acc: 17.1875 (15.1705)\n",
      "[0/25][306/782] Loss_D: 1.2206 (1.0238) Loss_G: 0.7669 (1.0191) D(x): 0.5362 D(G(z)): 0.4869 / 0.4528 Acc: 12.5000 (15.1618)\n",
      "[0/25][307/782] Loss_D: 1.1091 (1.0240) Loss_G: 0.9010 (1.0187) D(x): 0.5348 D(G(z)): 0.4614 / 0.4070 Acc: 15.6250 (15.1634)\n",
      "[0/25][308/782] Loss_D: 1.0687 (1.0242) Loss_G: 0.9718 (1.0185) D(x): 0.5534 D(G(z)): 0.4240 / 0.3920 Acc: 10.9375 (15.1497)\n",
      "[0/25][309/782] Loss_D: 1.0484 (1.0243) Loss_G: 0.8053 (1.0178) D(x): 0.5296 D(G(z)): 0.4363 / 0.4170 Acc: 17.1875 (15.1562)\n",
      "[0/25][310/782] Loss_D: 0.9788 (1.0241) Loss_G: 0.9026 (1.0175) D(x): 0.5759 D(G(z)): 0.4321 / 0.4114 Acc: 21.8750 (15.1779)\n",
      "[0/25][311/782] Loss_D: 1.2188 (1.0247) Loss_G: 0.8723 (1.0170) D(x): 0.5533 D(G(z)): 0.4755 / 0.4206 Acc: 14.0625 (15.1743)\n",
      "[0/25][312/782] Loss_D: 1.0757 (1.0249) Loss_G: 0.7640 (1.0162) D(x): 0.5520 D(G(z)): 0.4678 / 0.4359 Acc: 14.0625 (15.1707)\n",
      "[0/25][313/782] Loss_D: 1.0281 (1.0249) Loss_G: 0.9932 (1.0161) D(x): 0.5421 D(G(z)): 0.4087 / 0.3959 Acc: 14.0625 (15.1672)\n",
      "[0/25][314/782] Loss_D: 1.1742 (1.0254) Loss_G: 0.8013 (1.0154) D(x): 0.5305 D(G(z)): 0.4867 / 0.4169 Acc: 14.0625 (15.1637)\n",
      "[0/25][315/782] Loss_D: 1.1342 (1.0257) Loss_G: 0.9657 (1.0153) D(x): 0.5657 D(G(z)): 0.4478 / 0.3801 Acc: 9.3750 (15.1454)\n",
      "[0/25][316/782] Loss_D: 1.0062 (1.0257) Loss_G: 0.8326 (1.0147) D(x): 0.5900 D(G(z)): 0.4323 / 0.4408 Acc: 17.1875 (15.1518)\n",
      "[0/25][317/782] Loss_D: 1.1238 (1.0260) Loss_G: 0.9843 (1.0146) D(x): 0.5962 D(G(z)): 0.5093 / 0.3875 Acc: 12.5000 (15.1435)\n",
      "[0/25][318/782] Loss_D: 0.9484 (1.0257) Loss_G: 0.8688 (1.0141) D(x): 0.5464 D(G(z)): 0.4015 / 0.4018 Acc: 10.9375 (15.1303)\n",
      "[0/25][319/782] Loss_D: 1.2008 (1.0263) Loss_G: 0.7803 (1.0134) D(x): 0.5272 D(G(z)): 0.4844 / 0.4427 Acc: 17.1875 (15.1367)\n",
      "[0/25][320/782] Loss_D: 1.1609 (1.0267) Loss_G: 0.6272 (1.0122) D(x): 0.4895 D(G(z)): 0.4447 / 0.4871 Acc: 17.1875 (15.1431)\n",
      "[0/25][321/782] Loss_D: 1.2621 (1.0274) Loss_G: 0.8184 (1.0116) D(x): 0.5602 D(G(z)): 0.5208 / 0.4584 Acc: 12.5000 (15.1349)\n",
      "[0/25][322/782] Loss_D: 1.2391 (1.0281) Loss_G: 0.7118 (1.0107) D(x): 0.5104 D(G(z)): 0.4976 / 0.4551 Acc: 14.0625 (15.1316)\n",
      "[0/25][323/782] Loss_D: 1.3181 (1.0290) Loss_G: 0.6660 (1.0096) D(x): 0.5110 D(G(z)): 0.5197 / 0.4662 Acc: 12.5000 (15.1235)\n",
      "[0/25][324/782] Loss_D: 0.9799 (1.0288) Loss_G: 0.7175 (1.0087) D(x): 0.5137 D(G(z)): 0.4412 / 0.4602 Acc: 26.5625 (15.1587)\n",
      "[0/25][325/782] Loss_D: 1.0581 (1.0289) Loss_G: 0.6965 (1.0078) D(x): 0.5777 D(G(z)): 0.5273 / 0.4666 Acc: 26.5625 (15.1936)\n",
      "[0/25][326/782] Loss_D: 1.2834 (1.0297) Loss_G: 0.7197 (1.0069) D(x): 0.5103 D(G(z)): 0.4957 / 0.4600 Acc: 12.5000 (15.1854)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/25][327/782] Loss_D: 1.0876 (1.0299) Loss_G: 0.8636 (1.0064) D(x): 0.5493 D(G(z)): 0.4700 / 0.4112 Acc: 12.5000 (15.1772)\n",
      "[0/25][328/782] Loss_D: 0.9707 (1.0297) Loss_G: 0.7432 (1.0056) D(x): 0.5624 D(G(z)): 0.4708 / 0.4402 Acc: 26.5625 (15.2118)\n",
      "[0/25][329/782] Loss_D: 1.1092 (1.0299) Loss_G: 0.6722 (1.0046) D(x): 0.4678 D(G(z)): 0.4424 / 0.4473 Acc: 18.7500 (15.2225)\n",
      "[0/25][330/782] Loss_D: 0.9170 (1.0296) Loss_G: 0.8759 (1.0042) D(x): 0.5779 D(G(z)): 0.4280 / 0.4135 Acc: 21.8750 (15.2426)\n",
      "[0/25][331/782] Loss_D: 1.0267 (1.0296) Loss_G: 0.7850 (1.0036) D(x): 0.5915 D(G(z)): 0.4759 / 0.4528 Acc: 17.1875 (15.2485)\n",
      "[0/25][332/782] Loss_D: 0.9070 (1.0292) Loss_G: 0.8346 (1.0031) D(x): 0.5744 D(G(z)): 0.4379 / 0.4146 Acc: 15.6250 (15.2496)\n",
      "[0/25][333/782] Loss_D: 0.8472 (1.0287) Loss_G: 0.9651 (1.0030) D(x): 0.5946 D(G(z)): 0.4103 / 0.3971 Acc: 17.1875 (15.2554)\n",
      "[0/25][334/782] Loss_D: 0.9730 (1.0285) Loss_G: 0.8124 (1.0024) D(x): 0.5504 D(G(z)): 0.4516 / 0.4273 Acc: 21.8750 (15.2752)\n",
      "[0/25][335/782] Loss_D: 1.1193 (1.0288) Loss_G: 0.8859 (1.0020) D(x): 0.5528 D(G(z)): 0.4682 / 0.4224 Acc: 15.6250 (15.2762)\n",
      "[0/25][336/782] Loss_D: 0.9939 (1.0287) Loss_G: 0.8274 (1.0015) D(x): 0.5364 D(G(z)): 0.4565 / 0.4043 Acc: 23.4375 (15.3004)\n",
      "[0/25][337/782] Loss_D: 0.9848 (1.0285) Loss_G: 0.6476 (1.0005) D(x): 0.5612 D(G(z)): 0.4705 / 0.4770 Acc: 20.3125 (15.3153)\n",
      "[0/25][338/782] Loss_D: 0.9039 (1.0282) Loss_G: 0.7658 (0.9998) D(x): 0.5993 D(G(z)): 0.4601 / 0.4278 Acc: 20.3125 (15.3300)\n",
      "[0/25][339/782] Loss_D: 1.0233 (1.0282) Loss_G: 0.8437 (0.9993) D(x): 0.5514 D(G(z)): 0.4812 / 0.4326 Acc: 31.2500 (15.3768)\n",
      "[0/25][340/782] Loss_D: 1.0173 (1.0281) Loss_G: 0.9756 (0.9993) D(x): 0.5424 D(G(z)): 0.4562 / 0.3877 Acc: 18.7500 (15.3867)\n",
      "[0/25][341/782] Loss_D: 0.9889 (1.0280) Loss_G: 0.9544 (0.9991) D(x): 0.5523 D(G(z)): 0.4260 / 0.3757 Acc: 12.5000 (15.3783)\n",
      "[0/25][342/782] Loss_D: 0.8999 (1.0276) Loss_G: 1.0028 (0.9991) D(x): 0.5835 D(G(z)): 0.4400 / 0.3729 Acc: 17.1875 (15.3836)\n",
      "[0/25][343/782] Loss_D: 0.9079 (1.0273) Loss_G: 0.8452 (0.9987) D(x): 0.5801 D(G(z)): 0.4027 / 0.4396 Acc: 15.6250 (15.3843)\n",
      "[0/25][344/782] Loss_D: 0.8511 (1.0268) Loss_G: 1.0272 (0.9988) D(x): 0.6619 D(G(z)): 0.4549 / 0.3640 Acc: 20.3125 (15.3986)\n",
      "[0/25][345/782] Loss_D: 1.0191 (1.0268) Loss_G: 1.1058 (0.9991) D(x): 0.5987 D(G(z)): 0.4308 / 0.3470 Acc: 14.0625 (15.3947)\n",
      "[0/25][346/782] Loss_D: 0.9487 (1.0265) Loss_G: 1.0946 (0.9994) D(x): 0.5590 D(G(z)): 0.4054 / 0.3368 Acc: 20.3125 (15.4089)\n",
      "[0/25][347/782] Loss_D: 0.9843 (1.0264) Loss_G: 0.8783 (0.9990) D(x): 0.5355 D(G(z)): 0.3799 / 0.4095 Acc: 10.9375 (15.3960)\n",
      "[0/25][348/782] Loss_D: 1.0619 (1.0265) Loss_G: 0.8718 (0.9986) D(x): 0.6258 D(G(z)): 0.4807 / 0.3899 Acc: 3.1250 (15.3609)\n",
      "[0/25][349/782] Loss_D: 0.8810 (1.0261) Loss_G: 0.9796 (0.9986) D(x): 0.6073 D(G(z)): 0.4661 / 0.3691 Acc: 21.8750 (15.3795)\n",
      "[0/25][350/782] Loss_D: 1.0769 (1.0262) Loss_G: 1.1216 (0.9989) D(x): 0.4786 D(G(z)): 0.3757 / 0.3332 Acc: 14.0625 (15.3757)\n",
      "[0/25][351/782] Loss_D: 1.0585 (1.0263) Loss_G: 1.0268 (0.9990) D(x): 0.5508 D(G(z)): 0.4130 / 0.3511 Acc: 9.3750 (15.3587)\n",
      "[0/25][352/782] Loss_D: 0.7702 (1.0256) Loss_G: 1.1329 (0.9994) D(x): 0.5514 D(G(z)): 0.3664 / 0.3290 Acc: 28.1250 (15.3948)\n",
      "[0/25][353/782] Loss_D: 0.7882 (1.0249) Loss_G: 1.1151 (0.9997) D(x): 0.6440 D(G(z)): 0.4390 / 0.3249 Acc: 18.7500 (15.4043)\n",
      "[0/25][354/782] Loss_D: 0.9151 (1.0246) Loss_G: 1.1014 (1.0000) D(x): 0.5613 D(G(z)): 0.3688 / 0.3340 Acc: 12.5000 (15.3961)\n",
      "[0/25][355/782] Loss_D: 0.8220 (1.0241) Loss_G: 1.2605 (1.0007) D(x): 0.6214 D(G(z)): 0.3851 / 0.3093 Acc: 20.3125 (15.4099)\n",
      "[0/25][356/782] Loss_D: 0.7599 (1.0233) Loss_G: 1.3629 (1.0018) D(x): 0.6885 D(G(z)): 0.4001 / 0.2636 Acc: 9.3750 (15.3930)\n",
      "[0/25][357/782] Loss_D: 0.8290 (1.0228) Loss_G: 1.2555 (1.0025) D(x): 0.6182 D(G(z)): 0.3935 / 0.2707 Acc: 7.8125 (15.3719)\n",
      "[0/25][358/782] Loss_D: 0.9839 (1.0227) Loss_G: 1.0034 (1.0025) D(x): 0.5161 D(G(z)): 0.4225 / 0.3467 Acc: 17.1875 (15.3769)\n",
      "[0/25][359/782] Loss_D: 0.9154 (1.0224) Loss_G: 0.5193 (1.0011) D(x): 0.5139 D(G(z)): 0.4558 / 0.4979 Acc: 25.0000 (15.4036)\n",
      "[0/25][360/782] Loss_D: 1.2914 (1.0231) Loss_G: 0.6623 (1.0002) D(x): 0.5452 D(G(z)): 0.5469 / 0.4712 Acc: 7.8125 (15.3826)\n",
      "[0/25][361/782] Loss_D: 1.3483 (1.0240) Loss_G: 0.8554 (0.9998) D(x): 0.5326 D(G(z)): 0.5404 / 0.4247 Acc: 12.5000 (15.3747)\n",
      "[0/25][362/782] Loss_D: 1.2454 (1.0246) Loss_G: 0.8414 (0.9994) D(x): 0.4973 D(G(z)): 0.5078 / 0.3991 Acc: 15.6250 (15.3753)\n",
      "[0/25][363/782] Loss_D: 1.1368 (1.0249) Loss_G: 0.9523 (0.9992) D(x): 0.5131 D(G(z)): 0.4775 / 0.3655 Acc: 9.3750 (15.3589)\n",
      "[0/25][364/782] Loss_D: 1.3465 (1.0258) Loss_G: 1.1929 (0.9998) D(x): 0.4939 D(G(z)): 0.4888 / 0.3348 Acc: 10.9375 (15.3467)\n",
      "[0/25][365/782] Loss_D: 1.0285 (1.0258) Loss_G: 1.0807 (1.0000) D(x): 0.5618 D(G(z)): 0.4040 / 0.3679 Acc: 12.5000 (15.3390)\n",
      "[0/25][366/782] Loss_D: 1.0976 (1.0260) Loss_G: 0.9956 (1.0000) D(x): 0.5136 D(G(z)): 0.4047 / 0.3808 Acc: 12.5000 (15.3312)\n",
      "[0/25][367/782] Loss_D: 1.0272 (1.0260) Loss_G: 0.9713 (0.9999) D(x): 0.5286 D(G(z)): 0.3814 / 0.3743 Acc: 10.9375 (15.3193)\n",
      "[0/25][368/782] Loss_D: 0.9633 (1.0258) Loss_G: 0.9397 (0.9997) D(x): 0.5669 D(G(z)): 0.4426 / 0.3912 Acc: 17.1875 (15.3244)\n",
      "[0/25][369/782] Loss_D: 0.9549 (1.0257) Loss_G: 1.0905 (1.0000) D(x): 0.6238 D(G(z)): 0.4605 / 0.3268 Acc: 9.3750 (15.3083)\n",
      "[0/25][370/782] Loss_D: 0.9763 (1.0255) Loss_G: 1.2247 (1.0006) D(x): 0.5706 D(G(z)): 0.4161 / 0.3049 Acc: 12.5000 (15.3007)\n",
      "[0/25][371/782] Loss_D: 0.8926 (1.0252) Loss_G: 1.0011 (1.0006) D(x): 0.5692 D(G(z)): 0.3857 / 0.3548 Acc: 12.5000 (15.2932)\n",
      "[0/25][372/782] Loss_D: 1.0454 (1.0252) Loss_G: 0.8588 (1.0002) D(x): 0.5105 D(G(z)): 0.3908 / 0.3955 Acc: 14.0625 (15.2899)\n",
      "[0/25][373/782] Loss_D: 1.0343 (1.0252) Loss_G: 0.8710 (0.9999) D(x): 0.5833 D(G(z)): 0.4450 / 0.4281 Acc: 12.5000 (15.2824)\n",
      "[0/25][374/782] Loss_D: 1.0440 (1.0253) Loss_G: 0.9475 (0.9997) D(x): 0.6774 D(G(z)): 0.5120 / 0.4133 Acc: 9.3750 (15.2667)\n",
      "[0/25][375/782] Loss_D: 1.1812 (1.0257) Loss_G: 0.8780 (0.9994) D(x): 0.5961 D(G(z)): 0.5311 / 0.4151 Acc: 17.1875 (15.2718)\n",
      "[0/25][376/782] Loss_D: 1.2355 (1.0263) Loss_G: 0.9720 (0.9993) D(x): 0.5519 D(G(z)): 0.4667 / 0.3962 Acc: 10.9375 (15.2603)\n",
      "[0/25][377/782] Loss_D: 1.3859 (1.0272) Loss_G: 0.8692 (0.9990) D(x): 0.5029 D(G(z)): 0.5281 / 0.4005 Acc: 4.6875 (15.2323)\n",
      "[0/25][378/782] Loss_D: 1.5298 (1.0285) Loss_G: 0.7605 (0.9983) D(x): 0.4682 D(G(z)): 0.5576 / 0.4337 Acc: 17.1875 (15.2375)\n",
      "[0/25][379/782] Loss_D: 1.5450 (1.0299) Loss_G: 0.8187 (0.9979) D(x): 0.4133 D(G(z)): 0.5097 / 0.4292 Acc: 10.9375 (15.2262)\n",
      "[0/25][380/782] Loss_D: 1.4768 (1.0311) Loss_G: 0.9006 (0.9976) D(x): 0.4193 D(G(z)): 0.4752 / 0.4078 Acc: 9.3750 (15.2108)\n",
      "[0/25][381/782] Loss_D: 1.4735 (1.0322) Loss_G: 1.1618 (0.9980) D(x): 0.4355 D(G(z)): 0.5094 / 0.3131 Acc: 14.0625 (15.2078)\n",
      "[0/25][382/782] Loss_D: 1.1812 (1.0326) Loss_G: 1.1706 (0.9985) D(x): 0.4445 D(G(z)): 0.3931 / 0.3082 Acc: 14.0625 (15.2048)\n",
      "[0/25][383/782] Loss_D: 1.0885 (1.0328) Loss_G: 1.0561 (0.9986) D(x): 0.4806 D(G(z)): 0.3840 / 0.3472 Acc: 10.9375 (15.1937)\n",
      "[0/25][384/782] Loss_D: 1.0568 (1.0328) Loss_G: 0.9479 (0.9985) D(x): 0.4959 D(G(z)): 0.3784 / 0.3918 Acc: 12.5000 (15.1867)\n",
      "[0/25][385/782] Loss_D: 0.7721 (1.0322) Loss_G: 0.8118 (0.9980) D(x): 0.6223 D(G(z)): 0.4560 / 0.4008 Acc: 26.5625 (15.2162)\n",
      "[0/25][386/782] Loss_D: 0.8517 (1.0317) Loss_G: 0.6974 (0.9973) D(x): 0.5783 D(G(z)): 0.4174 / 0.4643 Acc: 20.3125 (15.2293)\n",
      "[0/25][387/782] Loss_D: 0.9258 (1.0314) Loss_G: 0.9491 (0.9971) D(x): 0.5994 D(G(z)): 0.4457 / 0.3748 Acc: 17.1875 (15.2344)\n",
      "[0/25][388/782] Loss_D: 0.8289 (1.0309) Loss_G: 0.8415 (0.9967) D(x): 0.5807 D(G(z)): 0.4346 / 0.3840 Acc: 21.8750 (15.2514)\n",
      "[0/25][389/782] Loss_D: 1.0660 (1.0310) Loss_G: 0.9982 (0.9967) D(x): 0.6121 D(G(z)): 0.4768 / 0.3756 Acc: 7.8125 (15.2324)\n",
      "[0/25][390/782] Loss_D: 1.0376 (1.0310) Loss_G: 0.7358 (0.9961) D(x): 0.4979 D(G(z)): 0.4090 / 0.4511 Acc: 17.1875 (15.2374)\n",
      "[0/25][391/782] Loss_D: 1.2374 (1.0315) Loss_G: 0.6925 (0.9953) D(x): 0.5178 D(G(z)): 0.5117 / 0.4753 Acc: 18.7500 (15.2463)\n",
      "[0/25][392/782] Loss_D: 1.0928 (1.0317) Loss_G: 0.6828 (0.9945) D(x): 0.5514 D(G(z)): 0.5294 / 0.4494 Acc: 15.6250 (15.2473)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/25][393/782] Loss_D: 1.3456 (1.0325) Loss_G: 0.8531 (0.9941) D(x): 0.4887 D(G(z)): 0.5169 / 0.3866 Acc: 10.9375 (15.2364)\n",
      "[0/25][394/782] Loss_D: 1.2554 (1.0330) Loss_G: 0.8112 (0.9937) D(x): 0.4535 D(G(z)): 0.4838 / 0.4422 Acc: 18.7500 (15.2453)\n",
      "[0/25][395/782] Loss_D: 1.0138 (1.0330) Loss_G: 0.8224 (0.9932) D(x): 0.5306 D(G(z)): 0.4601 / 0.3944 Acc: 15.6250 (15.2462)\n",
      "[0/25][396/782] Loss_D: 0.9658 (1.0328) Loss_G: 0.7628 (0.9927) D(x): 0.5191 D(G(z)): 0.4273 / 0.4398 Acc: 21.8750 (15.2629)\n",
      "[0/25][397/782] Loss_D: 1.0313 (1.0328) Loss_G: 0.7487 (0.9920) D(x): 0.4816 D(G(z)): 0.4450 / 0.4257 Acc: 25.0000 (15.2874)\n",
      "[0/25][398/782] Loss_D: 0.8886 (1.0325) Loss_G: 0.8120 (0.9916) D(x): 0.5746 D(G(z)): 0.4380 / 0.4132 Acc: 20.3125 (15.3000)\n",
      "[0/25][399/782] Loss_D: 1.1281 (1.0327) Loss_G: 0.8409 (0.9912) D(x): 0.5110 D(G(z)): 0.4543 / 0.4163 Acc: 17.1875 (15.3047)\n",
      "[0/25][400/782] Loss_D: 1.1498 (1.0330) Loss_G: 0.9116 (0.9910) D(x): 0.5445 D(G(z)): 0.4557 / 0.4196 Acc: 9.3750 (15.2899)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[0/25][401/782] Loss_D: 0.8864 (1.0326) Loss_G: 0.6798 (0.9902) D(x): 0.5285 D(G(z)): 0.4337 / 0.4411 Acc: 17.1875 (15.2946)\n",
      "[0/25][402/782] Loss_D: 0.8632 (1.0322) Loss_G: 0.6449 (0.9894) D(x): 0.5615 D(G(z)): 0.4668 / 0.4494 Acc: 23.4375 (15.3148)\n",
      "[0/25][403/782] Loss_D: 1.0347 (1.0322) Loss_G: 0.6968 (0.9887) D(x): 0.5441 D(G(z)): 0.4439 / 0.4637 Acc: 12.5000 (15.3079)\n",
      "[0/25][404/782] Loss_D: 0.6828 (1.0314) Loss_G: 0.8942 (0.9884) D(x): 0.6174 D(G(z)): 0.4034 / 0.3685 Acc: 20.3125 (15.3202)\n",
      "[0/25][405/782] Loss_D: 0.8900 (1.0310) Loss_G: 0.8903 (0.9882) D(x): 0.5610 D(G(z)): 0.4556 / 0.3715 Acc: 15.6250 (15.3210)\n",
      "[0/25][406/782] Loss_D: 0.9268 (1.0307) Loss_G: 0.8144 (0.9878) D(x): 0.5507 D(G(z)): 0.4371 / 0.4136 Acc: 18.7500 (15.3294)\n",
      "[0/25][407/782] Loss_D: 0.9389 (1.0305) Loss_G: 0.8605 (0.9875) D(x): 0.5547 D(G(z)): 0.4170 / 0.4245 Acc: 17.1875 (15.3339)\n",
      "[0/25][408/782] Loss_D: 1.0059 (1.0305) Loss_G: 0.8279 (0.9871) D(x): 0.5764 D(G(z)): 0.4792 / 0.4032 Acc: 20.3125 (15.3461)\n",
      "[0/25][409/782] Loss_D: 0.9515 (1.0303) Loss_G: 0.7775 (0.9866) D(x): 0.5312 D(G(z)): 0.3856 / 0.4124 Acc: 15.6250 (15.3468)\n",
      "[0/25][410/782] Loss_D: 1.0006 (1.0302) Loss_G: 0.7216 (0.9859) D(x): 0.6040 D(G(z)): 0.4991 / 0.4340 Acc: 20.3125 (15.3589)\n",
      "[0/25][411/782] Loss_D: 0.9090 (1.0299) Loss_G: 0.9882 (0.9859) D(x): 0.6153 D(G(z)): 0.4476 / 0.3791 Acc: 15.6250 (15.3595)\n",
      "[0/25][412/782] Loss_D: 0.9346 (1.0297) Loss_G: 0.9052 (0.9857) D(x): 0.5086 D(G(z)): 0.4047 / 0.3913 Acc: 28.1250 (15.3904)\n",
      "[0/25][413/782] Loss_D: 1.0373 (1.0297) Loss_G: 0.9567 (0.9856) D(x): 0.5569 D(G(z)): 0.4471 / 0.3795 Acc: 15.6250 (15.3910)\n",
      "[0/25][414/782] Loss_D: 0.9400 (1.0295) Loss_G: 0.9611 (0.9856) D(x): 0.4935 D(G(z)): 0.4439 / 0.3375 Acc: 21.8750 (15.4066)\n",
      "[0/25][415/782] Loss_D: 0.8994 (1.0292) Loss_G: 0.9733 (0.9856) D(x): 0.5787 D(G(z)): 0.4176 / 0.3520 Acc: 14.0625 (15.4034)\n",
      "[0/25][416/782] Loss_D: 0.9004 (1.0289) Loss_G: 1.0586 (0.9857) D(x): 0.5684 D(G(z)): 0.3766 / 0.3485 Acc: 10.9375 (15.3927)\n",
      "[0/25][417/782] Loss_D: 0.9716 (1.0287) Loss_G: 1.0733 (0.9859) D(x): 0.5348 D(G(z)): 0.3886 / 0.3473 Acc: 17.1875 (15.3970)\n",
      "[0/25][418/782] Loss_D: 1.0849 (1.0289) Loss_G: 1.1388 (0.9863) D(x): 0.5835 D(G(z)): 0.4770 / 0.3489 Acc: 18.7500 (15.4050)\n",
      "[0/25][419/782] Loss_D: 1.0402 (1.0289) Loss_G: 0.9613 (0.9862) D(x): 0.5377 D(G(z)): 0.4064 / 0.4039 Acc: 15.6250 (15.4055)\n",
      "[0/25][420/782] Loss_D: 0.9928 (1.0288) Loss_G: 0.8149 (0.9858) D(x): 0.5284 D(G(z)): 0.4168 / 0.4008 Acc: 18.7500 (15.4135)\n",
      "[0/25][421/782] Loss_D: 0.8577 (1.0284) Loss_G: 0.7996 (0.9854) D(x): 0.5669 D(G(z)): 0.4659 / 0.4137 Acc: 25.0000 (15.4362)\n",
      "[0/25][422/782] Loss_D: 0.9505 (1.0282) Loss_G: 0.9657 (0.9854) D(x): 0.6235 D(G(z)): 0.5230 / 0.3508 Acc: 21.8750 (15.4514)\n",
      "[0/25][423/782] Loss_D: 1.1895 (1.0286) Loss_G: 0.8904 (0.9851) D(x): 0.4424 D(G(z)): 0.3966 / 0.4103 Acc: 17.1875 (15.4555)\n",
      "[0/25][424/782] Loss_D: 1.1436 (1.0289) Loss_G: 0.7355 (0.9845) D(x): 0.5103 D(G(z)): 0.4375 / 0.4718 Acc: 14.0625 (15.4522)\n",
      "[0/25][425/782] Loss_D: 0.9650 (1.0287) Loss_G: 0.9079 (0.9844) D(x): 0.5684 D(G(z)): 0.4807 / 0.4022 Acc: 26.5625 (15.4783)\n",
      "[0/25][426/782] Loss_D: 0.9800 (1.0286) Loss_G: 0.9958 (0.9844) D(x): 0.6162 D(G(z)): 0.4871 / 0.3637 Acc: 12.5000 (15.4713)\n",
      "[0/25][427/782] Loss_D: 1.1407 (1.0289) Loss_G: 1.0776 (0.9846) D(x): 0.5220 D(G(z)): 0.4468 / 0.3498 Acc: 18.7500 (15.4790)\n",
      "[0/25][428/782] Loss_D: 1.1374 (1.0291) Loss_G: 0.9156 (0.9844) D(x): 0.5054 D(G(z)): 0.4316 / 0.3777 Acc: 10.9375 (15.4684)\n",
      "[0/25][429/782] Loss_D: 1.2029 (1.0295) Loss_G: 0.7818 (0.9840) D(x): 0.4970 D(G(z)): 0.4573 / 0.4459 Acc: 14.0625 (15.4651)\n",
      "[0/25][430/782] Loss_D: 1.0874 (1.0296) Loss_G: 0.6920 (0.9833) D(x): 0.5113 D(G(z)): 0.4167 / 0.4663 Acc: 10.9375 (15.4546)\n",
      "[0/25][431/782] Loss_D: 1.1029 (1.0298) Loss_G: 0.9729 (0.9833) D(x): 0.6332 D(G(z)): 0.5342 / 0.3860 Acc: 20.3125 (15.4659)\n",
      "[0/25][432/782] Loss_D: 1.0109 (1.0298) Loss_G: 1.0143 (0.9833) D(x): 0.5703 D(G(z)): 0.5105 / 0.3579 Acc: 28.1250 (15.4951)\n",
      "[0/25][433/782] Loss_D: 1.0376 (1.0298) Loss_G: 0.8730 (0.9831) D(x): 0.4696 D(G(z)): 0.4226 / 0.3977 Acc: 25.0000 (15.5170)\n",
      "[0/25][434/782] Loss_D: 1.0342 (1.0298) Loss_G: 0.7127 (0.9825) D(x): 0.4619 D(G(z)): 0.3767 / 0.4717 Acc: 21.8750 (15.5316)\n",
      "[0/25][435/782] Loss_D: 0.9540 (1.0296) Loss_G: 0.7959 (0.9820) D(x): 0.6014 D(G(z)): 0.4628 / 0.4427 Acc: 15.6250 (15.5318)\n",
      "[0/25][436/782] Loss_D: 0.9185 (1.0294) Loss_G: 1.0459 (0.9822) D(x): 0.6138 D(G(z)): 0.4539 / 0.3603 Acc: 18.7500 (15.5392)\n",
      "[0/25][437/782] Loss_D: 0.7889 (1.0288) Loss_G: 0.9748 (0.9822) D(x): 0.5715 D(G(z)): 0.4214 / 0.3563 Acc: 21.8750 (15.5537)\n",
      "[0/25][438/782] Loss_D: 0.8392 (1.0284) Loss_G: 0.8300 (0.9818) D(x): 0.5559 D(G(z)): 0.4354 / 0.3928 Acc: 25.0000 (15.5752)\n",
      "[0/25][439/782] Loss_D: 0.9320 (1.0282) Loss_G: 1.0483 (0.9820) D(x): 0.6329 D(G(z)): 0.4438 / 0.3783 Acc: 15.6250 (15.5753)\n",
      "[0/25][440/782] Loss_D: 1.0474 (1.0282) Loss_G: 0.8348 (0.9816) D(x): 0.5110 D(G(z)): 0.4309 / 0.4281 Acc: 21.8750 (15.5896)\n",
      "[0/25][441/782] Loss_D: 1.1100 (1.0284) Loss_G: 0.9241 (0.9815) D(x): 0.5470 D(G(z)): 0.4791 / 0.3865 Acc: 17.1875 (15.5932)\n",
      "[0/25][442/782] Loss_D: 1.0324 (1.0284) Loss_G: 1.1334 (0.9819) D(x): 0.5886 D(G(z)): 0.4471 / 0.3326 Acc: 14.0625 (15.5897)\n",
      "[0/25][443/782] Loss_D: 0.8197 (1.0279) Loss_G: 1.1156 (0.9822) D(x): 0.5502 D(G(z)): 0.3595 / 0.3259 Acc: 21.8750 (15.6039)\n",
      "[0/25][444/782] Loss_D: 1.0184 (1.0279) Loss_G: 0.8234 (0.9818) D(x): 0.5351 D(G(z)): 0.4086 / 0.4460 Acc: 17.1875 (15.6074)\n",
      "[0/25][445/782] Loss_D: 1.1272 (1.0281) Loss_G: 0.8515 (0.9815) D(x): 0.6481 D(G(z)): 0.5425 / 0.4175 Acc: 14.0625 (15.6040)\n",
      "[0/25][446/782] Loss_D: 1.2052 (1.0285) Loss_G: 0.8665 (0.9812) D(x): 0.5523 D(G(z)): 0.5723 / 0.4091 Acc: 23.4375 (15.6215)\n",
      "[0/25][447/782] Loss_D: 1.1081 (1.0287) Loss_G: 0.8298 (0.9809) D(x): 0.4473 D(G(z)): 0.4268 / 0.4253 Acc: 26.5625 (15.6459)\n",
      "[0/25][448/782] Loss_D: 1.1375 (1.0290) Loss_G: 0.6933 (0.9803) D(x): 0.5273 D(G(z)): 0.4998 / 0.4535 Acc: 15.6250 (15.6459)\n",
      "[0/25][449/782] Loss_D: 1.2112 (1.0294) Loss_G: 0.8019 (0.9799) D(x): 0.5139 D(G(z)): 0.4864 / 0.4388 Acc: 14.0625 (15.6424)\n",
      "[0/25][450/782] Loss_D: 0.9844 (1.0293) Loss_G: 0.7373 (0.9793) D(x): 0.5556 D(G(z)): 0.4638 / 0.4423 Acc: 17.1875 (15.6458)\n",
      "[0/25][451/782] Loss_D: 1.0326 (1.0293) Loss_G: 1.0755 (0.9795) D(x): 0.5453 D(G(z)): 0.4429 / 0.3514 Acc: 15.6250 (15.6457)\n",
      "[0/25][452/782] Loss_D: 0.9091 (1.0290) Loss_G: 1.0461 (0.9797) D(x): 0.5488 D(G(z)): 0.3977 / 0.3356 Acc: 18.7500 (15.6526)\n",
      "[0/25][453/782] Loss_D: 0.8050 (1.0285) Loss_G: 0.8667 (0.9794) D(x): 0.5655 D(G(z)): 0.3893 / 0.4201 Acc: 20.3125 (15.6629)\n",
      "[0/25][454/782] Loss_D: 0.7921 (1.0280) Loss_G: 0.9599 (0.9794) D(x): 0.6252 D(G(z)): 0.4445 / 0.3848 Acc: 29.6875 (15.6937)\n",
      "[0/25][455/782] Loss_D: 0.9522 (1.0278) Loss_G: 1.0626 (0.9796) D(x): 0.6033 D(G(z)): 0.4768 / 0.3388 Acc: 23.4375 (15.7107)\n",
      "[0/25][456/782] Loss_D: 0.9173 (1.0276) Loss_G: 1.0602 (0.9798) D(x): 0.4717 D(G(z)): 0.3475 / 0.3436 Acc: 21.8750 (15.7242)\n",
      "[0/25][457/782] Loss_D: 0.7514 (1.0270) Loss_G: 0.8729 (0.9795) D(x): 0.5450 D(G(z)): 0.3334 / 0.3945 Acc: 21.8750 (15.7376)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/25][458/782] Loss_D: 0.8025 (1.0265) Loss_G: 0.7565 (0.9790) D(x): 0.6102 D(G(z)): 0.4299 / 0.4351 Acc: 21.8750 (15.7510)\n",
      "[0/25][459/782] Loss_D: 1.0845 (1.0266) Loss_G: 0.8229 (0.9787) D(x): 0.5713 D(G(z)): 0.4946 / 0.4305 Acc: 17.1875 (15.7541)\n",
      "[0/25][460/782] Loss_D: 1.0012 (1.0266) Loss_G: 1.0187 (0.9788) D(x): 0.6057 D(G(z)): 0.4753 / 0.3670 Acc: 15.6250 (15.7538)\n",
      "[0/25][461/782] Loss_D: 0.8895 (1.0263) Loss_G: 1.1728 (0.9792) D(x): 0.5968 D(G(z)): 0.4422 / 0.3008 Acc: 14.0625 (15.7501)\n",
      "[0/25][462/782] Loss_D: 0.6798 (1.0255) Loss_G: 1.3370 (0.9800) D(x): 0.5838 D(G(z)): 0.3439 / 0.2647 Acc: 23.4375 (15.7667)\n",
      "[0/25][463/782] Loss_D: 1.0172 (1.0255) Loss_G: 1.0821 (0.9802) D(x): 0.4963 D(G(z)): 0.3715 / 0.3430 Acc: 18.7500 (15.7732)\n",
      "[0/25][464/782] Loss_D: 1.0168 (1.0255) Loss_G: 1.0741 (0.9804) D(x): 0.5750 D(G(z)): 0.4621 / 0.3286 Acc: 17.1875 (15.7762)\n",
      "[0/25][465/782] Loss_D: 0.7462 (1.0249) Loss_G: 1.1275 (0.9807) D(x): 0.5462 D(G(z)): 0.3508 / 0.3118 Acc: 18.7500 (15.7826)\n",
      "[0/25][466/782] Loss_D: 0.7731 (1.0243) Loss_G: 1.0449 (0.9809) D(x): 0.6330 D(G(z)): 0.4263 / 0.3216 Acc: 18.7500 (15.7889)\n",
      "[0/25][467/782] Loss_D: 1.0018 (1.0243) Loss_G: 1.2110 (0.9814) D(x): 0.5762 D(G(z)): 0.4229 / 0.3041 Acc: 12.5000 (15.7819)\n",
      "[0/25][468/782] Loss_D: 0.7949 (1.0238) Loss_G: 1.2290 (0.9819) D(x): 0.5692 D(G(z)): 0.3748 / 0.2744 Acc: 12.5000 (15.7749)\n",
      "[0/25][469/782] Loss_D: 0.9107 (1.0236) Loss_G: 0.8236 (0.9815) D(x): 0.4715 D(G(z)): 0.3344 / 0.3881 Acc: 15.6250 (15.7746)\n",
      "[0/25][470/782] Loss_D: 0.9674 (1.0234) Loss_G: 0.9853 (0.9815) D(x): 0.6635 D(G(z)): 0.5190 / 0.4031 Acc: 15.6250 (15.7743)\n",
      "[0/25][471/782] Loss_D: 0.8234 (1.0230) Loss_G: 1.1738 (0.9820) D(x): 0.5490 D(G(z)): 0.4164 / 0.3120 Acc: 25.0000 (15.7938)\n",
      "[0/25][472/782] Loss_D: 0.5670 (1.0221) Loss_G: 1.1982 (0.9824) D(x): 0.6659 D(G(z)): 0.3668 / 0.2996 Acc: 15.6250 (15.7935)\n",
      "[0/25][473/782] Loss_D: 0.7654 (1.0215) Loss_G: 0.9929 (0.9824) D(x): 0.5700 D(G(z)): 0.3699 / 0.3842 Acc: 25.0000 (15.8129)\n",
      "[0/25][474/782] Loss_D: 0.7224 (1.0209) Loss_G: 1.2619 (0.9830) D(x): 0.6178 D(G(z)): 0.4036 / 0.2980 Acc: 20.3125 (15.8224)\n",
      "[0/25][475/782] Loss_D: 0.7749 (1.0204) Loss_G: 1.2490 (0.9836) D(x): 0.5682 D(G(z)): 0.3477 / 0.2912 Acc: 12.5000 (15.8154)\n",
      "[0/25][476/782] Loss_D: 1.0656 (1.0205) Loss_G: 0.9867 (0.9836) D(x): 0.5358 D(G(z)): 0.4736 / 0.3540 Acc: 18.7500 (15.8215)\n",
      "[0/25][477/782] Loss_D: 0.6744 (1.0197) Loss_G: 1.2208 (0.9841) D(x): 0.6218 D(G(z)): 0.4550 / 0.2657 Acc: 28.1250 (15.8473)\n",
      "[0/25][478/782] Loss_D: 0.7991 (1.0193) Loss_G: 1.3128 (0.9848) D(x): 0.5928 D(G(z)): 0.3747 / 0.2780 Acc: 15.6250 (15.8468)\n",
      "[0/25][479/782] Loss_D: 0.8474 (1.0189) Loss_G: 0.9681 (0.9847) D(x): 0.5259 D(G(z)): 0.3423 / 0.3435 Acc: 15.6250 (15.8464)\n",
      "[0/25][480/782] Loss_D: 0.8544 (1.0186) Loss_G: 1.1165 (0.9850) D(x): 0.6198 D(G(z)): 0.4298 / 0.3402 Acc: 17.1875 (15.8491)\n",
      "[0/25][481/782] Loss_D: 0.7954 (1.0181) Loss_G: 0.8585 (0.9847) D(x): 0.6257 D(G(z)): 0.4316 / 0.3769 Acc: 12.5000 (15.8422)\n",
      "[0/25][482/782] Loss_D: 1.2523 (1.0186) Loss_G: 1.0431 (0.9849) D(x): 0.5524 D(G(z)): 0.5358 / 0.3498 Acc: 10.9375 (15.8320)\n",
      "[0/25][483/782] Loss_D: 1.0562 (1.0187) Loss_G: 1.1156 (0.9851) D(x): 0.5074 D(G(z)): 0.3844 / 0.3260 Acc: 7.8125 (15.8155)\n",
      "[0/25][484/782] Loss_D: 1.1703 (1.0190) Loss_G: 0.9468 (0.9851) D(x): 0.4802 D(G(z)): 0.4525 / 0.3732 Acc: 15.6250 (15.8151)\n",
      "[0/25][485/782] Loss_D: 1.2232 (1.0194) Loss_G: 0.8838 (0.9849) D(x): 0.4854 D(G(z)): 0.4817 / 0.3982 Acc: 14.0625 (15.8115)\n",
      "[0/25][486/782] Loss_D: 0.9241 (1.0192) Loss_G: 1.2442 (0.9854) D(x): 0.6053 D(G(z)): 0.4581 / 0.2785 Acc: 10.9375 (15.8015)\n",
      "[0/25][487/782] Loss_D: 0.8404 (1.0188) Loss_G: 1.1866 (0.9858) D(x): 0.5178 D(G(z)): 0.3535 / 0.3051 Acc: 20.3125 (15.8107)\n",
      "[0/25][488/782] Loss_D: 0.7976 (1.0184) Loss_G: 1.0144 (0.9859) D(x): 0.5821 D(G(z)): 0.3952 / 0.3318 Acc: 9.3750 (15.7975)\n",
      "[0/25][489/782] Loss_D: 1.0993 (1.0186) Loss_G: 0.8900 (0.9857) D(x): 0.4898 D(G(z)): 0.4424 / 0.3925 Acc: 17.1875 (15.8004)\n",
      "[0/25][490/782] Loss_D: 1.0552 (1.0186) Loss_G: 0.9190 (0.9855) D(x): 0.6062 D(G(z)): 0.5028 / 0.4030 Acc: 17.1875 (15.8032)\n",
      "[0/25][491/782] Loss_D: 0.7596 (1.0181) Loss_G: 1.1960 (0.9860) D(x): 0.5854 D(G(z)): 0.4031 / 0.3055 Acc: 21.8750 (15.8155)\n",
      "[0/25][492/782] Loss_D: 0.9348 (1.0179) Loss_G: 1.0694 (0.9861) D(x): 0.5539 D(G(z)): 0.4038 / 0.3253 Acc: 15.6250 (15.8152)\n",
      "[0/25][493/782] Loss_D: 0.9814 (1.0179) Loss_G: 0.9190 (0.9860) D(x): 0.5509 D(G(z)): 0.4767 / 0.3727 Acc: 26.5625 (15.8369)\n",
      "[0/25][494/782] Loss_D: 1.5822 (1.0190) Loss_G: 1.0705 (0.9862) D(x): 0.3943 D(G(z)): 0.4784 / 0.3470 Acc: 12.5000 (15.8302)\n",
      "[0/25][495/782] Loss_D: 1.4067 (1.0198) Loss_G: 1.0094 (0.9862) D(x): 0.4951 D(G(z)): 0.5494 / 0.3679 Acc: 14.0625 (15.8266)\n",
      "[0/25][496/782] Loss_D: 0.8779 (1.0195) Loss_G: 1.2703 (0.9868) D(x): 0.5223 D(G(z)): 0.3798 / 0.2948 Acc: 25.0000 (15.8451)\n",
      "[0/25][497/782] Loss_D: 1.2433 (1.0200) Loss_G: 1.1252 (0.9871) D(x): 0.5260 D(G(z)): 0.5020 / 0.3472 Acc: 23.4375 (15.8603)\n",
      "[0/25][498/782] Loss_D: 1.2666 (1.0204) Loss_G: 1.0333 (0.9871) D(x): 0.3909 D(G(z)): 0.3707 / 0.3615 Acc: 18.7500 (15.8661)\n",
      "[0/25][499/782] Loss_D: 1.3074 (1.0210) Loss_G: 0.7947 (0.9868) D(x): 0.4590 D(G(z)): 0.4474 / 0.4279 Acc: 10.9375 (15.8562)\n",
      "[0/25][500/782] Loss_D: 1.1301 (1.0212) Loss_G: 0.9301 (0.9866) D(x): 0.5894 D(G(z)): 0.5248 / 0.3909 Acc: 12.5000 (15.8496)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[0/25][501/782] Loss_D: 0.8377 (1.0209) Loss_G: 1.3768 (0.9874) D(x): 0.6090 D(G(z)): 0.3983 / 0.2797 Acc: 17.1875 (15.8522)\n",
      "[0/25][502/782] Loss_D: 1.0368 (1.0209) Loss_G: 1.0019 (0.9875) D(x): 0.4345 D(G(z)): 0.3244 / 0.3765 Acc: 23.4375 (15.8673)\n",
      "[0/25][503/782] Loss_D: 0.9138 (1.0207) Loss_G: 0.6664 (0.9868) D(x): 0.5471 D(G(z)): 0.4497 / 0.4775 Acc: 21.8750 (15.8792)\n",
      "[0/25][504/782] Loss_D: 1.0759 (1.0208) Loss_G: 0.8744 (0.9866) D(x): 0.5614 D(G(z)): 0.5142 / 0.3806 Acc: 15.6250 (15.8787)\n",
      "[0/25][505/782] Loss_D: 1.1481 (1.0211) Loss_G: 1.1783 (0.9870) D(x): 0.6107 D(G(z)): 0.5360 / 0.3297 Acc: 15.6250 (15.8782)\n",
      "[0/25][506/782] Loss_D: 1.1280 (1.0213) Loss_G: 1.0826 (0.9872) D(x): 0.4165 D(G(z)): 0.3625 / 0.3456 Acc: 20.3125 (15.8870)\n",
      "[0/25][507/782] Loss_D: 1.0618 (1.0213) Loss_G: 0.5805 (0.9864) D(x): 0.4580 D(G(z)): 0.4095 / 0.4756 Acc: 18.7500 (15.8926)\n",
      "[0/25][508/782] Loss_D: 1.2482 (1.0218) Loss_G: 0.7514 (0.9859) D(x): 0.5187 D(G(z)): 0.5439 / 0.4269 Acc: 21.8750 (15.9043)\n",
      "[0/25][509/782] Loss_D: 1.0189 (1.0218) Loss_G: 0.7176 (0.9854) D(x): 0.5165 D(G(z)): 0.4728 / 0.4326 Acc: 21.8750 (15.9161)\n",
      "[0/25][510/782] Loss_D: 1.1419 (1.0220) Loss_G: 0.8645 (0.9851) D(x): 0.5142 D(G(z)): 0.4926 / 0.3873 Acc: 14.0625 (15.9124)\n",
      "[0/25][511/782] Loss_D: 0.9707 (1.0219) Loss_G: 0.8908 (0.9850) D(x): 0.5356 D(G(z)): 0.4204 / 0.3968 Acc: 17.1875 (15.9149)\n",
      "[0/25][512/782] Loss_D: 0.9862 (1.0218) Loss_G: 1.0890 (0.9852) D(x): 0.5036 D(G(z)): 0.3965 / 0.3317 Acc: 18.7500 (15.9204)\n",
      "[0/25][513/782] Loss_D: 0.8388 (1.0215) Loss_G: 0.9217 (0.9850) D(x): 0.5599 D(G(z)): 0.4179 / 0.3821 Acc: 25.0000 (15.9381)\n",
      "[0/25][514/782] Loss_D: 0.9630 (1.0214) Loss_G: 0.7364 (0.9845) D(x): 0.5200 D(G(z)): 0.4554 / 0.4103 Acc: 25.0000 (15.9557)\n",
      "[0/25][515/782] Loss_D: 0.9729 (1.0213) Loss_G: 0.9741 (0.9845) D(x): 0.5208 D(G(z)): 0.4181 / 0.3568 Acc: 18.7500 (15.9611)\n",
      "[0/25][516/782] Loss_D: 0.9738 (1.0212) Loss_G: 0.6848 (0.9839) D(x): 0.5373 D(G(z)): 0.4515 / 0.4353 Acc: 18.7500 (15.9665)\n",
      "[0/25][517/782] Loss_D: 0.7859 (1.0207) Loss_G: 0.7947 (0.9836) D(x): 0.5781 D(G(z)): 0.4453 / 0.3916 Acc: 23.4375 (15.9809)\n",
      "[0/25][518/782] Loss_D: 1.0697 (1.0208) Loss_G: 0.8289 (0.9833) D(x): 0.5181 D(G(z)): 0.4648 / 0.4079 Acc: 17.1875 (15.9833)\n",
      "[0/25][519/782] Loss_D: 0.8762 (1.0206) Loss_G: 0.9155 (0.9832) D(x): 0.5510 D(G(z)): 0.4346 / 0.3598 Acc: 21.8750 (15.9946)\n",
      "[0/25][520/782] Loss_D: 1.1622 (1.0208) Loss_G: 0.6494 (0.9825) D(x): 0.4828 D(G(z)): 0.4753 / 0.4596 Acc: 21.8750 (16.0059)\n",
      "[0/25][521/782] Loss_D: 0.8269 (1.0205) Loss_G: 0.8243 (0.9822) D(x): 0.5912 D(G(z)): 0.4510 / 0.4060 Acc: 21.8750 (16.0171)\n",
      "[0/25][522/782] Loss_D: 0.9423 (1.0203) Loss_G: 0.8563 (0.9820) D(x): 0.5201 D(G(z)): 0.4371 / 0.3840 Acc: 20.3125 (16.0253)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/25][523/782] Loss_D: 0.8763 (1.0200) Loss_G: 0.8143 (0.9817) D(x): 0.5470 D(G(z)): 0.4415 / 0.3889 Acc: 23.4375 (16.0395)\n",
      "[0/25][524/782] Loss_D: 0.9596 (1.0199) Loss_G: 0.7475 (0.9812) D(x): 0.4965 D(G(z)): 0.4088 / 0.4300 Acc: 20.3125 (16.0476)\n",
      "[0/25][525/782] Loss_D: 0.7868 (1.0195) Loss_G: 0.7887 (0.9808) D(x): 0.5589 D(G(z)): 0.4343 / 0.4200 Acc: 23.4375 (16.0617)\n",
      "[0/25][526/782] Loss_D: 0.8182 (1.0191) Loss_G: 0.7621 (0.9804) D(x): 0.5582 D(G(z)): 0.4303 / 0.3965 Acc: 25.0000 (16.0786)\n",
      "[0/25][527/782] Loss_D: 0.6542 (1.0184) Loss_G: 1.0024 (0.9805) D(x): 0.6997 D(G(z)): 0.4566 / 0.3304 Acc: 17.1875 (16.0807)\n",
      "[0/25][528/782] Loss_D: 0.6542 (1.0177) Loss_G: 1.1390 (0.9808) D(x): 0.6037 D(G(z)): 0.3476 / 0.2960 Acc: 20.3125 (16.0887)\n",
      "[0/25][529/782] Loss_D: 0.9059 (1.0175) Loss_G: 0.8335 (0.9805) D(x): 0.5401 D(G(z)): 0.3897 / 0.3982 Acc: 12.5000 (16.0820)\n",
      "[0/25][530/782] Loss_D: 0.5785 (1.0167) Loss_G: 1.2141 (0.9809) D(x): 0.7567 D(G(z)): 0.4628 / 0.2669 Acc: 17.1875 (16.0840)\n",
      "[0/25][531/782] Loss_D: 0.5171 (1.0157) Loss_G: 1.2186 (0.9814) D(x): 0.6550 D(G(z)): 0.3714 / 0.2832 Acc: 25.0000 (16.1008)\n",
      "[0/25][532/782] Loss_D: 0.8362 (1.0154) Loss_G: 0.9592 (0.9813) D(x): 0.5183 D(G(z)): 0.3006 / 0.3559 Acc: 10.9375 (16.0911)\n",
      "[0/25][533/782] Loss_D: 0.9580 (1.0153) Loss_G: 0.9688 (0.9813) D(x): 0.5701 D(G(z)): 0.4559 / 0.3624 Acc: 10.9375 (16.0815)\n",
      "[0/25][534/782] Loss_D: 0.8164 (1.0149) Loss_G: 0.8366 (0.9810) D(x): 0.5425 D(G(z)): 0.4223 / 0.3881 Acc: 21.8750 (16.0923)\n",
      "[0/25][535/782] Loss_D: 0.8312 (1.0146) Loss_G: 1.2268 (0.9815) D(x): 0.6557 D(G(z)): 0.4857 / 0.2844 Acc: 20.3125 (16.1002)\n",
      "[0/25][536/782] Loss_D: 0.7729 (1.0141) Loss_G: 1.5667 (0.9826) D(x): 0.5974 D(G(z)): 0.4172 / 0.2204 Acc: 25.0000 (16.1167)\n",
      "[0/25][537/782] Loss_D: 0.9177 (1.0139) Loss_G: 1.0137 (0.9826) D(x): 0.4593 D(G(z)): 0.3033 / 0.3486 Acc: 17.1875 (16.1187)\n",
      "[0/25][538/782] Loss_D: 0.6875 (1.0133) Loss_G: 1.0978 (0.9829) D(x): 0.6350 D(G(z)): 0.4147 / 0.3195 Acc: 17.1875 (16.1207)\n",
      "[0/25][539/782] Loss_D: 0.7139 (1.0128) Loss_G: 1.1749 (0.9832) D(x): 0.6244 D(G(z)): 0.4094 / 0.3011 Acc: 29.6875 (16.1458)\n",
      "[0/25][540/782] Loss_D: 0.8772 (1.0125) Loss_G: 0.7908 (0.9829) D(x): 0.4795 D(G(z)): 0.3486 / 0.4333 Acc: 21.8750 (16.1564)\n",
      "[0/25][541/782] Loss_D: 0.7936 (1.0121) Loss_G: 0.8508 (0.9826) D(x): 0.6378 D(G(z)): 0.4669 / 0.3937 Acc: 20.3125 (16.1641)\n",
      "[0/25][542/782] Loss_D: 0.7336 (1.0116) Loss_G: 1.0569 (0.9828) D(x): 0.6520 D(G(z)): 0.4172 / 0.3379 Acc: 14.0625 (16.1602)\n",
      "[0/25][543/782] Loss_D: 0.6948 (1.0110) Loss_G: 0.9188 (0.9826) D(x): 0.6440 D(G(z)): 0.4102 / 0.3929 Acc: 21.8750 (16.1707)\n",
      "[0/25][544/782] Loss_D: 1.0341 (1.0111) Loss_G: 1.0193 (0.9827) D(x): 0.5695 D(G(z)): 0.5316 / 0.3451 Acc: 28.1250 (16.1927)\n",
      "[0/25][545/782] Loss_D: 0.9773 (1.0110) Loss_G: 1.0170 (0.9828) D(x): 0.4332 D(G(z)): 0.3820 / 0.3328 Acc: 21.8750 (16.2031)\n",
      "[0/25][546/782] Loss_D: 1.0632 (1.0111) Loss_G: 0.7799 (0.9824) D(x): 0.4921 D(G(z)): 0.4595 / 0.4294 Acc: 23.4375 (16.2163)\n",
      "[0/25][547/782] Loss_D: 1.0680 (1.0112) Loss_G: 0.7947 (0.9821) D(x): 0.5168 D(G(z)): 0.4381 / 0.4335 Acc: 15.6250 (16.2152)\n",
      "[0/25][548/782] Loss_D: 0.7749 (1.0108) Loss_G: 1.0184 (0.9821) D(x): 0.6397 D(G(z)): 0.4996 / 0.3481 Acc: 21.8750 (16.2255)\n",
      "[0/25][549/782] Loss_D: 1.1910 (1.0111) Loss_G: 0.9624 (0.9821) D(x): 0.4259 D(G(z)): 0.4469 / 0.3414 Acc: 18.7500 (16.2301)\n",
      "[0/25][550/782] Loss_D: 1.0367 (1.0112) Loss_G: 0.8139 (0.9818) D(x): 0.5590 D(G(z)): 0.5059 / 0.4073 Acc: 18.7500 (16.2347)\n",
      "[0/25][551/782] Loss_D: 1.1752 (1.0115) Loss_G: 0.9790 (0.9818) D(x): 0.4840 D(G(z)): 0.4551 / 0.3360 Acc: 10.9375 (16.2251)\n",
      "[0/25][552/782] Loss_D: 0.9172 (1.0113) Loss_G: 0.9474 (0.9817) D(x): 0.5417 D(G(z)): 0.4090 / 0.3649 Acc: 14.0625 (16.2212)\n",
      "[0/25][553/782] Loss_D: 1.1276 (1.0115) Loss_G: 0.6911 (0.9812) D(x): 0.5084 D(G(z)): 0.5206 / 0.4439 Acc: 21.8750 (16.2314)\n",
      "[0/25][554/782] Loss_D: 1.1095 (1.0117) Loss_G: 0.8040 (0.9809) D(x): 0.5092 D(G(z)): 0.4725 / 0.4227 Acc: 21.8750 (16.2416)\n",
      "[0/25][555/782] Loss_D: 0.9962 (1.0116) Loss_G: 0.9754 (0.9809) D(x): 0.5597 D(G(z)): 0.4862 / 0.3587 Acc: 20.3125 (16.2489)\n",
      "[0/25][556/782] Loss_D: 1.0777 (1.0118) Loss_G: 0.8743 (0.9807) D(x): 0.4907 D(G(z)): 0.4438 / 0.3845 Acc: 23.4375 (16.2618)\n",
      "[0/25][557/782] Loss_D: 1.2228 (1.0121) Loss_G: 0.8364 (0.9804) D(x): 0.4429 D(G(z)): 0.4217 / 0.4170 Acc: 17.1875 (16.2634)\n",
      "[0/25][558/782] Loss_D: 0.9020 (1.0119) Loss_G: 1.0240 (0.9805) D(x): 0.6195 D(G(z)): 0.5060 / 0.3472 Acc: 25.0000 (16.2791)\n",
      "[0/25][559/782] Loss_D: 1.1278 (1.0122) Loss_G: 0.8422 (0.9802) D(x): 0.5036 D(G(z)): 0.4712 / 0.3982 Acc: 17.1875 (16.2807)\n",
      "[0/25][560/782] Loss_D: 0.8160 (1.0118) Loss_G: 0.9574 (0.9802) D(x): 0.5148 D(G(z)): 0.3486 / 0.3664 Acc: 21.8750 (16.2907)\n",
      "[0/25][561/782] Loss_D: 1.1876 (1.0121) Loss_G: 0.9533 (0.9801) D(x): 0.5628 D(G(z)): 0.5211 / 0.4003 Acc: 10.9375 (16.2811)\n",
      "[0/25][562/782] Loss_D: 0.9011 (1.0119) Loss_G: 1.0049 (0.9802) D(x): 0.5816 D(G(z)): 0.4147 / 0.3536 Acc: 17.1875 (16.2827)\n",
      "[0/25][563/782] Loss_D: 1.0004 (1.0119) Loss_G: 0.8172 (0.9799) D(x): 0.6075 D(G(z)): 0.5084 / 0.3723 Acc: 9.3750 (16.2705)\n",
      "[0/25][564/782] Loss_D: 0.8812 (1.0117) Loss_G: 1.1376 (0.9802) D(x): 0.5134 D(G(z)): 0.3584 / 0.3206 Acc: 23.4375 (16.2832)\n",
      "[0/25][565/782] Loss_D: 1.1582 (1.0119) Loss_G: 0.9425 (0.9801) D(x): 0.4972 D(G(z)): 0.4717 / 0.3741 Acc: 14.0625 (16.2793)\n",
      "[0/25][566/782] Loss_D: 0.6881 (1.0114) Loss_G: 0.8965 (0.9800) D(x): 0.5836 D(G(z)): 0.3853 / 0.3636 Acc: 17.1875 (16.2809)\n",
      "[0/25][567/782] Loss_D: 0.5879 (1.0106) Loss_G: 0.7436 (0.9796) D(x): 0.5842 D(G(z)): 0.3717 / 0.4106 Acc: 25.0000 (16.2962)\n",
      "[0/25][568/782] Loss_D: 1.1885 (1.0109) Loss_G: 0.6726 (0.9790) D(x): 0.4305 D(G(z)): 0.4204 / 0.4709 Acc: 18.7500 (16.3005)\n",
      "[0/25][569/782] Loss_D: 1.0167 (1.0109) Loss_G: 0.7354 (0.9786) D(x): 0.5570 D(G(z)): 0.4719 / 0.4412 Acc: 20.3125 (16.3076)\n",
      "[0/25][570/782] Loss_D: 0.8463 (1.0106) Loss_G: 1.0040 (0.9786) D(x): 0.6765 D(G(z)): 0.5388 / 0.3250 Acc: 20.3125 (16.3146)\n",
      "[0/25][571/782] Loss_D: 0.9886 (1.0106) Loss_G: 0.9537 (0.9786) D(x): 0.4278 D(G(z)): 0.3570 / 0.3615 Acc: 34.3750 (16.3462)\n",
      "[0/25][572/782] Loss_D: 0.8525 (1.0103) Loss_G: 0.9197 (0.9785) D(x): 0.5472 D(G(z)): 0.4219 / 0.3545 Acc: 25.0000 (16.3613)\n",
      "[0/25][573/782] Loss_D: 0.9322 (1.0102) Loss_G: 0.8466 (0.9783) D(x): 0.5184 D(G(z)): 0.4383 / 0.3752 Acc: 25.0000 (16.3763)\n",
      "[0/25][574/782] Loss_D: 0.8633 (1.0099) Loss_G: 0.9384 (0.9782) D(x): 0.6294 D(G(z)): 0.5164 / 0.3583 Acc: 21.8750 (16.3859)\n",
      "[0/25][575/782] Loss_D: 0.8902 (1.0097) Loss_G: 0.8809 (0.9780) D(x): 0.4918 D(G(z)): 0.4002 / 0.3814 Acc: 26.5625 (16.4035)\n",
      "[0/25][576/782] Loss_D: 1.0074 (1.0097) Loss_G: 1.0227 (0.9781) D(x): 0.4970 D(G(z)): 0.4191 / 0.3328 Acc: 18.7500 (16.4076)\n",
      "[0/25][577/782] Loss_D: 0.8479 (1.0094) Loss_G: 0.6370 (0.9775) D(x): 0.5385 D(G(z)): 0.4160 / 0.4680 Acc: 25.0000 (16.4225)\n",
      "[0/25][578/782] Loss_D: 0.9128 (1.0093) Loss_G: 0.6650 (0.9770) D(x): 0.5786 D(G(z)): 0.4365 / 0.4466 Acc: 17.1875 (16.4238)\n",
      "[0/25][579/782] Loss_D: 0.8938 (1.0091) Loss_G: 0.9250 (0.9769) D(x): 0.5977 D(G(z)): 0.4763 / 0.3674 Acc: 21.8750 (16.4332)\n",
      "[0/25][580/782] Loss_D: 1.0705 (1.0092) Loss_G: 0.9254 (0.9768) D(x): 0.5058 D(G(z)): 0.4780 / 0.3552 Acc: 20.3125 (16.4399)\n",
      "[0/25][581/782] Loss_D: 0.7469 (1.0087) Loss_G: 0.9537 (0.9767) D(x): 0.5815 D(G(z)): 0.4445 / 0.3436 Acc: 25.0000 (16.4546)\n",
      "[0/25][582/782] Loss_D: 1.0765 (1.0088) Loss_G: 1.0993 (0.9770) D(x): 0.5028 D(G(z)): 0.4385 / 0.3092 Acc: 14.0625 (16.4505)\n",
      "[0/25][583/782] Loss_D: 0.6589 (1.0082) Loss_G: 1.0838 (0.9771) D(x): 0.6032 D(G(z)): 0.3536 / 0.3064 Acc: 18.7500 (16.4544)\n",
      "[0/25][584/782] Loss_D: 0.4675 (1.0073) Loss_G: 1.0833 (0.9773) D(x): 0.7039 D(G(z)): 0.3628 / 0.3201 Acc: 21.8750 (16.4637)\n",
      "[0/25][585/782] Loss_D: 0.5382 (1.0065) Loss_G: 1.2538 (0.9778) D(x): 0.6947 D(G(z)): 0.4030 / 0.2737 Acc: 20.3125 (16.4702)\n",
      "[0/25][586/782] Loss_D: 0.4524 (1.0056) Loss_G: 1.3674 (0.9785) D(x): 0.6712 D(G(z)): 0.3274 / 0.2419 Acc: 25.0000 (16.4848)\n",
      "[0/25][587/782] Loss_D: 0.4679 (1.0047) Loss_G: 1.2502 (0.9789) D(x): 0.6948 D(G(z)): 0.2927 / 0.2814 Acc: 14.0625 (16.4807)\n",
      "[0/25][588/782] Loss_D: 0.5678 (1.0039) Loss_G: 0.9130 (0.9788) D(x): 0.6151 D(G(z)): 0.3465 / 0.3592 Acc: 18.7500 (16.4845)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/25][589/782] Loss_D: 0.6615 (1.0033) Loss_G: 1.1987 (0.9792) D(x): 0.6760 D(G(z)): 0.4080 / 0.2715 Acc: 9.3750 (16.4725)\n",
      "[0/25][590/782] Loss_D: 0.7525 (1.0029) Loss_G: 1.2723 (0.9797) D(x): 0.6577 D(G(z)): 0.4556 / 0.2673 Acc: 17.1875 (16.4737)\n",
      "[0/25][591/782] Loss_D: 0.5691 (1.0022) Loss_G: 0.9340 (0.9796) D(x): 0.5711 D(G(z)): 0.2865 / 0.3424 Acc: 12.5000 (16.4670)\n",
      "[0/25][592/782] Loss_D: 0.9190 (1.0020) Loss_G: 0.6345 (0.9790) D(x): 0.4870 D(G(z)): 0.3612 / 0.4597 Acc: 20.3125 (16.4734)\n",
      "[0/25][593/782] Loss_D: 0.8954 (1.0019) Loss_G: 0.7231 (0.9786) D(x): 0.6498 D(G(z)): 0.5477 / 0.4231 Acc: 20.3125 (16.4799)\n",
      "[0/25][594/782] Loss_D: 0.7020 (1.0014) Loss_G: 1.3073 (0.9791) D(x): 0.6911 D(G(z)): 0.4509 / 0.2423 Acc: 23.4375 (16.4916)\n",
      "[0/25][595/782] Loss_D: 1.1136 (1.0016) Loss_G: 0.7105 (0.9787) D(x): 0.3788 D(G(z)): 0.2995 / 0.4279 Acc: 17.1875 (16.4928)\n",
      "[0/25][596/782] Loss_D: 0.9404 (1.0014) Loss_G: 0.9015 (0.9786) D(x): 0.7218 D(G(z)): 0.5692 / 0.3739 Acc: 10.9375 (16.4835)\n",
      "[0/25][597/782] Loss_D: 0.6444 (1.0009) Loss_G: 1.1383 (0.9788) D(x): 0.6256 D(G(z)): 0.3914 / 0.3003 Acc: 18.7500 (16.4872)\n",
      "[0/25][598/782] Loss_D: 0.9071 (1.0007) Loss_G: 0.7190 (0.9784) D(x): 0.5305 D(G(z)): 0.3820 / 0.4171 Acc: 10.9375 (16.4780)\n",
      "[0/25][599/782] Loss_D: 0.7669 (1.0003) Loss_G: 0.8069 (0.9781) D(x): 0.6115 D(G(z)): 0.3839 / 0.4204 Acc: 10.9375 (16.4688)\n",
      "[0/25][600/782] Loss_D: 0.8836 (1.0001) Loss_G: 0.7411 (0.9777) D(x): 0.6013 D(G(z)): 0.4793 / 0.4122 Acc: 14.0625 (16.4647)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[0/25][601/782] Loss_D: 0.9044 (1.0000) Loss_G: 1.0038 (0.9778) D(x): 0.6704 D(G(z)): 0.5434 / 0.3369 Acc: 14.0625 (16.4608)\n",
      "[0/25][602/782] Loss_D: 0.9798 (0.9999) Loss_G: 0.9533 (0.9777) D(x): 0.4151 D(G(z)): 0.3336 / 0.3397 Acc: 25.0000 (16.4749)\n",
      "[0/25][603/782] Loss_D: 0.9028 (0.9998) Loss_G: 0.6573 (0.9772) D(x): 0.4930 D(G(z)): 0.3769 / 0.4482 Acc: 17.1875 (16.4761)\n",
      "[0/25][604/782] Loss_D: 0.7744 (0.9994) Loss_G: 0.8186 (0.9769) D(x): 0.6616 D(G(z)): 0.4456 / 0.4018 Acc: 15.6250 (16.4747)\n",
      "[0/25][605/782] Loss_D: 0.8021 (0.9991) Loss_G: 0.9022 (0.9768) D(x): 0.7137 D(G(z)): 0.5195 / 0.3637 Acc: 18.7500 (16.4784)\n",
      "[0/25][606/782] Loss_D: 0.9411 (0.9990) Loss_G: 1.0226 (0.9769) D(x): 0.5281 D(G(z)): 0.4100 / 0.3403 Acc: 23.4375 (16.4899)\n",
      "[0/25][607/782] Loss_D: 0.9057 (0.9988) Loss_G: 0.8656 (0.9767) D(x): 0.5908 D(G(z)): 0.4287 / 0.4039 Acc: 12.5000 (16.4833)\n",
      "[0/25][608/782] Loss_D: 0.9298 (0.9987) Loss_G: 0.9430 (0.9766) D(x): 0.4540 D(G(z)): 0.3290 / 0.3612 Acc: 26.5625 (16.4999)\n",
      "[0/25][609/782] Loss_D: 0.8366 (0.9984) Loss_G: 0.6769 (0.9761) D(x): 0.6219 D(G(z)): 0.4918 / 0.4261 Acc: 18.7500 (16.5036)\n",
      "[0/25][610/782] Loss_D: 0.9335 (0.9983) Loss_G: 0.7145 (0.9757) D(x): 0.4774 D(G(z)): 0.3799 / 0.4202 Acc: 20.3125 (16.5098)\n",
      "[0/25][611/782] Loss_D: 0.8030 (0.9980) Loss_G: 0.9130 (0.9756) D(x): 0.6603 D(G(z)): 0.5090 / 0.3626 Acc: 28.1250 (16.5288)\n",
      "[0/25][612/782] Loss_D: 0.6703 (0.9975) Loss_G: 0.8895 (0.9755) D(x): 0.6487 D(G(z)): 0.4751 / 0.3607 Acc: 25.0000 (16.5426)\n",
      "[0/25][613/782] Loss_D: 0.8452 (0.9972) Loss_G: 0.9178 (0.9754) D(x): 0.4682 D(G(z)): 0.3180 / 0.3556 Acc: 17.1875 (16.5437)\n",
      "[0/25][614/782] Loss_D: 0.7866 (0.9969) Loss_G: 1.0210 (0.9755) D(x): 0.5808 D(G(z)): 0.3876 / 0.3620 Acc: 28.1250 (16.5625)\n",
      "[0/25][615/782] Loss_D: 0.9672 (0.9968) Loss_G: 0.7842 (0.9751) D(x): 0.5607 D(G(z)): 0.4779 / 0.4041 Acc: 20.3125 (16.5686)\n",
      "[0/25][616/782] Loss_D: 1.1406 (0.9971) Loss_G: 0.7076 (0.9747) D(x): 0.5034 D(G(z)): 0.4629 / 0.4636 Acc: 17.1875 (16.5696)\n",
      "[0/25][617/782] Loss_D: 0.5609 (0.9964) Loss_G: 0.8400 (0.9745) D(x): 0.6301 D(G(z)): 0.3734 / 0.3423 Acc: 15.6250 (16.5681)\n",
      "[0/25][618/782] Loss_D: 0.9445 (0.9963) Loss_G: 1.0332 (0.9746) D(x): 0.6143 D(G(z)): 0.4789 / 0.3473 Acc: 17.1875 (16.5691)\n",
      "[0/25][619/782] Loss_D: 1.0323 (0.9963) Loss_G: 1.1453 (0.9749) D(x): 0.5741 D(G(z)): 0.4418 / 0.3234 Acc: 7.8125 (16.5549)\n",
      "[0/25][620/782] Loss_D: 0.8968 (0.9962) Loss_G: 0.7758 (0.9745) D(x): 0.4779 D(G(z)): 0.3928 / 0.4034 Acc: 20.3125 (16.5610)\n",
      "[0/25][621/782] Loss_D: 1.1193 (0.9964) Loss_G: 0.7864 (0.9742) D(x): 0.5583 D(G(z)): 0.5328 / 0.4181 Acc: 23.4375 (16.5720)\n",
      "[0/25][622/782] Loss_D: 1.0950 (0.9965) Loss_G: 0.8825 (0.9741) D(x): 0.5617 D(G(z)): 0.4867 / 0.3979 Acc: 18.7500 (16.5755)\n",
      "[0/25][623/782] Loss_D: 1.1121 (0.9967) Loss_G: 0.7884 (0.9738) D(x): 0.4296 D(G(z)): 0.4168 / 0.4144 Acc: 23.4375 (16.5865)\n",
      "[0/25][624/782] Loss_D: 0.8551 (0.9965) Loss_G: 0.8743 (0.9736) D(x): 0.6121 D(G(z)): 0.4648 / 0.4179 Acc: 25.0000 (16.6000)\n",
      "[0/25][625/782] Loss_D: 0.8199 (0.9962) Loss_G: 0.8009 (0.9734) D(x): 0.5284 D(G(z)): 0.4025 / 0.3966 Acc: 28.1250 (16.6184)\n",
      "[0/25][626/782] Loss_D: 0.8901 (0.9960) Loss_G: 0.9473 (0.9733) D(x): 0.6283 D(G(z)): 0.4629 / 0.3762 Acc: 17.1875 (16.6193)\n",
      "[0/25][627/782] Loss_D: 1.0396 (0.9961) Loss_G: 1.1814 (0.9736) D(x): 0.6089 D(G(z)): 0.4953 / 0.3059 Acc: 18.7500 (16.6227)\n",
      "[0/25][628/782] Loss_D: 0.9785 (0.9961) Loss_G: 0.7329 (0.9733) D(x): 0.4818 D(G(z)): 0.3664 / 0.4445 Acc: 25.0000 (16.6360)\n",
      "[0/25][629/782] Loss_D: 1.0740 (0.9962) Loss_G: 0.8315 (0.9730) D(x): 0.6134 D(G(z)): 0.5303 / 0.4154 Acc: 15.6250 (16.6344)\n",
      "[0/25][630/782] Loss_D: 0.7142 (0.9958) Loss_G: 1.0941 (0.9732) D(x): 0.6371 D(G(z)): 0.3950 / 0.3422 Acc: 20.3125 (16.6403)\n",
      "[0/25][631/782] Loss_D: 0.9908 (0.9957) Loss_G: 0.9786 (0.9732) D(x): 0.5474 D(G(z)): 0.4622 / 0.3668 Acc: 25.0000 (16.6535)\n",
      "[0/25][632/782] Loss_D: 0.8920 (0.9956) Loss_G: 1.2897 (0.9737) D(x): 0.5791 D(G(z)): 0.4748 / 0.2860 Acc: 28.1250 (16.6716)\n",
      "[0/25][633/782] Loss_D: 0.9443 (0.9955) Loss_G: 0.8670 (0.9736) D(x): 0.5025 D(G(z)): 0.3568 / 0.3879 Acc: 14.0625 (16.6675)\n",
      "[0/25][634/782] Loss_D: 1.0368 (0.9956) Loss_G: 0.6362 (0.9730) D(x): 0.5360 D(G(z)): 0.4737 / 0.4813 Acc: 23.4375 (16.6781)\n",
      "[0/25][635/782] Loss_D: 1.1741 (0.9958) Loss_G: 0.8755 (0.9729) D(x): 0.4661 D(G(z)): 0.5365 / 0.3893 Acc: 34.3750 (16.7060)\n",
      "[0/25][636/782] Loss_D: 1.1255 (0.9961) Loss_G: 0.6869 (0.9724) D(x): 0.5039 D(G(z)): 0.4873 / 0.4401 Acc: 20.3125 (16.7116)\n",
      "[0/25][637/782] Loss_D: 0.7944 (0.9957) Loss_G: 1.0079 (0.9725) D(x): 0.6069 D(G(z)): 0.4596 / 0.3438 Acc: 29.6875 (16.7320)\n",
      "[0/25][638/782] Loss_D: 0.9643 (0.9957) Loss_G: 0.4803 (0.9717) D(x): 0.4317 D(G(z)): 0.4102 / 0.4750 Acc: 23.4375 (16.7425)\n",
      "[0/25][639/782] Loss_D: 1.0766 (0.9958) Loss_G: 0.9210 (0.9716) D(x): 0.6121 D(G(z)): 0.5502 / 0.3980 Acc: 21.8750 (16.7505)\n",
      "[0/25][640/782] Loss_D: 0.9233 (0.9957) Loss_G: 0.9331 (0.9716) D(x): 0.5641 D(G(z)): 0.4584 / 0.3662 Acc: 23.4375 (16.7609)\n",
      "[0/25][641/782] Loss_D: 1.0942 (0.9959) Loss_G: 0.7703 (0.9713) D(x): 0.4580 D(G(z)): 0.3979 / 0.4103 Acc: 9.3750 (16.7494)\n",
      "[0/25][642/782] Loss_D: 0.7495 (0.9955) Loss_G: 0.7403 (0.9709) D(x): 0.6462 D(G(z)): 0.4471 / 0.4288 Acc: 15.6250 (16.7477)\n",
      "[0/25][643/782] Loss_D: 0.7845 (0.9951) Loss_G: 0.8917 (0.9708) D(x): 0.5993 D(G(z)): 0.4226 / 0.3711 Acc: 14.0625 (16.7435)\n",
      "[0/25][644/782] Loss_D: 1.0027 (0.9952) Loss_G: 0.8019 (0.9705) D(x): 0.5149 D(G(z)): 0.4452 / 0.3928 Acc: 17.1875 (16.7442)\n",
      "[0/25][645/782] Loss_D: 0.9220 (0.9950) Loss_G: 0.8228 (0.9703) D(x): 0.5283 D(G(z)): 0.4092 / 0.3887 Acc: 15.6250 (16.7425)\n",
      "[0/25][646/782] Loss_D: 0.8520 (0.9948) Loss_G: 0.7495 (0.9700) D(x): 0.5223 D(G(z)): 0.4462 / 0.3889 Acc: 26.5625 (16.7576)\n",
      "[0/25][647/782] Loss_D: 0.9456 (0.9947) Loss_G: 0.8685 (0.9698) D(x): 0.5700 D(G(z)): 0.4816 / 0.3609 Acc: 18.7500 (16.7607)\n",
      "[0/25][648/782] Loss_D: 0.7657 (0.9944) Loss_G: 0.9785 (0.9698) D(x): 0.5597 D(G(z)): 0.3874 / 0.3572 Acc: 29.6875 (16.7806)\n",
      "[0/25][649/782] Loss_D: 1.0284 (0.9944) Loss_G: 0.7560 (0.9695) D(x): 0.5097 D(G(z)): 0.4148 / 0.4282 Acc: 14.0625 (16.7764)\n",
      "[0/25][650/782] Loss_D: 0.9964 (0.9944) Loss_G: 1.0261 (0.9696) D(x): 0.5741 D(G(z)): 0.4639 / 0.3458 Acc: 18.7500 (16.7795)\n",
      "[0/25][651/782] Loss_D: 0.8629 (0.9942) Loss_G: 0.7822 (0.9693) D(x): 0.5729 D(G(z)): 0.4394 / 0.4110 Acc: 18.7500 (16.7825)\n",
      "[0/25][652/782] Loss_D: 0.8914 (0.9941) Loss_G: 0.9209 (0.9692) D(x): 0.6031 D(G(z)): 0.4552 / 0.3941 Acc: 21.8750 (16.7903)\n",
      "[0/25][653/782] Loss_D: 0.8032 (0.9938) Loss_G: 1.0746 (0.9694) D(x): 0.5793 D(G(z)): 0.4056 / 0.3233 Acc: 18.7500 (16.7933)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/25][654/782] Loss_D: 0.8686 (0.9936) Loss_G: 1.2462 (0.9698) D(x): 0.6278 D(G(z)): 0.4619 / 0.2905 Acc: 21.8750 (16.8010)\n",
      "[0/25][655/782] Loss_D: 0.8848 (0.9934) Loss_G: 0.8255 (0.9696) D(x): 0.5119 D(G(z)): 0.4184 / 0.3810 Acc: 23.4375 (16.8112)\n",
      "[0/25][656/782] Loss_D: 1.0508 (0.9935) Loss_G: 0.8328 (0.9694) D(x): 0.5046 D(G(z)): 0.4451 / 0.3942 Acc: 15.6250 (16.8094)\n",
      "[0/25][657/782] Loss_D: 0.7766 (0.9932) Loss_G: 1.1443 (0.9696) D(x): 0.5782 D(G(z)): 0.4313 / 0.3147 Acc: 20.3125 (16.8147)\n",
      "[0/25][658/782] Loss_D: 1.1711 (0.9935) Loss_G: 0.9428 (0.9696) D(x): 0.4866 D(G(z)): 0.5045 / 0.3780 Acc: 21.8750 (16.8224)\n",
      "[0/25][659/782] Loss_D: 1.2728 (0.9939) Loss_G: 0.6502 (0.9691) D(x): 0.4504 D(G(z)): 0.5173 / 0.4604 Acc: 21.8750 (16.8300)\n",
      "[0/25][660/782] Loss_D: 1.2388 (0.9943) Loss_G: 0.7037 (0.9687) D(x): 0.4889 D(G(z)): 0.5464 / 0.4323 Acc: 25.0000 (16.8424)\n",
      "[0/25][661/782] Loss_D: 1.2244 (0.9946) Loss_G: 0.8639 (0.9685) D(x): 0.4671 D(G(z)): 0.4984 / 0.3908 Acc: 14.0625 (16.8382)\n",
      "[0/25][662/782] Loss_D: 1.2107 (0.9949) Loss_G: 0.7863 (0.9683) D(x): 0.4748 D(G(z)): 0.5475 / 0.4230 Acc: 29.6875 (16.8576)\n",
      "[0/25][663/782] Loss_D: 0.8766 (0.9948) Loss_G: 1.0067 (0.9683) D(x): 0.5515 D(G(z)): 0.4523 / 0.3512 Acc: 29.6875 (16.8769)\n",
      "[0/25][664/782] Loss_D: 1.2025 (0.9951) Loss_G: 0.6823 (0.9679) D(x): 0.4575 D(G(z)): 0.4748 / 0.4325 Acc: 20.3125 (16.8820)\n",
      "[0/25][665/782] Loss_D: 0.7542 (0.9947) Loss_G: 0.7388 (0.9676) D(x): 0.5442 D(G(z)): 0.3860 / 0.4159 Acc: 21.8750 (16.8895)\n",
      "[0/25][666/782] Loss_D: 0.8495 (0.9945) Loss_G: 0.7075 (0.9672) D(x): 0.5399 D(G(z)): 0.4434 / 0.4289 Acc: 28.1250 (16.9064)\n",
      "[0/25][667/782] Loss_D: 0.7164 (0.9941) Loss_G: 0.9695 (0.9672) D(x): 0.6946 D(G(z)): 0.4632 / 0.3817 Acc: 28.1250 (16.9232)\n",
      "[0/25][668/782] Loss_D: 0.8014 (0.9938) Loss_G: 1.1843 (0.9675) D(x): 0.5629 D(G(z)): 0.4001 / 0.3079 Acc: 20.3125 (16.9283)\n",
      "[0/25][669/782] Loss_D: 0.7917 (0.9935) Loss_G: 1.0277 (0.9676) D(x): 0.6440 D(G(z)): 0.4485 / 0.3506 Acc: 20.3125 (16.9333)\n",
      "[0/25][670/782] Loss_D: 0.9272 (0.9934) Loss_G: 0.9501 (0.9676) D(x): 0.5387 D(G(z)): 0.3984 / 0.3818 Acc: 15.6250 (16.9314)\n",
      "[0/25][671/782] Loss_D: 0.6484 (0.9929) Loss_G: 1.0085 (0.9676) D(x): 0.5607 D(G(z)): 0.3350 / 0.3409 Acc: 26.5625 (16.9457)\n",
      "[0/25][672/782] Loss_D: 0.9140 (0.9928) Loss_G: 0.7497 (0.9673) D(x): 0.5709 D(G(z)): 0.5086 / 0.4073 Acc: 25.0000 (16.9577)\n",
      "[0/25][673/782] Loss_D: 1.0103 (0.9928) Loss_G: 0.7082 (0.9669) D(x): 0.5476 D(G(z)): 0.4940 / 0.4355 Acc: 20.3125 (16.9626)\n",
      "[0/25][674/782] Loss_D: 1.2638 (0.9932) Loss_G: 0.6815 (0.9665) D(x): 0.5324 D(G(z)): 0.5508 / 0.4342 Acc: 10.9375 (16.9537)\n",
      "[0/25][675/782] Loss_D: 1.0454 (0.9933) Loss_G: 0.6745 (0.9661) D(x): 0.5027 D(G(z)): 0.4736 / 0.4711 Acc: 29.6875 (16.9725)\n",
      "[0/25][676/782] Loss_D: 1.1506 (0.9935) Loss_G: 0.8462 (0.9659) D(x): 0.4403 D(G(z)): 0.4656 / 0.3770 Acc: 25.0000 (16.9844)\n",
      "[0/25][677/782] Loss_D: 1.1425 (0.9937) Loss_G: 0.5631 (0.9653) D(x): 0.4349 D(G(z)): 0.4629 / 0.4652 Acc: 21.8750 (16.9916)\n",
      "[0/25][678/782] Loss_D: 1.0807 (0.9938) Loss_G: 0.6710 (0.9648) D(x): 0.5533 D(G(z)): 0.5373 / 0.4631 Acc: 25.0000 (17.0034)\n",
      "[0/25][679/782] Loss_D: 0.9002 (0.9937) Loss_G: 0.7703 (0.9646) D(x): 0.5980 D(G(z)): 0.5161 / 0.4128 Acc: 20.3125 (17.0083)\n",
      "[0/25][680/782] Loss_D: 1.0442 (0.9938) Loss_G: 0.9220 (0.9645) D(x): 0.4408 D(G(z)): 0.4112 / 0.3582 Acc: 26.5625 (17.0223)\n",
      "[0/25][681/782] Loss_D: 1.0548 (0.9939) Loss_G: 0.7725 (0.9642) D(x): 0.4519 D(G(z)): 0.4060 / 0.4118 Acc: 20.3125 (17.0271)\n",
      "[0/25][682/782] Loss_D: 0.8723 (0.9937) Loss_G: 0.6820 (0.9638) D(x): 0.5393 D(G(z)): 0.4527 / 0.4388 Acc: 25.0000 (17.0388)\n",
      "[0/25][683/782] Loss_D: 0.7604 (0.9933) Loss_G: 0.7713 (0.9635) D(x): 0.6167 D(G(z)): 0.4664 / 0.4134 Acc: 25.0000 (17.0504)\n",
      "[0/25][684/782] Loss_D: 0.7429 (0.9930) Loss_G: 0.9083 (0.9634) D(x): 0.6321 D(G(z)): 0.4757 / 0.3425 Acc: 25.0000 (17.0620)\n",
      "[0/25][685/782] Loss_D: 0.9049 (0.9929) Loss_G: 0.8813 (0.9633) D(x): 0.4498 D(G(z)): 0.3760 / 0.3781 Acc: 18.7500 (17.0645)\n",
      "[0/25][686/782] Loss_D: 0.9556 (0.9928) Loss_G: 0.8266 (0.9631) D(x): 0.5205 D(G(z)): 0.4471 / 0.4114 Acc: 21.8750 (17.0715)\n",
      "[0/25][687/782] Loss_D: 0.9945 (0.9928) Loss_G: 0.8659 (0.9630) D(x): 0.5417 D(G(z)): 0.4948 / 0.3796 Acc: 23.4375 (17.0808)\n",
      "[0/25][688/782] Loss_D: 1.1644 (0.9930) Loss_G: 0.7944 (0.9627) D(x): 0.4240 D(G(z)): 0.4673 / 0.3670 Acc: 20.3125 (17.0854)\n",
      "[0/25][689/782] Loss_D: 1.5850 (0.9939) Loss_G: 0.5234 (0.9621) D(x): 0.3402 D(G(z)): 0.5125 / 0.5300 Acc: 23.4375 (17.0947)\n",
      "[0/25][690/782] Loss_D: 1.1397 (0.9941) Loss_G: 0.4875 (0.9614) D(x): 0.5316 D(G(z)): 0.5803 / 0.4975 Acc: 26.5625 (17.1084)\n",
      "[0/25][691/782] Loss_D: 1.1298 (0.9943) Loss_G: 0.8417 (0.9612) D(x): 0.5732 D(G(z)): 0.5814 / 0.3829 Acc: 23.4375 (17.1175)\n",
      "[0/25][692/782] Loss_D: 1.0466 (0.9944) Loss_G: 0.9843 (0.9613) D(x): 0.4050 D(G(z)): 0.4097 / 0.3353 Acc: 29.6875 (17.1356)\n",
      "[0/25][693/782] Loss_D: 0.8987 (0.9943) Loss_G: 0.5882 (0.9607) D(x): 0.4709 D(G(z)): 0.3964 / 0.4404 Acc: 17.1875 (17.1357)\n",
      "[0/25][694/782] Loss_D: 0.8054 (0.9940) Loss_G: 0.6803 (0.9603) D(x): 0.5046 D(G(z)): 0.4583 / 0.4514 Acc: 37.5000 (17.1650)\n",
      "[0/25][695/782] Loss_D: 1.0110 (0.9940) Loss_G: 0.7670 (0.9601) D(x): 0.5352 D(G(z)): 0.5080 / 0.3935 Acc: 15.6250 (17.1628)\n",
      "[0/25][696/782] Loss_D: 0.9226 (0.9939) Loss_G: 0.7247 (0.9597) D(x): 0.4818 D(G(z)): 0.4522 / 0.4053 Acc: 29.6875 (17.1808)\n",
      "[0/25][697/782] Loss_D: 1.0753 (0.9940) Loss_G: 0.6508 (0.9593) D(x): 0.4868 D(G(z)): 0.4581 / 0.4658 Acc: 17.1875 (17.1808)\n",
      "[0/25][698/782] Loss_D: 0.8383 (0.9938) Loss_G: 0.6274 (0.9588) D(x): 0.5519 D(G(z)): 0.4392 / 0.4437 Acc: 15.6250 (17.1786)\n",
      "[0/25][699/782] Loss_D: 0.9260 (0.9937) Loss_G: 0.8180 (0.9586) D(x): 0.5900 D(G(z)): 0.4785 / 0.4076 Acc: 21.8750 (17.1853)\n",
      "[0/25][700/782] Loss_D: 0.7960 (0.9934) Loss_G: 0.7039 (0.9582) D(x): 0.5829 D(G(z)): 0.4399 / 0.4210 Acc: 18.7500 (17.1875)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[0/25][701/782] Loss_D: 0.6755 (0.9930) Loss_G: 0.7687 (0.9580) D(x): 0.5415 D(G(z)): 0.4383 / 0.3694 Acc: 29.6875 (17.2053)\n",
      "[0/25][702/782] Loss_D: 0.8254 (0.9927) Loss_G: 0.6622 (0.9575) D(x): 0.5390 D(G(z)): 0.4131 / 0.4165 Acc: 18.7500 (17.2075)\n",
      "[0/25][703/782] Loss_D: 0.6987 (0.9923) Loss_G: 0.6165 (0.9571) D(x): 0.5710 D(G(z)): 0.4441 / 0.4427 Acc: 21.8750 (17.2141)\n",
      "[0/25][704/782] Loss_D: 0.9387 (0.9922) Loss_G: 0.7817 (0.9568) D(x): 0.5492 D(G(z)): 0.4546 / 0.4304 Acc: 21.8750 (17.2207)\n",
      "[0/25][705/782] Loss_D: 1.0095 (0.9923) Loss_G: 0.8842 (0.9567) D(x): 0.5183 D(G(z)): 0.4536 / 0.3812 Acc: 18.7500 (17.2229)\n",
      "[0/25][706/782] Loss_D: 0.9008 (0.9921) Loss_G: 0.8564 (0.9566) D(x): 0.5446 D(G(z)): 0.5052 / 0.3211 Acc: 20.3125 (17.2273)\n",
      "[0/25][707/782] Loss_D: 0.9189 (0.9920) Loss_G: 0.7695 (0.9563) D(x): 0.4594 D(G(z)): 0.4000 / 0.3953 Acc: 25.0000 (17.2383)\n",
      "[0/25][708/782] Loss_D: 0.9409 (0.9920) Loss_G: 0.5798 (0.9558) D(x): 0.5004 D(G(z)): 0.4108 / 0.4859 Acc: 15.6250 (17.2360)\n",
      "[0/25][709/782] Loss_D: 0.8571 (0.9918) Loss_G: 0.7427 (0.9555) D(x): 0.5858 D(G(z)): 0.4364 / 0.4387 Acc: 17.1875 (17.2359)\n",
      "[0/25][710/782] Loss_D: 0.7593 (0.9914) Loss_G: 0.7164 (0.9551) D(x): 0.5600 D(G(z)): 0.4434 / 0.4082 Acc: 21.8750 (17.2424)\n",
      "[0/25][711/782] Loss_D: 0.6965 (0.9910) Loss_G: 0.8465 (0.9550) D(x): 0.6059 D(G(z)): 0.4452 / 0.3788 Acc: 26.5625 (17.2555)\n",
      "[0/25][712/782] Loss_D: 0.7552 (0.9907) Loss_G: 0.9014 (0.9549) D(x): 0.5704 D(G(z)): 0.3827 / 0.3769 Acc: 21.8750 (17.2620)\n",
      "[0/25][713/782] Loss_D: 0.8175 (0.9904) Loss_G: 0.7530 (0.9546) D(x): 0.5396 D(G(z)): 0.4322 / 0.4210 Acc: 26.5625 (17.2750)\n",
      "[0/25][714/782] Loss_D: 0.8553 (0.9903) Loss_G: 1.0368 (0.9547) D(x): 0.5560 D(G(z)): 0.4294 / 0.3321 Acc: 17.1875 (17.2749)\n",
      "[0/25][715/782] Loss_D: 0.5917 (0.9897) Loss_G: 0.9651 (0.9548) D(x): 0.6144 D(G(z)): 0.4000 / 0.3078 Acc: 20.3125 (17.2792)\n",
      "[0/25][716/782] Loss_D: 0.8232 (0.9895) Loss_G: 0.6766 (0.9544) D(x): 0.5112 D(G(z)): 0.3673 / 0.4647 Acc: 25.0000 (17.2899)\n",
      "[0/25][717/782] Loss_D: 0.7240 (0.9891) Loss_G: 0.8915 (0.9543) D(x): 0.6289 D(G(z)): 0.5441 / 0.3420 Acc: 35.9375 (17.3159)\n",
      "[0/25][718/782] Loss_D: 0.8343 (0.9889) Loss_G: 1.1021 (0.9545) D(x): 0.5794 D(G(z)): 0.4150 / 0.2960 Acc: 14.0625 (17.3114)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/25][719/782] Loss_D: 0.7653 (0.9886) Loss_G: 0.9914 (0.9545) D(x): 0.5442 D(G(z)): 0.4089 / 0.3290 Acc: 25.0000 (17.3220)\n",
      "[0/25][720/782] Loss_D: 0.9525 (0.9885) Loss_G: 1.0823 (0.9547) D(x): 0.4791 D(G(z)): 0.4094 / 0.3284 Acc: 25.0000 (17.3327)\n",
      "[0/25][721/782] Loss_D: 0.6091 (0.9880) Loss_G: 0.5393 (0.9541) D(x): 0.5262 D(G(z)): 0.3441 / 0.4570 Acc: 21.8750 (17.3390)\n",
      "[0/25][722/782] Loss_D: 0.8457 (0.9878) Loss_G: 0.5824 (0.9536) D(x): 0.6075 D(G(z)): 0.4686 / 0.4992 Acc: 17.1875 (17.3388)\n",
      "[0/25][723/782] Loss_D: 0.7651 (0.9875) Loss_G: 0.8456 (0.9535) D(x): 0.6185 D(G(z)): 0.4866 / 0.3734 Acc: 15.6250 (17.3364)\n",
      "[0/25][724/782] Loss_D: 0.7289 (0.9871) Loss_G: 1.2140 (0.9538) D(x): 0.6124 D(G(z)): 0.3982 / 0.3077 Acc: 21.8750 (17.3427)\n",
      "[0/25][725/782] Loss_D: 0.8323 (0.9869) Loss_G: 1.1844 (0.9542) D(x): 0.5681 D(G(z)): 0.4415 / 0.2807 Acc: 18.7500 (17.3446)\n",
      "[0/25][726/782] Loss_D: 0.7030 (0.9865) Loss_G: 1.1015 (0.9544) D(x): 0.5648 D(G(z)): 0.3910 / 0.3299 Acc: 26.5625 (17.3573)\n",
      "[0/25][727/782] Loss_D: 1.1562 (0.9868) Loss_G: 0.6799 (0.9540) D(x): 0.4380 D(G(z)): 0.4131 / 0.4714 Acc: 20.3125 (17.3613)\n",
      "[0/25][728/782] Loss_D: 0.6779 (0.9863) Loss_G: 0.6953 (0.9536) D(x): 0.6294 D(G(z)): 0.4535 / 0.4225 Acc: 25.0000 (17.3718)\n",
      "[0/25][729/782] Loss_D: 1.0131 (0.9864) Loss_G: 1.0030 (0.9537) D(x): 0.6607 D(G(z)): 0.6066 / 0.3286 Acc: 21.8750 (17.3780)\n",
      "[0/25][730/782] Loss_D: 0.7581 (0.9861) Loss_G: 1.0285 (0.9538) D(x): 0.5027 D(G(z)): 0.3775 / 0.3047 Acc: 25.0000 (17.3884)\n",
      "[0/25][731/782] Loss_D: 0.9759 (0.9861) Loss_G: 0.9228 (0.9538) D(x): 0.5071 D(G(z)): 0.4424 / 0.3610 Acc: 29.6875 (17.4052)\n",
      "[0/25][732/782] Loss_D: 0.8616 (0.9859) Loss_G: 0.8980 (0.9537) D(x): 0.5007 D(G(z)): 0.4129 / 0.3607 Acc: 23.4375 (17.4135)\n",
      "[0/25][733/782] Loss_D: 0.7625 (0.9856) Loss_G: 0.7809 (0.9534) D(x): 0.5356 D(G(z)): 0.3981 / 0.4012 Acc: 25.0000 (17.4238)\n",
      "[0/25][734/782] Loss_D: 0.8978 (0.9855) Loss_G: 0.9548 (0.9534) D(x): 0.6353 D(G(z)): 0.5267 / 0.3411 Acc: 18.7500 (17.4256)\n",
      "[0/25][735/782] Loss_D: 0.7359 (0.9851) Loss_G: 1.4214 (0.9541) D(x): 0.5506 D(G(z)): 0.3697 / 0.2551 Acc: 18.7500 (17.4274)\n",
      "[0/25][736/782] Loss_D: 0.7623 (0.9848) Loss_G: 1.0433 (0.9542) D(x): 0.4805 D(G(z)): 0.3835 / 0.2987 Acc: 26.5625 (17.4398)\n",
      "[0/25][737/782] Loss_D: 1.3916 (0.9854) Loss_G: 0.9469 (0.9542) D(x): 0.3488 D(G(z)): 0.4320 / 0.3307 Acc: 21.8750 (17.4458)\n",
      "[0/25][738/782] Loss_D: 0.7892 (0.9851) Loss_G: 0.8921 (0.9541) D(x): 0.5771 D(G(z)): 0.4375 / 0.3638 Acc: 14.0625 (17.4412)\n",
      "[0/25][739/782] Loss_D: 0.9653 (0.9851) Loss_G: 0.6683 (0.9537) D(x): 0.5647 D(G(z)): 0.5095 / 0.4387 Acc: 20.3125 (17.4451)\n",
      "[0/25][740/782] Loss_D: 0.8242 (0.9849) Loss_G: 0.7693 (0.9535) D(x): 0.5459 D(G(z)): 0.4251 / 0.4216 Acc: 26.5625 (17.4574)\n",
      "[0/25][741/782] Loss_D: 0.7144 (0.9845) Loss_G: 0.7750 (0.9532) D(x): 0.5355 D(G(z)): 0.4087 / 0.3855 Acc: 23.4375 (17.4655)\n",
      "[0/25][742/782] Loss_D: 0.8585 (0.9843) Loss_G: 0.6535 (0.9528) D(x): 0.5424 D(G(z)): 0.4662 / 0.4357 Acc: 26.5625 (17.4777)\n",
      "[0/25][743/782] Loss_D: 0.7084 (0.9840) Loss_G: 0.6329 (0.9524) D(x): 0.5417 D(G(z)): 0.3534 / 0.4347 Acc: 23.4375 (17.4857)\n",
      "[0/25][744/782] Loss_D: 0.7618 (0.9837) Loss_G: 0.9176 (0.9523) D(x): 0.6534 D(G(z)): 0.4666 / 0.3828 Acc: 23.4375 (17.4937)\n",
      "[0/25][745/782] Loss_D: 0.6445 (0.9832) Loss_G: 0.8470 (0.9522) D(x): 0.6452 D(G(z)): 0.4149 / 0.3938 Acc: 17.1875 (17.4933)\n",
      "[0/25][746/782] Loss_D: 0.9007 (0.9831) Loss_G: 0.8658 (0.9521) D(x): 0.4982 D(G(z)): 0.3978 / 0.3825 Acc: 18.7500 (17.4950)\n",
      "[0/25][747/782] Loss_D: 0.4844 (0.9824) Loss_G: 0.9595 (0.9521) D(x): 0.7321 D(G(z)): 0.4120 / 0.3286 Acc: 18.7500 (17.4967)\n",
      "[0/25][748/782] Loss_D: 0.6437 (0.9820) Loss_G: 0.9440 (0.9521) D(x): 0.5981 D(G(z)): 0.3624 / 0.3195 Acc: 14.0625 (17.4921)\n",
      "[0/25][749/782] Loss_D: 0.5620 (0.9814) Loss_G: 0.8463 (0.9520) D(x): 0.5942 D(G(z)): 0.3639 / 0.3491 Acc: 21.8750 (17.4979)\n",
      "[0/25][750/782] Loss_D: 0.5327 (0.9808) Loss_G: 1.0053 (0.9520) D(x): 0.6161 D(G(z)): 0.3575 / 0.3257 Acc: 21.8750 (17.5037)\n",
      "[0/25][751/782] Loss_D: 0.7317 (0.9805) Loss_G: 0.8843 (0.9519) D(x): 0.5799 D(G(z)): 0.4858 / 0.3424 Acc: 29.6875 (17.5199)\n",
      "[0/25][752/782] Loss_D: 0.9789 (0.9805) Loss_G: 1.0060 (0.9520) D(x): 0.4811 D(G(z)): 0.4211 / 0.3378 Acc: 23.4375 (17.5278)\n",
      "[0/25][753/782] Loss_D: 1.0051 (0.9805) Loss_G: 0.6461 (0.9516) D(x): 0.5781 D(G(z)): 0.5698 / 0.4526 Acc: 28.1250 (17.5419)\n",
      "[0/25][754/782] Loss_D: 1.1745 (0.9808) Loss_G: 0.6927 (0.9513) D(x): 0.4342 D(G(z)): 0.4438 / 0.4293 Acc: 12.5000 (17.5352)\n",
      "[0/25][755/782] Loss_D: 1.2950 (0.9812) Loss_G: 0.4612 (0.9506) D(x): 0.4786 D(G(z)): 0.5768 / 0.5037 Acc: 23.4375 (17.5430)\n",
      "[0/25][756/782] Loss_D: 1.1331 (0.9814) Loss_G: 0.7505 (0.9503) D(x): 0.4813 D(G(z)): 0.4752 / 0.4137 Acc: 14.0625 (17.5384)\n",
      "[0/25][757/782] Loss_D: 0.8354 (0.9812) Loss_G: 0.8691 (0.9502) D(x): 0.5775 D(G(z)): 0.4379 / 0.3777 Acc: 17.1875 (17.5379)\n",
      "[0/25][758/782] Loss_D: 0.9131 (0.9811) Loss_G: 0.8681 (0.9501) D(x): 0.5708 D(G(z)): 0.4554 / 0.3857 Acc: 21.8750 (17.5436)\n",
      "[0/25][759/782] Loss_D: 1.0588 (0.9812) Loss_G: 1.1667 (0.9504) D(x): 0.5927 D(G(z)): 0.5177 / 0.3038 Acc: 15.6250 (17.5411)\n",
      "[0/25][760/782] Loss_D: 0.9222 (0.9811) Loss_G: 1.1797 (0.9507) D(x): 0.5494 D(G(z)): 0.4536 / 0.2855 Acc: 15.6250 (17.5386)\n",
      "[0/25][761/782] Loss_D: 1.0677 (0.9812) Loss_G: 0.8920 (0.9506) D(x): 0.4899 D(G(z)): 0.4387 / 0.3765 Acc: 15.6250 (17.5361)\n",
      "[0/25][762/782] Loss_D: 1.3614 (0.9817) Loss_G: 0.7026 (0.9503) D(x): 0.4680 D(G(z)): 0.5661 / 0.4209 Acc: 21.8750 (17.5418)\n",
      "[0/25][763/782] Loss_D: 1.0551 (0.9818) Loss_G: 0.5893 (0.9498) D(x): 0.5035 D(G(z)): 0.4808 / 0.4363 Acc: 14.0625 (17.5372)\n",
      "[0/25][764/782] Loss_D: 1.1806 (0.9821) Loss_G: 0.6696 (0.9495) D(x): 0.4668 D(G(z)): 0.4802 / 0.4515 Acc: 17.1875 (17.5368)\n",
      "[0/25][765/782] Loss_D: 1.0597 (0.9822) Loss_G: 0.7025 (0.9491) D(x): 0.5642 D(G(z)): 0.5091 / 0.4305 Acc: 17.1875 (17.5363)\n",
      "[0/25][766/782] Loss_D: 0.8988 (0.9821) Loss_G: 0.8646 (0.9490) D(x): 0.6196 D(G(z)): 0.5041 / 0.3833 Acc: 18.7500 (17.5379)\n",
      "[0/25][767/782] Loss_D: 0.9499 (0.9820) Loss_G: 0.9402 (0.9490) D(x): 0.4844 D(G(z)): 0.4092 / 0.3682 Acc: 25.0000 (17.5476)\n",
      "[0/25][768/782] Loss_D: 0.5765 (0.9815) Loss_G: 1.1959 (0.9493) D(x): 0.6325 D(G(z)): 0.4312 / 0.2635 Acc: 26.5625 (17.5593)\n",
      "[0/25][769/782] Loss_D: 0.5813 (0.9810) Loss_G: 0.8614 (0.9492) D(x): 0.5148 D(G(z)): 0.3399 / 0.3447 Acc: 26.5625 (17.5710)\n",
      "[0/25][770/782] Loss_D: 1.0690 (0.9811) Loss_G: 0.4817 (0.9486) D(x): 0.4422 D(G(z)): 0.4830 / 0.4751 Acc: 23.4375 (17.5786)\n",
      "[0/25][771/782] Loss_D: 1.0658 (0.9812) Loss_G: 0.3023 (0.9478) D(x): 0.4546 D(G(z)): 0.4483 / 0.5924 Acc: 15.6250 (17.5761)\n",
      "[0/25][772/782] Loss_D: 0.8271 (0.9810) Loss_G: 0.8558 (0.9477) D(x): 0.7533 D(G(z)): 0.5963 / 0.3814 Acc: 23.4375 (17.5837)\n",
      "[0/25][773/782] Loss_D: 1.0030 (0.9811) Loss_G: 0.7252 (0.9474) D(x): 0.4803 D(G(z)): 0.4573 / 0.3740 Acc: 18.7500 (17.5852)\n",
      "[0/25][774/782] Loss_D: 0.9434 (0.9810) Loss_G: 0.8183 (0.9472) D(x): 0.4799 D(G(z)): 0.4280 / 0.3692 Acc: 20.3125 (17.5887)\n",
      "[0/25][775/782] Loss_D: 0.8436 (0.9808) Loss_G: 0.6301 (0.9468) D(x): 0.5155 D(G(z)): 0.4488 / 0.4311 Acc: 23.4375 (17.5962)\n",
      "[0/25][776/782] Loss_D: 1.2097 (0.9811) Loss_G: 0.6415 (0.9464) D(x): 0.4382 D(G(z)): 0.5257 / 0.4312 Acc: 25.0000 (17.6058)\n",
      "[0/25][777/782] Loss_D: 1.0239 (0.9812) Loss_G: 0.5578 (0.9459) D(x): 0.5175 D(G(z)): 0.5123 / 0.4789 Acc: 20.3125 (17.6093)\n",
      "[0/25][778/782] Loss_D: 0.8554 (0.9810) Loss_G: 0.5720 (0.9454) D(x): 0.5440 D(G(z)): 0.4885 / 0.4343 Acc: 18.7500 (17.6107)\n",
      "[0/25][779/782] Loss_D: 1.0055 (0.9810) Loss_G: 0.7682 (0.9452) D(x): 0.5214 D(G(z)): 0.5132 / 0.3717 Acc: 17.1875 (17.6102)\n",
      "[0/25][780/782] Loss_D: 1.0765 (0.9812) Loss_G: 0.8111 (0.9450) D(x): 0.4614 D(G(z)): 0.4799 / 0.3535 Acc: 21.8750 (17.6156)\n",
      "[0/25][781/782] Loss_D: 1.0779 (0.9813) Loss_G: 1.2116 (0.9454) D(x): 0.5891 D(G(z)): 0.5391 / 0.2829 Acc: 12.5000 (17.6091)\n",
      "[1/25][0/782] Loss_D: 1.1740 (0.9815) Loss_G: 0.7477 (0.9451) D(x): 0.3471 D(G(z)): 0.3590 / 0.4071 Acc: 21.8750 (17.6145)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[1/25][1/782] Loss_D: 0.8421 (0.9814) Loss_G: 0.6443 (0.9447) D(x): 0.4748 D(G(z)): 0.3831 / 0.4580 Acc: 25.0000 (17.6240)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/25][2/782] Loss_D: 1.0159 (0.9814) Loss_G: 0.7100 (0.9444) D(x): 0.5963 D(G(z)): 0.5671 / 0.4319 Acc: 23.4375 (17.6314)\n",
      "[1/25][3/782] Loss_D: 0.7195 (0.9811) Loss_G: 0.8084 (0.9443) D(x): 0.6189 D(G(z)): 0.4633 / 0.3726 Acc: 18.7500 (17.6328)\n",
      "[1/25][4/782] Loss_D: 0.7949 (0.9808) Loss_G: 1.0012 (0.9443) D(x): 0.5364 D(G(z)): 0.4355 / 0.3221 Acc: 32.8125 (17.6521)\n",
      "[1/25][5/782] Loss_D: 0.9155 (0.9808) Loss_G: 1.0580 (0.9445) D(x): 0.4999 D(G(z)): 0.4003 / 0.3366 Acc: 21.8750 (17.6574)\n",
      "[1/25][6/782] Loss_D: 0.6419 (0.9803) Loss_G: 0.8550 (0.9444) D(x): 0.5744 D(G(z)): 0.3813 / 0.3826 Acc: 26.5625 (17.6687)\n",
      "[1/25][7/782] Loss_D: 0.6619 (0.9799) Loss_G: 0.7283 (0.9441) D(x): 0.5401 D(G(z)): 0.3619 / 0.4273 Acc: 28.1250 (17.6820)\n",
      "[1/25][8/782] Loss_D: 0.5568 (0.9794) Loss_G: 0.7769 (0.9439) D(x): 0.6263 D(G(z)): 0.4174 / 0.3931 Acc: 26.5625 (17.6932)\n",
      "[1/25][9/782] Loss_D: 0.6658 (0.9790) Loss_G: 0.8667 (0.9438) D(x): 0.6016 D(G(z)): 0.4259 / 0.3614 Acc: 26.5625 (17.7044)\n",
      "[1/25][10/782] Loss_D: 0.6614 (0.9786) Loss_G: 0.9742 (0.9438) D(x): 0.5996 D(G(z)): 0.4169 / 0.3407 Acc: 29.6875 (17.7195)\n",
      "[1/25][11/782] Loss_D: 0.6986 (0.9782) Loss_G: 0.9717 (0.9439) D(x): 0.5527 D(G(z)): 0.3593 / 0.3317 Acc: 15.6250 (17.7169)\n",
      "[1/25][12/782] Loss_D: 0.4366 (0.9776) Loss_G: 0.7528 (0.9436) D(x): 0.6384 D(G(z)): 0.3897 / 0.3795 Acc: 26.5625 (17.7280)\n",
      "[1/25][13/782] Loss_D: 0.7203 (0.9772) Loss_G: 1.2229 (0.9440) D(x): 0.6926 D(G(z)): 0.5207 / 0.2585 Acc: 21.8750 (17.7332)\n",
      "[1/25][14/782] Loss_D: 0.6060 (0.9768) Loss_G: 1.1751 (0.9443) D(x): 0.5733 D(G(z)): 0.3040 / 0.2761 Acc: 14.0625 (17.7286)\n",
      "[1/25][15/782] Loss_D: 0.8506 (0.9766) Loss_G: 0.5203 (0.9437) D(x): 0.5553 D(G(z)): 0.5211 / 0.4430 Acc: 20.3125 (17.7318)\n",
      "[1/25][16/782] Loss_D: 1.1723 (0.9769) Loss_G: 0.6034 (0.9433) D(x): 0.5214 D(G(z)): 0.5290 / 0.4731 Acc: 10.9375 (17.7233)\n",
      "[1/25][17/782] Loss_D: 0.8813 (0.9767) Loss_G: 0.5702 (0.9428) D(x): 0.5236 D(G(z)): 0.4861 / 0.4572 Acc: 28.1250 (17.7363)\n",
      "[1/25][18/782] Loss_D: 0.8691 (0.9766) Loss_G: 0.6979 (0.9425) D(x): 0.5794 D(G(z)): 0.5229 / 0.4201 Acc: 28.1250 (17.7493)\n",
      "[1/25][19/782] Loss_D: 0.7929 (0.9764) Loss_G: 0.6966 (0.9422) D(x): 0.5974 D(G(z)): 0.5075 / 0.3895 Acc: 23.4375 (17.7564)\n",
      "[1/25][20/782] Loss_D: 0.9065 (0.9763) Loss_G: 0.8799 (0.9422) D(x): 0.5402 D(G(z)): 0.5055 / 0.3526 Acc: 28.1250 (17.7693)\n",
      "[1/25][21/782] Loss_D: 0.9375 (0.9762) Loss_G: 0.8231 (0.9420) D(x): 0.4419 D(G(z)): 0.3635 / 0.3664 Acc: 21.8750 (17.7744)\n",
      "[1/25][22/782] Loss_D: 0.9168 (0.9762) Loss_G: 0.6379 (0.9416) D(x): 0.4679 D(G(z)): 0.4157 / 0.4489 Acc: 26.5625 (17.7853)\n",
      "[1/25][23/782] Loss_D: 0.8313 (0.9760) Loss_G: 0.7126 (0.9413) D(x): 0.5539 D(G(z)): 0.4758 / 0.4266 Acc: 31.2500 (17.8020)\n",
      "[1/25][24/782] Loss_D: 0.6444 (0.9756) Loss_G: 0.6142 (0.9409) D(x): 0.6833 D(G(z)): 0.5330 / 0.4250 Acc: 25.0000 (17.8110)\n",
      "[1/25][25/782] Loss_D: 1.0699 (0.9757) Loss_G: 0.8726 (0.9409) D(x): 0.5783 D(G(z)): 0.5204 / 0.3858 Acc: 14.0625 (17.8063)\n",
      "[1/25][26/782] Loss_D: 0.8989 (0.9756) Loss_G: 0.6820 (0.9405) D(x): 0.5533 D(G(z)): 0.4601 / 0.4083 Acc: 17.1875 (17.8055)\n",
      "[1/25][27/782] Loss_D: 0.8326 (0.9754) Loss_G: 0.7192 (0.9403) D(x): 0.5000 D(G(z)): 0.4105 / 0.4162 Acc: 25.0000 (17.8144)\n",
      "[1/25][28/782] Loss_D: 0.7796 (0.9752) Loss_G: 0.7044 (0.9400) D(x): 0.5920 D(G(z)): 0.4563 / 0.4130 Acc: 23.4375 (17.8214)\n",
      "[1/25][29/782] Loss_D: 0.7338 (0.9749) Loss_G: 0.8245 (0.9398) D(x): 0.6955 D(G(z)): 0.5382 / 0.3858 Acc: 35.9375 (17.8437)\n",
      "[1/25][30/782] Loss_D: 0.8052 (0.9747) Loss_G: 1.1438 (0.9401) D(x): 0.6095 D(G(z)): 0.4756 / 0.2573 Acc: 14.0625 (17.8390)\n",
      "[1/25][31/782] Loss_D: 0.8533 (0.9745) Loss_G: 0.9758 (0.9401) D(x): 0.4655 D(G(z)): 0.3079 / 0.3367 Acc: 14.0625 (17.8344)\n",
      "[1/25][32/782] Loss_D: 0.9316 (0.9745) Loss_G: 0.7230 (0.9399) D(x): 0.6547 D(G(z)): 0.5302 / 0.4056 Acc: 9.3750 (17.8240)\n",
      "[1/25][33/782] Loss_D: 1.0643 (0.9746) Loss_G: 0.7070 (0.9396) D(x): 0.4389 D(G(z)): 0.4392 / 0.4152 Acc: 23.4375 (17.8309)\n",
      "[1/25][34/782] Loss_D: 0.8949 (0.9745) Loss_G: 0.6343 (0.9392) D(x): 0.5592 D(G(z)): 0.5122 / 0.4421 Acc: 28.1250 (17.8435)\n",
      "[1/25][35/782] Loss_D: 0.8330 (0.9743) Loss_G: 0.5500 (0.9387) D(x): 0.5294 D(G(z)): 0.4532 / 0.4677 Acc: 20.3125 (17.8465)\n",
      "[1/25][36/782] Loss_D: 0.9540 (0.9743) Loss_G: 0.8877 (0.9387) D(x): 0.5473 D(G(z)): 0.5010 / 0.3849 Acc: 26.5625 (17.8571)\n",
      "[1/25][37/782] Loss_D: 0.7456 (0.9740) Loss_G: 0.8504 (0.9385) D(x): 0.5313 D(G(z)): 0.4222 / 0.3581 Acc: 31.2500 (17.8735)\n",
      "[1/25][38/782] Loss_D: 0.8185 (0.9738) Loss_G: 0.8091 (0.9384) D(x): 0.4873 D(G(z)): 0.4098 / 0.3875 Acc: 29.6875 (17.8879)\n",
      "[1/25][39/782] Loss_D: 0.9581 (0.9738) Loss_G: 0.7548 (0.9382) D(x): 0.4788 D(G(z)): 0.4561 / 0.3921 Acc: 26.5625 (17.8984)\n",
      "[1/25][40/782] Loss_D: 0.9133 (0.9737) Loss_G: 0.7560 (0.9379) D(x): 0.5220 D(G(z)): 0.4721 / 0.3759 Acc: 15.6250 (17.8957)\n",
      "[1/25][41/782] Loss_D: 0.8973 (0.9736) Loss_G: 0.8712 (0.9379) D(x): 0.5196 D(G(z)): 0.4373 / 0.3462 Acc: 17.1875 (17.8948)\n",
      "[1/25][42/782] Loss_D: 0.7344 (0.9733) Loss_G: 0.9276 (0.9379) D(x): 0.5150 D(G(z)): 0.3848 / 0.3345 Acc: 23.4375 (17.9015)\n",
      "[1/25][43/782] Loss_D: 0.6966 (0.9730) Loss_G: 0.7428 (0.9376) D(x): 0.5656 D(G(z)): 0.4266 / 0.4015 Acc: 28.1250 (17.9139)\n",
      "[1/25][44/782] Loss_D: 0.6457 (0.9726) Loss_G: 0.9820 (0.9377) D(x): 0.6009 D(G(z)): 0.4177 / 0.3072 Acc: 12.5000 (17.9073)\n",
      "[1/25][45/782] Loss_D: 0.5304 (0.9721) Loss_G: 0.9007 (0.9376) D(x): 0.6066 D(G(z)): 0.4450 / 0.3228 Acc: 35.9375 (17.9291)\n",
      "[1/25][46/782] Loss_D: 0.7664 (0.9718) Loss_G: 0.6318 (0.9373) D(x): 0.4882 D(G(z)): 0.4361 / 0.4234 Acc: 34.3750 (17.9490)\n",
      "[1/25][47/782] Loss_D: 1.4010 (0.9723) Loss_G: 0.3752 (0.9366) D(x): 0.4214 D(G(z)): 0.5574 / 0.5338 Acc: 15.6250 (17.9462)\n",
      "[1/25][48/782] Loss_D: 1.3519 (0.9728) Loss_G: 0.5105 (0.9361) D(x): 0.4492 D(G(z)): 0.5665 / 0.5086 Acc: 20.3125 (17.9490)\n",
      "[1/25][49/782] Loss_D: 0.9398 (0.9728) Loss_G: 0.3973 (0.9354) D(x): 0.5410 D(G(z)): 0.5427 / 0.5380 Acc: 31.2500 (17.9650)\n",
      "[1/25][50/782] Loss_D: 1.0331 (0.9728) Loss_G: 0.5423 (0.9349) D(x): 0.4962 D(G(z)): 0.5073 / 0.4834 Acc: 18.7500 (17.9659)\n",
      "[1/25][51/782] Loss_D: 0.7207 (0.9725) Loss_G: 0.3756 (0.9343) D(x): 0.4700 D(G(z)): 0.4402 / 0.4669 Acc: 26.5625 (17.9762)\n",
      "[1/25][52/782] Loss_D: 0.8700 (0.9724) Loss_G: 0.5275 (0.9338) D(x): 0.5879 D(G(z)): 0.5204 / 0.4684 Acc: 18.7500 (17.9772)\n",
      "[1/25][53/782] Loss_D: 1.0090 (0.9725) Loss_G: 0.4669 (0.9332) D(x): 0.4610 D(G(z)): 0.4774 / 0.4884 Acc: 23.4375 (17.9837)\n",
      "[1/25][54/782] Loss_D: 0.8868 (0.9723) Loss_G: 0.5036 (0.9327) D(x): 0.5252 D(G(z)): 0.5056 / 0.4724 Acc: 20.3125 (17.9865)\n",
      "[1/25][55/782] Loss_D: 0.8610 (0.9722) Loss_G: 0.5966 (0.9323) D(x): 0.4820 D(G(z)): 0.5150 / 0.4183 Acc: 37.5000 (18.0098)\n",
      "[1/25][56/782] Loss_D: 0.8469 (0.9721) Loss_G: 0.6281 (0.9320) D(x): 0.5781 D(G(z)): 0.5188 / 0.4553 Acc: 29.6875 (18.0237)\n",
      "[1/25][57/782] Loss_D: 1.2447 (0.9724) Loss_G: 0.5712 (0.9315) D(x): 0.4072 D(G(z)): 0.4958 / 0.4718 Acc: 14.0625 (18.0190)\n",
      "[1/25][58/782] Loss_D: 1.0669 (0.9725) Loss_G: 0.5694 (0.9311) D(x): 0.4918 D(G(z)): 0.5140 / 0.4659 Acc: 25.0000 (18.0273)\n",
      "[1/25][59/782] Loss_D: 0.9182 (0.9724) Loss_G: 0.6794 (0.9308) D(x): 0.4877 D(G(z)): 0.4568 / 0.3747 Acc: 14.0625 (18.0226)\n",
      "[1/25][60/782] Loss_D: 0.9115 (0.9724) Loss_G: 0.6086 (0.9304) D(x): 0.4535 D(G(z)): 0.4629 / 0.4299 Acc: 29.6875 (18.0364)\n",
      "[1/25][61/782] Loss_D: 0.8054 (0.9722) Loss_G: 0.9042 (0.9304) D(x): 0.5587 D(G(z)): 0.5217 / 0.3425 Acc: 31.2500 (18.0521)\n",
      "[1/25][62/782] Loss_D: 0.8580 (0.9720) Loss_G: 0.7461 (0.9302) D(x): 0.4283 D(G(z)): 0.3693 / 0.3776 Acc: 26.5625 (18.0621)\n",
      "[1/25][63/782] Loss_D: 0.9388 (0.9720) Loss_G: 0.6420 (0.9298) D(x): 0.5098 D(G(z)): 0.4032 / 0.4572 Acc: 12.5000 (18.0556)\n",
      "[1/25][64/782] Loss_D: 0.9093 (0.9719) Loss_G: 0.6215 (0.9295) D(x): 0.5496 D(G(z)): 0.4874 / 0.4297 Acc: 18.7500 (18.0564)\n",
      "[1/25][65/782] Loss_D: 0.8468 (0.9718) Loss_G: 0.6513 (0.9291) D(x): 0.5291 D(G(z)): 0.4493 / 0.4162 Acc: 17.1875 (18.0554)\n",
      "[1/25][66/782] Loss_D: 0.6126 (0.9713) Loss_G: 0.9317 (0.9291) D(x): 0.5799 D(G(z)): 0.3751 / 0.3426 Acc: 21.8750 (18.0598)\n",
      "[1/25][67/782] Loss_D: 0.6213 (0.9709) Loss_G: 0.4853 (0.9286) D(x): 0.5410 D(G(z)): 0.4303 / 0.4255 Acc: 20.3125 (18.0625)\n",
      "[1/25][68/782] Loss_D: 0.6676 (0.9706) Loss_G: 0.7066 (0.9284) D(x): 0.5553 D(G(z)): 0.4282 / 0.4068 Acc: 25.0000 (18.0707)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/25][69/782] Loss_D: 0.8243 (0.9704) Loss_G: 0.7181 (0.9281) D(x): 0.5338 D(G(z)): 0.4398 / 0.4147 Acc: 18.7500 (18.0714)\n",
      "[1/25][70/782] Loss_D: 0.5660 (0.9699) Loss_G: 0.6057 (0.9277) D(x): 0.5821 D(G(z)): 0.4488 / 0.4096 Acc: 28.1250 (18.0832)\n",
      "[1/25][71/782] Loss_D: 0.8000 (0.9697) Loss_G: 0.7487 (0.9275) D(x): 0.5322 D(G(z)): 0.4733 / 0.3696 Acc: 28.1250 (18.0950)\n",
      "[1/25][72/782] Loss_D: 0.6448 (0.9694) Loss_G: 0.7922 (0.9274) D(x): 0.5430 D(G(z)): 0.4273 / 0.3791 Acc: 32.8125 (18.1122)\n",
      "[1/25][73/782] Loss_D: 0.7882 (0.9691) Loss_G: 0.6031 (0.9270) D(x): 0.4800 D(G(z)): 0.4318 / 0.4088 Acc: 21.8750 (18.1166)\n",
      "[1/25][74/782] Loss_D: 0.9829 (0.9692) Loss_G: 0.5512 (0.9265) D(x): 0.5038 D(G(z)): 0.4815 / 0.4984 Acc: 23.4375 (18.1228)\n",
      "[1/25][75/782] Loss_D: 0.8019 (0.9690) Loss_G: 0.6671 (0.9262) D(x): 0.5649 D(G(z)): 0.4779 / 0.3865 Acc: 17.1875 (18.1217)\n",
      "[1/25][76/782] Loss_D: 0.9187 (0.9689) Loss_G: 0.6847 (0.9260) D(x): 0.5356 D(G(z)): 0.4631 / 0.4212 Acc: 18.7500 (18.1225)\n",
      "[1/25][77/782] Loss_D: 0.7523 (0.9687) Loss_G: 0.5015 (0.9255) D(x): 0.5233 D(G(z)): 0.4441 / 0.4438 Acc: 10.9375 (18.1141)\n",
      "[1/25][78/782] Loss_D: 0.8886 (0.9686) Loss_G: 0.4389 (0.9249) D(x): 0.5488 D(G(z)): 0.5160 / 0.4922 Acc: 26.5625 (18.1239)\n",
      "[1/25][79/782] Loss_D: 0.9177 (0.9685) Loss_G: 0.6582 (0.9246) D(x): 0.5268 D(G(z)): 0.5044 / 0.4227 Acc: 29.6875 (18.1373)\n",
      "[1/25][80/782] Loss_D: 0.8618 (0.9684) Loss_G: 0.8151 (0.9245) D(x): 0.5381 D(G(z)): 0.4477 / 0.3700 Acc: 17.1875 (18.1362)\n",
      "[1/25][81/782] Loss_D: 0.8686 (0.9683) Loss_G: 0.5890 (0.9241) D(x): 0.5025 D(G(z)): 0.4617 / 0.4343 Acc: 26.5625 (18.1460)\n",
      "[1/25][82/782] Loss_D: 0.6853 (0.9679) Loss_G: 0.7822 (0.9239) D(x): 0.6108 D(G(z)): 0.4564 / 0.3821 Acc: 28.1250 (18.1575)\n",
      "[1/25][83/782] Loss_D: 0.6718 (0.9676) Loss_G: 0.9141 (0.9239) D(x): 0.5869 D(G(z)): 0.3982 / 0.3507 Acc: 18.7500 (18.1582)\n",
      "[1/25][84/782] Loss_D: 0.7490 (0.9673) Loss_G: 0.6642 (0.9236) D(x): 0.5922 D(G(z)): 0.4748 / 0.3905 Acc: 17.1875 (18.1571)\n",
      "[1/25][85/782] Loss_D: 0.6076 (0.9669) Loss_G: 0.7555 (0.9234) D(x): 0.5837 D(G(z)): 0.4434 / 0.3716 Acc: 28.1250 (18.1686)\n",
      "[1/25][86/782] Loss_D: 0.7673 (0.9667) Loss_G: 0.7222 (0.9232) D(x): 0.5306 D(G(z)): 0.3968 / 0.3945 Acc: 15.6250 (18.1656)\n",
      "[1/25][87/782] Loss_D: 0.7664 (0.9665) Loss_G: 0.8488 (0.9231) D(x): 0.5982 D(G(z)): 0.4628 / 0.3762 Acc: 21.8750 (18.1699)\n",
      "[1/25][88/782] Loss_D: 0.7260 (0.9662) Loss_G: 0.7444 (0.9229) D(x): 0.6131 D(G(z)): 0.4810 / 0.4009 Acc: 28.1250 (18.1813)\n",
      "[1/25][89/782] Loss_D: 0.8048 (0.9660) Loss_G: 0.7209 (0.9227) D(x): 0.5266 D(G(z)): 0.4227 / 0.3965 Acc: 20.3125 (18.1838)\n",
      "[1/25][90/782] Loss_D: 0.9566 (0.9660) Loss_G: 0.6266 (0.9223) D(x): 0.5027 D(G(z)): 0.4262 / 0.4815 Acc: 25.0000 (18.1916)\n",
      "[1/25][91/782] Loss_D: 0.5700 (0.9655) Loss_G: 0.6027 (0.9219) D(x): 0.6412 D(G(z)): 0.4898 / 0.4287 Acc: 29.6875 (18.2047)\n",
      "[1/25][92/782] Loss_D: 0.4213 (0.9649) Loss_G: 0.7785 (0.9218) D(x): 0.5957 D(G(z)): 0.4112 / 0.3418 Acc: 31.2500 (18.2196)\n",
      "[1/25][93/782] Loss_D: 0.7813 (0.9647) Loss_G: 0.8614 (0.9217) D(x): 0.4858 D(G(z)): 0.3746 / 0.3746 Acc: 26.5625 (18.2292)\n",
      "[1/25][94/782] Loss_D: 0.5720 (0.9643) Loss_G: 0.6317 (0.9214) D(x): 0.6226 D(G(z)): 0.4375 / 0.4276 Acc: 29.6875 (18.2422)\n",
      "[1/25][95/782] Loss_D: 0.7958 (0.9641) Loss_G: 0.5106 (0.9209) D(x): 0.6176 D(G(z)): 0.5098 / 0.4822 Acc: 23.4375 (18.2481)\n",
      "[1/25][96/782] Loss_D: 0.6190 (0.9637) Loss_G: 0.6690 (0.9206) D(x): 0.6314 D(G(z)): 0.4484 / 0.4188 Acc: 25.0000 (18.2558)\n",
      "[1/25][97/782] Loss_D: 1.1819 (0.9639) Loss_G: 0.7040 (0.9204) D(x): 0.4929 D(G(z)): 0.5524 / 0.4314 Acc: 26.5625 (18.2653)\n",
      "[1/25][98/782] Loss_D: 1.2857 (0.9643) Loss_G: 0.6429 (0.9201) D(x): 0.4511 D(G(z)): 0.5350 / 0.4497 Acc: 23.4375 (18.2711)\n",
      "[1/25][99/782] Loss_D: 0.9392 (0.9643) Loss_G: 0.7585 (0.9199) D(x): 0.4812 D(G(z)): 0.4671 / 0.4129 Acc: 31.2500 (18.2859)\n",
      "[1/25][100/782] Loss_D: 1.2074 (0.9645) Loss_G: 0.6057 (0.9195) D(x): 0.4059 D(G(z)): 0.5244 / 0.4382 Acc: 29.6875 (18.2988)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[1/25][101/782] Loss_D: 0.8167 (0.9644) Loss_G: 0.5662 (0.9191) D(x): 0.4981 D(G(z)): 0.4733 / 0.4428 Acc: 28.1250 (18.3099)\n",
      "[1/25][102/782] Loss_D: 1.0049 (0.9644) Loss_G: 0.7713 (0.9190) D(x): 0.5083 D(G(z)): 0.4587 / 0.4066 Acc: 17.1875 (18.3086)\n",
      "[1/25][103/782] Loss_D: 0.7825 (0.9642) Loss_G: 0.7567 (0.9188) D(x): 0.5919 D(G(z)): 0.5309 / 0.3610 Acc: 28.1250 (18.3197)\n",
      "[1/25][104/782] Loss_D: 0.5402 (0.9637) Loss_G: 0.8158 (0.9187) D(x): 0.5534 D(G(z)): 0.3650 / 0.3531 Acc: 26.5625 (18.3290)\n",
      "[1/25][105/782] Loss_D: 0.9046 (0.9637) Loss_G: 0.8844 (0.9186) D(x): 0.5033 D(G(z)): 0.4493 / 0.3463 Acc: 23.4375 (18.3347)\n",
      "[1/25][106/782] Loss_D: 0.6280 (0.9633) Loss_G: 0.7943 (0.9185) D(x): 0.5553 D(G(z)): 0.4211 / 0.3388 Acc: 23.4375 (18.3405)\n",
      "[1/25][107/782] Loss_D: 0.7350 (0.9630) Loss_G: 1.0337 (0.9186) D(x): 0.5292 D(G(z)): 0.4339 / 0.2994 Acc: 29.6875 (18.3532)\n",
      "[1/25][108/782] Loss_D: 0.7296 (0.9628) Loss_G: 0.9332 (0.9186) D(x): 0.5897 D(G(z)): 0.4370 / 0.3475 Acc: 21.8750 (18.3572)\n",
      "[1/25][109/782] Loss_D: 0.7278 (0.9625) Loss_G: 0.7048 (0.9184) D(x): 0.4893 D(G(z)): 0.3763 / 0.4181 Acc: 28.1250 (18.3681)\n",
      "[1/25][110/782] Loss_D: 0.6622 (0.9622) Loss_G: 0.7485 (0.9182) D(x): 0.6487 D(G(z)): 0.5172 / 0.3727 Acc: 21.8750 (18.3721)\n",
      "[1/25][111/782] Loss_D: 0.5744 (0.9617) Loss_G: 0.8750 (0.9182) D(x): 0.5944 D(G(z)): 0.4507 / 0.3283 Acc: 31.2500 (18.3865)\n",
      "[1/25][112/782] Loss_D: 0.5812 (0.9613) Loss_G: 0.6120 (0.9178) D(x): 0.5369 D(G(z)): 0.4045 / 0.3843 Acc: 26.5625 (18.3956)\n",
      "[1/25][113/782] Loss_D: 0.6763 (0.9610) Loss_G: 1.0319 (0.9179) D(x): 0.5723 D(G(z)): 0.4197 / 0.3070 Acc: 25.0000 (18.4030)\n",
      "[1/25][114/782] Loss_D: 0.5427 (0.9605) Loss_G: 0.6096 (0.9176) D(x): 0.5679 D(G(z)): 0.4148 / 0.4072 Acc: 28.1250 (18.4138)\n",
      "[1/25][115/782] Loss_D: 0.5869 (0.9601) Loss_G: 0.9969 (0.9177) D(x): 0.6287 D(G(z)): 0.4460 / 0.3166 Acc: 25.0000 (18.4211)\n",
      "[1/25][116/782] Loss_D: 0.7225 (0.9598) Loss_G: 1.1047 (0.9179) D(x): 0.6106 D(G(z)): 0.4678 / 0.2932 Acc: 26.5625 (18.4302)\n",
      "[1/25][117/782] Loss_D: 0.4767 (0.9593) Loss_G: 0.7825 (0.9177) D(x): 0.4474 D(G(z)): 0.3062 / 0.3231 Acc: 39.0625 (18.4531)\n",
      "[1/25][118/782] Loss_D: 0.6744 (0.9590) Loss_G: 0.6622 (0.9175) D(x): 0.4971 D(G(z)): 0.3976 / 0.3866 Acc: 28.1250 (18.4639)\n",
      "[1/25][119/782] Loss_D: 0.7148 (0.9587) Loss_G: 0.8779 (0.9174) D(x): 0.6577 D(G(z)): 0.4720 / 0.3923 Acc: 25.0000 (18.4711)\n",
      "[1/25][120/782] Loss_D: 0.6063 (0.9583) Loss_G: 0.9714 (0.9175) D(x): 0.6285 D(G(z)): 0.4678 / 0.3066 Acc: 28.1250 (18.4818)\n",
      "[1/25][121/782] Loss_D: 0.7535 (0.9581) Loss_G: 0.8114 (0.9174) D(x): 0.5365 D(G(z)): 0.4950 / 0.3443 Acc: 29.6875 (18.4942)\n",
      "[1/25][122/782] Loss_D: 0.9239 (0.9581) Loss_G: 0.8455 (0.9173) D(x): 0.5169 D(G(z)): 0.4825 / 0.3453 Acc: 23.4375 (18.4997)\n",
      "[1/25][123/782] Loss_D: 0.7688 (0.9579) Loss_G: 0.8825 (0.9172) D(x): 0.5465 D(G(z)): 0.4300 / 0.3224 Acc: 17.1875 (18.4982)\n",
      "[1/25][124/782] Loss_D: 0.8351 (0.9577) Loss_G: 0.6242 (0.9169) D(x): 0.4894 D(G(z)): 0.4283 / 0.4012 Acc: 25.0000 (18.5054)\n",
      "[1/25][125/782] Loss_D: 0.5979 (0.9573) Loss_G: 0.5470 (0.9165) D(x): 0.5745 D(G(z)): 0.4223 / 0.4107 Acc: 21.8750 (18.5091)\n",
      "[1/25][126/782] Loss_D: 0.5739 (0.9569) Loss_G: 0.8703 (0.9165) D(x): 0.6499 D(G(z)): 0.4342 / 0.3450 Acc: 21.8750 (18.5128)\n",
      "[1/25][127/782] Loss_D: 0.5569 (0.9565) Loss_G: 0.8279 (0.9164) D(x): 0.5730 D(G(z)): 0.3738 / 0.3270 Acc: 18.7500 (18.5130)\n",
      "[1/25][128/782] Loss_D: 0.8377 (0.9563) Loss_G: 0.7589 (0.9162) D(x): 0.6183 D(G(z)): 0.5346 / 0.3831 Acc: 18.7500 (18.5133)\n",
      "[1/25][129/782] Loss_D: 0.5456 (0.9559) Loss_G: 1.0052 (0.9163) D(x): 0.5475 D(G(z)): 0.4280 / 0.2800 Acc: 29.6875 (18.5256)\n",
      "[1/25][130/782] Loss_D: 0.6570 (0.9556) Loss_G: 0.8515 (0.9162) D(x): 0.5968 D(G(z)): 0.4510 / 0.3410 Acc: 25.0000 (18.5327)\n",
      "[1/25][131/782] Loss_D: 0.7620 (0.9553) Loss_G: 0.6570 (0.9159) D(x): 0.5319 D(G(z)): 0.4827 / 0.3828 Acc: 25.0000 (18.5397)\n",
      "[1/25][132/782] Loss_D: 1.1873 (0.9556) Loss_G: 0.6782 (0.9157) D(x): 0.4487 D(G(z)): 0.5213 / 0.4083 Acc: 20.3125 (18.5417)\n",
      "[1/25][133/782] Loss_D: 0.7059 (0.9553) Loss_G: 0.8704 (0.9156) D(x): 0.5853 D(G(z)): 0.4703 / 0.3322 Acc: 26.5625 (18.5504)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/25][134/782] Loss_D: 0.6694 (0.9550) Loss_G: 0.6173 (0.9153) D(x): 0.4461 D(G(z)): 0.3233 / 0.3844 Acc: 20.3125 (18.5523)\n",
      "[1/25][135/782] Loss_D: 0.7229 (0.9548) Loss_G: 0.6506 (0.9150) D(x): 0.5792 D(G(z)): 0.4564 / 0.4200 Acc: 25.0000 (18.5594)\n",
      "[1/25][136/782] Loss_D: 0.8048 (0.9546) Loss_G: 0.7561 (0.9148) D(x): 0.5554 D(G(z)): 0.4721 / 0.3780 Acc: 20.3125 (18.5613)\n",
      "[1/25][137/782] Loss_D: 0.8046 (0.9544) Loss_G: 0.8213 (0.9147) D(x): 0.4701 D(G(z)): 0.4130 / 0.3446 Acc: 26.5625 (18.5700)\n",
      "[1/25][138/782] Loss_D: 0.8420 (0.9543) Loss_G: 0.7939 (0.9146) D(x): 0.5039 D(G(z)): 0.4322 / 0.3817 Acc: 28.1250 (18.5803)\n",
      "[1/25][139/782] Loss_D: 0.8571 (0.9542) Loss_G: 0.7730 (0.9144) D(x): 0.5607 D(G(z)): 0.4883 / 0.3727 Acc: 20.3125 (18.5822)\n",
      "[1/25][140/782] Loss_D: 0.5924 (0.9538) Loss_G: 0.6567 (0.9142) D(x): 0.4977 D(G(z)): 0.3719 / 0.4092 Acc: 32.8125 (18.5976)\n",
      "[1/25][141/782] Loss_D: 0.8139 (0.9537) Loss_G: 1.0859 (0.9144) D(x): 0.6523 D(G(z)): 0.4927 / 0.3013 Acc: 18.7500 (18.5978)\n",
      "[1/25][142/782] Loss_D: 0.8717 (0.9536) Loss_G: 1.0584 (0.9145) D(x): 0.5584 D(G(z)): 0.4822 / 0.3065 Acc: 17.1875 (18.5963)\n",
      "[1/25][143/782] Loss_D: 0.7141 (0.9533) Loss_G: 0.7490 (0.9143) D(x): 0.5097 D(G(z)): 0.4127 / 0.3969 Acc: 34.3750 (18.6133)\n",
      "[1/25][144/782] Loss_D: 0.9221 (0.9533) Loss_G: 0.4562 (0.9138) D(x): 0.4831 D(G(z)): 0.4980 / 0.4666 Acc: 28.1250 (18.6236)\n",
      "[1/25][145/782] Loss_D: 0.9016 (0.9532) Loss_G: 0.8391 (0.9138) D(x): 0.4794 D(G(z)): 0.4460 / 0.3413 Acc: 31.2500 (18.6372)\n",
      "[1/25][146/782] Loss_D: 1.0941 (0.9534) Loss_G: 0.4198 (0.9132) D(x): 0.4920 D(G(z)): 0.5158 / 0.4944 Acc: 17.1875 (18.6356)\n",
      "[1/25][147/782] Loss_D: 0.9642 (0.9534) Loss_G: 0.5810 (0.9129) D(x): 0.5780 D(G(z)): 0.5655 / 0.4220 Acc: 23.4375 (18.6408)\n",
      "[1/25][148/782] Loss_D: 0.7539 (0.9532) Loss_G: 0.5543 (0.9125) D(x): 0.5085 D(G(z)): 0.4481 / 0.4214 Acc: 26.5625 (18.6493)\n",
      "[1/25][149/782] Loss_D: 0.8057 (0.9530) Loss_G: 0.5954 (0.9121) D(x): 0.4701 D(G(z)): 0.4083 / 0.4209 Acc: 23.4375 (18.6544)\n",
      "[1/25][150/782] Loss_D: 0.7154 (0.9528) Loss_G: 0.7492 (0.9120) D(x): 0.5816 D(G(z)): 0.5038 / 0.3675 Acc: 29.6875 (18.6663)\n",
      "[1/25][151/782] Loss_D: 0.7197 (0.9525) Loss_G: 0.7333 (0.9118) D(x): 0.5951 D(G(z)): 0.4945 / 0.3674 Acc: 25.0000 (18.6730)\n",
      "[1/25][152/782] Loss_D: 0.5251 (0.9521) Loss_G: 0.8794 (0.9117) D(x): 0.5924 D(G(z)): 0.4230 / 0.3224 Acc: 29.6875 (18.6848)\n",
      "[1/25][153/782] Loss_D: 0.8215 (0.9519) Loss_G: 0.8074 (0.9116) D(x): 0.4401 D(G(z)): 0.2892 / 0.3822 Acc: 20.3125 (18.6866)\n",
      "[1/25][154/782] Loss_D: 0.7153 (0.9517) Loss_G: 0.5989 (0.9113) D(x): 0.5262 D(G(z)): 0.4183 / 0.4604 Acc: 32.8125 (18.7016)\n",
      "[1/25][155/782] Loss_D: 0.7699 (0.9515) Loss_G: 0.8894 (0.9113) D(x): 0.6518 D(G(z)): 0.5494 / 0.3268 Acc: 21.8750 (18.7050)\n",
      "[1/25][156/782] Loss_D: 0.6393 (0.9511) Loss_G: 0.6571 (0.9110) D(x): 0.5551 D(G(z)): 0.4445 / 0.3887 Acc: 31.2500 (18.7184)\n",
      "[1/25][157/782] Loss_D: 0.6637 (0.9508) Loss_G: 0.5987 (0.9107) D(x): 0.5036 D(G(z)): 0.3862 / 0.4208 Acc: 25.0000 (18.7251)\n",
      "[1/25][158/782] Loss_D: 0.6229 (0.9505) Loss_G: 0.4581 (0.9102) D(x): 0.5855 D(G(z)): 0.4612 / 0.4645 Acc: 21.8750 (18.7284)\n",
      "[1/25][159/782] Loss_D: 0.8253 (0.9504) Loss_G: 0.6686 (0.9099) D(x): 0.5668 D(G(z)): 0.4998 / 0.3892 Acc: 18.7500 (18.7284)\n",
      "[1/25][160/782] Loss_D: 0.8584 (0.9503) Loss_G: 0.8643 (0.9099) D(x): 0.5825 D(G(z)): 0.5311 / 0.3291 Acc: 18.7500 (18.7285)\n",
      "[1/25][161/782] Loss_D: 0.5337 (0.9498) Loss_G: 0.7302 (0.9097) D(x): 0.5434 D(G(z)): 0.3849 / 0.3127 Acc: 17.1875 (18.7268)\n",
      "[1/25][162/782] Loss_D: 1.0094 (0.9499) Loss_G: 0.3736 (0.9091) D(x): 0.4521 D(G(z)): 0.4765 / 0.4766 Acc: 17.1875 (18.7252)\n",
      "[1/25][163/782] Loss_D: 1.0141 (0.9499) Loss_G: 0.5212 (0.9087) D(x): 0.5058 D(G(z)): 0.5047 / 0.4655 Acc: 21.8750 (18.7285)\n",
      "[1/25][164/782] Loss_D: 1.0116 (0.9500) Loss_G: 0.7494 (0.9085) D(x): 0.5296 D(G(z)): 0.5023 / 0.4033 Acc: 23.4375 (18.7335)\n",
      "[1/25][165/782] Loss_D: 0.9134 (0.9500) Loss_G: 0.6789 (0.9083) D(x): 0.4820 D(G(z)): 0.4490 / 0.4177 Acc: 21.8750 (18.7368)\n",
      "[1/25][166/782] Loss_D: 0.8737 (0.9499) Loss_G: 0.6134 (0.9080) D(x): 0.5115 D(G(z)): 0.4640 / 0.4143 Acc: 20.3125 (18.7385)\n",
      "[1/25][167/782] Loss_D: 0.5835 (0.9495) Loss_G: 0.5804 (0.9077) D(x): 0.5709 D(G(z)): 0.4748 / 0.3657 Acc: 23.4375 (18.7434)\n",
      "[1/25][168/782] Loss_D: 0.8580 (0.9494) Loss_G: 0.4685 (0.9072) D(x): 0.4497 D(G(z)): 0.4164 / 0.4491 Acc: 15.6250 (18.7401)\n",
      "[1/25][169/782] Loss_D: 0.7260 (0.9492) Loss_G: 0.4294 (0.9067) D(x): 0.5552 D(G(z)): 0.4655 / 0.4642 Acc: 14.0625 (18.7352)\n",
      "[1/25][170/782] Loss_D: 0.7073 (0.9489) Loss_G: 0.8846 (0.9067) D(x): 0.6220 D(G(z)): 0.4952 / 0.3232 Acc: 20.3125 (18.7369)\n",
      "[1/25][171/782] Loss_D: 0.8919 (0.9489) Loss_G: 0.7983 (0.9065) D(x): 0.4535 D(G(z)): 0.4065 / 0.3520 Acc: 21.8750 (18.7402)\n",
      "[1/25][172/782] Loss_D: 0.8214 (0.9487) Loss_G: 0.5883 (0.9062) D(x): 0.4765 D(G(z)): 0.4356 / 0.4030 Acc: 20.3125 (18.7418)\n",
      "[1/25][173/782] Loss_D: 0.9956 (0.9488) Loss_G: 0.4618 (0.9058) D(x): 0.4132 D(G(z)): 0.4872 / 0.4836 Acc: 32.8125 (18.7565)\n",
      "[1/25][174/782] Loss_D: 0.7081 (0.9485) Loss_G: 0.6043 (0.9054) D(x): 0.6393 D(G(z)): 0.5300 / 0.3959 Acc: 21.8750 (18.7598)\n",
      "[1/25][175/782] Loss_D: 0.7086 (0.9483) Loss_G: 0.7211 (0.9052) D(x): 0.5595 D(G(z)): 0.4708 / 0.3783 Acc: 20.3125 (18.7614)\n",
      "[1/25][176/782] Loss_D: 0.7184 (0.9480) Loss_G: 0.5976 (0.9049) D(x): 0.5673 D(G(z)): 0.5072 / 0.4351 Acc: 37.5000 (18.7810)\n",
      "[1/25][177/782] Loss_D: 0.7430 (0.9478) Loss_G: 0.6439 (0.9047) D(x): 0.4703 D(G(z)): 0.3710 / 0.3973 Acc: 21.8750 (18.7842)\n",
      "[1/25][178/782] Loss_D: 0.6035 (0.9475) Loss_G: 0.5410 (0.9043) D(x): 0.5759 D(G(z)): 0.4222 / 0.4171 Acc: 15.6250 (18.7809)\n",
      "[1/25][179/782] Loss_D: 0.7774 (0.9473) Loss_G: 0.4345 (0.9038) D(x): 0.5732 D(G(z)): 0.4410 / 0.4869 Acc: 10.9375 (18.7727)\n",
      "[1/25][180/782] Loss_D: 0.7147 (0.9470) Loss_G: 0.7005 (0.9036) D(x): 0.6065 D(G(z)): 0.5030 / 0.3625 Acc: 14.0625 (18.7678)\n",
      "[1/25][181/782] Loss_D: 0.7124 (0.9468) Loss_G: 0.7963 (0.9035) D(x): 0.5641 D(G(z)): 0.4496 / 0.3493 Acc: 18.7500 (18.7678)\n",
      "[1/25][182/782] Loss_D: 0.5980 (0.9464) Loss_G: 0.7011 (0.9033) D(x): 0.4886 D(G(z)): 0.3301 / 0.3756 Acc: 20.3125 (18.7694)\n",
      "[1/25][183/782] Loss_D: 0.4990 (0.9460) Loss_G: 0.6308 (0.9030) D(x): 0.5796 D(G(z)): 0.3932 / 0.4115 Acc: 31.2500 (18.7823)\n",
      "[1/25][184/782] Loss_D: 0.4793 (0.9455) Loss_G: 0.5310 (0.9026) D(x): 0.6017 D(G(z)): 0.4260 / 0.4381 Acc: 26.5625 (18.7904)\n",
      "[1/25][185/782] Loss_D: 0.5698 (0.9451) Loss_G: 0.6484 (0.9023) D(x): 0.5875 D(G(z)): 0.4406 / 0.3750 Acc: 23.4375 (18.7952)\n",
      "[1/25][186/782] Loss_D: 0.8251 (0.9450) Loss_G: 0.5863 (0.9020) D(x): 0.5489 D(G(z)): 0.4762 / 0.4217 Acc: 20.3125 (18.7968)\n",
      "[1/25][187/782] Loss_D: 0.7370 (0.9448) Loss_G: 0.8285 (0.9019) D(x): 0.5405 D(G(z)): 0.4073 / 0.3978 Acc: 25.0000 (18.8032)\n",
      "[1/25][188/782] Loss_D: 0.4907 (0.9443) Loss_G: 0.7310 (0.9017) D(x): 0.6331 D(G(z)): 0.4414 / 0.3696 Acc: 29.6875 (18.8144)\n",
      "[1/25][189/782] Loss_D: 0.7021 (0.9441) Loss_G: 0.7657 (0.9016) D(x): 0.5794 D(G(z)): 0.3877 / 0.3864 Acc: 17.1875 (18.8127)\n",
      "[1/25][190/782] Loss_D: 0.7913 (0.9439) Loss_G: 0.6724 (0.9014) D(x): 0.5923 D(G(z)): 0.4729 / 0.4225 Acc: 25.0000 (18.8191)\n",
      "[1/25][191/782] Loss_D: 0.6012 (0.9435) Loss_G: 0.8612 (0.9013) D(x): 0.5317 D(G(z)): 0.3964 / 0.3378 Acc: 31.2500 (18.8318)\n",
      "[1/25][192/782] Loss_D: 0.9146 (0.9435) Loss_G: 0.5124 (0.9009) D(x): 0.6130 D(G(z)): 0.5464 / 0.4534 Acc: 15.6250 (18.8285)\n",
      "[1/25][193/782] Loss_D: 0.7217 (0.9433) Loss_G: 0.6553 (0.9007) D(x): 0.5733 D(G(z)): 0.4833 / 0.3891 Acc: 28.1250 (18.8381)\n",
      "[1/25][194/782] Loss_D: 0.5602 (0.9429) Loss_G: 0.4895 (0.9003) D(x): 0.5118 D(G(z)): 0.3559 / 0.4509 Acc: 32.8125 (18.8524)\n",
      "[1/25][195/782] Loss_D: 0.5303 (0.9425) Loss_G: 0.4698 (0.8998) D(x): 0.5817 D(G(z)): 0.3837 / 0.4516 Acc: 20.3125 (18.8538)\n",
      "[1/25][196/782] Loss_D: 0.6929 (0.9422) Loss_G: 0.4050 (0.8993) D(x): 0.5739 D(G(z)): 0.5022 / 0.4603 Acc: 26.5625 (18.8617)\n",
      "[1/25][197/782] Loss_D: 0.7613 (0.9420) Loss_G: 0.8231 (0.8992) D(x): 0.6124 D(G(z)): 0.4740 / 0.3813 Acc: 26.5625 (18.8696)\n",
      "[1/25][198/782] Loss_D: 0.6132 (0.9417) Loss_G: 0.8329 (0.8992) D(x): 0.5779 D(G(z)): 0.4580 / 0.3239 Acc: 23.4375 (18.8742)\n",
      "[1/25][199/782] Loss_D: 0.8741 (0.9416) Loss_G: 0.7615 (0.8990) D(x): 0.5280 D(G(z)): 0.4659 / 0.3780 Acc: 20.3125 (18.8757)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/25][200/782] Loss_D: 0.5266 (0.9412) Loss_G: 0.5811 (0.8987) D(x): 0.4906 D(G(z)): 0.3570 / 0.4219 Acc: 42.1875 (18.8994)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[1/25][201/782] Loss_D: 0.6424 (0.9409) Loss_G: 0.6085 (0.8984) D(x): 0.6207 D(G(z)): 0.5044 / 0.3990 Acc: 21.8750 (18.9024)\n",
      "[1/25][202/782] Loss_D: 0.8101 (0.9408) Loss_G: 0.6828 (0.8982) D(x): 0.5041 D(G(z)): 0.4532 / 0.4078 Acc: 25.0000 (18.9086)\n",
      "[1/25][203/782] Loss_D: 0.8011 (0.9406) Loss_G: 0.4975 (0.8978) D(x): 0.5088 D(G(z)): 0.4935 / 0.4619 Acc: 29.6875 (18.9196)\n",
      "[1/25][204/782] Loss_D: 0.6647 (0.9403) Loss_G: 0.6127 (0.8975) D(x): 0.4903 D(G(z)): 0.4075 / 0.3704 Acc: 31.2500 (18.9321)\n",
      "[1/25][205/782] Loss_D: 1.0957 (0.9405) Loss_G: 0.4819 (0.8971) D(x): 0.4071 D(G(z)): 0.4804 / 0.4925 Acc: 29.6875 (18.9429)\n",
      "[1/25][206/782] Loss_D: 0.8779 (0.9404) Loss_G: 0.6164 (0.8968) D(x): 0.5498 D(G(z)): 0.5160 / 0.4757 Acc: 34.3750 (18.9585)\n",
      "[1/25][207/782] Loss_D: 0.8956 (0.9404) Loss_G: 0.7121 (0.8966) D(x): 0.5145 D(G(z)): 0.4921 / 0.3885 Acc: 32.8125 (18.9725)\n",
      "[1/25][208/782] Loss_D: 0.4098 (0.9399) Loss_G: 0.3694 (0.8961) D(x): 0.5954 D(G(z)): 0.3864 / 0.4884 Acc: 28.1250 (18.9818)\n",
      "[1/25][209/782] Loss_D: 0.5132 (0.9394) Loss_G: 0.6434 (0.8958) D(x): 0.6551 D(G(z)): 0.4864 / 0.3833 Acc: 26.5625 (18.9894)\n",
      "[1/25][210/782] Loss_D: 0.6711 (0.9392) Loss_G: 0.8692 (0.8958) D(x): 0.6481 D(G(z)): 0.4987 / 0.3075 Acc: 14.0625 (18.9845)\n",
      "[1/25][211/782] Loss_D: 0.5941 (0.9388) Loss_G: 0.7913 (0.8957) D(x): 0.5130 D(G(z)): 0.3299 / 0.3677 Acc: 28.1250 (18.9936)\n",
      "[1/25][212/782] Loss_D: 0.6497 (0.9385) Loss_G: 0.7609 (0.8955) D(x): 0.5422 D(G(z)): 0.4138 / 0.3635 Acc: 25.0000 (18.9997)\n",
      "[1/25][213/782] Loss_D: 0.4333 (0.9380) Loss_G: 0.4982 (0.8951) D(x): 0.5431 D(G(z)): 0.3647 / 0.4591 Acc: 37.5000 (19.0183)\n",
      "[1/25][214/782] Loss_D: 0.4904 (0.9376) Loss_G: 0.5395 (0.8948) D(x): 0.6270 D(G(z)): 0.4574 / 0.4244 Acc: 26.5625 (19.0258)\n",
      "[1/25][215/782] Loss_D: 0.7005 (0.9373) Loss_G: 0.7616 (0.8947) D(x): 0.6082 D(G(z)): 0.4759 / 0.4008 Acc: 31.2500 (19.0381)\n",
      "[1/25][216/782] Loss_D: 0.6517 (0.9370) Loss_G: 0.7985 (0.8946) D(x): 0.5903 D(G(z)): 0.4233 / 0.3764 Acc: 28.1250 (19.0472)\n",
      "[1/25][217/782] Loss_D: 0.5687 (0.9367) Loss_G: 0.6588 (0.8943) D(x): 0.5894 D(G(z)): 0.4443 / 0.3804 Acc: 25.0000 (19.0531)\n",
      "[1/25][218/782] Loss_D: 0.8987 (0.9366) Loss_G: 0.9969 (0.8944) D(x): 0.5251 D(G(z)): 0.4340 / 0.3253 Acc: 26.5625 (19.0606)\n",
      "[1/25][219/782] Loss_D: 0.6631 (0.9364) Loss_G: 0.8634 (0.8944) D(x): 0.5762 D(G(z)): 0.4050 / 0.3321 Acc: 15.6250 (19.0572)\n",
      "[1/25][220/782] Loss_D: 0.6530 (0.9361) Loss_G: 0.7599 (0.8943) D(x): 0.6073 D(G(z)): 0.4375 / 0.3815 Acc: 21.8750 (19.0600)\n",
      "[1/25][221/782] Loss_D: 0.6990 (0.9358) Loss_G: 0.7614 (0.8941) D(x): 0.5722 D(G(z)): 0.4475 / 0.3719 Acc: 29.6875 (19.0706)\n",
      "[1/25][222/782] Loss_D: 1.0524 (0.9360) Loss_G: 0.8729 (0.8941) D(x): 0.5187 D(G(z)): 0.5265 / 0.3272 Acc: 20.3125 (19.0718)\n",
      "[1/25][223/782] Loss_D: 0.7530 (0.9358) Loss_G: 1.0712 (0.8943) D(x): 0.5533 D(G(z)): 0.4692 / 0.2866 Acc: 28.1250 (19.0808)\n",
      "[1/25][224/782] Loss_D: 0.8187 (0.9357) Loss_G: 0.8249 (0.8942) D(x): 0.4843 D(G(z)): 0.4269 / 0.3572 Acc: 25.0000 (19.0867)\n",
      "[1/25][225/782] Loss_D: 0.5325 (0.9353) Loss_G: 0.6732 (0.8940) D(x): 0.5470 D(G(z)): 0.3877 / 0.3682 Acc: 23.4375 (19.0910)\n",
      "[1/25][226/782] Loss_D: 0.6481 (0.9350) Loss_G: 0.7083 (0.8938) D(x): 0.5606 D(G(z)): 0.4443 / 0.3822 Acc: 28.1250 (19.1000)\n",
      "[1/25][227/782] Loss_D: 0.7513 (0.9348) Loss_G: 1.0506 (0.8940) D(x): 0.6348 D(G(z)): 0.5082 / 0.3048 Acc: 32.8125 (19.1136)\n",
      "[1/25][228/782] Loss_D: 0.6967 (0.9346) Loss_G: 0.8515 (0.8939) D(x): 0.5071 D(G(z)): 0.3803 / 0.3372 Acc: 21.8750 (19.1163)\n",
      "[1/25][229/782] Loss_D: 0.4573 (0.9341) Loss_G: 0.5845 (0.8936) D(x): 0.5985 D(G(z)): 0.3616 / 0.4244 Acc: 17.1875 (19.1144)\n",
      "[1/25][230/782] Loss_D: 0.7003 (0.9339) Loss_G: 0.6677 (0.8934) D(x): 0.6317 D(G(z)): 0.5259 / 0.4131 Acc: 21.8750 (19.1171)\n",
      "[1/25][231/782] Loss_D: 0.5784 (0.9335) Loss_G: 0.7074 (0.8932) D(x): 0.5704 D(G(z)): 0.4352 / 0.3775 Acc: 23.4375 (19.1214)\n",
      "[1/25][232/782] Loss_D: 0.8230 (0.9334) Loss_G: 0.4788 (0.8928) D(x): 0.4352 D(G(z)): 0.4118 / 0.4376 Acc: 28.1250 (19.1302)\n",
      "[1/25][233/782] Loss_D: 0.7281 (0.9332) Loss_G: 0.5112 (0.8924) D(x): 0.6057 D(G(z)): 0.4989 / 0.4038 Acc: 15.6250 (19.1268)\n",
      "[1/25][234/782] Loss_D: 0.6638 (0.9329) Loss_G: 0.5485 (0.8921) D(x): 0.5755 D(G(z)): 0.4989 / 0.3883 Acc: 20.3125 (19.1279)\n",
      "[1/25][235/782] Loss_D: 0.6997 (0.9327) Loss_G: 0.7888 (0.8920) D(x): 0.5116 D(G(z)): 0.4287 / 0.3505 Acc: 25.0000 (19.1337)\n",
      "[1/25][236/782] Loss_D: 0.7150 (0.9325) Loss_G: 0.6755 (0.8918) D(x): 0.5575 D(G(z)): 0.4740 / 0.3531 Acc: 14.0625 (19.1287)\n",
      "[1/25][237/782] Loss_D: 0.6151 (0.9322) Loss_G: 0.5067 (0.8914) D(x): 0.5196 D(G(z)): 0.3791 / 0.4474 Acc: 25.0000 (19.1345)\n",
      "[1/25][238/782] Loss_D: 0.7785 (0.9320) Loss_G: 0.5677 (0.8911) D(x): 0.5881 D(G(z)): 0.4882 / 0.4303 Acc: 18.7500 (19.1341)\n",
      "[1/25][239/782] Loss_D: 0.8063 (0.9319) Loss_G: 0.6164 (0.8908) D(x): 0.4826 D(G(z)): 0.3655 / 0.4161 Acc: 15.6250 (19.1307)\n",
      "[1/25][240/782] Loss_D: 0.8046 (0.9318) Loss_G: 0.8263 (0.8908) D(x): 0.6005 D(G(z)): 0.5142 / 0.3727 Acc: 25.0000 (19.1364)\n",
      "[1/25][241/782] Loss_D: 0.7747 (0.9316) Loss_G: 0.8027 (0.8907) D(x): 0.6025 D(G(z)): 0.4816 / 0.3436 Acc: 12.5000 (19.1299)\n",
      "[1/25][242/782] Loss_D: 0.7865 (0.9315) Loss_G: 0.7548 (0.8905) D(x): 0.5264 D(G(z)): 0.4087 / 0.3895 Acc: 18.7500 (19.1296)\n",
      "[1/25][243/782] Loss_D: 0.7099 (0.9313) Loss_G: 0.6611 (0.8903) D(x): 0.5023 D(G(z)): 0.3815 / 0.3986 Acc: 20.3125 (19.1307)\n",
      "[1/25][244/782] Loss_D: 0.6714 (0.9310) Loss_G: 0.6318 (0.8901) D(x): 0.6241 D(G(z)): 0.4830 / 0.4084 Acc: 15.6250 (19.1273)\n",
      "[1/25][245/782] Loss_D: 0.7046 (0.9308) Loss_G: 0.9143 (0.8901) D(x): 0.6140 D(G(z)): 0.4520 / 0.3269 Acc: 15.6250 (19.1239)\n",
      "[1/25][246/782] Loss_D: 0.6597 (0.9305) Loss_G: 0.7762 (0.8900) D(x): 0.5476 D(G(z)): 0.4029 / 0.3510 Acc: 15.6250 (19.1205)\n",
      "[1/25][247/782] Loss_D: 0.7644 (0.9304) Loss_G: 0.8434 (0.8899) D(x): 0.5469 D(G(z)): 0.3871 / 0.3601 Acc: 17.1875 (19.1186)\n",
      "[1/25][248/782] Loss_D: 0.5630 (0.9300) Loss_G: 0.6988 (0.8897) D(x): 0.6047 D(G(z)): 0.4591 / 0.3814 Acc: 28.1250 (19.1274)\n",
      "[1/25][249/782] Loss_D: 0.6618 (0.9298) Loss_G: 0.6152 (0.8895) D(x): 0.5389 D(G(z)): 0.3816 / 0.4133 Acc: 14.0625 (19.1225)\n",
      "[1/25][250/782] Loss_D: 0.7029 (0.9295) Loss_G: 0.6056 (0.8892) D(x): 0.5776 D(G(z)): 0.5243 / 0.3962 Acc: 26.5625 (19.1297)\n",
      "[1/25][251/782] Loss_D: 0.7122 (0.9293) Loss_G: 0.4963 (0.8888) D(x): 0.5406 D(G(z)): 0.4119 / 0.4546 Acc: 17.1875 (19.1278)\n",
      "[1/25][252/782] Loss_D: 0.7527 (0.9292) Loss_G: 0.5572 (0.8885) D(x): 0.5460 D(G(z)): 0.4809 / 0.4291 Acc: 28.1250 (19.1365)\n",
      "[1/25][253/782] Loss_D: 0.9739 (0.9292) Loss_G: 0.5114 (0.8881) D(x): 0.4781 D(G(z)): 0.5020 / 0.4452 Acc: 25.0000 (19.1421)\n",
      "[1/25][254/782] Loss_D: 0.9179 (0.9292) Loss_G: 0.5926 (0.8879) D(x): 0.5370 D(G(z)): 0.4870 / 0.4386 Acc: 12.5000 (19.1357)\n",
      "[1/25][255/782] Loss_D: 0.9002 (0.9292) Loss_G: 0.5984 (0.8876) D(x): 0.5209 D(G(z)): 0.5041 / 0.4057 Acc: 20.3125 (19.1369)\n",
      "[1/25][256/782] Loss_D: 0.7826 (0.9290) Loss_G: 0.5021 (0.8872) D(x): 0.5365 D(G(z)): 0.4877 / 0.4113 Acc: 23.4375 (19.1410)\n",
      "[1/25][257/782] Loss_D: 0.5783 (0.9287) Loss_G: 0.6400 (0.8870) D(x): 0.5315 D(G(z)): 0.4113 / 0.3937 Acc: 28.1250 (19.1496)\n",
      "[1/25][258/782] Loss_D: 0.7466 (0.9285) Loss_G: 0.5978 (0.8867) D(x): 0.4639 D(G(z)): 0.4230 / 0.4024 Acc: 29.6875 (19.1598)\n",
      "[1/25][259/782] Loss_D: 0.7676 (0.9284) Loss_G: 0.7779 (0.8866) D(x): 0.6395 D(G(z)): 0.4722 / 0.3925 Acc: 14.0625 (19.1549)\n",
      "[1/25][260/782] Loss_D: 0.8377 (0.9283) Loss_G: 0.5463 (0.8863) D(x): 0.5001 D(G(z)): 0.4358 / 0.4325 Acc: 20.3125 (19.1560)\n",
      "[1/25][261/782] Loss_D: 0.7432 (0.9281) Loss_G: 0.5993 (0.8860) D(x): 0.5221 D(G(z)): 0.4575 / 0.4248 Acc: 29.6875 (19.1661)\n",
      "[1/25][262/782] Loss_D: 0.6392 (0.9278) Loss_G: 0.6403 (0.8857) D(x): 0.6049 D(G(z)): 0.3994 / 0.4006 Acc: 10.9375 (19.1582)\n",
      "[1/25][263/782] Loss_D: 0.7574 (0.9277) Loss_G: 0.6691 (0.8855) D(x): 0.5457 D(G(z)): 0.4419 / 0.3999 Acc: 25.0000 (19.1638)\n",
      "[1/25][264/782] Loss_D: 0.5703 (0.9273) Loss_G: 0.4370 (0.8851) D(x): 0.5671 D(G(z)): 0.4474 / 0.4381 Acc: 25.0000 (19.1694)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/25][265/782] Loss_D: 0.4323 (0.9268) Loss_G: 0.6771 (0.8849) D(x): 0.5921 D(G(z)): 0.3973 / 0.3677 Acc: 26.5625 (19.1764)\n",
      "[1/25][266/782] Loss_D: 0.6776 (0.9266) Loss_G: 0.5562 (0.8846) D(x): 0.5222 D(G(z)): 0.4713 / 0.3941 Acc: 28.1250 (19.1849)\n",
      "[1/25][267/782] Loss_D: 0.4372 (0.9261) Loss_G: 0.6891 (0.8844) D(x): 0.5850 D(G(z)): 0.4145 / 0.3531 Acc: 31.2500 (19.1964)\n",
      "[1/25][268/782] Loss_D: 0.4170 (0.9256) Loss_G: 0.8441 (0.8844) D(x): 0.6145 D(G(z)): 0.3981 / 0.3523 Acc: 32.8125 (19.2094)\n",
      "[1/25][269/782] Loss_D: 0.7250 (0.9255) Loss_G: 0.8112 (0.8843) D(x): 0.5794 D(G(z)): 0.4319 / 0.3596 Acc: 15.6250 (19.2060)\n",
      "[1/25][270/782] Loss_D: 0.6249 (0.9252) Loss_G: 0.8313 (0.8843) D(x): 0.5814 D(G(z)): 0.3999 / 0.3324 Acc: 17.1875 (19.2041)\n",
      "[1/25][271/782] Loss_D: 0.5623 (0.9248) Loss_G: 0.8784 (0.8842) D(x): 0.6012 D(G(z)): 0.4414 / 0.3024 Acc: 25.0000 (19.2096)\n",
      "[1/25][272/782] Loss_D: 0.5772 (0.9245) Loss_G: 0.7806 (0.8841) D(x): 0.5413 D(G(z)): 0.3424 / 0.3408 Acc: 18.7500 (19.2091)\n",
      "[1/25][273/782] Loss_D: 0.3638 (0.9240) Loss_G: 0.7293 (0.8840) D(x): 0.6015 D(G(z)): 0.3842 / 0.3450 Acc: 29.6875 (19.2190)\n",
      "[1/25][274/782] Loss_D: 0.6316 (0.9237) Loss_G: 0.7641 (0.8839) D(x): 0.6201 D(G(z)): 0.4785 / 0.3708 Acc: 26.5625 (19.2260)\n",
      "[1/25][275/782] Loss_D: 0.3674 (0.9232) Loss_G: 0.8154 (0.8838) D(x): 0.6171 D(G(z)): 0.4034 / 0.3434 Acc: 28.1250 (19.2344)\n",
      "[1/25][276/782] Loss_D: 0.6891 (0.9229) Loss_G: 0.6354 (0.8836) D(x): 0.5123 D(G(z)): 0.4233 / 0.3782 Acc: 29.6875 (19.2443)\n",
      "[1/25][277/782] Loss_D: 0.6883 (0.9227) Loss_G: 0.7397 (0.8835) D(x): 0.6293 D(G(z)): 0.5044 / 0.3564 Acc: 20.3125 (19.2453)\n",
      "[1/25][278/782] Loss_D: 0.5477 (0.9224) Loss_G: 0.6087 (0.8832) D(x): 0.5319 D(G(z)): 0.3877 / 0.3995 Acc: 28.1250 (19.2537)\n",
      "[1/25][279/782] Loss_D: 0.7031 (0.9222) Loss_G: 0.6853 (0.8830) D(x): 0.6147 D(G(z)): 0.4525 / 0.3935 Acc: 17.1875 (19.2517)\n",
      "[1/25][280/782] Loss_D: 0.6140 (0.9219) Loss_G: 0.5889 (0.8827) D(x): 0.5106 D(G(z)): 0.4303 / 0.3986 Acc: 26.5625 (19.2586)\n",
      "[1/25][281/782] Loss_D: 0.6442 (0.9216) Loss_G: 0.7203 (0.8826) D(x): 0.5814 D(G(z)): 0.4238 / 0.3871 Acc: 18.7500 (19.2581)\n",
      "[1/25][282/782] Loss_D: 0.8619 (0.9216) Loss_G: 0.6979 (0.8824) D(x): 0.5438 D(G(z)): 0.4687 / 0.3951 Acc: 15.6250 (19.2547)\n",
      "[1/25][283/782] Loss_D: 0.7715 (0.9214) Loss_G: 1.0371 (0.8826) D(x): 0.5549 D(G(z)): 0.4711 / 0.3040 Acc: 29.6875 (19.2645)\n",
      "[1/25][284/782] Loss_D: 0.6829 (0.9212) Loss_G: 0.7565 (0.8824) D(x): 0.5197 D(G(z)): 0.4378 / 0.3664 Acc: 31.2500 (19.2757)\n",
      "[1/25][285/782] Loss_D: 0.9497 (0.9212) Loss_G: 0.8054 (0.8824) D(x): 0.5287 D(G(z)): 0.4727 / 0.3865 Acc: 25.0000 (19.2811)\n",
      "[1/25][286/782] Loss_D: 0.6364 (0.9210) Loss_G: 0.8779 (0.8824) D(x): 0.5707 D(G(z)): 0.4057 / 0.3699 Acc: 31.2500 (19.2923)\n",
      "[1/25][287/782] Loss_D: 0.6412 (0.9207) Loss_G: 0.6583 (0.8821) D(x): 0.6057 D(G(z)): 0.4679 / 0.4013 Acc: 26.5625 (19.2991)\n",
      "[1/25][288/782] Loss_D: 0.5942 (0.9204) Loss_G: 0.6858 (0.8820) D(x): 0.5617 D(G(z)): 0.3834 / 0.3753 Acc: 23.4375 (19.3029)\n",
      "[1/25][289/782] Loss_D: 0.5653 (0.9201) Loss_G: 0.6009 (0.8817) D(x): 0.5994 D(G(z)): 0.4698 / 0.3923 Acc: 28.1250 (19.3112)\n",
      "[1/25][290/782] Loss_D: 0.7845 (0.9199) Loss_G: 0.7510 (0.8816) D(x): 0.5565 D(G(z)): 0.4607 / 0.3864 Acc: 23.4375 (19.3150)\n",
      "[1/25][291/782] Loss_D: 0.8010 (0.9198) Loss_G: 0.7126 (0.8814) D(x): 0.5870 D(G(z)): 0.5380 / 0.3714 Acc: 29.6875 (19.3247)\n",
      "[1/25][292/782] Loss_D: 0.5895 (0.9195) Loss_G: 0.8288 (0.8814) D(x): 0.6030 D(G(z)): 0.4868 / 0.3503 Acc: 40.6250 (19.3445)\n",
      "[1/25][293/782] Loss_D: 0.6455 (0.9193) Loss_G: 0.7722 (0.8813) D(x): 0.4633 D(G(z)): 0.3574 / 0.3355 Acc: 28.1250 (19.3526)\n",
      "[1/25][294/782] Loss_D: 0.8418 (0.9192) Loss_G: 0.7891 (0.8812) D(x): 0.5515 D(G(z)): 0.5279 / 0.3581 Acc: 28.1250 (19.3608)\n",
      "[1/25][295/782] Loss_D: 0.6881 (0.9190) Loss_G: 0.5613 (0.8809) D(x): 0.4955 D(G(z)): 0.4438 / 0.4076 Acc: 34.3750 (19.3747)\n",
      "[1/25][296/782] Loss_D: 0.8989 (0.9190) Loss_G: 0.4863 (0.8805) D(x): 0.4503 D(G(z)): 0.4761 / 0.4389 Acc: 26.5625 (19.3814)\n",
      "[1/25][297/782] Loss_D: 1.0536 (0.9191) Loss_G: 0.5172 (0.8802) D(x): 0.5077 D(G(z)): 0.5654 / 0.4306 Acc: 28.1250 (19.3895)\n",
      "[1/25][298/782] Loss_D: 1.1492 (0.9193) Loss_G: 0.4838 (0.8798) D(x): 0.4606 D(G(z)): 0.5728 / 0.4654 Acc: 28.1250 (19.3975)\n",
      "[1/25][299/782] Loss_D: 0.9790 (0.9193) Loss_G: 0.5163 (0.8795) D(x): 0.4676 D(G(z)): 0.4938 / 0.4513 Acc: 23.4375 (19.4013)\n",
      "[1/25][300/782] Loss_D: 1.0514 (0.9195) Loss_G: 0.5393 (0.8792) D(x): 0.5008 D(G(z)): 0.5325 / 0.4485 Acc: 21.8750 (19.4036)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[1/25][301/782] Loss_D: 0.8807 (0.9194) Loss_G: 0.5376 (0.8789) D(x): 0.5392 D(G(z)): 0.5213 / 0.4445 Acc: 23.4375 (19.4073)\n",
      "[1/25][302/782] Loss_D: 0.9082 (0.9194) Loss_G: 0.4188 (0.8784) D(x): 0.4597 D(G(z)): 0.4971 / 0.4402 Acc: 25.0000 (19.4124)\n",
      "[1/25][303/782] Loss_D: 1.1496 (0.9196) Loss_G: 0.4304 (0.8780) D(x): 0.4471 D(G(z)): 0.5465 / 0.4949 Acc: 17.1875 (19.4104)\n",
      "[1/25][304/782] Loss_D: 1.1359 (0.9198) Loss_G: 0.4640 (0.8776) D(x): 0.5253 D(G(z)): 0.5684 / 0.5010 Acc: 26.5625 (19.4170)\n",
      "[1/25][305/782] Loss_D: 1.3062 (0.9202) Loss_G: 0.2942 (0.8771) D(x): 0.3682 D(G(z)): 0.5532 / 0.5093 Acc: 25.0000 (19.4221)\n",
      "[1/25][306/782] Loss_D: 0.9219 (0.9202) Loss_G: 0.4094 (0.8767) D(x): 0.5104 D(G(z)): 0.4928 / 0.5081 Acc: 20.3125 (19.4229)\n",
      "[1/25][307/782] Loss_D: 0.9207 (0.9202) Loss_G: 0.3102 (0.8762) D(x): 0.5400 D(G(z)): 0.5556 / 0.5119 Acc: 26.5625 (19.4295)\n",
      "[1/25][308/782] Loss_D: 0.8541 (0.9201) Loss_G: 0.4350 (0.8757) D(x): 0.5182 D(G(z)): 0.5148 / 0.4588 Acc: 29.6875 (19.4389)\n",
      "[1/25][309/782] Loss_D: 0.8250 (0.9200) Loss_G: 0.3311 (0.8753) D(x): 0.5002 D(G(z)): 0.5251 / 0.4720 Acc: 17.1875 (19.4368)\n",
      "[1/25][310/782] Loss_D: 0.7929 (0.9199) Loss_G: 0.6075 (0.8750) D(x): 0.5756 D(G(z)): 0.4918 / 0.4194 Acc: 21.8750 (19.4390)\n",
      "[1/25][311/782] Loss_D: 0.9228 (0.9199) Loss_G: 0.4180 (0.8746) D(x): 0.4952 D(G(z)): 0.5016 / 0.4359 Acc: 17.1875 (19.4370)\n",
      "[1/25][312/782] Loss_D: 0.7475 (0.9198) Loss_G: 0.3370 (0.8741) D(x): 0.4991 D(G(z)): 0.5110 / 0.4443 Acc: 29.6875 (19.4463)\n",
      "[1/25][313/782] Loss_D: 0.8202 (0.9197) Loss_G: 0.4895 (0.8737) D(x): 0.4836 D(G(z)): 0.4433 / 0.4591 Acc: 20.3125 (19.4471)\n",
      "[1/25][314/782] Loss_D: 0.8422 (0.9196) Loss_G: 0.2801 (0.8732) D(x): 0.5010 D(G(z)): 0.4820 / 0.5287 Acc: 23.4375 (19.4508)\n",
      "[1/25][315/782] Loss_D: 0.9560 (0.9196) Loss_G: 0.3356 (0.8727) D(x): 0.4746 D(G(z)): 0.4727 / 0.4947 Acc: 17.1875 (19.4487)\n",
      "[1/25][316/782] Loss_D: 1.0516 (0.9198) Loss_G: 0.4359 (0.8723) D(x): 0.5493 D(G(z)): 0.5511 / 0.5053 Acc: 15.6250 (19.4452)\n",
      "[1/25][317/782] Loss_D: 0.8340 (0.9197) Loss_G: 0.4659 (0.8719) D(x): 0.5222 D(G(z)): 0.5156 / 0.4063 Acc: 23.4375 (19.4489)\n",
      "[1/25][318/782] Loss_D: 0.8484 (0.9196) Loss_G: 0.4384 (0.8716) D(x): 0.5084 D(G(z)): 0.5025 / 0.4489 Acc: 23.4375 (19.4525)\n",
      "[1/25][319/782] Loss_D: 0.7641 (0.9195) Loss_G: 0.4940 (0.8712) D(x): 0.4884 D(G(z)): 0.4410 / 0.4361 Acc: 21.8750 (19.4547)\n",
      "[1/25][320/782] Loss_D: 0.8509 (0.9194) Loss_G: 0.3567 (0.8707) D(x): 0.5513 D(G(z)): 0.5028 / 0.4678 Acc: 17.1875 (19.4526)\n",
      "[1/25][321/782] Loss_D: 0.8264 (0.9193) Loss_G: 0.3150 (0.8702) D(x): 0.4966 D(G(z)): 0.4602 / 0.4998 Acc: 20.3125 (19.4534)\n",
      "[1/25][322/782] Loss_D: 0.7837 (0.9192) Loss_G: 0.3772 (0.8698) D(x): 0.5785 D(G(z)): 0.5275 / 0.5017 Acc: 28.1250 (19.4613)\n",
      "[1/25][323/782] Loss_D: 0.8982 (0.9192) Loss_G: 0.3508 (0.8693) D(x): 0.4793 D(G(z)): 0.4990 / 0.4671 Acc: 28.1250 (19.4691)\n",
      "[1/25][324/782] Loss_D: 0.8781 (0.9192) Loss_G: 0.3394 (0.8688) D(x): 0.5011 D(G(z)): 0.5029 / 0.4511 Acc: 18.7500 (19.4684)\n",
      "[1/25][325/782] Loss_D: 0.7688 (0.9190) Loss_G: 0.3932 (0.8684) D(x): 0.5325 D(G(z)): 0.5177 / 0.4766 Acc: 26.5625 (19.4748)\n",
      "[1/25][326/782] Loss_D: 0.9150 (0.9190) Loss_G: 0.2586 (0.8679) D(x): 0.4760 D(G(z)): 0.4871 / 0.4992 Acc: 12.5000 (19.4686)\n",
      "[1/25][327/782] Loss_D: 1.0053 (0.9191) Loss_G: 0.3552 (0.8674) D(x): 0.4820 D(G(z)): 0.5066 / 0.4842 Acc: 12.5000 (19.4623)\n",
      "[1/25][328/782] Loss_D: 0.8087 (0.9190) Loss_G: 0.3228 (0.8669) D(x): 0.5028 D(G(z)): 0.5133 / 0.4597 Acc: 20.3125 (19.4630)\n",
      "[1/25][329/782] Loss_D: 0.8390 (0.9189) Loss_G: 0.4277 (0.8665) D(x): 0.5122 D(G(z)): 0.4604 / 0.4822 Acc: 15.6250 (19.4596)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/25][330/782] Loss_D: 0.6236 (0.9187) Loss_G: 0.3171 (0.8660) D(x): 0.5022 D(G(z)): 0.4474 / 0.4643 Acc: 26.5625 (19.4660)\n",
      "[1/25][331/782] Loss_D: 0.7319 (0.9185) Loss_G: 0.3894 (0.8656) D(x): 0.4816 D(G(z)): 0.4720 / 0.4306 Acc: 26.5625 (19.4723)\n",
      "[1/25][332/782] Loss_D: 0.5823 (0.9182) Loss_G: 0.3304 (0.8651) D(x): 0.5160 D(G(z)): 0.4395 / 0.4529 Acc: 21.8750 (19.4745)\n",
      "[1/25][333/782] Loss_D: 0.7359 (0.9180) Loss_G: 0.3863 (0.8647) D(x): 0.5580 D(G(z)): 0.5009 / 0.4684 Acc: 21.8750 (19.4766)\n",
      "[1/25][334/782] Loss_D: 0.8103 (0.9179) Loss_G: 0.3946 (0.8643) D(x): 0.5599 D(G(z)): 0.4621 / 0.4420 Acc: 9.3750 (19.4676)\n",
      "[1/25][335/782] Loss_D: 0.5526 (0.9176) Loss_G: 0.4534 (0.8639) D(x): 0.5670 D(G(z)): 0.4378 / 0.3991 Acc: 12.5000 (19.4614)\n",
      "[1/25][336/782] Loss_D: 0.6965 (0.9174) Loss_G: 0.4490 (0.8635) D(x): 0.5365 D(G(z)): 0.4587 / 0.4529 Acc: 20.3125 (19.4621)\n",
      "[1/25][337/782] Loss_D: 0.6528 (0.9172) Loss_G: 0.5446 (0.8632) D(x): 0.5303 D(G(z)): 0.4268 / 0.4176 Acc: 23.4375 (19.4657)\n",
      "[1/25][338/782] Loss_D: 0.8288 (0.9171) Loss_G: 0.3065 (0.8628) D(x): 0.5321 D(G(z)): 0.5281 / 0.4900 Acc: 25.0000 (19.4706)\n",
      "[1/25][339/782] Loss_D: 0.8078 (0.9170) Loss_G: 0.4635 (0.8624) D(x): 0.5469 D(G(z)): 0.4973 / 0.4495 Acc: 21.8750 (19.4728)\n",
      "[1/25][340/782] Loss_D: 0.7957 (0.9169) Loss_G: 0.4374 (0.8620) D(x): 0.5444 D(G(z)): 0.4796 / 0.4569 Acc: 20.3125 (19.4735)\n",
      "[1/25][341/782] Loss_D: 0.6233 (0.9166) Loss_G: 0.2526 (0.8615) D(x): 0.4543 D(G(z)): 0.4549 / 0.4840 Acc: 37.5000 (19.4895)\n",
      "[1/25][342/782] Loss_D: 0.7466 (0.9165) Loss_G: 0.1883 (0.8609) D(x): 0.5073 D(G(z)): 0.4969 / 0.5096 Acc: 18.7500 (19.4889)\n",
      "[1/25][343/782] Loss_D: 0.7758 (0.9163) Loss_G: 0.4797 (0.8605) D(x): 0.5592 D(G(z)): 0.5080 / 0.4356 Acc: 20.3125 (19.4896)\n",
      "[1/25][344/782] Loss_D: 0.7162 (0.9162) Loss_G: 0.5241 (0.8602) D(x): 0.5150 D(G(z)): 0.4775 / 0.4204 Acc: 23.4375 (19.4931)\n",
      "[1/25][345/782] Loss_D: 0.8511 (0.9161) Loss_G: 0.6015 (0.8600) D(x): 0.4889 D(G(z)): 0.4347 / 0.4063 Acc: 18.7500 (19.4925)\n",
      "[1/25][346/782] Loss_D: 0.5326 (0.9158) Loss_G: 0.2899 (0.8595) D(x): 0.5275 D(G(z)): 0.4185 / 0.4449 Acc: 18.7500 (19.4918)\n",
      "[1/25][347/782] Loss_D: 0.6094 (0.9155) Loss_G: 0.1914 (0.8589) D(x): 0.5364 D(G(z)): 0.4675 / 0.4926 Acc: 17.1875 (19.4898)\n",
      "[1/25][348/782] Loss_D: 0.5826 (0.9152) Loss_G: 0.3683 (0.8585) D(x): 0.5557 D(G(z)): 0.4692 / 0.4460 Acc: 18.7500 (19.4891)\n",
      "[1/25][349/782] Loss_D: 0.7054 (0.9150) Loss_G: 0.4249 (0.8581) D(x): 0.5165 D(G(z)): 0.4496 / 0.4359 Acc: 21.8750 (19.4912)\n",
      "[1/25][350/782] Loss_D: 0.4765 (0.9146) Loss_G: 0.3564 (0.8577) D(x): 0.5795 D(G(z)): 0.4810 / 0.4465 Acc: 23.4375 (19.4947)\n",
      "[1/25][351/782] Loss_D: 0.4904 (0.9143) Loss_G: 0.3479 (0.8572) D(x): 0.5571 D(G(z)): 0.4247 / 0.4723 Acc: 26.5625 (19.5009)\n",
      "[1/25][352/782] Loss_D: 0.6074 (0.9140) Loss_G: 0.4380 (0.8568) D(x): 0.5352 D(G(z)): 0.4518 / 0.4307 Acc: 26.5625 (19.5072)\n",
      "[1/25][353/782] Loss_D: 0.5216 (0.9136) Loss_G: 0.1717 (0.8562) D(x): 0.5530 D(G(z)): 0.4795 / 0.4780 Acc: 26.5625 (19.5134)\n",
      "[1/25][354/782] Loss_D: 0.7250 (0.9135) Loss_G: 0.4558 (0.8559) D(x): 0.5596 D(G(z)): 0.4848 / 0.4567 Acc: 20.3125 (19.5141)\n",
      "[1/25][355/782] Loss_D: 0.6836 (0.9133) Loss_G: 0.5246 (0.8556) D(x): 0.5517 D(G(z)): 0.4592 / 0.4004 Acc: 14.0625 (19.5093)\n",
      "[1/25][356/782] Loss_D: 0.6623 (0.9131) Loss_G: 0.4544 (0.8552) D(x): 0.5478 D(G(z)): 0.4344 / 0.4049 Acc: 14.0625 (19.5045)\n",
      "[1/25][357/782] Loss_D: 0.7449 (0.9129) Loss_G: 0.4186 (0.8549) D(x): 0.5027 D(G(z)): 0.4673 / 0.4407 Acc: 28.1250 (19.5121)\n",
      "[1/25][358/782] Loss_D: 0.7576 (0.9128) Loss_G: 0.2658 (0.8543) D(x): 0.4924 D(G(z)): 0.4841 / 0.4714 Acc: 18.7500 (19.5114)\n",
      "[1/25][359/782] Loss_D: 0.4381 (0.9124) Loss_G: 0.2954 (0.8538) D(x): 0.5543 D(G(z)): 0.4545 / 0.4510 Acc: 28.1250 (19.5189)\n",
      "[1/25][360/782] Loss_D: 0.7665 (0.9122) Loss_G: 0.3792 (0.8534) D(x): 0.5281 D(G(z)): 0.5015 / 0.4709 Acc: 21.8750 (19.5210)\n",
      "[1/25][361/782] Loss_D: 0.5816 (0.9119) Loss_G: 0.4154 (0.8530) D(x): 0.5355 D(G(z)): 0.4521 / 0.4371 Acc: 21.8750 (19.5231)\n",
      "[1/25][362/782] Loss_D: 0.8499 (0.9119) Loss_G: 0.3833 (0.8526) D(x): 0.5002 D(G(z)): 0.4957 / 0.4672 Acc: 25.0000 (19.5278)\n",
      "[1/25][363/782] Loss_D: 0.9560 (0.9119) Loss_G: 0.3840 (0.8522) D(x): 0.4987 D(G(z)): 0.4978 / 0.4566 Acc: 9.3750 (19.5190)\n",
      "[1/25][364/782] Loss_D: 0.6320 (0.9117) Loss_G: 0.3899 (0.8518) D(x): 0.5412 D(G(z)): 0.5007 / 0.4448 Acc: 29.6875 (19.5278)\n",
      "[1/25][365/782] Loss_D: 0.7844 (0.9116) Loss_G: 0.5282 (0.8515) D(x): 0.5012 D(G(z)): 0.4626 / 0.4319 Acc: 23.4375 (19.5313)\n",
      "[1/25][366/782] Loss_D: 0.7058 (0.9114) Loss_G: 0.4195 (0.8512) D(x): 0.5577 D(G(z)): 0.4858 / 0.4410 Acc: 20.3125 (19.5319)\n",
      "[1/25][367/782] Loss_D: 0.6679 (0.9112) Loss_G: 0.3705 (0.8508) D(x): 0.5220 D(G(z)): 0.4345 / 0.4747 Acc: 20.3125 (19.5326)\n",
      "[1/25][368/782] Loss_D: 0.6635 (0.9110) Loss_G: 0.5505 (0.8505) D(x): 0.5356 D(G(z)): 0.4352 / 0.4174 Acc: 18.7500 (19.5319)\n",
      "[1/25][369/782] Loss_D: 0.7726 (0.9108) Loss_G: 0.4428 (0.8501) D(x): 0.5441 D(G(z)): 0.4799 / 0.4442 Acc: 17.1875 (19.5299)\n",
      "[1/25][370/782] Loss_D: 0.8158 (0.9108) Loss_G: 0.2667 (0.8496) D(x): 0.4769 D(G(z)): 0.4837 / 0.4767 Acc: 17.1875 (19.5279)\n",
      "[1/25][371/782] Loss_D: 0.7941 (0.9107) Loss_G: 0.4308 (0.8493) D(x): 0.5335 D(G(z)): 0.4907 / 0.4548 Acc: 26.5625 (19.5340)\n",
      "[1/25][372/782] Loss_D: 0.7190 (0.9105) Loss_G: 0.2457 (0.8487) D(x): 0.4958 D(G(z)): 0.4867 / 0.4879 Acc: 23.4375 (19.5373)\n",
      "[1/25][373/782] Loss_D: 0.7752 (0.9104) Loss_G: 0.2589 (0.8482) D(x): 0.5445 D(G(z)): 0.4914 / 0.4982 Acc: 21.8750 (19.5394)\n",
      "[1/25][374/782] Loss_D: 0.9600 (0.9104) Loss_G: 0.3391 (0.8478) D(x): 0.5049 D(G(z)): 0.5200 / 0.4906 Acc: 20.3125 (19.5400)\n",
      "[1/25][375/782] Loss_D: 0.7217 (0.9103) Loss_G: 0.3437 (0.8474) D(x): 0.5150 D(G(z)): 0.4781 / 0.5007 Acc: 26.5625 (19.5461)\n",
      "[1/25][376/782] Loss_D: 0.8749 (0.9102) Loss_G: 0.3714 (0.8469) D(x): 0.5138 D(G(z)): 0.5033 / 0.4671 Acc: 12.5000 (19.5400)\n",
      "[1/25][377/782] Loss_D: 0.7560 (0.9101) Loss_G: 0.3368 (0.8465) D(x): 0.5033 D(G(z)): 0.4876 / 0.4662 Acc: 18.7500 (19.5393)\n",
      "[1/25][378/782] Loss_D: 0.8624 (0.9100) Loss_G: 0.3507 (0.8461) D(x): 0.4883 D(G(z)): 0.5158 / 0.4814 Acc: 23.4375 (19.5427)\n",
      "[1/25][379/782] Loss_D: 0.6293 (0.9098) Loss_G: 0.2657 (0.8456) D(x): 0.5292 D(G(z)): 0.5116 / 0.4853 Acc: 25.0000 (19.5474)\n",
      "[1/25][380/782] Loss_D: 0.7607 (0.9097) Loss_G: 0.3138 (0.8451) D(x): 0.5381 D(G(z)): 0.5215 / 0.4549 Acc: 17.1875 (19.5454)\n",
      "[1/25][381/782] Loss_D: 0.6007 (0.9094) Loss_G: 0.3774 (0.8447) D(x): 0.5216 D(G(z)): 0.4490 / 0.4274 Acc: 18.7500 (19.5447)\n",
      "[1/25][382/782] Loss_D: 0.7488 (0.9093) Loss_G: 0.2847 (0.8442) D(x): 0.4866 D(G(z)): 0.4710 / 0.4977 Acc: 21.8750 (19.5467)\n",
      "[1/25][383/782] Loss_D: 0.5666 (0.9090) Loss_G: 0.2348 (0.8437) D(x): 0.5191 D(G(z)): 0.4722 / 0.4646 Acc: 23.4375 (19.5500)\n",
      "[1/25][384/782] Loss_D: 0.5126 (0.9086) Loss_G: 0.3744 (0.8433) D(x): 0.5911 D(G(z)): 0.4716 / 0.4477 Acc: 25.0000 (19.5547)\n",
      "[1/25][385/782] Loss_D: 0.5943 (0.9084) Loss_G: 0.4166 (0.8430) D(x): 0.5482 D(G(z)): 0.4864 / 0.4243 Acc: 29.6875 (19.5634)\n",
      "[1/25][386/782] Loss_D: 0.7512 (0.9082) Loss_G: 0.3961 (0.8426) D(x): 0.5155 D(G(z)): 0.4457 / 0.4569 Acc: 14.0625 (19.5587)\n",
      "[1/25][387/782] Loss_D: 0.6241 (0.9080) Loss_G: 0.3065 (0.8421) D(x): 0.5315 D(G(z)): 0.4542 / 0.4714 Acc: 21.8750 (19.5606)\n",
      "[1/25][388/782] Loss_D: 0.5024 (0.9076) Loss_G: 0.2481 (0.8416) D(x): 0.5391 D(G(z)): 0.5215 / 0.4430 Acc: 28.1250 (19.5679)\n",
      "[1/25][389/782] Loss_D: 0.6407 (0.9074) Loss_G: 0.3673 (0.8412) D(x): 0.5032 D(G(z)): 0.4594 / 0.4520 Acc: 26.5625 (19.5739)\n",
      "[1/25][390/782] Loss_D: 0.7621 (0.9073) Loss_G: 0.4335 (0.8409) D(x): 0.5169 D(G(z)): 0.4526 / 0.4609 Acc: 20.3125 (19.5745)\n",
      "[1/25][391/782] Loss_D: 0.5381 (0.9070) Loss_G: 0.2955 (0.8404) D(x): 0.5136 D(G(z)): 0.4446 / 0.4585 Acc: 23.4375 (19.5778)\n",
      "[1/25][392/782] Loss_D: 0.6334 (0.9067) Loss_G: 0.4592 (0.8401) D(x): 0.5515 D(G(z)): 0.4608 / 0.4543 Acc: 26.5625 (19.5838)\n",
      "[1/25][393/782] Loss_D: 0.7390 (0.9066) Loss_G: 0.2542 (0.8396) D(x): 0.5245 D(G(z)): 0.4802 / 0.4815 Acc: 15.6250 (19.5804)\n",
      "[1/25][394/782] Loss_D: 0.8116 (0.9065) Loss_G: 0.2880 (0.8391) D(x): 0.5015 D(G(z)): 0.4646 / 0.5270 Acc: 14.0625 (19.5757)\n",
      "[1/25][395/782] Loss_D: 0.5828 (0.9063) Loss_G: 0.2528 (0.8386) D(x): 0.5496 D(G(z)): 0.4952 / 0.4665 Acc: 21.8750 (19.5777)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/25][396/782] Loss_D: 0.6292 (0.9060) Loss_G: 0.3753 (0.8382) D(x): 0.5406 D(G(z)): 0.4641 / 0.4863 Acc: 29.6875 (19.5862)\n",
      "[1/25][397/782] Loss_D: 0.7042 (0.9058) Loss_G: 0.5411 (0.8380) D(x): 0.5476 D(G(z)): 0.4632 / 0.3988 Acc: 17.1875 (19.5842)\n",
      "[1/25][398/782] Loss_D: 0.5253 (0.9055) Loss_G: 0.4824 (0.8377) D(x): 0.5794 D(G(z)): 0.4872 / 0.4196 Acc: 29.6875 (19.5928)\n",
      "[1/25][399/782] Loss_D: 0.5022 (0.9052) Loss_G: 0.3937 (0.8373) D(x): 0.5326 D(G(z)): 0.4691 / 0.4121 Acc: 32.8125 (19.6040)\n",
      "[1/25][400/782] Loss_D: 0.6663 (0.9050) Loss_G: 0.3639 (0.8369) D(x): 0.4914 D(G(z)): 0.4403 / 0.4403 Acc: 17.1875 (19.6019)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[1/25][401/782] Loss_D: 0.5130 (0.9046) Loss_G: 0.3857 (0.8365) D(x): 0.5112 D(G(z)): 0.4189 / 0.4200 Acc: 25.0000 (19.6065)\n",
      "[1/25][402/782] Loss_D: 0.6124 (0.9044) Loss_G: 0.4040 (0.8361) D(x): 0.5491 D(G(z)): 0.4893 / 0.4511 Acc: 34.3750 (19.6189)\n",
      "[1/25][403/782] Loss_D: 0.6593 (0.9042) Loss_G: 0.3744 (0.8357) D(x): 0.5823 D(G(z)): 0.5320 / 0.4476 Acc: 23.4375 (19.6222)\n",
      "[1/25][404/782] Loss_D: 0.5042 (0.9039) Loss_G: 0.3338 (0.8353) D(x): 0.5464 D(G(z)): 0.4317 / 0.4631 Acc: 25.0000 (19.6267)\n",
      "[1/25][405/782] Loss_D: 0.5323 (0.9035) Loss_G: 0.3798 (0.8349) D(x): 0.4974 D(G(z)): 0.4029 / 0.4680 Acc: 29.6875 (19.6352)\n",
      "[1/25][406/782] Loss_D: 0.7248 (0.9034) Loss_G: 0.3352 (0.8345) D(x): 0.5486 D(G(z)): 0.4878 / 0.4872 Acc: 21.8750 (19.6370)\n",
      "[1/25][407/782] Loss_D: 0.6597 (0.9032) Loss_G: 0.3386 (0.8341) D(x): 0.5560 D(G(z)): 0.4780 / 0.4686 Acc: 20.3125 (19.6376)\n",
      "[1/25][408/782] Loss_D: 0.5024 (0.9029) Loss_G: 0.4009 (0.8337) D(x): 0.5561 D(G(z)): 0.4591 / 0.4033 Acc: 17.1875 (19.6355)\n",
      "[1/25][409/782] Loss_D: 0.4301 (0.9025) Loss_G: 0.2931 (0.8333) D(x): 0.5692 D(G(z)): 0.4834 / 0.4293 Acc: 26.5625 (19.6414)\n",
      "[1/25][410/782] Loss_D: 0.5974 (0.9022) Loss_G: 0.3385 (0.8329) D(x): 0.5209 D(G(z)): 0.4664 / 0.4391 Acc: 28.1250 (19.6485)\n",
      "[1/25][411/782] Loss_D: 0.5960 (0.9019) Loss_G: 0.5820 (0.8327) D(x): 0.5320 D(G(z)): 0.4038 / 0.3968 Acc: 23.4375 (19.6516)\n",
      "[1/25][412/782] Loss_D: 0.5140 (0.9016) Loss_G: 0.2535 (0.8322) D(x): 0.5246 D(G(z)): 0.4373 / 0.4814 Acc: 25.0000 (19.6561)\n",
      "[1/25][413/782] Loss_D: 0.5191 (0.9013) Loss_G: 0.2102 (0.8317) D(x): 0.5367 D(G(z)): 0.4845 / 0.4612 Acc: 20.3125 (19.6567)\n",
      "[1/25][414/782] Loss_D: 0.6579 (0.9011) Loss_G: 0.3112 (0.8312) D(x): 0.5551 D(G(z)): 0.5270 / 0.4203 Acc: 18.7500 (19.6559)\n",
      "[1/25][415/782] Loss_D: 0.6732 (0.9009) Loss_G: 0.3256 (0.8308) D(x): 0.5327 D(G(z)): 0.4689 / 0.4736 Acc: 21.8750 (19.6578)\n",
      "[1/25][416/782] Loss_D: 0.5252 (0.9006) Loss_G: 0.2647 (0.8303) D(x): 0.5212 D(G(z)): 0.4653 / 0.4538 Acc: 28.1250 (19.6648)\n",
      "[1/25][417/782] Loss_D: 0.6411 (0.9004) Loss_G: 0.0672 (0.8297) D(x): 0.4814 D(G(z)): 0.4790 / 0.4885 Acc: 14.0625 (19.6602)\n",
      "[1/25][418/782] Loss_D: 0.6274 (0.9001) Loss_G: 0.3249 (0.8293) D(x): 0.5839 D(G(z)): 0.4797 / 0.4748 Acc: 17.1875 (19.6581)\n",
      "[1/25][419/782] Loss_D: 0.5630 (0.8999) Loss_G: 0.2678 (0.8288) D(x): 0.5737 D(G(z)): 0.4629 / 0.4751 Acc: 15.6250 (19.6547)\n",
      "[1/25][420/782] Loss_D: 0.5286 (0.8996) Loss_G: 0.2792 (0.8283) D(x): 0.5533 D(G(z)): 0.4841 / 0.4787 Acc: 29.6875 (19.6631)\n",
      "[1/25][421/782] Loss_D: 0.5511 (0.8993) Loss_G: 0.1764 (0.8278) D(x): 0.5222 D(G(z)): 0.4702 / 0.4989 Acc: 25.0000 (19.6675)\n",
      "[1/25][422/782] Loss_D: 0.7605 (0.8992) Loss_G: 0.3260 (0.8274) D(x): 0.5445 D(G(z)): 0.5161 / 0.4678 Acc: 18.7500 (19.6668)\n",
      "[1/25][423/782] Loss_D: 0.7100 (0.8990) Loss_G: 0.3773 (0.8270) D(x): 0.5074 D(G(z)): 0.4624 / 0.4375 Acc: 15.6250 (19.6634)\n",
      "[1/25][424/782] Loss_D: 0.8121 (0.8989) Loss_G: 0.2913 (0.8266) D(x): 0.4772 D(G(z)): 0.4410 / 0.4896 Acc: 10.9375 (19.6562)\n",
      "[1/25][425/782] Loss_D: 0.4437 (0.8986) Loss_G: 0.1719 (0.8260) D(x): 0.5879 D(G(z)): 0.4939 / 0.5139 Acc: 34.3750 (19.6684)\n",
      "[1/25][426/782] Loss_D: 0.5531 (0.8983) Loss_G: 0.2412 (0.8255) D(x): 0.5328 D(G(z)): 0.4909 / 0.4547 Acc: 26.5625 (19.6741)\n",
      "[1/25][427/782] Loss_D: 0.6310 (0.8980) Loss_G: 0.3473 (0.8251) D(x): 0.5474 D(G(z)): 0.5069 / 0.4664 Acc: 31.2500 (19.6836)\n",
      "[1/25][428/782] Loss_D: 0.6688 (0.8979) Loss_G: 0.4351 (0.8248) D(x): 0.5369 D(G(z)): 0.4764 / 0.4376 Acc: 21.8750 (19.6854)\n",
      "[1/25][429/782] Loss_D: 0.8045 (0.8978) Loss_G: 0.3068 (0.8244) D(x): 0.4943 D(G(z)): 0.4766 / 0.4791 Acc: 20.3125 (19.6860)\n",
      "[1/25][430/782] Loss_D: 0.6110 (0.8975) Loss_G: 0.3269 (0.8240) D(x): 0.5350 D(G(z)): 0.4698 / 0.4700 Acc: 31.2500 (19.6955)\n",
      "[1/25][431/782] Loss_D: 0.6116 (0.8973) Loss_G: 0.1238 (0.8234) D(x): 0.5136 D(G(z)): 0.4927 / 0.5198 Acc: 29.6875 (19.7037)\n",
      "[1/25][432/782] Loss_D: 0.4797 (0.8970) Loss_G: 0.1655 (0.8229) D(x): 0.5411 D(G(z)): 0.4906 / 0.4821 Acc: 29.6875 (19.7119)\n",
      "[1/25][433/782] Loss_D: 0.5235 (0.8967) Loss_G: 0.1477 (0.8223) D(x): 0.4850 D(G(z)): 0.4705 / 0.4929 Acc: 34.3750 (19.7240)\n",
      "[1/25][434/782] Loss_D: 0.7385 (0.8965) Loss_G: 0.2529 (0.8218) D(x): 0.5063 D(G(z)): 0.5245 / 0.4892 Acc: 26.5625 (19.7296)\n",
      "[1/25][435/782] Loss_D: 0.7595 (0.8964) Loss_G: 0.1923 (0.8213) D(x): 0.5234 D(G(z)): 0.5547 / 0.4624 Acc: 20.3125 (19.7301)\n",
      "[1/25][436/782] Loss_D: 0.4211 (0.8960) Loss_G: 0.2521 (0.8209) D(x): 0.5383 D(G(z)): 0.4622 / 0.4598 Acc: 31.2500 (19.7395)\n",
      "[1/25][437/782] Loss_D: 0.5804 (0.8958) Loss_G: 0.2978 (0.8204) D(x): 0.5243 D(G(z)): 0.4625 / 0.4433 Acc: 20.3125 (19.7400)\n",
      "[1/25][438/782] Loss_D: 0.5099 (0.8954) Loss_G: 0.2603 (0.8200) D(x): 0.5211 D(G(z)): 0.4849 / 0.4650 Acc: 35.9375 (19.7533)\n",
      "[1/25][439/782] Loss_D: 0.4755 (0.8951) Loss_G: 0.2966 (0.8195) D(x): 0.5363 D(G(z)): 0.4925 / 0.4645 Acc: 37.5000 (19.7678)\n",
      "[1/25][440/782] Loss_D: 0.6878 (0.8949) Loss_G: 0.3640 (0.8192) D(x): 0.5166 D(G(z)): 0.4711 / 0.4188 Acc: 15.6250 (19.7644)\n",
      "[1/25][441/782] Loss_D: 0.6970 (0.8948) Loss_G: 0.3361 (0.8188) D(x): 0.5074 D(G(z)): 0.4692 / 0.4483 Acc: 21.8750 (19.7661)\n",
      "[1/25][442/782] Loss_D: 0.7769 (0.8947) Loss_G: 0.3435 (0.8184) D(x): 0.5689 D(G(z)): 0.5412 / 0.4348 Acc: 9.3750 (19.7577)\n",
      "[1/25][443/782] Loss_D: 0.3489 (0.8942) Loss_G: 0.1929 (0.8179) D(x): 0.5151 D(G(z)): 0.4399 / 0.4592 Acc: 35.9375 (19.7709)\n",
      "[1/25][444/782] Loss_D: 0.5544 (0.8940) Loss_G: 0.2881 (0.8174) D(x): 0.5268 D(G(z)): 0.4755 / 0.4167 Acc: 15.6250 (19.7675)\n",
      "[1/25][445/782] Loss_D: 0.5219 (0.8937) Loss_G: 0.4298 (0.8171) D(x): 0.5439 D(G(z)): 0.4619 / 0.3958 Acc: 26.5625 (19.7730)\n",
      "[1/25][446/782] Loss_D: 0.5976 (0.8934) Loss_G: 0.2181 (0.8166) D(x): 0.5133 D(G(z)): 0.4623 / 0.5058 Acc: 29.6875 (19.7811)\n",
      "[1/25][447/782] Loss_D: 0.5632 (0.8931) Loss_G: 0.2467 (0.8162) D(x): 0.5589 D(G(z)): 0.5034 / 0.4806 Acc: 28.1250 (19.7879)\n",
      "[1/25][448/782] Loss_D: 0.4600 (0.8928) Loss_G: 0.2359 (0.8157) D(x): 0.5263 D(G(z)): 0.4771 / 0.4616 Acc: 34.3750 (19.7997)\n",
      "[1/25][449/782] Loss_D: 0.3594 (0.8924) Loss_G: 0.2915 (0.8153) D(x): 0.5656 D(G(z)): 0.4612 / 0.4393 Acc: 34.3750 (19.8115)\n",
      "[1/25][450/782] Loss_D: 0.3624 (0.8919) Loss_G: 0.4516 (0.8150) D(x): 0.5870 D(G(z)): 0.4477 / 0.4011 Acc: 34.3750 (19.8233)\n",
      "[1/25][451/782] Loss_D: 0.3785 (0.8915) Loss_G: 0.3534 (0.8146) D(x): 0.5589 D(G(z)): 0.4584 / 0.4237 Acc: 29.6875 (19.8313)\n",
      "[1/25][452/782] Loss_D: 0.4369 (0.8911) Loss_G: 0.3737 (0.8143) D(x): 0.5283 D(G(z)): 0.4132 / 0.4185 Acc: 28.1250 (19.8381)\n",
      "[1/25][453/782] Loss_D: 0.5652 (0.8909) Loss_G: 0.2168 (0.8138) D(x): 0.4990 D(G(z)): 0.4533 / 0.4791 Acc: 25.0000 (19.8422)\n",
      "[1/25][454/782] Loss_D: 0.4794 (0.8905) Loss_G: 0.1735 (0.8133) D(x): 0.5768 D(G(z)): 0.5143 / 0.5051 Acc: 37.5000 (19.8565)\n",
      "[1/25][455/782] Loss_D: 0.5961 (0.8903) Loss_G: 0.3166 (0.8129) D(x): 0.5702 D(G(z)): 0.4946 / 0.4563 Acc: 21.8750 (19.8581)\n",
      "[1/25][456/782] Loss_D: 0.5084 (0.8900) Loss_G: 0.3630 (0.8125) D(x): 0.5238 D(G(z)): 0.4686 / 0.4097 Acc: 29.6875 (19.8661)\n",
      "[1/25][457/782] Loss_D: 0.6083 (0.8898) Loss_G: 0.4074 (0.8122) D(x): 0.5350 D(G(z)): 0.4932 / 0.4437 Acc: 34.3750 (19.8778)\n",
      "[1/25][458/782] Loss_D: 0.4868 (0.8894) Loss_G: 0.3270 (0.8118) D(x): 0.4971 D(G(z)): 0.4268 / 0.4406 Acc: 28.1250 (19.8844)\n",
      "[1/25][459/782] Loss_D: 0.6965 (0.8893) Loss_G: 0.2501 (0.8113) D(x): 0.4809 D(G(z)): 0.4818 / 0.4381 Acc: 18.7500 (19.8835)\n",
      "[1/25][460/782] Loss_D: 0.5000 (0.8890) Loss_G: 0.1456 (0.8108) D(x): 0.4929 D(G(z)): 0.4605 / 0.4531 Acc: 21.8750 (19.8851)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/25][461/782] Loss_D: 0.4422 (0.8886) Loss_G: 0.2657 (0.8104) D(x): 0.5577 D(G(z)): 0.4665 / 0.4629 Acc: 26.5625 (19.8905)\n",
      "[1/25][462/782] Loss_D: 0.4473 (0.8883) Loss_G: -0.0160 (0.8097) D(x): 0.5055 D(G(z)): 0.4567 / 0.5475 Acc: 29.6875 (19.8983)\n",
      "[1/25][463/782] Loss_D: 0.3320 (0.8878) Loss_G: 0.1429 (0.8092) D(x): 0.5588 D(G(z)): 0.4513 / 0.4802 Acc: 31.2500 (19.9075)\n",
      "[1/25][464/782] Loss_D: 0.7566 (0.8877) Loss_G: 0.4489 (0.8089) D(x): 0.5579 D(G(z)): 0.5153 / 0.4215 Acc: 20.3125 (19.9078)\n",
      "[1/25][465/782] Loss_D: 0.6293 (0.8875) Loss_G: 0.4235 (0.8086) D(x): 0.5297 D(G(z)): 0.4698 / 0.3944 Acc: 15.6250 (19.9043)\n",
      "[1/25][466/782] Loss_D: 0.6047 (0.8873) Loss_G: 0.5079 (0.8083) D(x): 0.5533 D(G(z)): 0.4366 / 0.4222 Acc: 18.7500 (19.9034)\n",
      "[1/25][467/782] Loss_D: 0.5543 (0.8870) Loss_G: 0.2208 (0.8078) D(x): 0.5110 D(G(z)): 0.4525 / 0.4758 Acc: 25.0000 (19.9075)\n",
      "[1/25][468/782] Loss_D: 0.6481 (0.8868) Loss_G: 0.1207 (0.8073) D(x): 0.5067 D(G(z)): 0.4922 / 0.5264 Acc: 29.6875 (19.9153)\n",
      "[1/25][469/782] Loss_D: 0.7382 (0.8867) Loss_G: 0.2956 (0.8069) D(x): 0.5674 D(G(z)): 0.5375 / 0.4630 Acc: 23.4375 (19.9181)\n",
      "[1/25][470/782] Loss_D: 0.6613 (0.8865) Loss_G: 0.2658 (0.8065) D(x): 0.4873 D(G(z)): 0.4939 / 0.4499 Acc: 23.4375 (19.9209)\n",
      "[1/25][471/782] Loss_D: 0.5286 (0.8862) Loss_G: 0.3274 (0.8061) D(x): 0.5231 D(G(z)): 0.4887 / 0.4424 Acc: 35.9375 (19.9337)\n",
      "[1/25][472/782] Loss_D: 0.5709 (0.8860) Loss_G: 0.1594 (0.8056) D(x): 0.4880 D(G(z)): 0.4297 / 0.4766 Acc: 20.3125 (19.9340)\n",
      "[1/25][473/782] Loss_D: 0.6163 (0.8858) Loss_G: 0.2293 (0.8051) D(x): 0.5387 D(G(z)): 0.5425 / 0.4544 Acc: 29.6875 (19.9418)\n",
      "[1/25][474/782] Loss_D: 0.5867 (0.8855) Loss_G: 0.2600 (0.8047) D(x): 0.5231 D(G(z)): 0.4997 / 0.4372 Acc: 26.5625 (19.9470)\n",
      "[1/25][475/782] Loss_D: 0.4505 (0.8852) Loss_G: 0.2693 (0.8042) D(x): 0.4909 D(G(z)): 0.4722 / 0.4089 Acc: 31.2500 (19.9560)\n",
      "[1/25][476/782] Loss_D: 0.7417 (0.8851) Loss_G: 0.3848 (0.8039) D(x): 0.4622 D(G(z)): 0.4629 / 0.4484 Acc: 28.1250 (19.9625)\n",
      "[1/25][477/782] Loss_D: 0.3406 (0.8846) Loss_G: 0.2234 (0.8034) D(x): 0.5630 D(G(z)): 0.4523 / 0.4485 Acc: 29.6875 (19.9702)\n",
      "[1/25][478/782] Loss_D: 0.7466 (0.8845) Loss_G: 0.3371 (0.8031) D(x): 0.5451 D(G(z)): 0.5005 / 0.4709 Acc: 14.0625 (19.9656)\n",
      "[1/25][479/782] Loss_D: 0.5834 (0.8843) Loss_G: 0.1263 (0.8025) D(x): 0.4937 D(G(z)): 0.5153 / 0.4818 Acc: 34.3750 (19.9770)\n",
      "[1/25][480/782] Loss_D: 0.4782 (0.8840) Loss_G: 0.2323 (0.8021) D(x): 0.5032 D(G(z)): 0.4441 / 0.4467 Acc: 23.4375 (19.9797)\n",
      "[1/25][481/782] Loss_D: 0.5658 (0.8837) Loss_G: 0.1591 (0.8016) D(x): 0.5106 D(G(z)): 0.4527 / 0.4903 Acc: 21.8750 (19.9812)\n",
      "[1/25][482/782] Loss_D: 0.4269 (0.8834) Loss_G: 0.2687 (0.8012) D(x): 0.5966 D(G(z)): 0.4944 / 0.4699 Acc: 34.3750 (19.9926)\n",
      "[1/25][483/782] Loss_D: 0.4453 (0.8830) Loss_G: 0.4241 (0.8009) D(x): 0.5618 D(G(z)): 0.4416 / 0.3996 Acc: 21.8750 (19.9941)\n",
      "[1/25][484/782] Loss_D: 0.4048 (0.8826) Loss_G: 0.2957 (0.8005) D(x): 0.5508 D(G(z)): 0.4482 / 0.4196 Acc: 29.6875 (20.0017)\n",
      "[1/25][485/782] Loss_D: 0.3781 (0.8822) Loss_G: 0.4986 (0.8002) D(x): 0.5818 D(G(z)): 0.4594 / 0.3647 Acc: 26.5625 (20.0069)\n",
      "[1/25][486/782] Loss_D: 0.2488 (0.8817) Loss_G: 0.3426 (0.7999) D(x): 0.5578 D(G(z)): 0.4332 / 0.4152 Acc: 40.6250 (20.0231)\n",
      "[1/25][487/782] Loss_D: 0.3569 (0.8813) Loss_G: 0.3800 (0.7995) D(x): 0.5244 D(G(z)): 0.4253 / 0.4078 Acc: 32.8125 (20.0332)\n",
      "[1/25][488/782] Loss_D: 0.5118 (0.8810) Loss_G: 0.3139 (0.7991) D(x): 0.5377 D(G(z)): 0.4548 / 0.4218 Acc: 21.8750 (20.0347)\n",
      "[1/25][489/782] Loss_D: 0.4587 (0.8807) Loss_G: 0.2771 (0.7987) D(x): 0.5252 D(G(z)): 0.4374 / 0.4312 Acc: 25.0000 (20.0386)\n",
      "[1/25][490/782] Loss_D: 0.5812 (0.8805) Loss_G: 0.4936 (0.7985) D(x): 0.5980 D(G(z)): 0.5006 / 0.4293 Acc: 25.0000 (20.0425)\n",
      "[1/25][491/782] Loss_D: 0.4116 (0.8801) Loss_G: 0.6059 (0.7983) D(x): 0.5872 D(G(z)): 0.4449 / 0.3575 Acc: 31.2500 (20.0513)\n",
      "[1/25][492/782] Loss_D: 0.4525 (0.8798) Loss_G: 0.5510 (0.7982) D(x): 0.5447 D(G(z)): 0.4315 / 0.3603 Acc: 28.1250 (20.0576)\n",
      "[1/25][493/782] Loss_D: 0.5151 (0.8795) Loss_G: 0.3748 (0.7978) D(x): 0.4851 D(G(z)): 0.4095 / 0.4194 Acc: 31.2500 (20.0664)\n",
      "[1/25][494/782] Loss_D: 0.4230 (0.8791) Loss_G: 0.1854 (0.7973) D(x): 0.5613 D(G(z)): 0.4675 / 0.4452 Acc: 21.8750 (20.0678)\n",
      "[1/25][495/782] Loss_D: 0.6026 (0.8789) Loss_G: 0.3383 (0.7970) D(x): 0.5489 D(G(z)): 0.5185 / 0.4347 Acc: 25.0000 (20.0716)\n",
      "[1/25][496/782] Loss_D: 0.6449 (0.8787) Loss_G: 0.3445 (0.7966) D(x): 0.5569 D(G(z)): 0.4953 / 0.4531 Acc: 23.4375 (20.0743)\n",
      "[1/25][497/782] Loss_D: 0.5917 (0.8785) Loss_G: 0.3691 (0.7963) D(x): 0.5603 D(G(z)): 0.4798 / 0.4537 Acc: 23.4375 (20.0769)\n",
      "[1/25][498/782] Loss_D: 0.7062 (0.8784) Loss_G: 0.1970 (0.7958) D(x): 0.4814 D(G(z)): 0.4582 / 0.4684 Acc: 18.7500 (20.0759)\n",
      "[1/25][499/782] Loss_D: 0.4979 (0.8781) Loss_G: 0.3810 (0.7955) D(x): 0.5846 D(G(z)): 0.5026 / 0.4403 Acc: 28.1250 (20.0821)\n",
      "[1/25][500/782] Loss_D: 0.6587 (0.8779) Loss_G: 0.2185 (0.7951) D(x): 0.4769 D(G(z)): 0.4547 / 0.4831 Acc: 23.4375 (20.0848)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[1/25][501/782] Loss_D: 0.3647 (0.8775) Loss_G: 0.2819 (0.7947) D(x): 0.5747 D(G(z)): 0.4687 / 0.4394 Acc: 31.2500 (20.0935)\n",
      "[1/25][502/782] Loss_D: 0.4333 (0.8772) Loss_G: 0.1969 (0.7942) D(x): 0.5160 D(G(z)): 0.4767 / 0.4571 Acc: 34.3750 (20.1046)\n",
      "[1/25][503/782] Loss_D: 0.4986 (0.8769) Loss_G: 0.2298 (0.7938) D(x): 0.5375 D(G(z)): 0.4870 / 0.4343 Acc: 23.4375 (20.1072)\n",
      "[1/25][504/782] Loss_D: 0.4426 (0.8765) Loss_G: 0.2139 (0.7933) D(x): 0.5406 D(G(z)): 0.4427 / 0.4580 Acc: 17.1875 (20.1049)\n",
      "[1/25][505/782] Loss_D: 0.4473 (0.8762) Loss_G: 0.1867 (0.7928) D(x): 0.4644 D(G(z)): 0.4505 / 0.4511 Acc: 37.5000 (20.1184)\n",
      "[1/25][506/782] Loss_D: 0.4939 (0.8759) Loss_G: 0.1474 (0.7923) D(x): 0.5431 D(G(z)): 0.4764 / 0.4892 Acc: 26.5625 (20.1234)\n",
      "[1/25][507/782] Loss_D: 0.3884 (0.8755) Loss_G: 0.1141 (0.7918) D(x): 0.5906 D(G(z)): 0.5293 / 0.4849 Acc: 34.3750 (20.1344)\n",
      "[1/25][508/782] Loss_D: 0.8058 (0.8755) Loss_G: 0.3344 (0.7914) D(x): 0.5243 D(G(z)): 0.5054 / 0.4602 Acc: 17.1875 (20.1322)\n",
      "[1/25][509/782] Loss_D: 0.7090 (0.8753) Loss_G: 0.4695 (0.7912) D(x): 0.5115 D(G(z)): 0.4961 / 0.4050 Acc: 25.0000 (20.1359)\n",
      "[1/25][510/782] Loss_D: 0.4837 (0.8750) Loss_G: 0.2875 (0.7908) D(x): 0.5338 D(G(z)): 0.4966 / 0.4337 Acc: 37.5000 (20.1494)\n",
      "[1/25][511/782] Loss_D: 0.4516 (0.8747) Loss_G: 0.3158 (0.7904) D(x): 0.4457 D(G(z)): 0.4030 / 0.4125 Acc: 34.3750 (20.1604)\n",
      "[1/25][512/782] Loss_D: 0.6116 (0.8745) Loss_G: 0.2905 (0.7901) D(x): 0.4981 D(G(z)): 0.4515 / 0.4870 Acc: 28.1250 (20.1665)\n",
      "[1/25][513/782] Loss_D: 0.5417 (0.8742) Loss_G: 0.1012 (0.7895) D(x): 0.5322 D(G(z)): 0.5254 / 0.4836 Acc: 26.5625 (20.1714)\n",
      "[1/25][514/782] Loss_D: 0.2639 (0.8738) Loss_G: 0.2751 (0.7891) D(x): 0.5857 D(G(z)): 0.4478 / 0.4518 Acc: 28.1250 (20.1776)\n",
      "[1/25][515/782] Loss_D: 0.6702 (0.8736) Loss_G: 0.4531 (0.7889) D(x): 0.5520 D(G(z)): 0.4811 / 0.4198 Acc: 21.8750 (20.1789)\n",
      "[1/25][516/782] Loss_D: 0.5588 (0.8734) Loss_G: 0.2302 (0.7884) D(x): 0.4834 D(G(z)): 0.4475 / 0.4611 Acc: 32.8125 (20.1886)\n",
      "[1/25][517/782] Loss_D: 0.4680 (0.8731) Loss_G: 0.4136 (0.7882) D(x): 0.5328 D(G(z)): 0.4757 / 0.3758 Acc: 31.2500 (20.1971)\n",
      "[1/25][518/782] Loss_D: 0.4610 (0.8727) Loss_G: 0.4624 (0.7879) D(x): 0.5283 D(G(z)): 0.4708 / 0.3877 Acc: 34.3750 (20.2080)\n",
      "[1/25][519/782] Loss_D: 0.5108 (0.8725) Loss_G: 0.1406 (0.7874) D(x): 0.4499 D(G(z)): 0.4079 / 0.4724 Acc: 26.5625 (20.2129)\n",
      "[1/25][520/782] Loss_D: 0.6346 (0.8723) Loss_G: 0.2217 (0.7870) D(x): 0.5180 D(G(z)): 0.4627 / 0.5048 Acc: 25.0000 (20.2166)\n",
      "[1/25][521/782] Loss_D: 0.5962 (0.8721) Loss_G: 0.3214 (0.7866) D(x): 0.5925 D(G(z)): 0.5291 / 0.4332 Acc: 21.8750 (20.2178)\n",
      "[1/25][522/782] Loss_D: 0.4950 (0.8718) Loss_G: 0.3219 (0.7863) D(x): 0.5468 D(G(z)): 0.4705 / 0.4111 Acc: 21.8750 (20.2191)\n",
      "[1/25][523/782] Loss_D: 0.6725 (0.8716) Loss_G: 0.4239 (0.7860) D(x): 0.5083 D(G(z)): 0.4634 / 0.4136 Acc: 17.1875 (20.2168)\n",
      "[1/25][524/782] Loss_D: 0.4746 (0.8713) Loss_G: 0.3375 (0.7856) D(x): 0.5036 D(G(z)): 0.3890 / 0.4239 Acc: 20.3125 (20.2169)\n",
      "[1/25][525/782] Loss_D: 0.4168 (0.8710) Loss_G: 0.2085 (0.7852) D(x): 0.5272 D(G(z)): 0.4298 / 0.4671 Acc: 28.1250 (20.2229)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/25][526/782] Loss_D: 0.2606 (0.8705) Loss_G: 0.4278 (0.7849) D(x): 0.6328 D(G(z)): 0.4435 / 0.4054 Acc: 26.5625 (20.2278)\n",
      "[1/25][527/782] Loss_D: 0.3591 (0.8701) Loss_G: 0.5065 (0.7847) D(x): 0.5987 D(G(z)): 0.4275 / 0.3674 Acc: 26.5625 (20.2326)\n",
      "[1/25][528/782] Loss_D: 0.3660 (0.8697) Loss_G: 0.4640 (0.7845) D(x): 0.5860 D(G(z)): 0.4080 / 0.3659 Acc: 15.6250 (20.2291)\n",
      "[1/25][529/782] Loss_D: 0.3749 (0.8694) Loss_G: 0.4525 (0.7842) D(x): 0.5694 D(G(z)): 0.4033 / 0.4031 Acc: 29.6875 (20.2363)\n",
      "[1/25][530/782] Loss_D: 0.3486 (0.8690) Loss_G: 0.5360 (0.7840) D(x): 0.5700 D(G(z)): 0.3981 / 0.3504 Acc: 17.1875 (20.2340)\n",
      "[1/25][531/782] Loss_D: 0.2572 (0.8685) Loss_G: 0.5082 (0.7838) D(x): 0.5904 D(G(z)): 0.3937 / 0.3788 Acc: 31.2500 (20.2423)\n",
      "[1/25][532/782] Loss_D: 0.1590 (0.8680) Loss_G: 0.4665 (0.7836) D(x): 0.6251 D(G(z)): 0.4144 / 0.3800 Acc: 31.2500 (20.2507)\n",
      "[1/25][533/782] Loss_D: 0.4340 (0.8676) Loss_G: 0.5399 (0.7834) D(x): 0.6142 D(G(z)): 0.4539 / 0.3803 Acc: 25.0000 (20.2543)\n",
      "[1/25][534/782] Loss_D: 0.4708 (0.8673) Loss_G: 0.3262 (0.7830) D(x): 0.5412 D(G(z)): 0.4392 / 0.4359 Acc: 32.8125 (20.2639)\n",
      "[1/25][535/782] Loss_D: 0.5995 (0.8671) Loss_G: 0.3394 (0.7827) D(x): 0.5719 D(G(z)): 0.5326 / 0.4447 Acc: 28.1250 (20.2698)\n",
      "[1/25][536/782] Loss_D: 0.8360 (0.8671) Loss_G: 0.2264 (0.7823) D(x): 0.4869 D(G(z)): 0.5405 / 0.4700 Acc: 21.8750 (20.2710)\n",
      "[1/25][537/782] Loss_D: 0.8192 (0.8671) Loss_G: 0.3557 (0.7820) D(x): 0.4970 D(G(z)): 0.5565 / 0.4197 Acc: 28.1250 (20.2770)\n",
      "[1/25][538/782] Loss_D: 0.8235 (0.8670) Loss_G: 0.3935 (0.7817) D(x): 0.4176 D(G(z)): 0.4776 / 0.4141 Acc: 23.4375 (20.2794)\n",
      "[1/25][539/782] Loss_D: 0.7283 (0.8669) Loss_G: 0.2915 (0.7813) D(x): 0.4334 D(G(z)): 0.4319 / 0.4917 Acc: 32.8125 (20.2889)\n",
      "[1/25][540/782] Loss_D: 0.4927 (0.8666) Loss_G: 0.1804 (0.7808) D(x): 0.5253 D(G(z)): 0.4886 / 0.4540 Acc: 26.5625 (20.2936)\n",
      "[1/25][541/782] Loss_D: 0.4434 (0.8663) Loss_G: 0.2798 (0.7805) D(x): 0.5708 D(G(z)): 0.5129 / 0.4428 Acc: 31.2500 (20.3019)\n",
      "[1/25][542/782] Loss_D: 0.3945 (0.8660) Loss_G: 0.4987 (0.7802) D(x): 0.5416 D(G(z)): 0.3869 / 0.3968 Acc: 21.8750 (20.3031)\n",
      "[1/25][543/782] Loss_D: 0.6034 (0.8658) Loss_G: 0.2962 (0.7799) D(x): 0.5390 D(G(z)): 0.4527 / 0.4650 Acc: 23.4375 (20.3054)\n",
      "[1/25][544/782] Loss_D: 0.3398 (0.8654) Loss_G: 0.3216 (0.7795) D(x): 0.6107 D(G(z)): 0.5069 / 0.4102 Acc: 31.2500 (20.3137)\n",
      "[1/25][545/782] Loss_D: 0.3593 (0.8650) Loss_G: 0.4744 (0.7793) D(x): 0.5650 D(G(z)): 0.4859 / 0.3595 Acc: 34.3750 (20.3243)\n",
      "[1/25][546/782] Loss_D: 0.6968 (0.8649) Loss_G: 0.1879 (0.7789) D(x): 0.4534 D(G(z)): 0.4589 / 0.4891 Acc: 23.4375 (20.3266)\n",
      "[1/25][547/782] Loss_D: 0.4238 (0.8645) Loss_G: 0.1439 (0.7784) D(x): 0.5159 D(G(z)): 0.4484 / 0.4649 Acc: 31.2500 (20.3348)\n",
      "[1/25][548/782] Loss_D: 0.6208 (0.8643) Loss_G: 0.2551 (0.7780) D(x): 0.5599 D(G(z)): 0.5609 / 0.4650 Acc: 34.3750 (20.3454)\n",
      "[1/25][549/782] Loss_D: 0.5477 (0.8641) Loss_G: 0.0979 (0.7775) D(x): 0.5127 D(G(z)): 0.5134 / 0.4697 Acc: 28.1250 (20.3512)\n",
      "[1/25][550/782] Loss_D: 0.6621 (0.8640) Loss_G: 0.1715 (0.7770) D(x): 0.4548 D(G(z)): 0.4752 / 0.4711 Acc: 21.8750 (20.3524)\n",
      "[1/25][551/782] Loss_D: 0.6034 (0.8638) Loss_G: 0.1370 (0.7765) D(x): 0.5163 D(G(z)): 0.4923 / 0.4950 Acc: 21.8750 (20.3535)\n",
      "[1/25][552/782] Loss_D: 0.5481 (0.8635) Loss_G: 0.2330 (0.7761) D(x): 0.5713 D(G(z)): 0.4982 / 0.4486 Acc: 12.5000 (20.3476)\n",
      "[1/25][553/782] Loss_D: 0.3828 (0.8632) Loss_G: 0.2251 (0.7757) D(x): 0.5247 D(G(z)): 0.4711 / 0.4267 Acc: 28.1250 (20.3534)\n",
      "[1/25][554/782] Loss_D: 0.2695 (0.8627) Loss_G: 0.4004 (0.7754) D(x): 0.5231 D(G(z)): 0.3885 / 0.4129 Acc: 34.3750 (20.3639)\n",
      "[1/25][555/782] Loss_D: 0.4032 (0.8624) Loss_G: 0.2558 (0.7751) D(x): 0.5871 D(G(z)): 0.4567 / 0.4467 Acc: 20.3125 (20.3639)\n",
      "[1/25][556/782] Loss_D: 0.4800 (0.8621) Loss_G: 0.4782 (0.7748) D(x): 0.5886 D(G(z)): 0.4631 / 0.3871 Acc: 20.3125 (20.3638)\n",
      "[1/25][557/782] Loss_D: 0.6260 (0.8619) Loss_G: 0.5692 (0.7747) D(x): 0.5822 D(G(z)): 0.4788 / 0.3636 Acc: 21.8750 (20.3650)\n",
      "[1/25][558/782] Loss_D: 0.5197 (0.8617) Loss_G: 0.4653 (0.7745) D(x): 0.5271 D(G(z)): 0.4441 / 0.3673 Acc: 18.7500 (20.3638)\n",
      "[1/25][559/782] Loss_D: 0.4934 (0.8614) Loss_G: 0.3225 (0.7741) D(x): 0.5219 D(G(z)): 0.4475 / 0.4312 Acc: 21.8750 (20.3649)\n",
      "[1/25][560/782] Loss_D: 0.3217 (0.8610) Loss_G: 0.2358 (0.7737) D(x): 0.5476 D(G(z)): 0.4385 / 0.4461 Acc: 29.6875 (20.3718)\n",
      "[1/25][561/782] Loss_D: 0.4609 (0.8607) Loss_G: 0.1836 (0.7733) D(x): 0.5003 D(G(z)): 0.4498 / 0.4535 Acc: 31.2500 (20.3799)\n",
      "[1/25][562/782] Loss_D: 0.6823 (0.8606) Loss_G: 0.1669 (0.7728) D(x): 0.4937 D(G(z)): 0.5137 / 0.4639 Acc: 21.8750 (20.3810)\n",
      "[1/25][563/782] Loss_D: 0.6817 (0.8604) Loss_G: 0.2234 (0.7724) D(x): 0.5141 D(G(z)): 0.5321 / 0.4563 Acc: 25.0000 (20.3845)\n",
      "[1/25][564/782] Loss_D: 0.5990 (0.8602) Loss_G: 0.2588 (0.7720) D(x): 0.5122 D(G(z)): 0.5229 / 0.4204 Acc: 26.5625 (20.3891)\n",
      "[1/25][565/782] Loss_D: 0.7115 (0.8601) Loss_G: 0.1894 (0.7716) D(x): 0.4452 D(G(z)): 0.4580 / 0.4447 Acc: 20.3125 (20.3890)\n",
      "[1/25][566/782] Loss_D: 0.5309 (0.8599) Loss_G: 0.2725 (0.7712) D(x): 0.5181 D(G(z)): 0.4899 / 0.4209 Acc: 28.1250 (20.3947)\n",
      "[1/25][567/782] Loss_D: 0.6468 (0.8597) Loss_G: 0.2117 (0.7708) D(x): 0.4948 D(G(z)): 0.4993 / 0.4361 Acc: 15.6250 (20.3912)\n",
      "[1/25][568/782] Loss_D: 0.3749 (0.8594) Loss_G: 0.3117 (0.7705) D(x): 0.5173 D(G(z)): 0.4235 / 0.4302 Acc: 28.1250 (20.3969)\n",
      "[1/25][569/782] Loss_D: 0.3180 (0.8590) Loss_G: 0.2889 (0.7701) D(x): 0.5602 D(G(z)): 0.4434 / 0.4173 Acc: 28.1250 (20.4026)\n",
      "[1/25][570/782] Loss_D: 0.5472 (0.8587) Loss_G: 0.0359 (0.7696) D(x): 0.4688 D(G(z)): 0.4334 / 0.5188 Acc: 26.5625 (20.4072)\n",
      "[1/25][571/782] Loss_D: 0.5302 (0.8585) Loss_G: 0.4273 (0.7693) D(x): 0.5938 D(G(z)): 0.4889 / 0.4044 Acc: 23.4375 (20.4094)\n",
      "[1/25][572/782] Loss_D: 0.4057 (0.8582) Loss_G: 0.3151 (0.7690) D(x): 0.5548 D(G(z)): 0.4068 / 0.4372 Acc: 26.5625 (20.4140)\n",
      "[1/25][573/782] Loss_D: 0.5676 (0.8579) Loss_G: 0.3806 (0.7687) D(x): 0.5442 D(G(z)): 0.4714 / 0.4289 Acc: 28.1250 (20.4197)\n",
      "[1/25][574/782] Loss_D: 0.6419 (0.8578) Loss_G: 0.4489 (0.7685) D(x): 0.5113 D(G(z)): 0.4399 / 0.3843 Acc: 17.1875 (20.4173)\n",
      "[1/25][575/782] Loss_D: 0.2492 (0.8573) Loss_G: 0.2879 (0.7681) D(x): 0.5956 D(G(z)): 0.4222 / 0.4293 Acc: 31.2500 (20.4253)\n",
      "[1/25][576/782] Loss_D: 0.3759 (0.8570) Loss_G: 0.5287 (0.7679) D(x): 0.5657 D(G(z)): 0.4390 / 0.3524 Acc: 35.9375 (20.4367)\n",
      "[1/25][577/782] Loss_D: 0.3073 (0.8566) Loss_G: 0.3824 (0.7677) D(x): 0.5265 D(G(z)): 0.3874 / 0.4054 Acc: 31.2500 (20.4446)\n",
      "[1/25][578/782] Loss_D: 0.4636 (0.8563) Loss_G: 0.3014 (0.7673) D(x): 0.4952 D(G(z)): 0.4003 / 0.4376 Acc: 28.1250 (20.4503)\n",
      "[1/25][579/782] Loss_D: 0.3744 (0.8559) Loss_G: 0.2249 (0.7669) D(x): 0.5994 D(G(z)): 0.4881 / 0.4522 Acc: 29.6875 (20.4570)\n",
      "[1/25][580/782] Loss_D: 0.3066 (0.8555) Loss_G: 0.1983 (0.7665) D(x): 0.5886 D(G(z)): 0.4685 / 0.4533 Acc: 25.0000 (20.4604)\n",
      "[1/25][581/782] Loss_D: 0.6312 (0.8554) Loss_G: 0.3673 (0.7662) D(x): 0.5284 D(G(z)): 0.4881 / 0.4114 Acc: 23.4375 (20.4626)\n",
      "[1/25][582/782] Loss_D: 0.4031 (0.8550) Loss_G: 0.2120 (0.7658) D(x): 0.5492 D(G(z)): 0.4687 / 0.4474 Acc: 29.6875 (20.4693)\n",
      "[1/25][583/782] Loss_D: 0.3828 (0.8547) Loss_G: 0.2605 (0.7654) D(x): 0.5251 D(G(z)): 0.4638 / 0.4271 Acc: 34.3750 (20.4795)\n",
      "[1/25][584/782] Loss_D: 0.4514 (0.8544) Loss_G: 0.1198 (0.7650) D(x): 0.4989 D(G(z)): 0.4346 / 0.4554 Acc: 21.8750 (20.4805)\n",
      "[1/25][585/782] Loss_D: 0.6050 (0.8542) Loss_G: 0.3068 (0.7646) D(x): 0.5430 D(G(z)): 0.4903 / 0.4261 Acc: 25.0000 (20.4838)\n",
      "[1/25][586/782] Loss_D: 0.5734 (0.8540) Loss_G: 0.3031 (0.7643) D(x): 0.5396 D(G(z)): 0.4697 / 0.4310 Acc: 20.3125 (20.4837)\n",
      "[1/25][587/782] Loss_D: 0.5749 (0.8538) Loss_G: 0.3361 (0.7640) D(x): 0.4933 D(G(z)): 0.4427 / 0.4486 Acc: 26.5625 (20.4881)\n",
      "[1/25][588/782] Loss_D: 0.4905 (0.8535) Loss_G: 0.2706 (0.7636) D(x): 0.5419 D(G(z)): 0.4572 / 0.4410 Acc: 21.8750 (20.4892)\n",
      "[1/25][589/782] Loss_D: 0.2982 (0.8531) Loss_G: 0.2500 (0.7632) D(x): 0.5376 D(G(z)): 0.4511 / 0.4194 Acc: 29.6875 (20.4959)\n",
      "[1/25][590/782] Loss_D: 0.5025 (0.8529) Loss_G: 0.4095 (0.7630) D(x): 0.5452 D(G(z)): 0.4691 / 0.4024 Acc: 29.6875 (20.5025)\n",
      "[1/25][591/782] Loss_D: 0.4794 (0.8526) Loss_G: 0.2010 (0.7626) D(x): 0.4730 D(G(z)): 0.4296 / 0.4280 Acc: 21.8750 (20.5035)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/25][592/782] Loss_D: 0.6495 (0.8525) Loss_G: 0.2074 (0.7622) D(x): 0.4813 D(G(z)): 0.4910 / 0.4863 Acc: 28.1250 (20.5091)\n",
      "[1/25][593/782] Loss_D: 0.4780 (0.8522) Loss_G: 0.2459 (0.7618) D(x): 0.5801 D(G(z)): 0.4926 / 0.4653 Acc: 26.5625 (20.5135)\n",
      "[1/25][594/782] Loss_D: 0.5626 (0.8520) Loss_G: 0.2644 (0.7614) D(x): 0.5598 D(G(z)): 0.5056 / 0.4897 Acc: 32.8125 (20.5224)\n",
      "[1/25][595/782] Loss_D: 0.6008 (0.8518) Loss_G: 0.2960 (0.7611) D(x): 0.4966 D(G(z)): 0.4886 / 0.4238 Acc: 25.0000 (20.5257)\n",
      "[1/25][596/782] Loss_D: 0.6451 (0.8516) Loss_G: 0.3547 (0.7608) D(x): 0.5009 D(G(z)): 0.4519 / 0.4543 Acc: 20.3125 (20.5255)\n",
      "[1/25][597/782] Loss_D: 0.4126 (0.8513) Loss_G: 0.0794 (0.7603) D(x): 0.5046 D(G(z)): 0.4835 / 0.4760 Acc: 35.9375 (20.5367)\n",
      "[1/25][598/782] Loss_D: 0.4704 (0.8510) Loss_G: 0.1724 (0.7599) D(x): 0.5323 D(G(z)): 0.5075 / 0.4445 Acc: 26.5625 (20.5410)\n",
      "[1/25][599/782] Loss_D: 0.4172 (0.8507) Loss_G: 0.1975 (0.7595) D(x): 0.5213 D(G(z)): 0.4562 / 0.4655 Acc: 32.8125 (20.5499)\n",
      "[1/25][600/782] Loss_D: 0.4783 (0.8505) Loss_G: 0.0890 (0.7590) D(x): 0.5544 D(G(z)): 0.4974 / 0.4892 Acc: 23.4375 (20.5520)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[1/25][601/782] Loss_D: 0.5259 (0.8502) Loss_G: 0.2989 (0.7587) D(x): 0.5599 D(G(z)): 0.4901 / 0.4161 Acc: 18.7500 (20.5507)\n",
      "[1/25][602/782] Loss_D: 0.5819 (0.8500) Loss_G: 0.3829 (0.7584) D(x): 0.5543 D(G(z)): 0.4797 / 0.4058 Acc: 18.7500 (20.5494)\n",
      "[1/25][603/782] Loss_D: 0.5351 (0.8498) Loss_G: 0.3144 (0.7581) D(x): 0.5363 D(G(z)): 0.4611 / 0.4355 Acc: 20.3125 (20.5492)\n",
      "[1/25][604/782] Loss_D: 0.4663 (0.8495) Loss_G: 0.1041 (0.7576) D(x): 0.4691 D(G(z)): 0.4345 / 0.4729 Acc: 29.6875 (20.5558)\n",
      "[1/25][605/782] Loss_D: 0.6616 (0.8494) Loss_G: 0.2135 (0.7572) D(x): 0.4984 D(G(z)): 0.4948 / 0.4810 Acc: 25.0000 (20.5590)\n",
      "[1/25][606/782] Loss_D: 0.7737 (0.8493) Loss_G: 0.0893 (0.7567) D(x): 0.4873 D(G(z)): 0.4914 / 0.5248 Acc: 15.6250 (20.5555)\n",
      "[1/25][607/782] Loss_D: 0.6098 (0.8492) Loss_G: 0.1604 (0.7563) D(x): 0.5622 D(G(z)): 0.5392 / 0.4888 Acc: 23.4375 (20.5576)\n",
      "[1/25][608/782] Loss_D: 0.5834 (0.8490) Loss_G: 0.1970 (0.7559) D(x): 0.5265 D(G(z)): 0.5289 / 0.4433 Acc: 32.8125 (20.5664)\n",
      "[1/25][609/782] Loss_D: 0.2046 (0.8485) Loss_G: 0.1614 (0.7555) D(x): 0.5616 D(G(z)): 0.4706 / 0.4096 Acc: 28.1250 (20.5718)\n",
      "[1/25][610/782] Loss_D: 0.3860 (0.8482) Loss_G: 0.5495 (0.7553) D(x): 0.4707 D(G(z)): 0.3764 / 0.3474 Acc: 32.8125 (20.5806)\n",
      "[1/25][611/782] Loss_D: 0.4302 (0.8479) Loss_G: 0.2824 (0.7550) D(x): 0.5159 D(G(z)): 0.4339 / 0.4213 Acc: 21.8750 (20.5815)\n",
      "[1/25][612/782] Loss_D: 0.2944 (0.8475) Loss_G: 0.2700 (0.7546) D(x): 0.5583 D(G(z)): 0.4502 / 0.4166 Acc: 31.2500 (20.5892)\n",
      "[1/25][613/782] Loss_D: 0.3011 (0.8471) Loss_G: 0.2434 (0.7543) D(x): 0.5727 D(G(z)): 0.4469 / 0.4428 Acc: 34.3750 (20.5990)\n",
      "[1/25][614/782] Loss_D: 0.3903 (0.8468) Loss_G: 0.2567 (0.7539) D(x): 0.5609 D(G(z)): 0.4493 / 0.4131 Acc: 12.5000 (20.5932)\n",
      "[1/25][615/782] Loss_D: 0.3645 (0.8464) Loss_G: 0.2370 (0.7535) D(x): 0.5485 D(G(z)): 0.4546 / 0.4297 Acc: 23.4375 (20.5953)\n",
      "[1/25][616/782] Loss_D: 0.2992 (0.8460) Loss_G: 0.4571 (0.7533) D(x): 0.5846 D(G(z)): 0.4666 / 0.3530 Acc: 25.0000 (20.5984)\n",
      "[1/25][617/782] Loss_D: 0.4078 (0.8457) Loss_G: 0.2266 (0.7529) D(x): 0.5223 D(G(z)): 0.4506 / 0.4314 Acc: 25.0000 (20.6016)\n",
      "[1/25][618/782] Loss_D: 0.3014 (0.8453) Loss_G: 0.3093 (0.7526) D(x): 0.5366 D(G(z)): 0.4287 / 0.3978 Acc: 26.5625 (20.6058)\n",
      "[1/25][619/782] Loss_D: 0.6699 (0.8452) Loss_G: 0.2421 (0.7523) D(x): 0.4690 D(G(z)): 0.4696 / 0.4379 Acc: 18.7500 (20.6045)\n",
      "[1/25][620/782] Loss_D: 0.4027 (0.8449) Loss_G: 0.3668 (0.7520) D(x): 0.5828 D(G(z)): 0.4817 / 0.3952 Acc: 26.5625 (20.6087)\n",
      "[1/25][621/782] Loss_D: 0.3434 (0.8445) Loss_G: 0.3516 (0.7517) D(x): 0.5629 D(G(z)): 0.4454 / 0.3813 Acc: 18.7500 (20.6074)\n",
      "[1/25][622/782] Loss_D: 0.4700 (0.8443) Loss_G: 0.2259 (0.7513) D(x): 0.5080 D(G(z)): 0.4451 / 0.4175 Acc: 18.7500 (20.6061)\n",
      "[1/25][623/782] Loss_D: 0.5632 (0.8441) Loss_G: 0.1664 (0.7509) D(x): 0.4971 D(G(z)): 0.4328 / 0.5031 Acc: 18.7500 (20.6048)\n",
      "[1/25][624/782] Loss_D: 0.2114 (0.8436) Loss_G: 0.0771 (0.7504) D(x): 0.6161 D(G(z)): 0.5115 / 0.4795 Acc: 37.5000 (20.6168)\n",
      "[1/25][625/782] Loss_D: 0.4119 (0.8433) Loss_G: 0.1886 (0.7500) D(x): 0.5008 D(G(z)): 0.4392 / 0.4349 Acc: 23.4375 (20.6188)\n",
      "[1/25][626/782] Loss_D: 0.3589 (0.8430) Loss_G: 0.1694 (0.7496) D(x): 0.5596 D(G(z)): 0.4949 / 0.4480 Acc: 31.2500 (20.6263)\n",
      "[1/25][627/782] Loss_D: 0.3784 (0.8426) Loss_G: 0.1550 (0.7492) D(x): 0.5157 D(G(z)): 0.4743 / 0.4740 Acc: 37.5000 (20.6383)\n",
      "[1/25][628/782] Loss_D: 0.4621 (0.8424) Loss_G: 0.4001 (0.7490) D(x): 0.5741 D(G(z)): 0.5199 / 0.4044 Acc: 35.9375 (20.6491)\n",
      "[1/25][629/782] Loss_D: 0.5349 (0.8421) Loss_G: 0.1005 (0.7485) D(x): 0.4878 D(G(z)): 0.4791 / 0.4760 Acc: 21.8750 (20.6500)\n",
      "[1/25][630/782] Loss_D: 0.1781 (0.8417) Loss_G: 0.0674 (0.7480) D(x): 0.5203 D(G(z)): 0.4184 / 0.4544 Acc: 34.3750 (20.6597)\n",
      "[1/25][631/782] Loss_D: 0.6701 (0.8416) Loss_G: 0.2130 (0.7476) D(x): 0.5067 D(G(z)): 0.4854 / 0.5002 Acc: 15.6250 (20.6562)\n",
      "[1/25][632/782] Loss_D: 0.6014 (0.8414) Loss_G: 0.2267 (0.7473) D(x): 0.5357 D(G(z)): 0.4978 / 0.4803 Acc: 25.0000 (20.6592)\n",
      "[1/25][633/782] Loss_D: 0.6499 (0.8413) Loss_G: 0.3132 (0.7470) D(x): 0.5034 D(G(z)): 0.5020 / 0.4245 Acc: 25.0000 (20.6623)\n",
      "[1/25][634/782] Loss_D: 0.6872 (0.8411) Loss_G: 0.2765 (0.7466) D(x): 0.4370 D(G(z)): 0.4638 / 0.4312 Acc: 25.0000 (20.6654)\n",
      "[1/25][635/782] Loss_D: 0.4845 (0.8409) Loss_G: 0.1937 (0.7462) D(x): 0.4807 D(G(z)): 0.4199 / 0.4504 Acc: 20.3125 (20.6651)\n",
      "[1/25][636/782] Loss_D: 0.6586 (0.8408) Loss_G: 0.0163 (0.7457) D(x): 0.5190 D(G(z)): 0.5065 / 0.5162 Acc: 12.5000 (20.6594)\n",
      "[1/25][637/782] Loss_D: 0.5539 (0.8406) Loss_G: 0.2439 (0.7454) D(x): 0.5004 D(G(z)): 0.4898 / 0.4427 Acc: 23.4375 (20.6613)\n",
      "[1/25][638/782] Loss_D: 0.2391 (0.8401) Loss_G: 0.2612 (0.7450) D(x): 0.5207 D(G(z)): 0.4583 / 0.3706 Acc: 32.8125 (20.6699)\n",
      "[1/25][639/782] Loss_D: 0.3561 (0.8398) Loss_G: 0.2870 (0.7447) D(x): 0.5385 D(G(z)): 0.4332 / 0.4043 Acc: 26.5625 (20.6740)\n",
      "[1/25][640/782] Loss_D: 0.3667 (0.8395) Loss_G: 0.3829 (0.7445) D(x): 0.5357 D(G(z)): 0.4149 / 0.3939 Acc: 23.4375 (20.6759)\n",
      "[1/25][641/782] Loss_D: 0.2879 (0.8391) Loss_G: 0.1211 (0.7440) D(x): 0.5630 D(G(z)): 0.4401 / 0.4533 Acc: 25.0000 (20.6790)\n",
      "[1/25][642/782] Loss_D: 0.3845 (0.8388) Loss_G: 0.2518 (0.7437) D(x): 0.5666 D(G(z)): 0.4624 / 0.4224 Acc: 23.4375 (20.6809)\n",
      "[1/25][643/782] Loss_D: 0.2816 (0.8384) Loss_G: 0.2928 (0.7434) D(x): 0.5376 D(G(z)): 0.4472 / 0.4075 Acc: 34.3750 (20.6905)\n",
      "[1/25][644/782] Loss_D: 0.3073 (0.8380) Loss_G: 0.3982 (0.7431) D(x): 0.5659 D(G(z)): 0.4484 / 0.3818 Acc: 29.6875 (20.6968)\n",
      "[1/25][645/782] Loss_D: 0.5382 (0.8378) Loss_G: 0.5075 (0.7429) D(x): 0.5824 D(G(z)): 0.4729 / 0.3457 Acc: 14.0625 (20.6922)\n",
      "[1/25][646/782] Loss_D: 0.4066 (0.8375) Loss_G: 0.2647 (0.7426) D(x): 0.5120 D(G(z)): 0.4216 / 0.4275 Acc: 20.3125 (20.6919)\n",
      "[1/25][647/782] Loss_D: 0.3141 (0.8371) Loss_G: 0.2289 (0.7423) D(x): 0.5574 D(G(z)): 0.4302 / 0.3991 Acc: 26.5625 (20.6960)\n",
      "[1/25][648/782] Loss_D: 0.3933 (0.8368) Loss_G: 0.2851 (0.7419) D(x): 0.5646 D(G(z)): 0.4415 / 0.4005 Acc: 10.9375 (20.6892)\n",
      "[1/25][649/782] Loss_D: 0.4993 (0.8366) Loss_G: 0.1782 (0.7415) D(x): 0.5110 D(G(z)): 0.5054 / 0.4291 Acc: 26.5625 (20.6933)\n",
      "[1/25][650/782] Loss_D: 0.3757 (0.8362) Loss_G: 0.2366 (0.7412) D(x): 0.5419 D(G(z)): 0.4439 / 0.4355 Acc: 21.8750 (20.6941)\n",
      "[1/25][651/782] Loss_D: 0.3710 (0.8359) Loss_G: 0.1700 (0.7408) D(x): 0.5159 D(G(z)): 0.4573 / 0.4337 Acc: 28.1250 (20.6993)\n",
      "[1/25][652/782] Loss_D: 0.2400 (0.8355) Loss_G: 0.0902 (0.7403) D(x): 0.6017 D(G(z)): 0.4795 / 0.4843 Acc: 34.3750 (20.7088)\n",
      "[1/25][653/782] Loss_D: 0.4894 (0.8353) Loss_G: 0.2497 (0.7400) D(x): 0.4989 D(G(z)): 0.4750 / 0.4264 Acc: 21.8750 (20.7097)\n",
      "[1/25][654/782] Loss_D: 0.3091 (0.8349) Loss_G: 0.2112 (0.7396) D(x): 0.5180 D(G(z)): 0.3892 / 0.4261 Acc: 26.5625 (20.7137)\n",
      "[1/25][655/782] Loss_D: 0.2414 (0.8345) Loss_G: 0.1584 (0.7392) D(x): 0.5473 D(G(z)): 0.4126 / 0.4084 Acc: 20.3125 (20.7134)\n",
      "[1/25][656/782] Loss_D: 0.4888 (0.8342) Loss_G: 0.3291 (0.7389) D(x): 0.6000 D(G(z)): 0.5090 / 0.4368 Acc: 25.0000 (20.7164)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/25][657/782] Loss_D: 0.2519 (0.8338) Loss_G: 0.2697 (0.7386) D(x): 0.5979 D(G(z)): 0.4275 / 0.4146 Acc: 25.0000 (20.7194)\n",
      "[1/25][658/782] Loss_D: 0.3306 (0.8335) Loss_G: 0.0940 (0.7382) D(x): 0.5640 D(G(z)): 0.4892 / 0.4393 Acc: 21.8750 (20.7202)\n",
      "[1/25][659/782] Loss_D: 0.2797 (0.8331) Loss_G: 0.2372 (0.7378) D(x): 0.5872 D(G(z)): 0.4287 / 0.4078 Acc: 14.0625 (20.7156)\n",
      "[1/25][660/782] Loss_D: 0.2761 (0.8327) Loss_G: 0.3762 (0.7376) D(x): 0.5364 D(G(z)): 0.4471 / 0.3732 Acc: 34.3750 (20.7251)\n",
      "[1/25][661/782] Loss_D: 0.2307 (0.8323) Loss_G: 0.1222 (0.7371) D(x): 0.4982 D(G(z)): 0.3869 / 0.4541 Acc: 29.6875 (20.7313)\n",
      "[1/25][662/782] Loss_D: 0.4205 (0.8320) Loss_G: 0.3382 (0.7369) D(x): 0.5881 D(G(z)): 0.4860 / 0.4334 Acc: 29.6875 (20.7375)\n",
      "[1/25][663/782] Loss_D: 0.4382 (0.8318) Loss_G: 0.1651 (0.7365) D(x): 0.5452 D(G(z)): 0.5237 / 0.4586 Acc: 31.2500 (20.7447)\n",
      "[1/25][664/782] Loss_D: 0.4830 (0.8315) Loss_G: 0.2815 (0.7362) D(x): 0.4762 D(G(z)): 0.4444 / 0.4097 Acc: 21.8750 (20.7455)\n",
      "[1/25][665/782] Loss_D: 0.3130 (0.8312) Loss_G: 0.1799 (0.7358) D(x): 0.6091 D(G(z)): 0.5691 / 0.4278 Acc: 29.6875 (20.7517)\n",
      "[1/25][666/782] Loss_D: 0.4665 (0.8309) Loss_G: 0.2197 (0.7354) D(x): 0.4444 D(G(z)): 0.4362 / 0.4329 Acc: 32.8125 (20.7600)\n",
      "[1/25][667/782] Loss_D: 0.8077 (0.8309) Loss_G: 0.2311 (0.7351) D(x): 0.4838 D(G(z)): 0.5050 / 0.4858 Acc: 20.3125 (20.7597)\n",
      "[1/25][668/782] Loss_D: 0.2555 (0.8305) Loss_G: 0.1645 (0.7347) D(x): 0.5598 D(G(z)): 0.4608 / 0.4326 Acc: 31.2500 (20.7669)\n",
      "[1/25][669/782] Loss_D: 0.3495 (0.8302) Loss_G: 0.0945 (0.7342) D(x): 0.5135 D(G(z)): 0.4468 / 0.4796 Acc: 29.6875 (20.7731)\n",
      "[1/25][670/782] Loss_D: 0.3219 (0.8298) Loss_G: 0.3438 (0.7340) D(x): 0.5856 D(G(z)): 0.4456 / 0.3806 Acc: 21.8750 (20.7738)\n",
      "[1/25][671/782] Loss_D: 0.3506 (0.8295) Loss_G: 0.1286 (0.7335) D(x): 0.4963 D(G(z)): 0.4884 / 0.4474 Acc: 39.0625 (20.7864)\n",
      "[1/25][672/782] Loss_D: 0.4195 (0.8292) Loss_G: 0.1019 (0.7331) D(x): 0.4670 D(G(z)): 0.4688 / 0.4629 Acc: 37.5000 (20.7979)\n",
      "[1/25][673/782] Loss_D: 0.3155 (0.8288) Loss_G: 0.2720 (0.7328) D(x): 0.5741 D(G(z)): 0.4517 / 0.4053 Acc: 23.4375 (20.7997)\n",
      "[1/25][674/782] Loss_D: 0.3318 (0.8285) Loss_G: 0.0730 (0.7323) D(x): 0.5129 D(G(z)): 0.4109 / 0.4704 Acc: 26.5625 (20.8037)\n",
      "[1/25][675/782] Loss_D: 0.6229 (0.8284) Loss_G: 0.2608 (0.7320) D(x): 0.5929 D(G(z)): 0.6051 / 0.4453 Acc: 32.8125 (20.8119)\n",
      "[1/25][676/782] Loss_D: 0.4497 (0.8281) Loss_G: 0.3216 (0.7317) D(x): 0.4577 D(G(z)): 0.4144 / 0.4055 Acc: 25.0000 (20.8148)\n",
      "[1/25][677/782] Loss_D: 0.3393 (0.8278) Loss_G: 0.1275 (0.7313) D(x): 0.5029 D(G(z)): 0.4389 / 0.4450 Acc: 29.6875 (20.8208)\n",
      "[1/25][678/782] Loss_D: 0.4936 (0.8275) Loss_G: 0.2766 (0.7310) D(x): 0.5195 D(G(z)): 0.4359 / 0.4204 Acc: 18.7500 (20.8194)\n",
      "[1/25][679/782] Loss_D: 0.3559 (0.8272) Loss_G: 0.3289 (0.7307) D(x): 0.6053 D(G(z)): 0.4721 / 0.3932 Acc: 18.7500 (20.8180)\n",
      "[1/25][680/782] Loss_D: 0.4099 (0.8269) Loss_G: 0.3597 (0.7305) D(x): 0.5612 D(G(z)): 0.4365 / 0.4003 Acc: 18.7500 (20.8166)\n",
      "[1/25][681/782] Loss_D: 0.2658 (0.8265) Loss_G: 0.1615 (0.7301) D(x): 0.5206 D(G(z)): 0.4201 / 0.4137 Acc: 25.0000 (20.8195)\n",
      "[1/25][682/782] Loss_D: 0.3160 (0.8262) Loss_G: 0.2944 (0.7298) D(x): 0.5634 D(G(z)): 0.4746 / 0.4102 Acc: 34.3750 (20.8287)\n",
      "[1/25][683/782] Loss_D: 0.4045 (0.8259) Loss_G: 0.2547 (0.7295) D(x): 0.5413 D(G(z)): 0.4737 / 0.4166 Acc: 28.1250 (20.8337)\n",
      "[1/25][684/782] Loss_D: 0.4706 (0.8257) Loss_G: 0.1698 (0.7291) D(x): 0.5033 D(G(z)): 0.4332 / 0.4499 Acc: 21.8750 (20.8344)\n",
      "[1/25][685/782] Loss_D: 0.2604 (0.8253) Loss_G: 0.2753 (0.7288) D(x): 0.5202 D(G(z)): 0.4430 / 0.4216 Acc: 39.0625 (20.8468)\n",
      "[1/25][686/782] Loss_D: 0.4620 (0.8250) Loss_G: 0.3738 (0.7285) D(x): 0.5644 D(G(z)): 0.4500 / 0.3874 Acc: 20.3125 (20.8465)\n",
      "[1/25][687/782] Loss_D: 0.3362 (0.8247) Loss_G: 0.2567 (0.7282) D(x): 0.5518 D(G(z)): 0.4557 / 0.4217 Acc: 26.5625 (20.8503)\n",
      "[1/25][688/782] Loss_D: 0.1999 (0.8243) Loss_G: 0.3112 (0.7279) D(x): 0.6098 D(G(z)): 0.4372 / 0.4001 Acc: 25.0000 (20.8532)\n",
      "[1/25][689/782] Loss_D: 0.4377 (0.8240) Loss_G: 0.1586 (0.7276) D(x): 0.5010 D(G(z)): 0.4465 / 0.4577 Acc: 25.0000 (20.8560)\n",
      "[1/25][690/782] Loss_D: 0.5330 (0.8238) Loss_G: 0.0509 (0.7271) D(x): 0.5821 D(G(z)): 0.5851 / 0.4868 Acc: 28.1250 (20.8609)\n",
      "[1/25][691/782] Loss_D: 0.4166 (0.8235) Loss_G: 0.1972 (0.7267) D(x): 0.4866 D(G(z)): 0.4259 / 0.4395 Acc: 26.5625 (20.8648)\n",
      "[1/25][692/782] Loss_D: 0.2175 (0.8231) Loss_G: 0.2406 (0.7264) D(x): 0.6274 D(G(z)): 0.4657 / 0.4156 Acc: 25.0000 (20.8676)\n",
      "[1/25][693/782] Loss_D: 0.5902 (0.8230) Loss_G: 0.1741 (0.7260) D(x): 0.5205 D(G(z)): 0.4805 / 0.4613 Acc: 23.4375 (20.8693)\n",
      "[1/25][694/782] Loss_D: 0.5369 (0.8228) Loss_G: 0.1546 (0.7256) D(x): 0.5352 D(G(z)): 0.5178 / 0.4651 Acc: 23.4375 (20.8711)\n",
      "[1/25][695/782] Loss_D: 0.5203 (0.8226) Loss_G: 0.1319 (0.7252) D(x): 0.5205 D(G(z)): 0.5200 / 0.4354 Acc: 18.7500 (20.8696)\n",
      "[1/25][696/782] Loss_D: 0.3970 (0.8223) Loss_G: 0.1963 (0.7249) D(x): 0.5625 D(G(z)): 0.4840 / 0.4332 Acc: 28.1250 (20.8745)\n",
      "[1/25][697/782] Loss_D: 0.6570 (0.8222) Loss_G: 0.3059 (0.7246) D(x): 0.4825 D(G(z)): 0.4794 / 0.4446 Acc: 28.1250 (20.8794)\n",
      "[1/25][698/782] Loss_D: 0.5435 (0.8220) Loss_G: 0.0113 (0.7241) D(x): 0.4661 D(G(z)): 0.4230 / 0.5260 Acc: 17.1875 (20.8769)\n",
      "[1/25][699/782] Loss_D: 0.8713 (0.8220) Loss_G: -0.0614 (0.7236) D(x): 0.4655 D(G(z)): 0.6048 / 0.5433 Acc: 25.0000 (20.8797)\n",
      "[1/25][700/782] Loss_D: 0.5480 (0.8218) Loss_G: 0.1735 (0.7232) D(x): 0.5424 D(G(z)): 0.5391 / 0.4142 Acc: 20.3125 (20.8793)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[1/25][701/782] Loss_D: 0.5103 (0.8216) Loss_G: 0.1973 (0.7229) D(x): 0.5000 D(G(z)): 0.4740 / 0.4192 Acc: 18.7500 (20.8779)\n",
      "[1/25][702/782] Loss_D: 0.4303 (0.8214) Loss_G: 0.2060 (0.7225) D(x): 0.4860 D(G(z)): 0.4185 / 0.4342 Acc: 23.4375 (20.8796)\n",
      "[1/25][703/782] Loss_D: 0.4985 (0.8211) Loss_G: 0.1466 (0.7221) D(x): 0.5166 D(G(z)): 0.4992 / 0.4472 Acc: 17.1875 (20.8771)\n",
      "[1/25][704/782] Loss_D: 0.3016 (0.8208) Loss_G: 0.2842 (0.7218) D(x): 0.5135 D(G(z)): 0.4219 / 0.4103 Acc: 37.5000 (20.8883)\n",
      "[1/25][705/782] Loss_D: 0.3786 (0.8205) Loss_G: 0.1447 (0.7214) D(x): 0.4984 D(G(z)): 0.4304 / 0.4424 Acc: 26.5625 (20.8921)\n",
      "[1/25][706/782] Loss_D: 0.2880 (0.8201) Loss_G: -0.0144 (0.7210) D(x): 0.5746 D(G(z)): 0.4519 / 0.5311 Acc: 21.8750 (20.8928)\n",
      "[1/25][707/782] Loss_D: 0.3110 (0.8198) Loss_G: 0.0821 (0.7205) D(x): 0.5839 D(G(z)): 0.4963 / 0.4539 Acc: 23.4375 (20.8945)\n",
      "[1/25][708/782] Loss_D: 0.4269 (0.8195) Loss_G: 0.2071 (0.7202) D(x): 0.5130 D(G(z)): 0.4545 / 0.4432 Acc: 26.5625 (20.8983)\n",
      "[1/25][709/782] Loss_D: 0.3134 (0.8192) Loss_G: 0.1746 (0.7198) D(x): 0.5191 D(G(z)): 0.4492 / 0.4281 Acc: 28.1250 (20.9032)\n",
      "[1/25][710/782] Loss_D: 0.4331 (0.8189) Loss_G: 0.0610 (0.7194) D(x): 0.5273 D(G(z)): 0.4466 / 0.4829 Acc: 12.5000 (20.8975)\n",
      "[1/25][711/782] Loss_D: 0.2516 (0.8186) Loss_G: 0.0930 (0.7190) D(x): 0.5943 D(G(z)): 0.4284 / 0.4635 Acc: 17.1875 (20.8950)\n",
      "[1/25][712/782] Loss_D: 0.4861 (0.8183) Loss_G: 0.2377 (0.7186) D(x): 0.5356 D(G(z)): 0.5088 / 0.4103 Acc: 26.5625 (20.8988)\n",
      "[1/25][713/782] Loss_D: 0.3410 (0.8180) Loss_G: 0.1548 (0.7183) D(x): 0.4808 D(G(z)): 0.4457 / 0.4047 Acc: 25.0000 (20.9016)\n",
      "[1/25][714/782] Loss_D: 0.3220 (0.8177) Loss_G: 0.1291 (0.7179) D(x): 0.5218 D(G(z)): 0.4320 / 0.4153 Acc: 15.6250 (20.8980)\n",
      "[1/25][715/782] Loss_D: 0.4855 (0.8175) Loss_G: 0.2967 (0.7176) D(x): 0.5270 D(G(z)): 0.4665 / 0.4342 Acc: 23.4375 (20.8997)\n",
      "[1/25][716/782] Loss_D: 0.4023 (0.8172) Loss_G: 0.2213 (0.7172) D(x): 0.5072 D(G(z)): 0.4322 / 0.4044 Acc: 20.3125 (20.8993)\n",
      "[1/25][717/782] Loss_D: 0.2721 (0.8168) Loss_G: 0.1640 (0.7169) D(x): 0.5182 D(G(z)): 0.4273 / 0.4545 Acc: 32.8125 (20.9073)\n",
      "[1/25][718/782] Loss_D: 0.3467 (0.8165) Loss_G: 0.1970 (0.7165) D(x): 0.6151 D(G(z)): 0.4539 / 0.4359 Acc: 14.0625 (20.9027)\n",
      "[1/25][719/782] Loss_D: 0.3155 (0.8162) Loss_G: 0.2911 (0.7162) D(x): 0.6444 D(G(z)): 0.4928 / 0.4207 Acc: 25.0000 (20.9055)\n",
      "[1/25][720/782] Loss_D: 0.5909 (0.8160) Loss_G: 0.3765 (0.7160) D(x): 0.5137 D(G(z)): 0.4998 / 0.3775 Acc: 18.7500 (20.9040)\n",
      "[1/25][721/782] Loss_D: 0.4346 (0.8158) Loss_G: 0.2248 (0.7157) D(x): 0.4850 D(G(z)): 0.4078 / 0.4227 Acc: 20.3125 (20.9036)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/25][722/782] Loss_D: 0.3508 (0.8155) Loss_G: 0.2352 (0.7154) D(x): 0.5549 D(G(z)): 0.4190 / 0.4350 Acc: 20.3125 (20.9032)\n",
      "[1/25][723/782] Loss_D: 0.2266 (0.8151) Loss_G: 0.1818 (0.7150) D(x): 0.5784 D(G(z)): 0.4343 / 0.4297 Acc: 23.4375 (20.9049)\n",
      "[1/25][724/782] Loss_D: 0.4046 (0.8148) Loss_G: 0.1378 (0.7146) D(x): 0.5531 D(G(z)): 0.4953 / 0.4467 Acc: 23.4375 (20.9066)\n",
      "[1/25][725/782] Loss_D: 0.2221 (0.8144) Loss_G: 0.1789 (0.7143) D(x): 0.5288 D(G(z)): 0.4680 / 0.4119 Acc: 31.2500 (20.9135)\n",
      "[1/25][726/782] Loss_D: 0.4791 (0.8142) Loss_G: 0.0812 (0.7139) D(x): 0.5110 D(G(z)): 0.5118 / 0.4854 Acc: 29.6875 (20.9193)\n",
      "[1/25][727/782] Loss_D: 0.2683 (0.8138) Loss_G: 0.0531 (0.7134) D(x): 0.5483 D(G(z)): 0.4759 / 0.4423 Acc: 21.8750 (20.9199)\n",
      "[1/25][728/782] Loss_D: 0.3414 (0.8135) Loss_G: 0.0769 (0.7130) D(x): 0.4797 D(G(z)): 0.4576 / 0.4494 Acc: 28.1250 (20.9247)\n",
      "[1/25][729/782] Loss_D: 0.5221 (0.8133) Loss_G: 0.1779 (0.7127) D(x): 0.5324 D(G(z)): 0.5161 / 0.4455 Acc: 20.3125 (20.9243)\n",
      "[1/25][730/782] Loss_D: 0.3581 (0.8130) Loss_G: 0.1891 (0.7123) D(x): 0.5043 D(G(z)): 0.4565 / 0.4170 Acc: 29.6875 (20.9301)\n",
      "[1/25][731/782] Loss_D: 0.4603 (0.8128) Loss_G: 0.2249 (0.7120) D(x): 0.5139 D(G(z)): 0.4553 / 0.4294 Acc: 18.7500 (20.9286)\n",
      "[1/25][732/782] Loss_D: 0.4457 (0.8125) Loss_G: 0.0669 (0.7116) D(x): 0.5714 D(G(z)): 0.5231 / 0.4775 Acc: 20.3125 (20.9282)\n",
      "[1/25][733/782] Loss_D: 0.1860 (0.8121) Loss_G: 0.1666 (0.7112) D(x): 0.5335 D(G(z)): 0.4123 / 0.4277 Acc: 26.5625 (20.9319)\n",
      "[1/25][734/782] Loss_D: 0.3521 (0.8118) Loss_G: -0.0688 (0.7107) D(x): 0.5020 D(G(z)): 0.4804 / 0.4906 Acc: 32.8125 (20.9398)\n",
      "[1/25][735/782] Loss_D: 0.3413 (0.8115) Loss_G: -0.0701 (0.7102) D(x): 0.5327 D(G(z)): 0.4680 / 0.5061 Acc: 21.8750 (20.9404)\n",
      "[1/25][736/782] Loss_D: 0.4833 (0.8113) Loss_G: 0.1534 (0.7098) D(x): 0.5875 D(G(z)): 0.5272 / 0.4744 Acc: 17.1875 (20.9379)\n",
      "[1/25][737/782] Loss_D: 0.4909 (0.8111) Loss_G: 0.6430 (0.7098) D(x): 0.6119 D(G(z)): 0.5242 / 0.3284 Acc: 26.5625 (20.9416)\n",
      "[1/25][738/782] Loss_D: 0.6432 (0.8110) Loss_G: 0.1689 (0.7094) D(x): 0.3466 D(G(z)): 0.3802 / 0.4115 Acc: 26.5625 (20.9453)\n",
      "[1/25][739/782] Loss_D: 0.6375 (0.8109) Loss_G: 0.0487 (0.7090) D(x): 0.4688 D(G(z)): 0.4720 / 0.5194 Acc: 23.4375 (20.9469)\n",
      "[1/25][740/782] Loss_D: 0.4082 (0.8106) Loss_G: 0.0143 (0.7085) D(x): 0.5450 D(G(z)): 0.4917 / 0.5147 Acc: 23.4375 (20.9486)\n",
      "[1/25][741/782] Loss_D: 0.3514 (0.8103) Loss_G: 0.2613 (0.7082) D(x): 0.5881 D(G(z)): 0.5242 / 0.4070 Acc: 28.1250 (20.9533)\n",
      "[1/25][742/782] Loss_D: 0.3235 (0.8100) Loss_G: 0.3287 (0.7080) D(x): 0.5211 D(G(z)): 0.4380 / 0.3776 Acc: 25.0000 (20.9559)\n",
      "[1/25][743/782] Loss_D: 0.4551 (0.8097) Loss_G: 0.1992 (0.7076) D(x): 0.4671 D(G(z)): 0.4258 / 0.4424 Acc: 28.1250 (20.9606)\n",
      "[1/25][744/782] Loss_D: 0.4079 (0.8095) Loss_G: 0.0610 (0.7072) D(x): 0.5209 D(G(z)): 0.4610 / 0.5008 Acc: 26.5625 (20.9643)\n",
      "[1/25][745/782] Loss_D: 0.6306 (0.8094) Loss_G: 0.1032 (0.7068) D(x): 0.5339 D(G(z)): 0.5446 / 0.4681 Acc: 20.3125 (20.9639)\n",
      "[1/25][746/782] Loss_D: 0.4399 (0.8091) Loss_G: 0.3238 (0.7066) D(x): 0.5988 D(G(z)): 0.5308 / 0.4166 Acc: 28.1250 (20.9686)\n",
      "[1/25][747/782] Loss_D: 0.5176 (0.8089) Loss_G: 0.3582 (0.7063) D(x): 0.4799 D(G(z)): 0.4598 / 0.4035 Acc: 32.8125 (20.9763)\n",
      "[1/25][748/782] Loss_D: 0.5104 (0.8087) Loss_G: 0.2052 (0.7060) D(x): 0.5221 D(G(z)): 0.4708 / 0.4448 Acc: 21.8750 (20.9769)\n",
      "[1/25][749/782] Loss_D: 0.3797 (0.8085) Loss_G: -0.0562 (0.7055) D(x): 0.4618 D(G(z)): 0.4289 / 0.4841 Acc: 26.5625 (20.9805)\n",
      "[1/25][750/782] Loss_D: 0.3225 (0.8081) Loss_G: 0.0474 (0.7051) D(x): 0.5827 D(G(z)): 0.4538 / 0.4829 Acc: 18.7500 (20.9791)\n",
      "[1/25][751/782] Loss_D: 0.4299 (0.8079) Loss_G: 0.2390 (0.7048) D(x): 0.5884 D(G(z)): 0.5169 / 0.4318 Acc: 23.4375 (20.9807)\n",
      "[1/25][752/782] Loss_D: 0.3399 (0.8076) Loss_G: 0.1264 (0.7044) D(x): 0.5031 D(G(z)): 0.4531 / 0.4348 Acc: 25.0000 (20.9833)\n",
      "[1/25][753/782] Loss_D: 0.5873 (0.8074) Loss_G: 0.1818 (0.7041) D(x): 0.4963 D(G(z)): 0.4968 / 0.4526 Acc: 28.1250 (20.9880)\n",
      "[1/25][754/782] Loss_D: 0.3008 (0.8071) Loss_G: 0.0324 (0.7036) D(x): 0.5741 D(G(z)): 0.4903 / 0.4731 Acc: 23.4375 (20.9895)\n",
      "[1/25][755/782] Loss_D: 0.4536 (0.8069) Loss_G: 0.1651 (0.7033) D(x): 0.5415 D(G(z)): 0.5272 / 0.4470 Acc: 25.0000 (20.9922)\n",
      "[1/25][756/782] Loss_D: 0.4672 (0.8067) Loss_G: 0.1880 (0.7029) D(x): 0.4900 D(G(z)): 0.4850 / 0.4287 Acc: 26.5625 (20.9958)\n",
      "[1/25][757/782] Loss_D: 0.4885 (0.8065) Loss_G: 0.1448 (0.7026) D(x): 0.5028 D(G(z)): 0.4576 / 0.4547 Acc: 17.1875 (20.9933)\n",
      "[1/25][758/782] Loss_D: 0.2988 (0.8061) Loss_G: 0.0807 (0.7022) D(x): 0.5127 D(G(z)): 0.4677 / 0.4486 Acc: 29.6875 (20.9989)\n",
      "[1/25][759/782] Loss_D: 0.4847 (0.8059) Loss_G: 0.1480 (0.7018) D(x): 0.5431 D(G(z)): 0.5160 / 0.4535 Acc: 23.4375 (21.0005)\n",
      "[1/25][760/782] Loss_D: 0.2428 (0.8056) Loss_G: 0.1620 (0.7015) D(x): 0.6038 D(G(z)): 0.5414 / 0.4086 Acc: 35.9375 (21.0102)\n",
      "[1/25][761/782] Loss_D: 0.2348 (0.8052) Loss_G: 0.2404 (0.7012) D(x): 0.5289 D(G(z)): 0.4355 / 0.3907 Acc: 29.6875 (21.0158)\n",
      "[1/25][762/782] Loss_D: 0.3017 (0.8049) Loss_G: 0.0820 (0.7008) D(x): 0.4991 D(G(z)): 0.4114 / 0.4360 Acc: 18.7500 (21.0144)\n",
      "[1/25][763/782] Loss_D: 0.3803 (0.8046) Loss_G: 0.1392 (0.7004) D(x): 0.5293 D(G(z)): 0.4137 / 0.4610 Acc: 21.8750 (21.0149)\n",
      "[1/25][764/782] Loss_D: 0.3341 (0.8043) Loss_G: -0.0580 (0.6999) D(x): 0.6027 D(G(z)): 0.5161 / 0.4926 Acc: 20.3125 (21.0145)\n",
      "[1/25][765/782] Loss_D: 0.3272 (0.8040) Loss_G: 0.1550 (0.6996) D(x): 0.5470 D(G(z)): 0.4702 / 0.4126 Acc: 23.4375 (21.0160)\n",
      "[1/25][766/782] Loss_D: 0.4179 (0.8037) Loss_G: 0.1122 (0.6992) D(x): 0.4919 D(G(z)): 0.4556 / 0.4542 Acc: 21.8750 (21.0166)\n",
      "[1/25][767/782] Loss_D: 0.4017 (0.8035) Loss_G: 0.3417 (0.6990) D(x): 0.5542 D(G(z)): 0.4625 / 0.3924 Acc: 21.8750 (21.0171)\n",
      "[1/25][768/782] Loss_D: 0.4119 (0.8032) Loss_G: -0.0179 (0.6985) D(x): 0.4990 D(G(z)): 0.4874 / 0.4907 Acc: 29.6875 (21.0227)\n",
      "[1/25][769/782] Loss_D: 0.4294 (0.8030) Loss_G: 0.1684 (0.6982) D(x): 0.5413 D(G(z)): 0.4865 / 0.4096 Acc: 20.3125 (21.0223)\n",
      "[1/25][770/782] Loss_D: 0.3592 (0.8027) Loss_G: 0.1657 (0.6978) D(x): 0.5177 D(G(z)): 0.4424 / 0.4196 Acc: 20.3125 (21.0218)\n",
      "[1/25][771/782] Loss_D: 0.2527 (0.8023) Loss_G: -0.0358 (0.6973) D(x): 0.5095 D(G(z)): 0.4070 / 0.4972 Acc: 20.3125 (21.0214)\n",
      "[1/25][772/782] Loss_D: 0.3829 (0.8021) Loss_G: 0.3154 (0.6971) D(x): 0.6282 D(G(z)): 0.4991 / 0.3926 Acc: 17.1875 (21.0189)\n",
      "[1/25][773/782] Loss_D: 0.4201 (0.8018) Loss_G: 0.2895 (0.6968) D(x): 0.5809 D(G(z)): 0.4860 / 0.3886 Acc: 15.6250 (21.0154)\n",
      "[1/25][774/782] Loss_D: 0.3184 (0.8015) Loss_G: 0.1870 (0.6965) D(x): 0.4657 D(G(z)): 0.4154 / 0.4052 Acc: 25.0000 (21.0180)\n",
      "[1/25][775/782] Loss_D: 0.1870 (0.8011) Loss_G: -0.0617 (0.6960) D(x): 0.5465 D(G(z)): 0.4029 / 0.5267 Acc: 25.0000 (21.0205)\n",
      "[1/25][776/782] Loss_D: 0.3431 (0.8008) Loss_G: -0.0922 (0.6955) D(x): 0.5397 D(G(z)): 0.4672 / 0.5011 Acc: 17.1875 (21.0181)\n",
      "[1/25][777/782] Loss_D: 0.3684 (0.8005) Loss_G: 0.1585 (0.6952) D(x): 0.5932 D(G(z)): 0.4936 / 0.4335 Acc: 18.7500 (21.0166)\n",
      "[1/25][778/782] Loss_D: 0.2451 (0.8002) Loss_G: 0.2643 (0.6949) D(x): 0.5705 D(G(z)): 0.4647 / 0.3867 Acc: 25.0000 (21.0192)\n",
      "[1/25][779/782] Loss_D: 0.2624 (0.7998) Loss_G: 0.1373 (0.6945) D(x): 0.4825 D(G(z)): 0.3852 / 0.4436 Acc: 26.5625 (21.0227)\n",
      "[1/25][780/782] Loss_D: 0.1870 (0.7995) Loss_G: 0.2210 (0.6942) D(x): 0.5799 D(G(z)): 0.4561 / 0.4025 Acc: 32.8125 (21.0303)\n",
      "[1/25][781/782] Loss_D: 0.9292 (0.7995) Loss_G: 0.3203 (0.6940) D(x): 0.5026 D(G(z)): 0.4974 / 0.4517 Acc: 12.5000 (21.0248)\n",
      "[2/25][0/782] Loss_D: 0.4195 (0.7993) Loss_G: 0.0655 (0.6936) D(x): 0.5028 D(G(z)): 0.4678 / 0.4634 Acc: 21.8750 (21.0254)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[2/25][1/782] Loss_D: 0.2987 (0.7990) Loss_G: 0.1308 (0.6932) D(x): 0.5383 D(G(z)): 0.4634 / 0.4607 Acc: 31.2500 (21.0319)\n",
      "[2/25][2/782] Loss_D: 0.3413 (0.7987) Loss_G: 0.2029 (0.6929) D(x): 0.5302 D(G(z)): 0.4466 / 0.4441 Acc: 32.8125 (21.0394)\n",
      "[2/25][3/782] Loss_D: 0.4176 (0.7984) Loss_G: 0.1621 (0.6926) D(x): 0.5212 D(G(z)): 0.4849 / 0.4559 Acc: 31.2500 (21.0459)\n",
      "[2/25][4/782] Loss_D: 0.4786 (0.7982) Loss_G: 0.1134 (0.6922) D(x): 0.4978 D(G(z)): 0.4791 / 0.4710 Acc: 25.0000 (21.0484)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/25][5/782] Loss_D: 0.2392 (0.7979) Loss_G: 0.0993 (0.6918) D(x): 0.5199 D(G(z)): 0.4408 / 0.4537 Acc: 31.2500 (21.0549)\n",
      "[2/25][6/782] Loss_D: 0.5597 (0.7977) Loss_G: -0.0243 (0.6914) D(x): 0.5156 D(G(z)): 0.5369 / 0.4870 Acc: 23.4375 (21.0565)\n",
      "[2/25][7/782] Loss_D: 0.4632 (0.7975) Loss_G: 0.0931 (0.6910) D(x): 0.5467 D(G(z)): 0.5691 / 0.4257 Acc: 25.0000 (21.0590)\n",
      "[2/25][8/782] Loss_D: 0.3623 (0.7972) Loss_G: 0.1369 (0.6906) D(x): 0.5036 D(G(z)): 0.4571 / 0.4477 Acc: 26.5625 (21.0625)\n",
      "[2/25][9/782] Loss_D: 0.3901 (0.7970) Loss_G: 0.1029 (0.6903) D(x): 0.4701 D(G(z)): 0.4519 / 0.4436 Acc: 32.8125 (21.0699)\n",
      "[2/25][10/782] Loss_D: 0.2825 (0.7967) Loss_G: 0.1464 (0.6899) D(x): 0.5342 D(G(z)): 0.4033 / 0.4457 Acc: 23.4375 (21.0714)\n",
      "[2/25][11/782] Loss_D: 0.2230 (0.7963) Loss_G: 0.0472 (0.6895) D(x): 0.5633 D(G(z)): 0.4921 / 0.4599 Acc: 29.6875 (21.0769)\n",
      "[2/25][12/782] Loss_D: 0.3113 (0.7960) Loss_G: 0.0145 (0.6891) D(x): 0.5198 D(G(z)): 0.4901 / 0.4525 Acc: 32.8125 (21.0843)\n",
      "[2/25][13/782] Loss_D: 0.2877 (0.7957) Loss_G: 0.2815 (0.6888) D(x): 0.5710 D(G(z)): 0.4972 / 0.3852 Acc: 29.6875 (21.0898)\n",
      "[2/25][14/782] Loss_D: 0.4345 (0.7954) Loss_G: 0.1835 (0.6885) D(x): 0.4728 D(G(z)): 0.4776 / 0.4200 Acc: 29.6875 (21.0952)\n",
      "[2/25][15/782] Loss_D: 0.5363 (0.7953) Loss_G: 0.0100 (0.6881) D(x): 0.4663 D(G(z)): 0.4287 / 0.4804 Acc: 14.0625 (21.0908)\n",
      "[2/25][16/782] Loss_D: 0.5628 (0.7951) Loss_G: 0.0331 (0.6877) D(x): 0.5326 D(G(z)): 0.5061 / 0.5068 Acc: 23.4375 (21.0923)\n",
      "[2/25][17/782] Loss_D: 0.4292 (0.7949) Loss_G: 0.3976 (0.6875) D(x): 0.5777 D(G(z)): 0.4953 / 0.3603 Acc: 21.8750 (21.0928)\n",
      "[2/25][18/782] Loss_D: 0.5019 (0.7947) Loss_G: 0.2743 (0.6872) D(x): 0.5018 D(G(z)): 0.4532 / 0.4108 Acc: 20.3125 (21.0923)\n",
      "[2/25][19/782] Loss_D: 0.1960 (0.7943) Loss_G: 0.2915 (0.6870) D(x): 0.5141 D(G(z)): 0.3987 / 0.3764 Acc: 25.0000 (21.0947)\n",
      "[2/25][20/782] Loss_D: 0.4117 (0.7941) Loss_G: 0.0929 (0.6866) D(x): 0.5038 D(G(z)): 0.4962 / 0.4619 Acc: 31.2500 (21.1011)\n",
      "[2/25][21/782] Loss_D: 0.3435 (0.7938) Loss_G: 0.0128 (0.6862) D(x): 0.4853 D(G(z)): 0.4383 / 0.4742 Acc: 26.5625 (21.1046)\n",
      "[2/25][22/782] Loss_D: 0.4081 (0.7936) Loss_G: 0.1577 (0.6858) D(x): 0.5704 D(G(z)): 0.5255 / 0.4637 Acc: 23.4375 (21.1061)\n",
      "[2/25][23/782] Loss_D: 0.6646 (0.7935) Loss_G: 0.1377 (0.6855) D(x): 0.5010 D(G(z)): 0.4961 / 0.4503 Acc: 7.8125 (21.0977)\n",
      "[2/25][24/782] Loss_D: 0.2696 (0.7931) Loss_G: 0.0327 (0.6851) D(x): 0.4952 D(G(z)): 0.4189 / 0.4497 Acc: 26.5625 (21.1011)\n",
      "[2/25][25/782] Loss_D: 0.3111 (0.7928) Loss_G: 0.0730 (0.6847) D(x): 0.5066 D(G(z)): 0.4386 / 0.4541 Acc: 26.5625 (21.1046)\n",
      "[2/25][26/782] Loss_D: 0.2409 (0.7925) Loss_G: 0.1516 (0.6844) D(x): 0.6174 D(G(z)): 0.4800 / 0.4414 Acc: 25.0000 (21.1070)\n",
      "[2/25][27/782] Loss_D: 0.3919 (0.7922) Loss_G: 0.3420 (0.6841) D(x): 0.5618 D(G(z)): 0.4756 / 0.3888 Acc: 21.8750 (21.1075)\n",
      "[2/25][28/782] Loss_D: 0.4497 (0.7920) Loss_G: 0.3138 (0.6839) D(x): 0.5023 D(G(z)): 0.4764 / 0.3724 Acc: 21.8750 (21.1080)\n",
      "[2/25][29/782] Loss_D: 0.3000 (0.7917) Loss_G: 0.0487 (0.6835) D(x): 0.4833 D(G(z)): 0.3864 / 0.4703 Acc: 23.4375 (21.1094)\n",
      "[2/25][30/782] Loss_D: 0.3451 (0.7914) Loss_G: 0.0603 (0.6831) D(x): 0.5338 D(G(z)): 0.4754 / 0.4859 Acc: 31.2500 (21.1158)\n",
      "[2/25][31/782] Loss_D: 0.5055 (0.7913) Loss_G: 0.3090 (0.6829) D(x): 0.5654 D(G(z)): 0.5284 / 0.3942 Acc: 26.5625 (21.1192)\n",
      "[2/25][32/782] Loss_D: 0.4426 (0.7910) Loss_G: 0.1834 (0.6826) D(x): 0.5021 D(G(z)): 0.4578 / 0.4209 Acc: 28.1250 (21.1236)\n",
      "[2/25][33/782] Loss_D: 0.4346 (0.7908) Loss_G: 0.0822 (0.6822) D(x): 0.4973 D(G(z)): 0.4038 / 0.4770 Acc: 17.1875 (21.1211)\n",
      "[2/25][34/782] Loss_D: 0.3766 (0.7906) Loss_G: 0.0941 (0.6818) D(x): 0.5314 D(G(z)): 0.4698 / 0.4770 Acc: 23.4375 (21.1226)\n",
      "[2/25][35/782] Loss_D: 0.3290 (0.7903) Loss_G: 0.1315 (0.6815) D(x): 0.5492 D(G(z)): 0.4787 / 0.4732 Acc: 31.2500 (21.1289)\n",
      "[2/25][36/782] Loss_D: 0.4518 (0.7901) Loss_G: 0.1548 (0.6812) D(x): 0.5632 D(G(z)): 0.5080 / 0.4245 Acc: 20.3125 (21.1284)\n",
      "[2/25][37/782] Loss_D: 0.4434 (0.7898) Loss_G: 0.1217 (0.6808) D(x): 0.5071 D(G(z)): 0.4779 / 0.4518 Acc: 29.6875 (21.1337)\n",
      "[2/25][38/782] Loss_D: 0.5406 (0.7897) Loss_G: 0.1455 (0.6805) D(x): 0.4963 D(G(z)): 0.4555 / 0.4416 Acc: 15.6250 (21.1303)\n",
      "[2/25][39/782] Loss_D: 0.3128 (0.7894) Loss_G: 0.1634 (0.6802) D(x): 0.5561 D(G(z)): 0.4768 / 0.4378 Acc: 25.0000 (21.1327)\n",
      "[2/25][40/782] Loss_D: 0.2902 (0.7891) Loss_G: -0.0048 (0.6797) D(x): 0.5353 D(G(z)): 0.4356 / 0.4903 Acc: 23.4375 (21.1342)\n",
      "[2/25][41/782] Loss_D: 0.5036 (0.7889) Loss_G: -0.0089 (0.6793) D(x): 0.5291 D(G(z)): 0.5170 / 0.4910 Acc: 21.8750 (21.1346)\n",
      "[2/25][42/782] Loss_D: 0.3670 (0.7886) Loss_G: -0.0450 (0.6788) D(x): 0.5035 D(G(z)): 0.4699 / 0.4792 Acc: 23.4375 (21.1360)\n",
      "[2/25][43/782] Loss_D: 0.3959 (0.7884) Loss_G: 0.1555 (0.6785) D(x): 0.5601 D(G(z)): 0.4944 / 0.4490 Acc: 23.4375 (21.1375)\n",
      "[2/25][44/782] Loss_D: 0.2494 (0.7881) Loss_G: 0.0727 (0.6781) D(x): 0.5785 D(G(z)): 0.4490 / 0.4818 Acc: 26.5625 (21.1408)\n",
      "[2/25][45/782] Loss_D: 0.3159 (0.7878) Loss_G: 0.0695 (0.6778) D(x): 0.5822 D(G(z)): 0.4898 / 0.4593 Acc: 23.4375 (21.1423)\n",
      "[2/25][46/782] Loss_D: 0.3952 (0.7875) Loss_G: 0.1453 (0.6774) D(x): 0.5290 D(G(z)): 0.4887 / 0.4590 Acc: 28.1250 (21.1466)\n",
      "[2/25][47/782] Loss_D: 0.4977 (0.7873) Loss_G: 0.0886 (0.6771) D(x): 0.5339 D(G(z)): 0.4964 / 0.4555 Acc: 15.6250 (21.1432)\n",
      "[2/25][48/782] Loss_D: 0.1036 (0.7869) Loss_G: 0.0407 (0.6767) D(x): 0.5733 D(G(z)): 0.4637 / 0.4835 Acc: 42.1875 (21.1562)\n",
      "[2/25][49/782] Loss_D: 0.3471 (0.7866) Loss_G: 0.0185 (0.6763) D(x): 0.5241 D(G(z)): 0.4767 / 0.4797 Acc: 23.4375 (21.1576)\n",
      "[2/25][50/782] Loss_D: 0.3598 (0.7864) Loss_G: 0.1894 (0.6760) D(x): 0.5429 D(G(z)): 0.4838 / 0.4365 Acc: 28.1250 (21.1620)\n",
      "[2/25][51/782] Loss_D: 0.4503 (0.7862) Loss_G: 0.0216 (0.6756) D(x): 0.4932 D(G(z)): 0.4522 / 0.5119 Acc: 26.5625 (21.1653)\n",
      "[2/25][52/782] Loss_D: 0.5289 (0.7860) Loss_G: 0.1092 (0.6752) D(x): 0.5545 D(G(z)): 0.5206 / 0.4932 Acc: 23.4375 (21.1667)\n",
      "[2/25][53/782] Loss_D: 0.4505 (0.7858) Loss_G: 0.0905 (0.6749) D(x): 0.5341 D(G(z)): 0.4956 / 0.4633 Acc: 18.7500 (21.1652)\n",
      "[2/25][54/782] Loss_D: 0.5223 (0.7856) Loss_G: 0.2118 (0.6746) D(x): 0.5057 D(G(z)): 0.4812 / 0.4398 Acc: 21.8750 (21.1657)\n",
      "[2/25][55/782] Loss_D: 0.4999 (0.7855) Loss_G: 0.1482 (0.6742) D(x): 0.4620 D(G(z)): 0.4207 / 0.4333 Acc: 18.7500 (21.1642)\n",
      "[2/25][56/782] Loss_D: 0.3543 (0.7852) Loss_G: 0.1211 (0.6739) D(x): 0.5467 D(G(z)): 0.4698 / 0.4441 Acc: 23.4375 (21.1656)\n",
      "[2/25][57/782] Loss_D: 0.3730 (0.7849) Loss_G: 0.0636 (0.6735) D(x): 0.4792 D(G(z)): 0.4319 / 0.4518 Acc: 20.3125 (21.1650)\n",
      "[2/25][58/782] Loss_D: 0.4560 (0.7847) Loss_G: -0.0254 (0.6731) D(x): 0.5555 D(G(z)): 0.5511 / 0.4888 Acc: 25.0000 (21.1674)\n",
      "[2/25][59/782] Loss_D: 0.3241 (0.7845) Loss_G: 0.1297 (0.6728) D(x): 0.5109 D(G(z)): 0.4549 / 0.4458 Acc: 28.1250 (21.1717)\n",
      "[2/25][60/782] Loss_D: 0.4925 (0.7843) Loss_G: 0.4161 (0.6726) D(x): 0.5162 D(G(z)): 0.4633 / 0.4039 Acc: 29.6875 (21.1769)\n",
      "[2/25][61/782] Loss_D: 0.3982 (0.7840) Loss_G: 0.1822 (0.6723) D(x): 0.5037 D(G(z)): 0.4571 / 0.4278 Acc: 25.0000 (21.1793)\n",
      "[2/25][62/782] Loss_D: 0.1739 (0.7837) Loss_G: 0.1361 (0.6720) D(x): 0.5859 D(G(z)): 0.4552 / 0.4424 Acc: 34.3750 (21.1874)\n",
      "[2/25][63/782] Loss_D: 0.2992 (0.7834) Loss_G: 0.0500 (0.6716) D(x): 0.5446 D(G(z)): 0.4634 / 0.4685 Acc: 21.8750 (21.1878)\n",
      "[2/25][64/782] Loss_D: 0.4018 (0.7831) Loss_G: 0.1954 (0.6713) D(x): 0.5676 D(G(z)): 0.5080 / 0.4355 Acc: 23.4375 (21.1892)\n",
      "[2/25][65/782] Loss_D: 0.0921 (0.7827) Loss_G: 0.0444 (0.6709) D(x): 0.5849 D(G(z)): 0.4500 / 0.4369 Acc: 26.5625 (21.1925)\n",
      "[2/25][66/782] Loss_D: 0.3148 (0.7824) Loss_G: 0.3519 (0.6707) D(x): 0.5643 D(G(z)): 0.4199 / 0.3795 Acc: 17.1875 (21.1900)\n",
      "[2/25][67/782] Loss_D: 0.2826 (0.7821) Loss_G: 0.2745 (0.6705) D(x): 0.5331 D(G(z)): 0.4645 / 0.3994 Acc: 35.9375 (21.1991)\n",
      "[2/25][68/782] Loss_D: 0.4525 (0.7819) Loss_G: 0.2561 (0.6702) D(x): 0.5098 D(G(z)): 0.3975 / 0.4477 Acc: 18.7500 (21.1976)\n",
      "[2/25][69/782] Loss_D: 0.3087 (0.7816) Loss_G: 0.0506 (0.6698) D(x): 0.5126 D(G(z)): 0.4202 / 0.4553 Acc: 25.0000 (21.1999)\n",
      "[2/25][70/782] Loss_D: 0.2600 (0.7813) Loss_G: 0.1165 (0.6695) D(x): 0.5734 D(G(z)): 0.4111 / 0.4619 Acc: 21.8750 (21.2003)\n",
      "[2/25][71/782] Loss_D: 0.2516 (0.7810) Loss_G: 0.2969 (0.6693) D(x): 0.7198 D(G(z)): 0.5427 / 0.3830 Acc: 21.8750 (21.2007)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/25][72/782] Loss_D: 0.2956 (0.7807) Loss_G: 0.2727 (0.6690) D(x): 0.5083 D(G(z)): 0.4002 / 0.3909 Acc: 28.1250 (21.2049)\n",
      "[2/25][73/782] Loss_D: 0.3199 (0.7804) Loss_G: 0.1871 (0.6687) D(x): 0.4794 D(G(z)): 0.4241 / 0.4273 Acc: 29.6875 (21.2101)\n",
      "[2/25][74/782] Loss_D: 0.3563 (0.7802) Loss_G: 0.1247 (0.6684) D(x): 0.5207 D(G(z)): 0.4226 / 0.4898 Acc: 21.8750 (21.2105)\n",
      "[2/25][75/782] Loss_D: 0.6731 (0.7801) Loss_G: 0.1970 (0.6681) D(x): 0.5904 D(G(z)): 0.5699 / 0.4361 Acc: 14.0625 (21.2062)\n",
      "[2/25][76/782] Loss_D: 0.4423 (0.7799) Loss_G: 0.3407 (0.6679) D(x): 0.5281 D(G(z)): 0.4717 / 0.4100 Acc: 28.1250 (21.2104)\n",
      "[2/25][77/782] Loss_D: 0.3755 (0.7796) Loss_G: 0.0813 (0.6676) D(x): 0.4728 D(G(z)): 0.4071 / 0.4378 Acc: 20.3125 (21.2098)\n",
      "[2/25][78/782] Loss_D: 0.3178 (0.7794) Loss_G: 0.2657 (0.6673) D(x): 0.5603 D(G(z)): 0.4707 / 0.4131 Acc: 28.1250 (21.2141)\n",
      "[2/25][79/782] Loss_D: 0.3215 (0.7791) Loss_G: 0.0753 (0.6670) D(x): 0.5105 D(G(z)): 0.4683 / 0.4503 Acc: 28.1250 (21.2183)\n",
      "[2/25][80/782] Loss_D: 0.2478 (0.7788) Loss_G: 0.1117 (0.6666) D(x): 0.5801 D(G(z)): 0.4360 / 0.4483 Acc: 21.8750 (21.2187)\n",
      "[2/25][81/782] Loss_D: 0.4850 (0.7786) Loss_G: 0.2775 (0.6664) D(x): 0.5819 D(G(z)): 0.5035 / 0.4393 Acc: 23.4375 (21.2200)\n",
      "[2/25][82/782] Loss_D: 0.3981 (0.7783) Loss_G: 0.2338 (0.6661) D(x): 0.5120 D(G(z)): 0.4293 / 0.4281 Acc: 23.4375 (21.2213)\n",
      "[2/25][83/782] Loss_D: 0.3674 (0.7781) Loss_G: 0.1204 (0.6658) D(x): 0.4922 D(G(z)): 0.4641 / 0.4533 Acc: 29.6875 (21.2265)\n",
      "[2/25][84/782] Loss_D: 0.3208 (0.7778) Loss_G: 0.0941 (0.6654) D(x): 0.5525 D(G(z)): 0.4526 / 0.4566 Acc: 21.8750 (21.2269)\n",
      "[2/25][85/782] Loss_D: 0.2699 (0.7775) Loss_G: 0.2305 (0.6652) D(x): 0.5728 D(G(z)): 0.4620 / 0.4129 Acc: 23.4375 (21.2282)\n",
      "[2/25][86/782] Loss_D: 0.2691 (0.7772) Loss_G: 0.2346 (0.6649) D(x): 0.5263 D(G(z)): 0.4044 / 0.3954 Acc: 21.8750 (21.2286)\n",
      "[2/25][87/782] Loss_D: 0.1700 (0.7768) Loss_G: -0.0025 (0.6645) D(x): 0.5618 D(G(z)): 0.4937 / 0.4465 Acc: 34.3750 (21.2366)\n",
      "[2/25][88/782] Loss_D: 0.2895 (0.7765) Loss_G: -0.0085 (0.6641) D(x): 0.5093 D(G(z)): 0.4336 / 0.4844 Acc: 23.4375 (21.2379)\n",
      "[2/25][89/782] Loss_D: 0.2920 (0.7762) Loss_G: 0.2736 (0.6639) D(x): 0.6213 D(G(z)): 0.5331 / 0.4000 Acc: 32.8125 (21.2449)\n",
      "[2/25][90/782] Loss_D: 0.4179 (0.7760) Loss_G: 0.2705 (0.6636) D(x): 0.5078 D(G(z)): 0.4359 / 0.4195 Acc: 21.8750 (21.2453)\n",
      "[2/25][91/782] Loss_D: 0.3759 (0.7758) Loss_G: 0.3799 (0.6635) D(x): 0.5509 D(G(z)): 0.4403 / 0.3732 Acc: 15.6250 (21.2419)\n",
      "[2/25][92/782] Loss_D: 0.4334 (0.7756) Loss_G: 0.2023 (0.6632) D(x): 0.4507 D(G(z)): 0.4185 / 0.4047 Acc: 23.4375 (21.2432)\n",
      "[2/25][93/782] Loss_D: 0.3524 (0.7753) Loss_G: 0.2679 (0.6629) D(x): 0.5564 D(G(z)): 0.4390 / 0.4159 Acc: 20.3125 (21.2426)\n",
      "[2/25][94/782] Loss_D: 0.2108 (0.7750) Loss_G: 0.0268 (0.6626) D(x): 0.5735 D(G(z)): 0.4521 / 0.4723 Acc: 29.6875 (21.2477)\n",
      "[2/25][95/782] Loss_D: 0.4313 (0.7748) Loss_G: 0.0854 (0.6622) D(x): 0.5242 D(G(z)): 0.4921 / 0.4622 Acc: 21.8750 (21.2481)\n",
      "[2/25][96/782] Loss_D: 0.3107 (0.7745) Loss_G: 0.0260 (0.6618) D(x): 0.5260 D(G(z)): 0.4043 / 0.5118 Acc: 26.5625 (21.2513)\n",
      "[2/25][97/782] Loss_D: 0.1778 (0.7741) Loss_G: -0.0145 (0.6614) D(x): 0.5434 D(G(z)): 0.4587 / 0.4669 Acc: 26.5625 (21.2545)\n",
      "[2/25][98/782] Loss_D: 0.3312 (0.7739) Loss_G: 0.1641 (0.6611) D(x): 0.5776 D(G(z)): 0.4965 / 0.4246 Acc: 23.4375 (21.2558)\n",
      "[2/25][99/782] Loss_D: 0.3901 (0.7736) Loss_G: 0.0947 (0.6608) D(x): 0.4902 D(G(z)): 0.4441 / 0.4751 Acc: 25.0000 (21.2581)\n",
      "[2/25][100/782] Loss_D: 0.4404 (0.7734) Loss_G: 0.1060 (0.6605) D(x): 0.5188 D(G(z)): 0.4976 / 0.4397 Acc: 23.4375 (21.2594)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[2/25][101/782] Loss_D: 0.3296 (0.7732) Loss_G: 0.1175 (0.6601) D(x): 0.5561 D(G(z)): 0.4591 / 0.4522 Acc: 25.0000 (21.2616)\n",
      "[2/25][102/782] Loss_D: 0.1893 (0.7728) Loss_G: 0.1810 (0.6598) D(x): 0.5339 D(G(z)): 0.4379 / 0.4130 Acc: 35.9375 (21.2704)\n",
      "[2/25][103/782] Loss_D: 0.3355 (0.7726) Loss_G: 0.2352 (0.6596) D(x): 0.5492 D(G(z)): 0.4879 / 0.4025 Acc: 34.3750 (21.2783)\n",
      "[2/25][104/782] Loss_D: 0.4949 (0.7724) Loss_G: 0.1689 (0.6593) D(x): 0.4922 D(G(z)): 0.4827 / 0.4436 Acc: 25.0000 (21.2805)\n",
      "[2/25][105/782] Loss_D: 0.4977 (0.7722) Loss_G: 0.1310 (0.6590) D(x): 0.4738 D(G(z)): 0.4603 / 0.4391 Acc: 21.8750 (21.2809)\n",
      "[2/25][106/782] Loss_D: 0.3568 (0.7720) Loss_G: 0.2678 (0.6587) D(x): 0.5254 D(G(z)): 0.4449 / 0.4350 Acc: 31.2500 (21.2868)\n",
      "[2/25][107/782] Loss_D: 0.1128 (0.7716) Loss_G: 0.1935 (0.6585) D(x): 0.6030 D(G(z)): 0.4696 / 0.4030 Acc: 32.8125 (21.2937)\n",
      "[2/25][108/782] Loss_D: 0.2653 (0.7713) Loss_G: 0.2821 (0.6582) D(x): 0.5593 D(G(z)): 0.4357 / 0.4200 Acc: 31.2500 (21.2997)\n",
      "[2/25][109/782] Loss_D: 0.4655 (0.7711) Loss_G: 0.3511 (0.6581) D(x): 0.5191 D(G(z)): 0.4370 / 0.4015 Acc: 21.8750 (21.3000)\n",
      "[2/25][110/782] Loss_D: 0.0680 (0.7707) Loss_G: 0.3235 (0.6579) D(x): 0.6035 D(G(z)): 0.4059 / 0.4032 Acc: 37.5000 (21.3097)\n",
      "[2/25][111/782] Loss_D: 0.1467 (0.7703) Loss_G: 0.2298 (0.6576) D(x): 0.5751 D(G(z)): 0.3883 / 0.3961 Acc: 21.8750 (21.3100)\n",
      "[2/25][112/782] Loss_D: 0.0647 (0.7699) Loss_G: 0.2474 (0.6574) D(x): 0.5841 D(G(z)): 0.3827 / 0.3989 Acc: 29.6875 (21.3150)\n",
      "[2/25][113/782] Loss_D: 0.2745 (0.7696) Loss_G: 0.3078 (0.6571) D(x): 0.5532 D(G(z)): 0.4204 / 0.3877 Acc: 25.0000 (21.3172)\n",
      "[2/25][114/782] Loss_D: 0.1511 (0.7692) Loss_G: 0.2268 (0.6569) D(x): 0.5934 D(G(z)): 0.3844 / 0.4264 Acc: 14.0625 (21.3129)\n",
      "[2/25][115/782] Loss_D: 0.1317 (0.7688) Loss_G: 0.2126 (0.6566) D(x): 0.6535 D(G(z)): 0.4899 / 0.4028 Acc: 21.8750 (21.3132)\n",
      "[2/25][116/782] Loss_D: 0.3006 (0.7686) Loss_G: 0.2351 (0.6564) D(x): 0.5043 D(G(z)): 0.3986 / 0.4191 Acc: 20.3125 (21.3126)\n",
      "[2/25][117/782] Loss_D: 0.3526 (0.7683) Loss_G: 0.1179 (0.6561) D(x): 0.5776 D(G(z)): 0.4771 / 0.4846 Acc: 29.6875 (21.3176)\n",
      "[2/25][118/782] Loss_D: 0.4540 (0.7681) Loss_G: 0.2923 (0.6558) D(x): 0.6453 D(G(z)): 0.5625 / 0.4120 Acc: 18.7500 (21.3161)\n",
      "[2/25][119/782] Loss_D: 0.6699 (0.7681) Loss_G: 0.4467 (0.6557) D(x): 0.4284 D(G(z)): 0.4721 / 0.3530 Acc: 28.1250 (21.3201)\n",
      "[2/25][120/782] Loss_D: 0.5934 (0.7680) Loss_G: 0.0440 (0.6553) D(x): 0.4091 D(G(z)): 0.4165 / 0.4889 Acc: 18.7500 (21.3186)\n",
      "[2/25][121/782] Loss_D: 0.4779 (0.7678) Loss_G: 0.0458 (0.6550) D(x): 0.5266 D(G(z)): 0.4918 / 0.4844 Acc: 15.6250 (21.3152)\n",
      "[2/25][122/782] Loss_D: 0.4308 (0.7676) Loss_G: 0.0551 (0.6546) D(x): 0.5280 D(G(z)): 0.4802 / 0.4440 Acc: 12.5000 (21.3100)\n",
      "[2/25][123/782] Loss_D: 0.3508 (0.7674) Loss_G: 0.1302 (0.6543) D(x): 0.5429 D(G(z)): 0.4467 / 0.4664 Acc: 26.5625 (21.3131)\n",
      "[2/25][124/782] Loss_D: 0.5091 (0.7672) Loss_G: 0.3202 (0.6541) D(x): 0.5329 D(G(z)): 0.5070 / 0.4014 Acc: 25.0000 (21.3153)\n",
      "[2/25][125/782] Loss_D: 0.2265 (0.7669) Loss_G: 0.2084 (0.6539) D(x): 0.5208 D(G(z)): 0.4286 / 0.3980 Acc: 31.2500 (21.3212)\n",
      "[2/25][126/782] Loss_D: 0.2302 (0.7666) Loss_G: 0.1128 (0.6535) D(x): 0.5548 D(G(z)): 0.4156 / 0.4366 Acc: 17.1875 (21.3187)\n",
      "[2/25][127/782] Loss_D: 0.4926 (0.7664) Loss_G: 0.2143 (0.6533) D(x): 0.5183 D(G(z)): 0.4752 / 0.4416 Acc: 23.4375 (21.3200)\n",
      "[2/25][128/782] Loss_D: 0.2727 (0.7661) Loss_G: 0.2249 (0.6530) D(x): 0.5435 D(G(z)): 0.4333 / 0.4004 Acc: 26.5625 (21.3231)\n",
      "[2/25][129/782] Loss_D: 0.1162 (0.7657) Loss_G: 0.1729 (0.6527) D(x): 0.5444 D(G(z)): 0.4195 / 0.4188 Acc: 35.9375 (21.3317)\n",
      "[2/25][130/782] Loss_D: 0.1836 (0.7654) Loss_G: 0.1866 (0.6525) D(x): 0.5756 D(G(z)): 0.4605 / 0.4287 Acc: 37.5000 (21.3413)\n",
      "[2/25][131/782] Loss_D: 0.2603 (0.7651) Loss_G: 0.2705 (0.6522) D(x): 0.5489 D(G(z)): 0.4125 / 0.3997 Acc: 20.3125 (21.3407)\n",
      "[2/25][132/782] Loss_D: 0.1963 (0.7647) Loss_G: 0.0715 (0.6519) D(x): 0.6080 D(G(z)): 0.5150 / 0.4085 Acc: 29.6875 (21.3456)\n",
      "[2/25][133/782] Loss_D: 0.5580 (0.7646) Loss_G: 0.3542 (0.6517) D(x): 0.4460 D(G(z)): 0.4351 / 0.3983 Acc: 23.4375 (21.3468)\n",
      "[2/25][134/782] Loss_D: 0.5012 (0.7645) Loss_G: 0.0346 (0.6514) D(x): 0.5203 D(G(z)): 0.5008 / 0.4972 Acc: 21.8750 (21.3471)\n",
      "[2/25][135/782] Loss_D: 0.3923 (0.7643) Loss_G: 0.0310 (0.6510) D(x): 0.5462 D(G(z)): 0.4770 / 0.5045 Acc: 21.8750 (21.3474)\n",
      "[2/25][136/782] Loss_D: 0.3751 (0.7640) Loss_G: 0.2066 (0.6507) D(x): 0.5574 D(G(z)): 0.4848 / 0.4098 Acc: 23.4375 (21.3487)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/25][137/782] Loss_D: 0.3892 (0.7638) Loss_G: 0.3838 (0.6506) D(x): 0.5636 D(G(z)): 0.4718 / 0.3732 Acc: 20.3125 (21.3480)\n",
      "[2/25][138/782] Loss_D: 0.4270 (0.7636) Loss_G: 0.0792 (0.6502) D(x): 0.4620 D(G(z)): 0.4247 / 0.4304 Acc: 20.3125 (21.3474)\n",
      "[2/25][139/782] Loss_D: 0.2619 (0.7633) Loss_G: 0.1511 (0.6500) D(x): 0.5429 D(G(z)): 0.4658 / 0.4276 Acc: 29.6875 (21.3523)\n",
      "[2/25][140/782] Loss_D: 0.4560 (0.7631) Loss_G: 0.2282 (0.6497) D(x): 0.5664 D(G(z)): 0.5164 / 0.4236 Acc: 20.3125 (21.3517)\n",
      "[2/25][141/782] Loss_D: 0.4101 (0.7629) Loss_G: 0.2671 (0.6495) D(x): 0.4562 D(G(z)): 0.4578 / 0.3958 Acc: 35.9375 (21.3603)\n",
      "[2/25][142/782] Loss_D: 0.3321 (0.7627) Loss_G: 0.1759 (0.6492) D(x): 0.4860 D(G(z)): 0.4455 / 0.4307 Acc: 31.2500 (21.3661)\n",
      "[2/25][143/782] Loss_D: 0.2228 (0.7624) Loss_G: 0.1978 (0.6489) D(x): 0.5219 D(G(z)): 0.4186 / 0.4180 Acc: 35.9375 (21.3746)\n",
      "[2/25][144/782] Loss_D: 0.3437 (0.7621) Loss_G: 0.0585 (0.6486) D(x): 0.5294 D(G(z)): 0.4613 / 0.4820 Acc: 26.5625 (21.3776)\n",
      "[2/25][145/782] Loss_D: 0.2937 (0.7618) Loss_G: 0.2068 (0.6483) D(x): 0.5665 D(G(z)): 0.4344 / 0.4048 Acc: 20.3125 (21.3770)\n",
      "[2/25][146/782] Loss_D: 0.1404 (0.7615) Loss_G: 0.2838 (0.6481) D(x): 0.5828 D(G(z)): 0.4487 / 0.3851 Acc: 32.8125 (21.3837)\n",
      "[2/25][147/782] Loss_D: 0.1266 (0.7611) Loss_G: 0.2318 (0.6479) D(x): 0.5424 D(G(z)): 0.3913 / 0.4177 Acc: 37.5000 (21.3931)\n",
      "[2/25][148/782] Loss_D: 0.2638 (0.7608) Loss_G: 0.3595 (0.6477) D(x): 0.5664 D(G(z)): 0.4113 / 0.3800 Acc: 18.7500 (21.3916)\n",
      "[2/25][149/782] Loss_D: 0.2250 (0.7605) Loss_G: 0.0741 (0.6474) D(x): 0.5897 D(G(z)): 0.4213 / 0.4434 Acc: 17.1875 (21.3891)\n",
      "[2/25][150/782] Loss_D: 0.1576 (0.7601) Loss_G: 0.1582 (0.6471) D(x): 0.5928 D(G(z)): 0.4570 / 0.4269 Acc: 32.8125 (21.3958)\n",
      "[2/25][151/782] Loss_D: 0.0701 (0.7597) Loss_G: 0.4810 (0.6470) D(x): 0.6025 D(G(z)): 0.4126 / 0.3371 Acc: 34.3750 (21.4033)\n",
      "[2/25][152/782] Loss_D: 0.3661 (0.7595) Loss_G: 0.2432 (0.6468) D(x): 0.4907 D(G(z)): 0.4131 / 0.3829 Acc: 23.4375 (21.4045)\n",
      "[2/25][153/782] Loss_D: 0.2249 (0.7592) Loss_G: 0.2045 (0.6465) D(x): 0.5703 D(G(z)): 0.4418 / 0.4351 Acc: 31.2500 (21.4103)\n",
      "[2/25][154/782] Loss_D: 0.6845 (0.7592) Loss_G: -0.0732 (0.6461) D(x): 0.5205 D(G(z)): 0.5689 / 0.5517 Acc: 28.1250 (21.4142)\n",
      "[2/25][155/782] Loss_D: 0.3912 (0.7589) Loss_G: -0.0391 (0.6457) D(x): 0.5630 D(G(z)): 0.5219 / 0.5199 Acc: 29.6875 (21.4190)\n",
      "[2/25][156/782] Loss_D: 0.5402 (0.7588) Loss_G: 0.0887 (0.6454) D(x): 0.5232 D(G(z)): 0.5257 / 0.4593 Acc: 20.3125 (21.4183)\n",
      "[2/25][157/782] Loss_D: 0.5072 (0.7587) Loss_G: 0.2660 (0.6451) D(x): 0.5449 D(G(z)): 0.4897 / 0.4369 Acc: 17.1875 (21.4159)\n",
      "[2/25][158/782] Loss_D: 0.2772 (0.7584) Loss_G: 0.3545 (0.6450) D(x): 0.5567 D(G(z)): 0.4457 / 0.3912 Acc: 29.6875 (21.4207)\n",
      "[2/25][159/782] Loss_D: 0.4551 (0.7582) Loss_G: 0.1327 (0.6447) D(x): 0.4994 D(G(z)): 0.4533 / 0.4415 Acc: 26.5625 (21.4237)\n",
      "[2/25][160/782] Loss_D: 0.2622 (0.7579) Loss_G: 0.0589 (0.6443) D(x): 0.5402 D(G(z)): 0.4652 / 0.4724 Acc: 34.3750 (21.4312)\n",
      "[2/25][161/782] Loss_D: 0.2846 (0.7577) Loss_G: 0.0777 (0.6440) D(x): 0.5038 D(G(z)): 0.4445 / 0.4477 Acc: 32.8125 (21.4378)\n",
      "[2/25][162/782] Loss_D: 0.4056 (0.7575) Loss_G: 0.0004 (0.6436) D(x): 0.5110 D(G(z)): 0.4867 / 0.5153 Acc: 29.6875 (21.4425)\n",
      "[2/25][163/782] Loss_D: 0.3247 (0.7572) Loss_G: 0.2018 (0.6434) D(x): 0.5833 D(G(z)): 0.4971 / 0.4101 Acc: 17.1875 (21.4401)\n",
      "[2/25][164/782] Loss_D: 0.4303 (0.7570) Loss_G: 0.0981 (0.6431) D(x): 0.4809 D(G(z)): 0.4663 / 0.4402 Acc: 26.5625 (21.4430)\n",
      "[2/25][165/782] Loss_D: 0.4283 (0.7568) Loss_G: 0.0184 (0.6427) D(x): 0.4819 D(G(z)): 0.4694 / 0.4831 Acc: 25.0000 (21.4451)\n",
      "[2/25][166/782] Loss_D: 0.4937 (0.7567) Loss_G: 0.1834 (0.6424) D(x): 0.5251 D(G(z)): 0.5011 / 0.4345 Acc: 25.0000 (21.4471)\n",
      "[2/25][167/782] Loss_D: 0.5076 (0.7565) Loss_G: 0.2506 (0.6422) D(x): 0.5194 D(G(z)): 0.4959 / 0.4366 Acc: 26.5625 (21.4501)\n",
      "[2/25][168/782] Loss_D: 0.4266 (0.7563) Loss_G: 0.1503 (0.6419) D(x): 0.4650 D(G(z)): 0.4191 / 0.4409 Acc: 25.0000 (21.4521)\n",
      "[2/25][169/782] Loss_D: 0.2542 (0.7560) Loss_G: 0.1582 (0.6416) D(x): 0.5665 D(G(z)): 0.4716 / 0.4164 Acc: 28.1250 (21.4560)\n",
      "[2/25][170/782] Loss_D: 0.4229 (0.7559) Loss_G: 0.3205 (0.6415) D(x): 0.5505 D(G(z)): 0.5051 / 0.3790 Acc: 21.8750 (21.4562)\n",
      "[2/25][171/782] Loss_D: 0.2800 (0.7556) Loss_G: 0.0698 (0.6411) D(x): 0.4966 D(G(z)): 0.4330 / 0.4426 Acc: 23.4375 (21.4574)\n",
      "[2/25][172/782] Loss_D: 0.2701 (0.7553) Loss_G: 0.1812 (0.6409) D(x): 0.5565 D(G(z)): 0.4100 / 0.4415 Acc: 23.4375 (21.4585)\n",
      "[2/25][173/782] Loss_D: 0.3263 (0.7551) Loss_G: 0.1843 (0.6406) D(x): 0.5699 D(G(z)): 0.4849 / 0.4656 Acc: 34.3750 (21.4659)\n",
      "[2/25][174/782] Loss_D: 0.4005 (0.7549) Loss_G: 0.1061 (0.6403) D(x): 0.5096 D(G(z)): 0.4481 / 0.4759 Acc: 23.4375 (21.4671)\n",
      "[2/25][175/782] Loss_D: 0.4030 (0.7547) Loss_G: 0.1618 (0.6400) D(x): 0.5258 D(G(z)): 0.4667 / 0.4751 Acc: 25.0000 (21.4691)\n",
      "[2/25][176/782] Loss_D: 0.3310 (0.7544) Loss_G: 0.1982 (0.6398) D(x): 0.6157 D(G(z)): 0.4859 / 0.3960 Acc: 9.3750 (21.4622)\n",
      "[2/25][177/782] Loss_D: 0.2986 (0.7541) Loss_G: 0.1578 (0.6395) D(x): 0.5028 D(G(z)): 0.4156 / 0.4480 Acc: 34.3750 (21.4696)\n",
      "[2/25][178/782] Loss_D: 0.4153 (0.7540) Loss_G: 0.0800 (0.6392) D(x): 0.5305 D(G(z)): 0.4451 / 0.4980 Acc: 23.4375 (21.4707)\n",
      "[2/25][179/782] Loss_D: 0.2346 (0.7537) Loss_G: 0.2620 (0.6390) D(x): 0.5630 D(G(z)): 0.4647 / 0.4120 Acc: 31.2500 (21.4763)\n",
      "[2/25][180/782] Loss_D: 0.2977 (0.7534) Loss_G: 0.2624 (0.6387) D(x): 0.5694 D(G(z)): 0.4700 / 0.4141 Acc: 23.4375 (21.4774)\n",
      "[2/25][181/782] Loss_D: 0.3279 (0.7531) Loss_G: 0.2550 (0.6385) D(x): 0.5546 D(G(z)): 0.4441 / 0.4240 Acc: 23.4375 (21.4786)\n",
      "[2/25][182/782] Loss_D: 0.3477 (0.7529) Loss_G: 0.0512 (0.6382) D(x): 0.5805 D(G(z)): 0.4968 / 0.4702 Acc: 21.8750 (21.4788)\n",
      "[2/25][183/782] Loss_D: 0.1999 (0.7526) Loss_G: 0.2267 (0.6379) D(x): 0.5580 D(G(z)): 0.4582 / 0.4031 Acc: 29.6875 (21.4835)\n",
      "[2/25][184/782] Loss_D: 0.2360 (0.7523) Loss_G: 0.3296 (0.6378) D(x): 0.5973 D(G(z)): 0.5289 / 0.3646 Acc: 37.5000 (21.4926)\n",
      "[2/25][185/782] Loss_D: 0.2342 (0.7520) Loss_G: 0.1933 (0.6375) D(x): 0.5125 D(G(z)): 0.4114 / 0.4062 Acc: 28.1250 (21.4964)\n",
      "[2/25][186/782] Loss_D: 0.2369 (0.7517) Loss_G: 0.2850 (0.6373) D(x): 0.5791 D(G(z)): 0.4622 / 0.4261 Acc: 32.8125 (21.5029)\n",
      "[2/25][187/782] Loss_D: 0.5931 (0.7516) Loss_G: 0.1873 (0.6371) D(x): 0.5135 D(G(z)): 0.5189 / 0.4410 Acc: 25.0000 (21.5049)\n",
      "[2/25][188/782] Loss_D: 0.4155 (0.7514) Loss_G: 0.3713 (0.6369) D(x): 0.5323 D(G(z)): 0.4722 / 0.3547 Acc: 23.4375 (21.5060)\n",
      "[2/25][189/782] Loss_D: 0.2605 (0.7512) Loss_G: -0.0048 (0.6365) D(x): 0.5335 D(G(z)): 0.4250 / 0.4745 Acc: 26.5625 (21.5089)\n",
      "[2/25][190/782] Loss_D: 0.3815 (0.7509) Loss_G: 0.1240 (0.6362) D(x): 0.5683 D(G(z)): 0.4779 / 0.4854 Acc: 31.2500 (21.5144)\n",
      "[2/25][191/782] Loss_D: 0.5742 (0.7508) Loss_G: 0.0914 (0.6359) D(x): 0.5260 D(G(z)): 0.4869 / 0.5029 Acc: 20.3125 (21.5137)\n",
      "[2/25][192/782] Loss_D: 0.4373 (0.7507) Loss_G: 0.3403 (0.6358) D(x): 0.5577 D(G(z)): 0.5203 / 0.3901 Acc: 29.6875 (21.5184)\n",
      "[2/25][193/782] Loss_D: 0.3652 (0.7504) Loss_G: 0.1453 (0.6355) D(x): 0.5005 D(G(z)): 0.4587 / 0.4494 Acc: 32.8125 (21.5248)\n",
      "[2/25][194/782] Loss_D: 0.3478 (0.7502) Loss_G: 0.3794 (0.6353) D(x): 0.5138 D(G(z)): 0.4285 / 0.3554 Acc: 17.1875 (21.5223)\n",
      "[2/25][195/782] Loss_D: 0.4967 (0.7501) Loss_G: 0.1561 (0.6351) D(x): 0.5128 D(G(z)): 0.4184 / 0.4662 Acc: 18.7500 (21.5208)\n",
      "[2/25][196/782] Loss_D: 0.3710 (0.7499) Loss_G: 0.1920 (0.6348) D(x): 0.5754 D(G(z)): 0.4469 / 0.4478 Acc: 18.7500 (21.5192)\n",
      "[2/25][197/782] Loss_D: 0.2917 (0.7496) Loss_G: 0.3932 (0.6347) D(x): 0.5031 D(G(z)): 0.4386 / 0.3402 Acc: 34.3750 (21.5265)\n",
      "[2/25][198/782] Loss_D: 0.3428 (0.7494) Loss_G: 0.6235 (0.6347) D(x): 0.4983 D(G(z)): 0.3841 / 0.2956 Acc: 25.0000 (21.5285)\n",
      "[2/25][199/782] Loss_D: 0.2117 (0.7491) Loss_G: 0.4956 (0.6346) D(x): 0.5065 D(G(z)): 0.3579 / 0.3362 Acc: 31.2500 (21.5340)\n",
      "[2/25][200/782] Loss_D: 0.0870 (0.7487) Loss_G: 0.3932 (0.6345) D(x): 0.5905 D(G(z)): 0.3854 / 0.3476 Acc: 26.5625 (21.5368)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[2/25][201/782] Loss_D: 0.2180 (0.7484) Loss_G: 0.5070 (0.6344) D(x): 0.5717 D(G(z)): 0.4287 / 0.3320 Acc: 31.2500 (21.5423)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/25][202/782] Loss_D: 0.0889 (0.7480) Loss_G: 0.4527 (0.6343) D(x): 0.6049 D(G(z)): 0.3578 / 0.3402 Acc: 21.8750 (21.5425)\n",
      "[2/25][203/782] Loss_D: 0.1344 (0.7477) Loss_G: 0.4763 (0.6342) D(x): 0.6095 D(G(z)): 0.3686 / 0.3541 Acc: 21.8750 (21.5427)\n",
      "[2/25][204/782] Loss_D: 0.4660 (0.7475) Loss_G: 0.3872 (0.6341) D(x): 0.5830 D(G(z)): 0.4879 / 0.3808 Acc: 26.5625 (21.5455)\n",
      "[2/25][205/782] Loss_D: 0.2514 (0.7472) Loss_G: 0.3403 (0.6339) D(x): 0.6364 D(G(z)): 0.4963 / 0.3480 Acc: 20.3125 (21.5448)\n",
      "[2/25][206/782] Loss_D: 0.4113 (0.7470) Loss_G: 0.1569 (0.6336) D(x): 0.5431 D(G(z)): 0.4837 / 0.4125 Acc: 23.4375 (21.5459)\n",
      "[2/25][207/782] Loss_D: 0.3725 (0.7468) Loss_G: -0.0009 (0.6333) D(x): 0.4911 D(G(z)): 0.4347 / 0.5303 Acc: 28.1250 (21.5496)\n",
      "[2/25][208/782] Loss_D: 0.6573 (0.7468) Loss_G: -0.0144 (0.6329) D(x): 0.5767 D(G(z)): 0.5787 / 0.5328 Acc: 18.7500 (21.5480)\n",
      "[2/25][209/782] Loss_D: 0.2495 (0.7465) Loss_G: 0.5858 (0.6329) D(x): 0.5875 D(G(z)): 0.4784 / 0.3173 Acc: 35.9375 (21.5562)\n",
      "[2/25][210/782] Loss_D: 0.5656 (0.7464) Loss_G: 0.2831 (0.6327) D(x): 0.4296 D(G(z)): 0.4054 / 0.3963 Acc: 23.4375 (21.5572)\n",
      "[2/25][211/782] Loss_D: 0.4255 (0.7462) Loss_G: 0.3244 (0.6325) D(x): 0.5166 D(G(z)): 0.4310 / 0.3771 Acc: 20.3125 (21.5565)\n",
      "[2/25][212/782] Loss_D: 0.3524 (0.7460) Loss_G: 0.3369 (0.6323) D(x): 0.5310 D(G(z)): 0.4252 / 0.3970 Acc: 29.6875 (21.5611)\n",
      "[2/25][213/782] Loss_D: 0.1987 (0.7457) Loss_G: 0.2184 (0.6321) D(x): 0.5922 D(G(z)): 0.4941 / 0.4154 Acc: 34.3750 (21.5683)\n",
      "[2/25][214/782] Loss_D: 0.4233 (0.7455) Loss_G: 0.2841 (0.6319) D(x): 0.5272 D(G(z)): 0.4784 / 0.4203 Acc: 31.2500 (21.5737)\n",
      "[2/25][215/782] Loss_D: 0.3962 (0.7453) Loss_G: 0.2246 (0.6317) D(x): 0.5377 D(G(z)): 0.4863 / 0.4121 Acc: 29.6875 (21.5783)\n",
      "[2/25][216/782] Loss_D: 0.2743 (0.7450) Loss_G: 0.2569 (0.6315) D(x): 0.4957 D(G(z)): 0.3992 / 0.3735 Acc: 32.8125 (21.5846)\n",
      "[2/25][217/782] Loss_D: 0.0696 (0.7447) Loss_G: 0.4197 (0.6313) D(x): 0.6402 D(G(z)): 0.4457 / 0.3682 Acc: 37.5000 (21.5935)\n",
      "[2/25][218/782] Loss_D: 0.3106 (0.7444) Loss_G: 0.1049 (0.6311) D(x): 0.5305 D(G(z)): 0.4398 / 0.4381 Acc: 25.0000 (21.5955)\n",
      "[2/25][219/782] Loss_D: 0.1718 (0.7441) Loss_G: -0.0215 (0.6307) D(x): 0.5261 D(G(z)): 0.4245 / 0.4837 Acc: 32.8125 (21.6017)\n",
      "[2/25][220/782] Loss_D: 0.1353 (0.7438) Loss_G: 0.1975 (0.6304) D(x): 0.5954 D(G(z)): 0.4492 / 0.4501 Acc: 35.9375 (21.6098)\n",
      "[2/25][221/782] Loss_D: 0.3909 (0.7436) Loss_G: 0.1981 (0.6302) D(x): 0.5325 D(G(z)): 0.5134 / 0.4393 Acc: 34.3750 (21.6169)\n",
      "[2/25][222/782] Loss_D: 0.4545 (0.7434) Loss_G: 0.0669 (0.6299) D(x): 0.5254 D(G(z)): 0.5166 / 0.4567 Acc: 23.4375 (21.6179)\n",
      "[2/25][223/782] Loss_D: 0.1727 (0.7431) Loss_G: 0.2698 (0.6297) D(x): 0.5605 D(G(z)): 0.4456 / 0.3728 Acc: 31.2500 (21.6233)\n",
      "[2/25][224/782] Loss_D: 0.3772 (0.7429) Loss_G: 0.1466 (0.6294) D(x): 0.4644 D(G(z)): 0.4133 / 0.4334 Acc: 29.6875 (21.6278)\n",
      "[2/25][225/782] Loss_D: 0.1899 (0.7426) Loss_G: 0.0899 (0.6291) D(x): 0.5913 D(G(z)): 0.5068 / 0.4601 Acc: 42.1875 (21.6393)\n",
      "[2/25][226/782] Loss_D: 0.4944 (0.7424) Loss_G: 0.2120 (0.6289) D(x): 0.5043 D(G(z)): 0.4272 / 0.4490 Acc: 20.3125 (21.6386)\n",
      "[2/25][227/782] Loss_D: 0.3088 (0.7422) Loss_G: 0.1324 (0.6286) D(x): 0.5285 D(G(z)): 0.4797 / 0.4402 Acc: 34.3750 (21.6457)\n",
      "[2/25][228/782] Loss_D: 0.2833 (0.7419) Loss_G: 0.2606 (0.6284) D(x): 0.5601 D(G(z)): 0.4635 / 0.3906 Acc: 23.4375 (21.6467)\n",
      "[2/25][229/782] Loss_D: 0.4210 (0.7417) Loss_G: 0.2958 (0.6282) D(x): 0.5530 D(G(z)): 0.4878 / 0.4007 Acc: 23.4375 (21.6477)\n",
      "[2/25][230/782] Loss_D: 0.2673 (0.7415) Loss_G: 0.1935 (0.6280) D(x): 0.5139 D(G(z)): 0.4016 / 0.4375 Acc: 29.6875 (21.6522)\n",
      "[2/25][231/782] Loss_D: 0.3762 (0.7413) Loss_G: 0.0369 (0.6276) D(x): 0.5433 D(G(z)): 0.4917 / 0.4783 Acc: 26.5625 (21.6549)\n",
      "[2/25][232/782] Loss_D: 0.1965 (0.7410) Loss_G: 0.1147 (0.6274) D(x): 0.5781 D(G(z)): 0.4511 / 0.4739 Acc: 31.2500 (21.6602)\n",
      "[2/25][233/782] Loss_D: 0.2692 (0.7407) Loss_G: 0.1456 (0.6271) D(x): 0.5855 D(G(z)): 0.4657 / 0.4198 Acc: 18.7500 (21.6586)\n",
      "[2/25][234/782] Loss_D: 0.2931 (0.7405) Loss_G: 0.0965 (0.6268) D(x): 0.5247 D(G(z)): 0.4221 / 0.4407 Acc: 20.3125 (21.6579)\n",
      "[2/25][235/782] Loss_D: 0.4303 (0.7403) Loss_G: 0.2450 (0.6266) D(x): 0.6061 D(G(z)): 0.5263 / 0.4302 Acc: 23.4375 (21.6589)\n",
      "[2/25][236/782] Loss_D: 0.4217 (0.7401) Loss_G: 0.3459 (0.6264) D(x): 0.5262 D(G(z)): 0.5038 / 0.3581 Acc: 23.4375 (21.6598)\n",
      "[2/25][237/782] Loss_D: 0.7142 (0.7401) Loss_G: 0.1936 (0.6262) D(x): 0.3726 D(G(z)): 0.3736 / 0.4403 Acc: 18.7500 (21.6582)\n",
      "[2/25][238/782] Loss_D: 0.5814 (0.7400) Loss_G: -0.0691 (0.6258) D(x): 0.4352 D(G(z)): 0.5149 / 0.5548 Acc: 39.0625 (21.6679)\n",
      "[2/25][239/782] Loss_D: 0.4190 (0.7398) Loss_G: -0.0635 (0.6254) D(x): 0.5590 D(G(z)): 0.5370 / 0.5120 Acc: 21.8750 (21.6680)\n",
      "[2/25][240/782] Loss_D: 0.4782 (0.7397) Loss_G: 0.4927 (0.6253) D(x): 0.6364 D(G(z)): 0.5695 / 0.3300 Acc: 28.1250 (21.6716)\n",
      "[2/25][241/782] Loss_D: 0.4928 (0.7396) Loss_G: 0.3365 (0.6252) D(x): 0.4591 D(G(z)): 0.4221 / 0.3818 Acc: 28.1250 (21.6751)\n",
      "[2/25][242/782] Loss_D: 0.1630 (0.7392) Loss_G: 0.2986 (0.6250) D(x): 0.5043 D(G(z)): 0.4016 / 0.3591 Acc: 32.8125 (21.6813)\n",
      "[2/25][243/782] Loss_D: 0.3391 (0.7390) Loss_G: 0.0525 (0.6247) D(x): 0.4863 D(G(z)): 0.4532 / 0.4582 Acc: 32.8125 (21.6875)\n",
      "[2/25][244/782] Loss_D: 0.5431 (0.7389) Loss_G: 0.2826 (0.6245) D(x): 0.5359 D(G(z)): 0.4802 / 0.4310 Acc: 23.4375 (21.6884)\n",
      "[2/25][245/782] Loss_D: 0.2218 (0.7386) Loss_G: 0.3530 (0.6244) D(x): 0.6144 D(G(z)): 0.5094 / 0.3742 Acc: 32.8125 (21.6946)\n",
      "[2/25][246/782] Loss_D: 0.5407 (0.7385) Loss_G: 0.2224 (0.6241) D(x): 0.4404 D(G(z)): 0.4122 / 0.4173 Acc: 20.3125 (21.6938)\n",
      "[2/25][247/782] Loss_D: 0.4405 (0.7383) Loss_G: 0.1526 (0.6239) D(x): 0.4872 D(G(z)): 0.4409 / 0.4709 Acc: 29.6875 (21.6982)\n",
      "[2/25][248/782] Loss_D: 0.1898 (0.7380) Loss_G: 0.0373 (0.6235) D(x): 0.5588 D(G(z)): 0.4453 / 0.4740 Acc: 29.6875 (21.7026)\n",
      "[2/25][249/782] Loss_D: 0.2216 (0.7378) Loss_G: 0.0265 (0.6232) D(x): 0.5716 D(G(z)): 0.4692 / 0.4773 Acc: 28.1250 (21.7062)\n",
      "[2/25][250/782] Loss_D: 0.1700 (0.7374) Loss_G: 0.1407 (0.6229) D(x): 0.5771 D(G(z)): 0.4655 / 0.4452 Acc: 37.5000 (21.7149)\n",
      "[2/25][251/782] Loss_D: 0.3191 (0.7372) Loss_G: 0.2521 (0.6227) D(x): 0.5457 D(G(z)): 0.4368 / 0.4368 Acc: 29.6875 (21.7193)\n",
      "[2/25][252/782] Loss_D: 0.4949 (0.7371) Loss_G: 0.1169 (0.6225) D(x): 0.5019 D(G(z)): 0.4373 / 0.4885 Acc: 20.3125 (21.7185)\n",
      "[2/25][253/782] Loss_D: 0.4365 (0.7369) Loss_G: 0.0699 (0.6222) D(x): 0.5081 D(G(z)): 0.5091 / 0.4868 Acc: 34.3750 (21.7255)\n",
      "[2/25][254/782] Loss_D: 0.5679 (0.7368) Loss_G: 0.0931 (0.6219) D(x): 0.5139 D(G(z)): 0.5111 / 0.4746 Acc: 21.8750 (21.7255)\n",
      "[2/25][255/782] Loss_D: 0.4247 (0.7367) Loss_G: 0.2537 (0.6217) D(x): 0.5214 D(G(z)): 0.4933 / 0.4049 Acc: 25.0000 (21.7273)\n",
      "[2/25][256/782] Loss_D: 0.5284 (0.7365) Loss_G: 0.2896 (0.6215) D(x): 0.5041 D(G(z)): 0.4930 / 0.3986 Acc: 15.6250 (21.7240)\n",
      "[2/25][257/782] Loss_D: 0.2967 (0.7363) Loss_G: -0.0570 (0.6211) D(x): 0.4769 D(G(z)): 0.4153 / 0.4993 Acc: 32.8125 (21.7301)\n",
      "[2/25][258/782] Loss_D: 0.5092 (0.7362) Loss_G: 0.1395 (0.6209) D(x): 0.5163 D(G(z)): 0.4913 / 0.4691 Acc: 23.4375 (21.7310)\n",
      "[2/25][259/782] Loss_D: 0.3397 (0.7360) Loss_G: 0.0525 (0.6205) D(x): 0.5318 D(G(z)): 0.4955 / 0.4719 Acc: 23.4375 (21.7319)\n",
      "[2/25][260/782] Loss_D: 0.4960 (0.7358) Loss_G: 0.1195 (0.6203) D(x): 0.4860 D(G(z)): 0.5074 / 0.4243 Acc: 25.0000 (21.7337)\n",
      "[2/25][261/782] Loss_D: 0.3671 (0.7356) Loss_G: 0.1707 (0.6200) D(x): 0.5536 D(G(z)): 0.4759 / 0.4485 Acc: 25.0000 (21.7355)\n",
      "[2/25][262/782] Loss_D: 0.3851 (0.7354) Loss_G: 0.2550 (0.6198) D(x): 0.5637 D(G(z)): 0.4811 / 0.4201 Acc: 21.8750 (21.7356)\n",
      "[2/25][263/782] Loss_D: 0.1927 (0.7351) Loss_G: 0.1304 (0.6196) D(x): 0.4741 D(G(z)): 0.3912 / 0.4082 Acc: 32.8125 (21.7417)\n",
      "[2/25][264/782] Loss_D: 0.3111 (0.7349) Loss_G: 0.2545 (0.6194) D(x): 0.5611 D(G(z)): 0.4543 / 0.4127 Acc: 18.7500 (21.7400)\n",
      "[2/25][265/782] Loss_D: 0.2720 (0.7346) Loss_G: 0.1401 (0.6191) D(x): 0.5504 D(G(z)): 0.4783 / 0.4296 Acc: 29.6875 (21.7444)\n",
      "[2/25][266/782] Loss_D: 0.2109 (0.7344) Loss_G: 0.0858 (0.6188) D(x): 0.5686 D(G(z)): 0.4624 / 0.4503 Acc: 26.5625 (21.7470)\n",
      "[2/25][267/782] Loss_D: 0.1550 (0.7340) Loss_G: 0.1880 (0.6186) D(x): 0.6184 D(G(z)): 0.4567 / 0.4281 Acc: 23.4375 (21.7479)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/25][268/782] Loss_D: 0.2242 (0.7338) Loss_G: 0.1961 (0.6183) D(x): 0.5670 D(G(z)): 0.4343 / 0.3940 Acc: 18.7500 (21.7463)\n",
      "[2/25][269/782] Loss_D: 0.2313 (0.7335) Loss_G: 0.2101 (0.6181) D(x): 0.5592 D(G(z)): 0.4544 / 0.4191 Acc: 26.5625 (21.7489)\n",
      "[2/25][270/782] Loss_D: 0.2359 (0.7332) Loss_G: 0.2706 (0.6179) D(x): 0.5945 D(G(z)): 0.5004 / 0.3723 Acc: 29.6875 (21.7532)\n",
      "[2/25][271/782] Loss_D: 0.2383 (0.7330) Loss_G: 0.3582 (0.6178) D(x): 0.5550 D(G(z)): 0.4002 / 0.3871 Acc: 25.0000 (21.7550)\n",
      "[2/25][272/782] Loss_D: 0.3763 (0.7328) Loss_G: 0.1793 (0.6175) D(x): 0.5260 D(G(z)): 0.3894 / 0.4690 Acc: 18.7500 (21.7534)\n",
      "[2/25][273/782] Loss_D: 0.1700 (0.7325) Loss_G: 0.3312 (0.6174) D(x): 0.5946 D(G(z)): 0.5134 / 0.3674 Acc: 40.6250 (21.7636)\n",
      "[2/25][274/782] Loss_D: 0.2264 (0.7322) Loss_G: 0.4156 (0.6173) D(x): 0.5923 D(G(z)): 0.5320 / 0.3284 Acc: 34.3750 (21.7705)\n",
      "[2/25][275/782] Loss_D: 0.5199 (0.7321) Loss_G: 0.4054 (0.6172) D(x): 0.4414 D(G(z)): 0.3980 / 0.3546 Acc: 23.4375 (21.7714)\n",
      "[2/25][276/782] Loss_D: 0.5524 (0.7320) Loss_G: 0.1711 (0.6169) D(x): 0.4885 D(G(z)): 0.4874 / 0.4609 Acc: 21.8750 (21.7715)\n",
      "[2/25][277/782] Loss_D: 0.3640 (0.7318) Loss_G: -0.0095 (0.6166) D(x): 0.5208 D(G(z)): 0.4274 / 0.5156 Acc: 25.0000 (21.7732)\n",
      "[2/25][278/782] Loss_D: 0.4264 (0.7316) Loss_G: 0.0941 (0.6163) D(x): 0.5961 D(G(z)): 0.5964 / 0.4382 Acc: 32.8125 (21.7792)\n",
      "[2/25][279/782] Loss_D: 0.3918 (0.7314) Loss_G: 0.1027 (0.6160) D(x): 0.5218 D(G(z)): 0.4913 / 0.4500 Acc: 29.6875 (21.7835)\n",
      "[2/25][280/782] Loss_D: 0.5342 (0.7313) Loss_G: 0.2952 (0.6158) D(x): 0.4664 D(G(z)): 0.4760 / 0.3967 Acc: 29.6875 (21.7878)\n",
      "[2/25][281/782] Loss_D: 0.5668 (0.7312) Loss_G: 0.1296 (0.6156) D(x): 0.4282 D(G(z)): 0.4496 / 0.4717 Acc: 26.5625 (21.7904)\n",
      "[2/25][282/782] Loss_D: 0.4768 (0.7311) Loss_G: 0.1469 (0.6153) D(x): 0.4843 D(G(z)): 0.4912 / 0.4592 Acc: 31.2500 (21.7955)\n",
      "[2/25][283/782] Loss_D: 0.2670 (0.7308) Loss_G: -0.0084 (0.6150) D(x): 0.5276 D(G(z)): 0.4795 / 0.4931 Acc: 31.2500 (21.8006)\n",
      "[2/25][284/782] Loss_D: 0.2708 (0.7306) Loss_G: 0.0165 (0.6147) D(x): 0.5495 D(G(z)): 0.4517 / 0.4982 Acc: 31.2500 (21.8057)\n",
      "[2/25][285/782] Loss_D: 0.6604 (0.7305) Loss_G: 0.0618 (0.6144) D(x): 0.4852 D(G(z)): 0.5179 / 0.4910 Acc: 25.0000 (21.8074)\n",
      "[2/25][286/782] Loss_D: 0.3049 (0.7303) Loss_G: 0.4414 (0.6143) D(x): 0.5767 D(G(z)): 0.5215 / 0.3612 Acc: 39.0625 (21.8168)\n",
      "[2/25][287/782] Loss_D: 0.4608 (0.7302) Loss_G: 0.1017 (0.6140) D(x): 0.4169 D(G(z)): 0.4090 / 0.4580 Acc: 29.6875 (21.8210)\n",
      "[2/25][288/782] Loss_D: 0.5311 (0.7301) Loss_G: 0.2838 (0.6138) D(x): 0.5406 D(G(z)): 0.4986 / 0.4225 Acc: 21.8750 (21.8210)\n",
      "[2/25][289/782] Loss_D: 0.3929 (0.7299) Loss_G: 0.1400 (0.6136) D(x): 0.5707 D(G(z)): 0.4932 / 0.4462 Acc: 18.7500 (21.8194)\n",
      "[2/25][290/782] Loss_D: 0.0893 (0.7295) Loss_G: 0.1942 (0.6133) D(x): 0.5528 D(G(z)): 0.4301 / 0.3928 Acc: 37.5000 (21.8278)\n",
      "[2/25][291/782] Loss_D: 0.5042 (0.7294) Loss_G: 0.3558 (0.6132) D(x): 0.5083 D(G(z)): 0.4984 / 0.3771 Acc: 23.4375 (21.8287)\n",
      "[2/25][292/782] Loss_D: 0.4651 (0.7293) Loss_G: 0.2158 (0.6130) D(x): 0.4493 D(G(z)): 0.4175 / 0.4408 Acc: 32.8125 (21.8346)\n",
      "[2/25][293/782] Loss_D: 0.2212 (0.7290) Loss_G: 0.0895 (0.6127) D(x): 0.5970 D(G(z)): 0.4821 / 0.4478 Acc: 26.5625 (21.8372)\n",
      "[2/25][294/782] Loss_D: 0.3901 (0.7288) Loss_G: 0.0408 (0.6124) D(x): 0.4859 D(G(z)): 0.4804 / 0.4741 Acc: 34.3750 (21.8439)\n",
      "[2/25][295/782] Loss_D: 0.5266 (0.7287) Loss_G: 0.0195 (0.6121) D(x): 0.4919 D(G(z)): 0.4705 / 0.5178 Acc: 25.0000 (21.8456)\n",
      "[2/25][296/782] Loss_D: 0.5204 (0.7286) Loss_G: -0.0399 (0.6117) D(x): 0.4870 D(G(z)): 0.5031 / 0.5450 Acc: 31.2500 (21.8507)\n",
      "[2/25][297/782] Loss_D: 0.4264 (0.7284) Loss_G: 0.0693 (0.6114) D(x): 0.5375 D(G(z)): 0.5240 / 0.4560 Acc: 25.0000 (21.8523)\n",
      "[2/25][298/782] Loss_D: 0.2419 (0.7282) Loss_G: 0.0507 (0.6111) D(x): 0.5845 D(G(z)): 0.4638 / 0.4864 Acc: 28.1250 (21.8557)\n",
      "[2/25][299/782] Loss_D: 0.2618 (0.7279) Loss_G: 0.2006 (0.6109) D(x): 0.5508 D(G(z)): 0.4422 / 0.4324 Acc: 34.3750 (21.8624)\n",
      "[2/25][300/782] Loss_D: 0.3512 (0.7277) Loss_G: 0.2250 (0.6107) D(x): 0.5331 D(G(z)): 0.4325 / 0.4175 Acc: 20.3125 (21.8616)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[2/25][301/782] Loss_D: 0.3370 (0.7275) Loss_G: 0.2222 (0.6105) D(x): 0.5640 D(G(z)): 0.4290 / 0.4438 Acc: 18.7500 (21.8599)\n",
      "[2/25][302/782] Loss_D: 0.5680 (0.7274) Loss_G: 0.3404 (0.6104) D(x): 0.6146 D(G(z)): 0.5324 / 0.3986 Acc: 10.9375 (21.8541)\n",
      "[2/25][303/782] Loss_D: 0.4604 (0.7273) Loss_G: 0.4006 (0.6102) D(x): 0.5169 D(G(z)): 0.4642 / 0.3916 Acc: 26.5625 (21.8566)\n",
      "[2/25][304/782] Loss_D: 0.1916 (0.7270) Loss_G: 0.3937 (0.6101) D(x): 0.4815 D(G(z)): 0.3361 / 0.3552 Acc: 29.6875 (21.8608)\n",
      "[2/25][305/782] Loss_D: 0.3076 (0.7268) Loss_G: 0.1296 (0.6099) D(x): 0.5127 D(G(z)): 0.4278 / 0.4308 Acc: 23.4375 (21.8616)\n",
      "[2/25][306/782] Loss_D: 0.3155 (0.7265) Loss_G: 0.0623 (0.6096) D(x): 0.5731 D(G(z)): 0.4681 / 0.4578 Acc: 20.3125 (21.8608)\n",
      "[2/25][307/782] Loss_D: 0.2758 (0.7263) Loss_G: 0.3958 (0.6095) D(x): 0.6046 D(G(z)): 0.4859 / 0.3698 Acc: 29.6875 (21.8650)\n",
      "[2/25][308/782] Loss_D: 0.3071 (0.7261) Loss_G: 0.1315 (0.6092) D(x): 0.4990 D(G(z)): 0.4211 / 0.4251 Acc: 21.8750 (21.8650)\n",
      "[2/25][309/782] Loss_D: 0.2462 (0.7258) Loss_G: 0.1463 (0.6090) D(x): 0.5147 D(G(z)): 0.4211 / 0.4265 Acc: 29.6875 (21.8692)\n",
      "[2/25][310/782] Loss_D: 0.3166 (0.7256) Loss_G: -0.0509 (0.6086) D(x): 0.5250 D(G(z)): 0.4548 / 0.4951 Acc: 23.4375 (21.8700)\n",
      "[2/25][311/782] Loss_D: 0.3684 (0.7254) Loss_G: 0.2440 (0.6084) D(x): 0.5657 D(G(z)): 0.4877 / 0.4261 Acc: 25.0000 (21.8717)\n",
      "[2/25][312/782] Loss_D: 0.5124 (0.7253) Loss_G: 0.1385 (0.6082) D(x): 0.5252 D(G(z)): 0.4897 / 0.4145 Acc: 14.0625 (21.8675)\n",
      "[2/25][313/782] Loss_D: 0.1035 (0.7250) Loss_G: 0.1579 (0.6079) D(x): 0.5383 D(G(z)): 0.4058 / 0.4084 Acc: 31.2500 (21.8725)\n",
      "[2/25][314/782] Loss_D: 0.1920 (0.7247) Loss_G: 0.1486 (0.6077) D(x): 0.5902 D(G(z)): 0.4887 / 0.4350 Acc: 35.9375 (21.8800)\n",
      "[2/25][315/782] Loss_D: 0.2545 (0.7244) Loss_G: 0.2557 (0.6075) D(x): 0.5350 D(G(z)): 0.4517 / 0.3946 Acc: 29.6875 (21.8841)\n",
      "[2/25][316/782] Loss_D: 0.1772 (0.7241) Loss_G: 0.2096 (0.6073) D(x): 0.5770 D(G(z)): 0.3997 / 0.4133 Acc: 20.3125 (21.8833)\n",
      "[2/25][317/782] Loss_D: 0.2601 (0.7239) Loss_G: 0.3932 (0.6072) D(x): 0.5548 D(G(z)): 0.4544 / 0.3529 Acc: 25.0000 (21.8850)\n",
      "[2/25][318/782] Loss_D: 0.3830 (0.7237) Loss_G: 0.1969 (0.6069) D(x): 0.4818 D(G(z)): 0.3761 / 0.4378 Acc: 21.8750 (21.8850)\n",
      "[2/25][319/782] Loss_D: 0.2004 (0.7234) Loss_G: 0.0010 (0.6066) D(x): 0.6194 D(G(z)): 0.4998 / 0.4951 Acc: 29.6875 (21.8891)\n",
      "[2/25][320/782] Loss_D: 0.1501 (0.7231) Loss_G: 0.1989 (0.6064) D(x): 0.6081 D(G(z)): 0.4558 / 0.4188 Acc: 26.5625 (21.8916)\n",
      "[2/25][321/782] Loss_D: 0.2028 (0.7229) Loss_G: 0.2209 (0.6062) D(x): 0.4891 D(G(z)): 0.4087 / 0.4080 Acc: 37.5000 (21.8999)\n",
      "[2/25][322/782] Loss_D: 0.5057 (0.7227) Loss_G: 0.2086 (0.6060) D(x): 0.5396 D(G(z)): 0.5209 / 0.4272 Acc: 21.8750 (21.8998)\n",
      "[2/25][323/782] Loss_D: 0.4006 (0.7226) Loss_G: 0.2750 (0.6058) D(x): 0.5522 D(G(z)): 0.5240 / 0.3905 Acc: 34.3750 (21.9064)\n",
      "[2/25][324/782] Loss_D: 0.3576 (0.7224) Loss_G: 0.1747 (0.6056) D(x): 0.5594 D(G(z)): 0.4781 / 0.4363 Acc: 21.8750 (21.9064)\n",
      "[2/25][325/782] Loss_D: 0.4576 (0.7222) Loss_G: 0.3136 (0.6054) D(x): 0.5723 D(G(z)): 0.5066 / 0.4026 Acc: 25.0000 (21.9081)\n",
      "[2/25][326/782] Loss_D: 0.5411 (0.7221) Loss_G: 0.2437 (0.6052) D(x): 0.5087 D(G(z)): 0.4593 / 0.4341 Acc: 18.7500 (21.9064)\n",
      "[2/25][327/782] Loss_D: 0.4119 (0.7220) Loss_G: 0.4199 (0.6051) D(x): 0.5463 D(G(z)): 0.4848 / 0.3535 Acc: 25.0000 (21.9080)\n",
      "[2/25][328/782] Loss_D: 0.2457 (0.7217) Loss_G: 0.4649 (0.6051) D(x): 0.5335 D(G(z)): 0.3602 / 0.3837 Acc: 26.5625 (21.9105)\n",
      "[2/25][329/782] Loss_D: 0.2209 (0.7215) Loss_G: 0.0301 (0.6048) D(x): 0.5354 D(G(z)): 0.4128 / 0.4677 Acc: 25.0000 (21.9121)\n",
      "[2/25][330/782] Loss_D: 0.4462 (0.7213) Loss_G: 0.1179 (0.6045) D(x): 0.5048 D(G(z)): 0.4992 / 0.4746 Acc: 39.0625 (21.9212)\n",
      "[2/25][331/782] Loss_D: 0.4249 (0.7212) Loss_G: 0.3433 (0.6044) D(x): 0.5888 D(G(z)): 0.5315 / 0.3875 Acc: 29.6875 (21.9253)\n",
      "[2/25][332/782] Loss_D: 0.4367 (0.7210) Loss_G: 0.2581 (0.6042) D(x): 0.5091 D(G(z)): 0.4225 / 0.4292 Acc: 18.7500 (21.9236)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/25][333/782] Loss_D: 0.4750 (0.7209) Loss_G: 0.3283 (0.6040) D(x): 0.4797 D(G(z)): 0.4541 / 0.3836 Acc: 29.6875 (21.9277)\n",
      "[2/25][334/782] Loss_D: 0.2220 (0.7206) Loss_G: 0.0043 (0.6037) D(x): 0.4990 D(G(z)): 0.3687 / 0.5140 Acc: 31.2500 (21.9326)\n",
      "[2/25][335/782] Loss_D: 0.6421 (0.7206) Loss_G: 0.1432 (0.6035) D(x): 0.5823 D(G(z)): 0.5477 / 0.4614 Acc: 10.9375 (21.9268)\n",
      "[2/25][336/782] Loss_D: 0.3457 (0.7204) Loss_G: 0.2949 (0.6033) D(x): 0.5867 D(G(z)): 0.5001 / 0.3957 Acc: 25.0000 (21.9284)\n",
      "[2/25][337/782] Loss_D: 0.2224 (0.7201) Loss_G: 0.3317 (0.6032) D(x): 0.5211 D(G(z)): 0.3759 / 0.3872 Acc: 31.2500 (21.9333)\n",
      "[2/25][338/782] Loss_D: 0.2720 (0.7199) Loss_G: 0.2272 (0.6030) D(x): 0.5407 D(G(z)): 0.4744 / 0.4174 Acc: 32.8125 (21.9390)\n",
      "[2/25][339/782] Loss_D: 0.3013 (0.7197) Loss_G: 0.3132 (0.6028) D(x): 0.5585 D(G(z)): 0.4516 / 0.3924 Acc: 31.2500 (21.9439)\n",
      "[2/25][340/782] Loss_D: 0.3626 (0.7195) Loss_G: 0.1678 (0.6026) D(x): 0.4938 D(G(z)): 0.4040 / 0.4448 Acc: 21.8750 (21.9439)\n",
      "[2/25][341/782] Loss_D: -0.0120 (0.7191) Loss_G: 0.1152 (0.6023) D(x): 0.6244 D(G(z)): 0.3697 / 0.4195 Acc: 25.0000 (21.9455)\n",
      "[2/25][342/782] Loss_D: 0.1169 (0.7188) Loss_G: 0.3728 (0.6022) D(x): 0.6617 D(G(z)): 0.4353 / 0.3785 Acc: 21.8750 (21.9455)\n",
      "[2/25][343/782] Loss_D: 0.3276 (0.7186) Loss_G: 0.1594 (0.6020) D(x): 0.5261 D(G(z)): 0.3785 / 0.4613 Acc: 20.3125 (21.9446)\n",
      "[2/25][344/782] Loss_D: 0.2244 (0.7183) Loss_G: 0.2789 (0.6018) D(x): 0.6009 D(G(z)): 0.4391 / 0.3915 Acc: 20.3125 (21.9438)\n",
      "[2/25][345/782] Loss_D: 0.2628 (0.7181) Loss_G: 0.4077 (0.6017) D(x): 0.5640 D(G(z)): 0.4428 / 0.3593 Acc: 31.2500 (21.9486)\n",
      "[2/25][346/782] Loss_D: 0.2955 (0.7179) Loss_G: 0.2927 (0.6016) D(x): 0.5193 D(G(z)): 0.3950 / 0.4003 Acc: 25.0000 (21.9502)\n",
      "[2/25][347/782] Loss_D: 0.1632 (0.7176) Loss_G: 0.0995 (0.6013) D(x): 0.5624 D(G(z)): 0.4178 / 0.4284 Acc: 21.8750 (21.9502)\n",
      "[2/25][348/782] Loss_D: 0.4905 (0.7175) Loss_G: 0.1368 (0.6011) D(x): 0.5216 D(G(z)): 0.4935 / 0.4856 Acc: 28.1250 (21.9534)\n",
      "[2/25][349/782] Loss_D: 0.2440 (0.7172) Loss_G: 0.1881 (0.6008) D(x): 0.6167 D(G(z)): 0.5102 / 0.4299 Acc: 29.6875 (21.9575)\n",
      "[2/25][350/782] Loss_D: 0.5613 (0.7171) Loss_G: 0.0270 (0.6005) D(x): 0.4545 D(G(z)): 0.4582 / 0.4662 Acc: 17.1875 (21.9550)\n",
      "[2/25][351/782] Loss_D: 0.4227 (0.7170) Loss_G: 0.1565 (0.6003) D(x): 0.5445 D(G(z)): 0.5084 / 0.4545 Acc: 29.6875 (21.9590)\n",
      "[2/25][352/782] Loss_D: 0.4756 (0.7168) Loss_G: -0.0202 (0.6000) D(x): 0.5028 D(G(z)): 0.4857 / 0.5139 Acc: 18.7500 (21.9573)\n",
      "[2/25][353/782] Loss_D: 0.4271 (0.7167) Loss_G: -0.0717 (0.5996) D(x): 0.5680 D(G(z)): 0.5629 / 0.4837 Acc: 20.3125 (21.9565)\n",
      "[2/25][354/782] Loss_D: 0.3418 (0.7165) Loss_G: 0.4223 (0.5995) D(x): 0.5002 D(G(z)): 0.4494 / 0.3645 Acc: 34.3750 (21.9629)\n",
      "[2/25][355/782] Loss_D: 0.3737 (0.7163) Loss_G: 0.0362 (0.5993) D(x): 0.4760 D(G(z)): 0.4411 / 0.4680 Acc: 25.0000 (21.9645)\n",
      "[2/25][356/782] Loss_D: 0.6237 (0.7163) Loss_G: 0.1867 (0.5990) D(x): 0.5050 D(G(z)): 0.5574 / 0.4328 Acc: 28.1250 (21.9677)\n",
      "[2/25][357/782] Loss_D: 0.5579 (0.7162) Loss_G: 0.0651 (0.5988) D(x): 0.4720 D(G(z)): 0.4884 / 0.4793 Acc: 25.0000 (21.9693)\n",
      "[2/25][358/782] Loss_D: 0.5797 (0.7161) Loss_G: 0.0815 (0.5985) D(x): 0.4749 D(G(z)): 0.4822 / 0.5058 Acc: 31.2500 (21.9741)\n",
      "[2/25][359/782] Loss_D: 0.6513 (0.7161) Loss_G: 0.1436 (0.5983) D(x): 0.5370 D(G(z)): 0.5480 / 0.4734 Acc: 26.5625 (21.9765)\n",
      "[2/25][360/782] Loss_D: 0.2852 (0.7159) Loss_G: 0.2562 (0.5981) D(x): 0.5194 D(G(z)): 0.4422 / 0.3922 Acc: 31.2500 (21.9813)\n",
      "[2/25][361/782] Loss_D: 0.4924 (0.7157) Loss_G: 0.1049 (0.5978) D(x): 0.4806 D(G(z)): 0.4909 / 0.4397 Acc: 29.6875 (21.9853)\n",
      "[2/25][362/782] Loss_D: 0.5432 (0.7157) Loss_G: 0.0527 (0.5975) D(x): 0.4680 D(G(z)): 0.4541 / 0.4841 Acc: 25.0000 (21.9869)\n",
      "[2/25][363/782] Loss_D: 0.4191 (0.7155) Loss_G: 0.0840 (0.5973) D(x): 0.5235 D(G(z)): 0.5026 / 0.4650 Acc: 32.8125 (21.9925)\n",
      "[2/25][364/782] Loss_D: 0.6463 (0.7155) Loss_G: 0.0646 (0.5970) D(x): 0.5405 D(G(z)): 0.5642 / 0.4815 Acc: 21.8750 (21.9925)\n",
      "[2/25][365/782] Loss_D: 0.4305 (0.7153) Loss_G: 0.2602 (0.5968) D(x): 0.5271 D(G(z)): 0.4917 / 0.3699 Acc: 21.8750 (21.9924)\n",
      "[2/25][366/782] Loss_D: 0.3079 (0.7151) Loss_G: -0.0183 (0.5965) D(x): 0.5209 D(G(z)): 0.4641 / 0.4522 Acc: 23.4375 (21.9931)\n",
      "[2/25][367/782] Loss_D: 0.5444 (0.7150) Loss_G: 0.2562 (0.5963) D(x): 0.4688 D(G(z)): 0.4870 / 0.4026 Acc: 31.2500 (21.9979)\n",
      "[2/25][368/782] Loss_D: 0.3210 (0.7148) Loss_G: 0.1578 (0.5961) D(x): 0.5781 D(G(z)): 0.4392 / 0.4518 Acc: 20.3125 (21.9971)\n",
      "[2/25][369/782] Loss_D: 0.1978 (0.7145) Loss_G: 0.1133 (0.5958) D(x): 0.6241 D(G(z)): 0.4970 / 0.4783 Acc: 32.8125 (22.0026)\n",
      "[2/25][370/782] Loss_D: 0.5833 (0.7145) Loss_G: 0.2449 (0.5957) D(x): 0.4676 D(G(z)): 0.4695 / 0.4130 Acc: 21.8750 (22.0026)\n",
      "[2/25][371/782] Loss_D: 0.3305 (0.7143) Loss_G: 0.2899 (0.5955) D(x): 0.5891 D(G(z)): 0.4348 / 0.4278 Acc: 25.0000 (22.0041)\n",
      "[2/25][372/782] Loss_D: 0.1685 (0.7140) Loss_G: 0.4040 (0.5954) D(x): 0.5327 D(G(z)): 0.3889 / 0.3656 Acc: 37.5000 (22.0121)\n",
      "[2/25][373/782] Loss_D: 0.4163 (0.7138) Loss_G: 0.1468 (0.5952) D(x): 0.5256 D(G(z)): 0.4965 / 0.4288 Acc: 23.4375 (22.0129)\n",
      "[2/25][374/782] Loss_D: 0.2778 (0.7136) Loss_G: 0.2415 (0.5950) D(x): 0.5797 D(G(z)): 0.4458 / 0.3997 Acc: 21.8750 (22.0128)\n",
      "[2/25][375/782] Loss_D: 0.2265 (0.7134) Loss_G: 0.1902 (0.5948) D(x): 0.5540 D(G(z)): 0.4303 / 0.4143 Acc: 21.8750 (22.0127)\n",
      "[2/25][376/782] Loss_D: 0.4498 (0.7132) Loss_G: 0.2418 (0.5946) D(x): 0.5044 D(G(z)): 0.5044 / 0.3614 Acc: 20.3125 (22.0118)\n",
      "[2/25][377/782] Loss_D: 0.2323 (0.7130) Loss_G: 0.1507 (0.5944) D(x): 0.4972 D(G(z)): 0.4272 / 0.4174 Acc: 34.3750 (22.0182)\n",
      "[2/25][378/782] Loss_D: 0.2106 (0.7127) Loss_G: 0.2657 (0.5942) D(x): 0.5830 D(G(z)): 0.4267 / 0.4032 Acc: 25.0000 (22.0198)\n",
      "[2/25][379/782] Loss_D: 0.1963 (0.7125) Loss_G: 0.2828 (0.5940) D(x): 0.6042 D(G(z)): 0.4891 / 0.3641 Acc: 31.2500 (22.0245)\n",
      "[2/25][380/782] Loss_D: 0.1954 (0.7122) Loss_G: 0.3069 (0.5939) D(x): 0.5509 D(G(z)): 0.3925 / 0.3699 Acc: 21.8750 (22.0244)\n",
      "[2/25][381/782] Loss_D: 0.3462 (0.7120) Loss_G: -0.1324 (0.5935) D(x): 0.4849 D(G(z)): 0.4290 / 0.5487 Acc: 25.0000 (22.0260)\n",
      "[2/25][382/782] Loss_D: 0.1669 (0.7117) Loss_G: 0.4429 (0.5934) D(x): 0.6543 D(G(z)): 0.5063 / 0.3500 Acc: 35.9375 (22.0331)\n",
      "[2/25][383/782] Loss_D: 0.1470 (0.7114) Loss_G: 0.0802 (0.5932) D(x): 0.5040 D(G(z)): 0.3853 / 0.4440 Acc: 28.1250 (22.0362)\n",
      "[2/25][384/782] Loss_D: 0.3362 (0.7112) Loss_G: 0.2484 (0.5930) D(x): 0.5631 D(G(z)): 0.4818 / 0.3993 Acc: 25.0000 (22.0377)\n",
      "[2/25][385/782] Loss_D: 0.4372 (0.7111) Loss_G: 0.5074 (0.5930) D(x): 0.5466 D(G(z)): 0.4570 / 0.3432 Acc: 15.6250 (22.0345)\n",
      "[2/25][386/782] Loss_D: 0.2880 (0.7109) Loss_G: 0.1862 (0.5928) D(x): 0.5125 D(G(z)): 0.4093 / 0.4159 Acc: 21.8750 (22.0344)\n",
      "[2/25][387/782] Loss_D: 0.1502 (0.7106) Loss_G: 0.1613 (0.5925) D(x): 0.5914 D(G(z)): 0.4683 / 0.3847 Acc: 26.5625 (22.0367)\n",
      "[2/25][388/782] Loss_D: 0.2687 (0.7104) Loss_G: 0.3912 (0.5924) D(x): 0.5617 D(G(z)): 0.4658 / 0.3509 Acc: 25.0000 (22.0382)\n",
      "[2/25][389/782] Loss_D: 0.3308 (0.7102) Loss_G: 0.2920 (0.5923) D(x): 0.4872 D(G(z)): 0.3907 / 0.3852 Acc: 23.4375 (22.0389)\n",
      "[2/25][390/782] Loss_D: 0.2242 (0.7099) Loss_G: 0.0572 (0.5920) D(x): 0.5354 D(G(z)): 0.3792 / 0.4933 Acc: 20.3125 (22.0380)\n",
      "[2/25][391/782] Loss_D: 0.5591 (0.7099) Loss_G: 0.2887 (0.5918) D(x): 0.6179 D(G(z)): 0.5974 / 0.3827 Acc: 17.1875 (22.0356)\n",
      "[2/25][392/782] Loss_D: 0.2993 (0.7096) Loss_G: 0.2033 (0.5917) D(x): 0.4929 D(G(z)): 0.3875 / 0.4070 Acc: 18.7500 (22.0339)\n",
      "[2/25][393/782] Loss_D: 0.0825 (0.7093) Loss_G: -0.1400 (0.5913) D(x): 0.5558 D(G(z)): 0.3753 / 0.5279 Acc: 25.0000 (22.0354)\n",
      "[2/25][394/782] Loss_D: 0.2210 (0.7091) Loss_G: 0.1862 (0.5911) D(x): 0.6191 D(G(z)): 0.4965 / 0.4056 Acc: 29.6875 (22.0393)\n",
      "[2/25][395/782] Loss_D: -0.0229 (0.7087) Loss_G: 0.3188 (0.5909) D(x): 0.6406 D(G(z)): 0.3979 / 0.3566 Acc: 26.5625 (22.0416)\n",
      "[2/25][396/782] Loss_D: 0.3657 (0.7085) Loss_G: 0.4094 (0.5908) D(x): 0.5115 D(G(z)): 0.4462 / 0.3391 Acc: 25.0000 (22.0431)\n",
      "[2/25][397/782] Loss_D: 0.1241 (0.7082) Loss_G: 0.0326 (0.5906) D(x): 0.5078 D(G(z)): 0.3905 / 0.4518 Acc: 31.2500 (22.0478)\n",
      "[2/25][398/782] Loss_D: 0.2192 (0.7080) Loss_G: 0.2633 (0.5904) D(x): 0.5763 D(G(z)): 0.4318 / 0.3994 Acc: 23.4375 (22.0485)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/25][399/782] Loss_D: 0.1922 (0.7077) Loss_G: 0.4186 (0.5903) D(x): 0.6567 D(G(z)): 0.4589 / 0.3746 Acc: 21.8750 (22.0484)\n",
      "[2/25][400/782] Loss_D: 0.1245 (0.7074) Loss_G: 0.2327 (0.5901) D(x): 0.5579 D(G(z)): 0.4186 / 0.3728 Acc: 28.1250 (22.0515)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[2/25][401/782] Loss_D: 0.2916 (0.7072) Loss_G: 0.0956 (0.5899) D(x): 0.4947 D(G(z)): 0.3773 / 0.4528 Acc: 18.7500 (22.0498)\n",
      "[2/25][402/782] Loss_D: 0.0631 (0.7069) Loss_G: 0.1296 (0.5896) D(x): 0.5509 D(G(z)): 0.4668 / 0.4111 Acc: 46.8750 (22.0625)\n",
      "[2/25][403/782] Loss_D: 0.4058 (0.7067) Loss_G: 0.2695 (0.5895) D(x): 0.5179 D(G(z)): 0.4500 / 0.3822 Acc: 20.3125 (22.0616)\n",
      "[2/25][404/782] Loss_D: 0.2493 (0.7065) Loss_G: 0.0014 (0.5892) D(x): 0.4943 D(G(z)): 0.4104 / 0.4809 Acc: 26.5625 (22.0639)\n",
      "[2/25][405/782] Loss_D: 0.4137 (0.7063) Loss_G: 0.1769 (0.5890) D(x): 0.5547 D(G(z)): 0.5018 / 0.4212 Acc: 20.3125 (22.0630)\n",
      "[2/25][406/782] Loss_D: 0.1563 (0.7061) Loss_G: 0.3568 (0.5888) D(x): 0.5697 D(G(z)): 0.4790 / 0.3387 Acc: 29.6875 (22.0668)\n",
      "[2/25][407/782] Loss_D: 0.4819 (0.7060) Loss_G: 0.1993 (0.5886) D(x): 0.4477 D(G(z)): 0.3676 / 0.4463 Acc: 18.7500 (22.0652)\n",
      "[2/25][408/782] Loss_D: 0.2690 (0.7057) Loss_G: 0.0227 (0.5884) D(x): 0.5230 D(G(z)): 0.4575 / 0.4521 Acc: 23.4375 (22.0659)\n",
      "[2/25][409/782] Loss_D: 0.5834 (0.7057) Loss_G: 0.3089 (0.5882) D(x): 0.4644 D(G(z)): 0.5274 / 0.3884 Acc: 32.8125 (22.0713)\n",
      "[2/25][410/782] Loss_D: 0.2252 (0.7054) Loss_G: 0.0831 (0.5880) D(x): 0.5156 D(G(z)): 0.4632 / 0.4291 Acc: 32.8125 (22.0767)\n",
      "[2/25][411/782] Loss_D: 0.3749 (0.7053) Loss_G: 0.2426 (0.5878) D(x): 0.5135 D(G(z)): 0.4210 / 0.4165 Acc: 20.3125 (22.0758)\n",
      "[2/25][412/782] Loss_D: 0.4024 (0.7051) Loss_G: -0.0133 (0.5875) D(x): 0.5369 D(G(z)): 0.4670 / 0.5349 Acc: 23.4375 (22.0765)\n",
      "[2/25][413/782] Loss_D: 0.3770 (0.7049) Loss_G: 0.1251 (0.5872) D(x): 0.5502 D(G(z)): 0.5058 / 0.4753 Acc: 32.8125 (22.0820)\n",
      "[2/25][414/782] Loss_D: 0.3631 (0.7048) Loss_G: -0.0104 (0.5869) D(x): 0.5255 D(G(z)): 0.4508 / 0.4937 Acc: 28.1250 (22.0850)\n",
      "[2/25][415/782] Loss_D: 0.3128 (0.7046) Loss_G: 0.1893 (0.5867) D(x): 0.5436 D(G(z)): 0.4753 / 0.4210 Acc: 32.8125 (22.0904)\n",
      "[2/25][416/782] Loss_D: 0.1966 (0.7043) Loss_G: 0.1248 (0.5865) D(x): 0.5504 D(G(z)): 0.4548 / 0.4431 Acc: 31.2500 (22.0951)\n",
      "[2/25][417/782] Loss_D: 0.2679 (0.7041) Loss_G: 0.1100 (0.5863) D(x): 0.5723 D(G(z)): 0.4510 / 0.4527 Acc: 28.1250 (22.0981)\n",
      "[2/25][418/782] Loss_D: 0.4426 (0.7040) Loss_G: 0.0843 (0.5860) D(x): 0.5215 D(G(z)): 0.4945 / 0.4650 Acc: 28.1250 (22.1011)\n",
      "[2/25][419/782] Loss_D: 0.3555 (0.7038) Loss_G: 0.1544 (0.5858) D(x): 0.5205 D(G(z)): 0.4479 / 0.4316 Acc: 25.0000 (22.1026)\n",
      "[2/25][420/782] Loss_D: 0.3807 (0.7036) Loss_G: 0.1062 (0.5856) D(x): 0.5552 D(G(z)): 0.5040 / 0.4531 Acc: 28.1250 (22.1056)\n",
      "[2/25][421/782] Loss_D: 0.4888 (0.7035) Loss_G: 0.1877 (0.5854) D(x): 0.4907 D(G(z)): 0.4354 / 0.4483 Acc: 26.5625 (22.1079)\n",
      "[2/25][422/782] Loss_D: 0.4397 (0.7034) Loss_G: 0.1677 (0.5852) D(x): 0.5858 D(G(z)): 0.5279 / 0.4533 Acc: 21.8750 (22.1078)\n",
      "[2/25][423/782] Loss_D: 0.3477 (0.7032) Loss_G: 0.1183 (0.5849) D(x): 0.5628 D(G(z)): 0.4566 / 0.4116 Acc: 9.3750 (22.1014)\n",
      "[2/25][424/782] Loss_D: 0.4162 (0.7031) Loss_G: 0.0561 (0.5846) D(x): 0.5186 D(G(z)): 0.4564 / 0.4721 Acc: 18.7500 (22.0997)\n",
      "[2/25][425/782] Loss_D: 0.4807 (0.7029) Loss_G: -0.0626 (0.5843) D(x): 0.4990 D(G(z)): 0.5116 / 0.5193 Acc: 25.0000 (22.1011)\n",
      "[2/25][426/782] Loss_D: 0.4262 (0.7028) Loss_G: -0.0856 (0.5840) D(x): 0.5268 D(G(z)): 0.5392 / 0.5220 Acc: 35.9375 (22.1081)\n",
      "[2/25][427/782] Loss_D: 0.4152 (0.7027) Loss_G: 0.4590 (0.5839) D(x): 0.5777 D(G(z)): 0.5435 / 0.3672 Acc: 35.9375 (22.1150)\n",
      "[2/25][428/782] Loss_D: 0.4047 (0.7025) Loss_G: 0.1609 (0.5837) D(x): 0.4574 D(G(z)): 0.4471 / 0.4059 Acc: 23.4375 (22.1157)\n",
      "[2/25][429/782] Loss_D: 0.4109 (0.7024) Loss_G: -0.0615 (0.5834) D(x): 0.4726 D(G(z)): 0.4555 / 0.5181 Acc: 28.1250 (22.1187)\n",
      "[2/25][430/782] Loss_D: 0.3297 (0.7022) Loss_G: 0.0681 (0.5831) D(x): 0.6223 D(G(z)): 0.4910 / 0.4697 Acc: 15.6250 (22.1154)\n",
      "[2/25][431/782] Loss_D: 0.3710 (0.7020) Loss_G: 0.3855 (0.5830) D(x): 0.5783 D(G(z)): 0.5343 / 0.3531 Acc: 32.8125 (22.1208)\n",
      "[2/25][432/782] Loss_D: 0.5496 (0.7019) Loss_G: 0.2915 (0.5829) D(x): 0.4304 D(G(z)): 0.4444 / 0.3823 Acc: 23.4375 (22.1215)\n",
      "[2/25][433/782] Loss_D: 0.4537 (0.7018) Loss_G: 0.3917 (0.5828) D(x): 0.5661 D(G(z)): 0.4646 / 0.3804 Acc: 20.3125 (22.1206)\n",
      "[2/25][434/782] Loss_D: 0.3748 (0.7017) Loss_G: 0.5777 (0.5828) D(x): 0.5548 D(G(z)): 0.4634 / 0.3189 Acc: 21.8750 (22.1204)\n",
      "[2/25][435/782] Loss_D: 0.3034 (0.7015) Loss_G: 0.0658 (0.5825) D(x): 0.4551 D(G(z)): 0.3691 / 0.4589 Acc: 28.1250 (22.1234)\n",
      "[2/25][436/782] Loss_D: 0.3047 (0.7013) Loss_G: 0.0698 (0.5823) D(x): 0.5703 D(G(z)): 0.4732 / 0.4885 Acc: 23.4375 (22.1241)\n",
      "[2/25][437/782] Loss_D: 0.3928 (0.7011) Loss_G: 0.1782 (0.5821) D(x): 0.5295 D(G(z)): 0.4548 / 0.4401 Acc: 25.0000 (22.1255)\n",
      "[2/25][438/782] Loss_D: 0.3214 (0.7009) Loss_G: 0.1644 (0.5819) D(x): 0.6174 D(G(z)): 0.4878 / 0.4291 Acc: 18.7500 (22.1238)\n",
      "[2/25][439/782] Loss_D: 0.4511 (0.7008) Loss_G: 0.3487 (0.5817) D(x): 0.4608 D(G(z)): 0.4256 / 0.3977 Acc: 29.6875 (22.1276)\n",
      "[2/25][440/782] Loss_D: 0.3293 (0.7006) Loss_G: 0.1778 (0.5815) D(x): 0.5273 D(G(z)): 0.4496 / 0.4259 Acc: 29.6875 (22.1314)\n",
      "[2/25][441/782] Loss_D: 0.5645 (0.7005) Loss_G: -0.0465 (0.5812) D(x): 0.4466 D(G(z)): 0.4534 / 0.5004 Acc: 18.7500 (22.1297)\n",
      "[2/25][442/782] Loss_D: 0.2245 (0.7003) Loss_G: 0.2832 (0.5811) D(x): 0.6015 D(G(z)): 0.4810 / 0.3951 Acc: 25.0000 (22.1311)\n",
      "[2/25][443/782] Loss_D: 0.2905 (0.7001) Loss_G: 0.1467 (0.5809) D(x): 0.4840 D(G(z)): 0.4028 / 0.4294 Acc: 28.1250 (22.1341)\n",
      "[2/25][444/782] Loss_D: 0.0525 (0.6998) Loss_G: 0.4353 (0.5808) D(x): 0.6412 D(G(z)): 0.4431 / 0.3361 Acc: 31.2500 (22.1387)\n",
      "[2/25][445/782] Loss_D: 0.2368 (0.6995) Loss_G: 0.2471 (0.5806) D(x): 0.5361 D(G(z)): 0.3875 / 0.4098 Acc: 26.5625 (22.1409)\n",
      "[2/25][446/782] Loss_D: 0.3016 (0.6993) Loss_G: 0.1341 (0.5804) D(x): 0.5635 D(G(z)): 0.4148 / 0.4353 Acc: 18.7500 (22.1392)\n",
      "[2/25][447/782] Loss_D: 0.0819 (0.6990) Loss_G: 0.3399 (0.5803) D(x): 0.6102 D(G(z)): 0.4740 / 0.3296 Acc: 26.5625 (22.1414)\n",
      "[2/25][448/782] Loss_D: 0.1298 (0.6988) Loss_G: 0.1439 (0.5801) D(x): 0.5118 D(G(z)): 0.3419 / 0.4085 Acc: 20.3125 (22.1405)\n",
      "[2/25][449/782] Loss_D: 0.2839 (0.6985) Loss_G: 0.3751 (0.5800) D(x): 0.5966 D(G(z)): 0.5134 / 0.3720 Acc: 35.9375 (22.1473)\n",
      "[2/25][450/782] Loss_D: 0.1764 (0.6983) Loss_G: 0.1701 (0.5798) D(x): 0.5452 D(G(z)): 0.4173 / 0.4100 Acc: 31.2500 (22.1518)\n",
      "[2/25][451/782] Loss_D: 0.3201 (0.6981) Loss_G: 0.1860 (0.5796) D(x): 0.5780 D(G(z)): 0.4850 / 0.4197 Acc: 23.4375 (22.1525)\n",
      "[2/25][452/782] Loss_D: 0.2317 (0.6979) Loss_G: 0.3167 (0.5794) D(x): 0.5492 D(G(z)): 0.4651 / 0.3386 Acc: 29.6875 (22.1562)\n",
      "[2/25][453/782] Loss_D: 0.2413 (0.6976) Loss_G: 0.1713 (0.5792) D(x): 0.4858 D(G(z)): 0.3449 / 0.4162 Acc: 14.0625 (22.1522)\n",
      "[2/25][454/782] Loss_D: 0.3509 (0.6975) Loss_G: -0.1750 (0.5789) D(x): 0.5165 D(G(z)): 0.4964 / 0.5181 Acc: 26.5625 (22.1544)\n",
      "[2/25][455/782] Loss_D: 0.2323 (0.6972) Loss_G: 0.1982 (0.5787) D(x): 0.6046 D(G(z)): 0.4895 / 0.4030 Acc: 26.5625 (22.1566)\n",
      "[2/25][456/782] Loss_D: 0.3920 (0.6971) Loss_G: 0.2308 (0.5785) D(x): 0.5550 D(G(z)): 0.4818 / 0.4172 Acc: 25.0000 (22.1580)\n",
      "[2/25][457/782] Loss_D: 0.4264 (0.6970) Loss_G: 0.2093 (0.5783) D(x): 0.5416 D(G(z)): 0.4584 / 0.4441 Acc: 20.3125 (22.1571)\n",
      "[2/25][458/782] Loss_D: 0.2212 (0.6967) Loss_G: 0.1661 (0.5781) D(x): 0.5104 D(G(z)): 0.4551 / 0.4156 Acc: 37.5000 (22.1646)\n",
      "[2/25][459/782] Loss_D: 0.3160 (0.6965) Loss_G: 0.0917 (0.5779) D(x): 0.5111 D(G(z)): 0.4444 / 0.4625 Acc: 29.6875 (22.1684)\n",
      "[2/25][460/782] Loss_D: 0.4582 (0.6964) Loss_G: 0.2891 (0.5777) D(x): 0.5585 D(G(z)): 0.5212 / 0.4054 Acc: 29.6875 (22.1721)\n",
      "[2/25][461/782] Loss_D: 0.1496 (0.6961) Loss_G: 0.0084 (0.5775) D(x): 0.5233 D(G(z)): 0.4048 / 0.4860 Acc: 32.8125 (22.1773)\n",
      "[2/25][462/782] Loss_D: 0.4086 (0.6960) Loss_G: 0.0604 (0.5772) D(x): 0.6027 D(G(z)): 0.5412 / 0.4636 Acc: 20.3125 (22.1764)\n",
      "[2/25][463/782] Loss_D: 0.5697 (0.6959) Loss_G: 0.4769 (0.5771) D(x): 0.5310 D(G(z)): 0.4683 / 0.3581 Acc: 17.1875 (22.1739)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/25][464/782] Loss_D: 0.2161 (0.6957) Loss_G: 0.2470 (0.5770) D(x): 0.5159 D(G(z)): 0.4210 / 0.4141 Acc: 31.2500 (22.1784)\n",
      "[2/25][465/782] Loss_D: 0.4262 (0.6956) Loss_G: 0.3127 (0.5769) D(x): 0.4847 D(G(z)): 0.4424 / 0.3971 Acc: 32.8125 (22.1837)\n",
      "[2/25][466/782] Loss_D: 0.3875 (0.6954) Loss_G: 0.3061 (0.5767) D(x): 0.5342 D(G(z)): 0.4909 / 0.3933 Acc: 34.3750 (22.1897)\n",
      "[2/25][467/782] Loss_D: 0.5275 (0.6953) Loss_G: 0.0494 (0.5765) D(x): 0.4464 D(G(z)): 0.4107 / 0.4982 Acc: 23.4375 (22.1903)\n",
      "[2/25][468/782] Loss_D: 0.5319 (0.6953) Loss_G: 0.2851 (0.5763) D(x): 0.5447 D(G(z)): 0.5721 / 0.3949 Acc: 31.2500 (22.1947)\n",
      "[2/25][469/782] Loss_D: 0.4550 (0.6951) Loss_G: 0.5257 (0.5763) D(x): 0.5517 D(G(z)): 0.4653 / 0.3459 Acc: 23.4375 (22.1953)\n",
      "[2/25][470/782] Loss_D: 0.4719 (0.6950) Loss_G: 0.3341 (0.5762) D(x): 0.4384 D(G(z)): 0.4255 / 0.3777 Acc: 32.8125 (22.2006)\n",
      "[2/25][471/782] Loss_D: 0.2711 (0.6948) Loss_G: 0.2169 (0.5760) D(x): 0.4956 D(G(z)): 0.3751 / 0.4125 Acc: 23.4375 (22.2012)\n",
      "[2/25][472/782] Loss_D: 0.4409 (0.6947) Loss_G: 0.3758 (0.5759) D(x): 0.6262 D(G(z)): 0.5735 / 0.3598 Acc: 26.5625 (22.2033)\n",
      "[2/25][473/782] Loss_D: 0.3754 (0.6945) Loss_G: 0.3857 (0.5758) D(x): 0.4947 D(G(z)): 0.4062 / 0.3747 Acc: 25.0000 (22.2047)\n",
      "[2/25][474/782] Loss_D: 0.2582 (0.6943) Loss_G: 0.2608 (0.5757) D(x): 0.5483 D(G(z)): 0.4207 / 0.3813 Acc: 28.1250 (22.2076)\n",
      "[2/25][475/782] Loss_D: 0.2064 (0.6941) Loss_G: 0.3152 (0.5755) D(x): 0.6253 D(G(z)): 0.4149 / 0.4210 Acc: 18.7500 (22.2059)\n",
      "[2/25][476/782] Loss_D: 0.2583 (0.6939) Loss_G: 0.2217 (0.5754) D(x): 0.6175 D(G(z)): 0.5077 / 0.3987 Acc: 23.4375 (22.2065)\n",
      "[2/25][477/782] Loss_D: 0.4065 (0.6937) Loss_G: 0.3112 (0.5752) D(x): 0.5278 D(G(z)): 0.4901 / 0.3800 Acc: 29.6875 (22.2101)\n",
      "[2/25][478/782] Loss_D: 0.3017 (0.6935) Loss_G: 0.2258 (0.5751) D(x): 0.5163 D(G(z)): 0.4576 / 0.4064 Acc: 29.6875 (22.2138)\n",
      "[2/25][479/782] Loss_D: 0.2529 (0.6933) Loss_G: 0.1866 (0.5749) D(x): 0.5658 D(G(z)): 0.4375 / 0.4200 Acc: 21.8750 (22.2136)\n",
      "[2/25][480/782] Loss_D: 0.5323 (0.6932) Loss_G: -0.0962 (0.5745) D(x): 0.4930 D(G(z)): 0.5057 / 0.5497 Acc: 21.8750 (22.2135)\n",
      "[2/25][481/782] Loss_D: 0.4837 (0.6931) Loss_G: -0.0009 (0.5743) D(x): 0.5127 D(G(z)): 0.5437 / 0.4814 Acc: 23.4375 (22.2141)\n",
      "[2/25][482/782] Loss_D: 0.3828 (0.6930) Loss_G: 0.1653 (0.5741) D(x): 0.5195 D(G(z)): 0.4992 / 0.4159 Acc: 21.8750 (22.2139)\n",
      "[2/25][483/782] Loss_D: 0.5864 (0.6929) Loss_G: 0.1728 (0.5739) D(x): 0.5010 D(G(z)): 0.5515 / 0.4322 Acc: 29.6875 (22.2176)\n",
      "[2/25][484/782] Loss_D: 0.3624 (0.6928) Loss_G: 0.2578 (0.5737) D(x): 0.5206 D(G(z)): 0.4742 / 0.3845 Acc: 28.1250 (22.2204)\n",
      "[2/25][485/782] Loss_D: 0.1195 (0.6925) Loss_G: 0.1183 (0.5735) D(x): 0.5426 D(G(z)): 0.4162 / 0.4000 Acc: 29.6875 (22.2241)\n",
      "[2/25][486/782] Loss_D: 0.2106 (0.6923) Loss_G: 0.4459 (0.5734) D(x): 0.5946 D(G(z)): 0.4255 / 0.3356 Acc: 20.3125 (22.2232)\n",
      "[2/25][487/782] Loss_D: 0.2716 (0.6921) Loss_G: -0.0500 (0.5731) D(x): 0.4627 D(G(z)): 0.3784 / 0.4922 Acc: 28.1250 (22.2260)\n",
      "[2/25][488/782] Loss_D: 0.5915 (0.6920) Loss_G: -0.1302 (0.5728) D(x): 0.4643 D(G(z)): 0.4615 / 0.5687 Acc: 17.1875 (22.2236)\n",
      "[2/25][489/782] Loss_D: 0.4227 (0.6919) Loss_G: 0.3094 (0.5726) D(x): 0.6965 D(G(z)): 0.6130 / 0.3936 Acc: 29.6875 (22.2272)\n",
      "[2/25][490/782] Loss_D: 0.7059 (0.6919) Loss_G: 0.4422 (0.5726) D(x): 0.4318 D(G(z)): 0.5009 / 0.3478 Acc: 28.1250 (22.2301)\n",
      "[2/25][491/782] Loss_D: 0.2619 (0.6917) Loss_G: 0.3482 (0.5725) D(x): 0.4250 D(G(z)): 0.3191 / 0.3595 Acc: 34.3750 (22.2360)\n",
      "[2/25][492/782] Loss_D: 0.3947 (0.6915) Loss_G: 0.1531 (0.5723) D(x): 0.5493 D(G(z)): 0.3974 / 0.4719 Acc: 17.1875 (22.2335)\n",
      "[2/25][493/782] Loss_D: 0.6112 (0.6915) Loss_G: 0.0455 (0.5720) D(x): 0.5920 D(G(z)): 0.5817 / 0.4799 Acc: 14.0625 (22.2296)\n",
      "[2/25][494/782] Loss_D: 0.6770 (0.6915) Loss_G: 0.1071 (0.5718) D(x): 0.5152 D(G(z)): 0.5641 / 0.4564 Acc: 25.0000 (22.2309)\n",
      "[2/25][495/782] Loss_D: 0.6789 (0.6915) Loss_G: 0.2399 (0.5716) D(x): 0.4745 D(G(z)): 0.5691 / 0.3743 Acc: 25.0000 (22.2323)\n",
      "[2/25][496/782] Loss_D: 0.4792 (0.6914) Loss_G: -0.0559 (0.5713) D(x): 0.4391 D(G(z)): 0.4619 / 0.4749 Acc: 25.0000 (22.2336)\n",
      "[2/25][497/782] Loss_D: 0.4427 (0.6913) Loss_G: -0.0241 (0.5710) D(x): 0.5142 D(G(z)): 0.5077 / 0.5160 Acc: 25.0000 (22.2349)\n",
      "[2/25][498/782] Loss_D: 0.2446 (0.6910) Loss_G: 0.0545 (0.5708) D(x): 0.6457 D(G(z)): 0.5380 / 0.4406 Acc: 21.8750 (22.2348)\n",
      "[2/25][499/782] Loss_D: 0.2993 (0.6908) Loss_G: 0.2806 (0.5706) D(x): 0.5542 D(G(z)): 0.4644 / 0.3790 Acc: 26.5625 (22.2369)\n",
      "[2/25][500/782] Loss_D: 0.1163 (0.6906) Loss_G: 0.1041 (0.5704) D(x): 0.4886 D(G(z)): 0.3544 / 0.4242 Acc: 28.1250 (22.2397)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[2/25][501/782] Loss_D: 0.3815 (0.6904) Loss_G: 0.1504 (0.5702) D(x): 0.5525 D(G(z)): 0.4976 / 0.4097 Acc: 18.7500 (22.2380)\n",
      "[2/25][502/782] Loss_D: 0.4187 (0.6903) Loss_G: 0.0270 (0.5699) D(x): 0.5411 D(G(z)): 0.4833 / 0.4666 Acc: 17.1875 (22.2356)\n",
      "[2/25][503/782] Loss_D: 0.5034 (0.6902) Loss_G: 0.1996 (0.5698) D(x): 0.5529 D(G(z)): 0.5154 / 0.4186 Acc: 17.1875 (22.2331)\n",
      "[2/25][504/782] Loss_D: 0.3823 (0.6900) Loss_G: 0.2108 (0.5696) D(x): 0.4617 D(G(z)): 0.3881 / 0.4169 Acc: 25.0000 (22.2345)\n",
      "[2/25][505/782] Loss_D: 0.2180 (0.6898) Loss_G: 0.0280 (0.5693) D(x): 0.5671 D(G(z)): 0.4483 / 0.4867 Acc: 26.5625 (22.2366)\n",
      "[2/25][506/782] Loss_D: 0.3069 (0.6896) Loss_G: 0.0953 (0.5691) D(x): 0.6143 D(G(z)): 0.5515 / 0.4233 Acc: 23.4375 (22.2371)\n",
      "[2/25][507/782] Loss_D: 0.2671 (0.6894) Loss_G: 0.1610 (0.5689) D(x): 0.4896 D(G(z)): 0.4118 / 0.4041 Acc: 23.4375 (22.2377)\n",
      "[2/25][508/782] Loss_D: 0.4664 (0.6893) Loss_G: 0.3103 (0.5688) D(x): 0.5154 D(G(z)): 0.4410 / 0.4123 Acc: 20.3125 (22.2368)\n",
      "[2/25][509/782] Loss_D: 0.2960 (0.6891) Loss_G: 0.0940 (0.5686) D(x): 0.5492 D(G(z)): 0.4163 / 0.4527 Acc: 14.0625 (22.2329)\n",
      "[2/25][510/782] Loss_D: 0.3025 (0.6889) Loss_G: -0.0131 (0.5683) D(x): 0.4933 D(G(z)): 0.4719 / 0.4758 Acc: 34.3750 (22.2387)\n",
      "[2/25][511/782] Loss_D: 0.2427 (0.6887) Loss_G: 0.1923 (0.5681) D(x): 0.5857 D(G(z)): 0.4376 / 0.4655 Acc: 32.8125 (22.2438)\n",
      "[2/25][512/782] Loss_D: 0.3385 (0.6886) Loss_G: -0.0048 (0.5678) D(x): 0.5585 D(G(z)): 0.4853 / 0.5140 Acc: 25.0000 (22.2451)\n",
      "[2/25][513/782] Loss_D: 0.3847 (0.6884) Loss_G: 0.2060 (0.5676) D(x): 0.5395 D(G(z)): 0.4415 / 0.4208 Acc: 20.3125 (22.2442)\n",
      "[2/25][514/782] Loss_D: 0.3216 (0.6882) Loss_G: 0.0869 (0.5674) D(x): 0.5272 D(G(z)): 0.4584 / 0.4210 Acc: 18.7500 (22.2425)\n",
      "[2/25][515/782] Loss_D: 0.2910 (0.6881) Loss_G: 0.2250 (0.5672) D(x): 0.5501 D(G(z)): 0.4648 / 0.4305 Acc: 34.3750 (22.2483)\n",
      "[2/25][516/782] Loss_D: 0.4186 (0.6879) Loss_G: 0.1196 (0.5670) D(x): 0.4761 D(G(z)): 0.4261 / 0.4493 Acc: 20.3125 (22.2474)\n",
      "[2/25][517/782] Loss_D: 0.3327 (0.6878) Loss_G: 0.1160 (0.5668) D(x): 0.5766 D(G(z)): 0.4381 / 0.4882 Acc: 26.5625 (22.2495)\n",
      "[2/25][518/782] Loss_D: 0.4330 (0.6876) Loss_G: 0.1352 (0.5666) D(x): 0.5571 D(G(z)): 0.5314 / 0.4371 Acc: 26.5625 (22.2516)\n",
      "[2/25][519/782] Loss_D: 0.3212 (0.6875) Loss_G: 0.3814 (0.5665) D(x): 0.5340 D(G(z)): 0.3804 / 0.3786 Acc: 23.4375 (22.2521)\n",
      "[2/25][520/782] Loss_D: 0.2594 (0.6872) Loss_G: 0.4509 (0.5665) D(x): 0.5494 D(G(z)): 0.4489 / 0.3414 Acc: 31.2500 (22.2564)\n",
      "[2/25][521/782] Loss_D: 0.2624 (0.6870) Loss_G: 0.2468 (0.5663) D(x): 0.5485 D(G(z)): 0.4303 / 0.3893 Acc: 23.4375 (22.2570)\n",
      "[2/25][522/782] Loss_D: 0.1065 (0.6868) Loss_G: 0.1391 (0.5661) D(x): 0.5830 D(G(z)): 0.4135 / 0.4140 Acc: 26.5625 (22.2591)\n",
      "[2/25][523/782] Loss_D: 0.4458 (0.6867) Loss_G: 0.3272 (0.5660) D(x): 0.5329 D(G(z)): 0.4559 / 0.3907 Acc: 20.3125 (22.2581)\n",
      "[2/25][524/782] Loss_D: 0.3059 (0.6865) Loss_G: 0.2781 (0.5659) D(x): 0.6062 D(G(z)): 0.4909 / 0.3963 Acc: 28.1250 (22.2610)\n",
      "[2/25][525/782] Loss_D: 0.2159 (0.6862) Loss_G: 0.2828 (0.5657) D(x): 0.5517 D(G(z)): 0.3960 / 0.3735 Acc: 20.3125 (22.2600)\n",
      "[2/25][526/782] Loss_D: 0.2114 (0.6860) Loss_G: 0.3040 (0.5656) D(x): 0.5612 D(G(z)): 0.4345 / 0.3837 Acc: 29.6875 (22.2636)\n",
      "[2/25][527/782] Loss_D: 0.0997 (0.6857) Loss_G: 0.2896 (0.5655) D(x): 0.5774 D(G(z)): 0.4308 / 0.3821 Acc: 28.1250 (22.2664)\n",
      "[2/25][528/782] Loss_D: 0.1762 (0.6855) Loss_G: 0.1304 (0.5653) D(x): 0.5330 D(G(z)): 0.3928 / 0.4399 Acc: 31.2500 (22.2707)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/25][529/782] Loss_D: 0.1008 (0.6852) Loss_G: 0.3377 (0.5651) D(x): 0.6598 D(G(z)): 0.4861 / 0.3698 Acc: 32.8125 (22.2757)\n",
      "[2/25][530/782] Loss_D: 0.1311 (0.6849) Loss_G: 0.2074 (0.5650) D(x): 0.5686 D(G(z)): 0.4209 / 0.4115 Acc: 29.6875 (22.2792)\n",
      "[2/25][531/782] Loss_D: 0.3458 (0.6848) Loss_G: 0.2017 (0.5648) D(x): 0.6153 D(G(z)): 0.4975 / 0.4200 Acc: 25.0000 (22.2805)\n",
      "[2/25][532/782] Loss_D: 0.4202 (0.6847) Loss_G: 0.2443 (0.5646) D(x): 0.4895 D(G(z)): 0.4011 / 0.4063 Acc: 21.8750 (22.2803)\n",
      "[2/25][533/782] Loss_D: 0.3310 (0.6845) Loss_G: 0.0380 (0.5644) D(x): 0.5937 D(G(z)): 0.4998 / 0.4971 Acc: 25.0000 (22.2816)\n",
      "[2/25][534/782] Loss_D: 0.4127 (0.6844) Loss_G: 0.1313 (0.5642) D(x): 0.5213 D(G(z)): 0.4880 / 0.4287 Acc: 21.8750 (22.2814)\n",
      "[2/25][535/782] Loss_D: 0.2183 (0.6841) Loss_G: 0.2997 (0.5641) D(x): 0.5100 D(G(z)): 0.4376 / 0.3522 Acc: 32.8125 (22.2865)\n",
      "[2/25][536/782] Loss_D: 0.4161 (0.6840) Loss_G: -0.1458 (0.5637) D(x): 0.4559 D(G(z)): 0.4478 / 0.5194 Acc: 20.3125 (22.2855)\n",
      "[2/25][537/782] Loss_D: 0.5498 (0.6839) Loss_G: 0.0104 (0.5635) D(x): 0.4852 D(G(z)): 0.4961 / 0.5114 Acc: 29.6875 (22.2890)\n",
      "[2/25][538/782] Loss_D: 0.5241 (0.6839) Loss_G: 0.5109 (0.5634) D(x): 0.5491 D(G(z)): 0.5546 / 0.3387 Acc: 26.5625 (22.2911)\n",
      "[2/25][539/782] Loss_D: 0.1302 (0.6836) Loss_G: 0.3934 (0.5634) D(x): 0.5132 D(G(z)): 0.3582 / 0.3763 Acc: 31.2500 (22.2953)\n",
      "[2/25][540/782] Loss_D: 0.0853 (0.6833) Loss_G: -0.0630 (0.5631) D(x): 0.5077 D(G(z)): 0.3789 / 0.5180 Acc: 29.6875 (22.2988)\n",
      "[2/25][541/782] Loss_D: 0.5857 (0.6833) Loss_G: 0.1909 (0.5629) D(x): 0.6608 D(G(z)): 0.6138 / 0.4090 Acc: 12.5000 (22.2942)\n",
      "[2/25][542/782] Loss_D: 0.5178 (0.6832) Loss_G: 0.2854 (0.5628) D(x): 0.4831 D(G(z)): 0.4835 / 0.4014 Acc: 29.6875 (22.2977)\n",
      "[2/25][543/782] Loss_D: 0.2217 (0.6830) Loss_G: 0.3236 (0.5626) D(x): 0.5163 D(G(z)): 0.3972 / 0.3904 Acc: 31.2500 (22.3019)\n",
      "[2/25][544/782] Loss_D: 0.3051 (0.6828) Loss_G: 0.2068 (0.5625) D(x): 0.5684 D(G(z)): 0.4992 / 0.4063 Acc: 28.1250 (22.3047)\n",
      "[2/25][545/782] Loss_D: 0.1776 (0.6826) Loss_G: 0.3361 (0.5624) D(x): 0.5964 D(G(z)): 0.4829 / 0.3523 Acc: 31.2500 (22.3089)\n",
      "[2/25][546/782] Loss_D: 0.3818 (0.6824) Loss_G: 0.2639 (0.5622) D(x): 0.4092 D(G(z)): 0.3218 / 0.3975 Acc: 26.5625 (22.3110)\n",
      "[2/25][547/782] Loss_D: 0.3473 (0.6823) Loss_G: 0.2843 (0.5621) D(x): 0.5297 D(G(z)): 0.4856 / 0.3881 Acc: 31.2500 (22.3152)\n",
      "[2/25][548/782] Loss_D: 0.3734 (0.6821) Loss_G: 0.2468 (0.5619) D(x): 0.5362 D(G(z)): 0.4794 / 0.4125 Acc: 35.9375 (22.3216)\n",
      "[2/25][549/782] Loss_D: 0.0730 (0.6818) Loss_G: 0.0719 (0.5617) D(x): 0.6026 D(G(z)): 0.4547 / 0.4476 Acc: 32.8125 (22.3266)\n",
      "[2/25][550/782] Loss_D: 0.2023 (0.6816) Loss_G: 0.1067 (0.5615) D(x): 0.6210 D(G(z)): 0.4959 / 0.4221 Acc: 21.8750 (22.3264)\n",
      "[2/25][551/782] Loss_D: 0.0942 (0.6813) Loss_G: 0.4738 (0.5615) D(x): 0.6283 D(G(z)): 0.4335 / 0.3333 Acc: 34.3750 (22.3321)\n",
      "[2/25][552/782] Loss_D: 0.3128 (0.6811) Loss_G: 0.4041 (0.5614) D(x): 0.5413 D(G(z)): 0.4297 / 0.3495 Acc: 21.8750 (22.3319)\n",
      "[2/25][553/782] Loss_D: 0.1736 (0.6809) Loss_G: 0.1797 (0.5612) D(x): 0.5527 D(G(z)): 0.3683 / 0.4277 Acc: 21.8750 (22.3317)\n",
      "[2/25][554/782] Loss_D: 0.1477 (0.6807) Loss_G: 0.1146 (0.5610) D(x): 0.5193 D(G(z)): 0.3994 / 0.4302 Acc: 31.2500 (22.3359)\n",
      "[2/25][555/782] Loss_D: 0.2584 (0.6805) Loss_G: 0.3858 (0.5609) D(x): 0.5822 D(G(z)): 0.4940 / 0.3296 Acc: 25.0000 (22.3371)\n",
      "[2/25][556/782] Loss_D: 0.2035 (0.6802) Loss_G: 0.2969 (0.5608) D(x): 0.5692 D(G(z)): 0.4392 / 0.3496 Acc: 20.3125 (22.3362)\n",
      "[2/25][557/782] Loss_D: 0.4752 (0.6801) Loss_G: 0.1404 (0.5606) D(x): 0.3967 D(G(z)): 0.3805 / 0.4635 Acc: 37.5000 (22.3433)\n",
      "[2/25][558/782] Loss_D: 0.6094 (0.6801) Loss_G: 0.1666 (0.5604) D(x): 0.5106 D(G(z)): 0.5628 / 0.4337 Acc: 26.5625 (22.3453)\n",
      "[2/25][559/782] Loss_D: 0.1925 (0.6799) Loss_G: 0.1919 (0.5602) D(x): 0.5607 D(G(z)): 0.4622 / 0.4111 Acc: 34.3750 (22.3510)\n",
      "[2/25][560/782] Loss_D: 0.4377 (0.6798) Loss_G: 0.4888 (0.5602) D(x): 0.5113 D(G(z)): 0.4828 / 0.3238 Acc: 25.0000 (22.3522)\n",
      "[2/25][561/782] Loss_D: 0.4829 (0.6797) Loss_G: 0.3206 (0.5601) D(x): 0.4355 D(G(z)): 0.3224 / 0.4179 Acc: 17.1875 (22.3498)\n",
      "[2/25][562/782] Loss_D: 0.3959 (0.6795) Loss_G: 0.1772 (0.5599) D(x): 0.5958 D(G(z)): 0.5365 / 0.4467 Acc: 29.6875 (22.3532)\n",
      "[2/25][563/782] Loss_D: 0.2476 (0.6793) Loss_G: 0.2353 (0.5597) D(x): 0.5458 D(G(z)): 0.4100 / 0.4343 Acc: 28.1250 (22.3559)\n",
      "[2/25][564/782] Loss_D: 0.3086 (0.6792) Loss_G: 0.3750 (0.5597) D(x): 0.5258 D(G(z)): 0.4549 / 0.3318 Acc: 20.3125 (22.3550)\n",
      "[2/25][565/782] Loss_D: 0.1148 (0.6789) Loss_G: 0.6680 (0.5597) D(x): 0.6701 D(G(z)): 0.4429 / 0.3117 Acc: 32.8125 (22.3599)\n",
      "[2/25][566/782] Loss_D: 0.5635 (0.6788) Loss_G: 0.3039 (0.5596) D(x): 0.4260 D(G(z)): 0.3868 / 0.3997 Acc: 21.8750 (22.3597)\n",
      "[2/25][567/782] Loss_D: 0.6109 (0.6788) Loss_G: -0.0202 (0.5593) D(x): 0.4177 D(G(z)): 0.4633 / 0.5338 Acc: 28.1250 (22.3624)\n",
      "[2/25][568/782] Loss_D: 0.2516 (0.6786) Loss_G: 0.1574 (0.5591) D(x): 0.6669 D(G(z)): 0.5612 / 0.4268 Acc: 29.6875 (22.3658)\n",
      "[2/25][569/782] Loss_D: 0.4345 (0.6785) Loss_G: 0.1968 (0.5590) D(x): 0.5070 D(G(z)): 0.4786 / 0.4159 Acc: 29.6875 (22.3692)\n",
      "[2/25][570/782] Loss_D: 0.2942 (0.6783) Loss_G: 0.1073 (0.5587) D(x): 0.5436 D(G(z)): 0.5399 / 0.4179 Acc: 31.2500 (22.3734)\n",
      "[2/25][571/782] Loss_D: 0.3861 (0.6782) Loss_G: 0.1468 (0.5586) D(x): 0.4890 D(G(z)): 0.4586 / 0.4197 Acc: 26.5625 (22.3754)\n",
      "[2/25][572/782] Loss_D: 0.9983 (0.6783) Loss_G: 0.0928 (0.5583) D(x): 0.3944 D(G(z)): 0.6098 / 0.4681 Acc: 32.8125 (22.3802)\n",
      "[2/25][573/782] Loss_D: 1.0738 (0.6785) Loss_G: -0.0617 (0.5580) D(x): 0.4337 D(G(z)): 0.6293 / 0.5423 Acc: 23.4375 (22.3807)\n",
      "[2/25][574/782] Loss_D: 0.7921 (0.6786) Loss_G: 0.1596 (0.5579) D(x): 0.3750 D(G(z)): 0.5333 / 0.3905 Acc: 25.0000 (22.3820)\n",
      "[2/25][575/782] Loss_D: 0.5948 (0.6785) Loss_G: 0.3158 (0.5577) D(x): 0.4913 D(G(z)): 0.5174 / 0.3758 Acc: 23.4375 (22.3824)\n",
      "[2/25][576/782] Loss_D: 0.6111 (0.6785) Loss_G: 0.2907 (0.5576) D(x): 0.4241 D(G(z)): 0.4013 / 0.4199 Acc: 20.3125 (22.3815)\n",
      "[2/25][577/782] Loss_D: 0.2081 (0.6783) Loss_G: -0.0871 (0.5573) D(x): 0.5715 D(G(z)): 0.4065 / 0.5576 Acc: 25.0000 (22.3827)\n",
      "[2/25][578/782] Loss_D: 0.3581 (0.6781) Loss_G: -0.0068 (0.5571) D(x): 0.6086 D(G(z)): 0.5366 / 0.4843 Acc: 23.4375 (22.3832)\n",
      "[2/25][579/782] Loss_D: 0.3589 (0.6780) Loss_G: 0.4689 (0.5570) D(x): 0.6701 D(G(z)): 0.5068 / 0.3632 Acc: 23.4375 (22.3837)\n",
      "[2/25][580/782] Loss_D: 0.1869 (0.6777) Loss_G: 0.2290 (0.5569) D(x): 0.5216 D(G(z)): 0.3806 / 0.3947 Acc: 25.0000 (22.3849)\n",
      "[2/25][581/782] Loss_D: -0.0743 (0.6774) Loss_G: 0.1638 (0.5567) D(x): 0.6201 D(G(z)): 0.3856 / 0.4110 Acc: 32.8125 (22.3898)\n",
      "[2/25][582/782] Loss_D: 0.1270 (0.6771) Loss_G: 0.4961 (0.5567) D(x): 0.6507 D(G(z)): 0.4288 / 0.3442 Acc: 23.4375 (22.3903)\n",
      "[2/25][583/782] Loss_D: -0.0932 (0.6768) Loss_G: 0.3094 (0.5565) D(x): 0.5984 D(G(z)): 0.3603 / 0.3604 Acc: 32.8125 (22.3951)\n",
      "[2/25][584/782] Loss_D: 0.0327 (0.6765) Loss_G: 0.5094 (0.5565) D(x): 0.5846 D(G(z)): 0.3182 / 0.3414 Acc: 29.6875 (22.3985)\n",
      "[2/25][585/782] Loss_D: 0.1872 (0.6763) Loss_G: 0.4711 (0.5565) D(x): 0.6132 D(G(z)): 0.4749 / 0.3237 Acc: 28.1250 (22.4012)\n",
      "[2/25][586/782] Loss_D: 0.0919 (0.6760) Loss_G: 0.2493 (0.5563) D(x): 0.5346 D(G(z)): 0.3625 / 0.4076 Acc: 35.9375 (22.4075)\n",
      "[2/25][587/782] Loss_D: 0.1360 (0.6757) Loss_G: 0.2727 (0.5562) D(x): 0.6299 D(G(z)): 0.4976 / 0.3735 Acc: 31.2500 (22.4116)\n",
      "[2/25][588/782] Loss_D: 0.4223 (0.6756) Loss_G: 0.3177 (0.5561) D(x): 0.4783 D(G(z)): 0.4423 / 0.3876 Acc: 34.3750 (22.4171)\n",
      "[2/25][589/782] Loss_D: 0.3146 (0.6754) Loss_G: 0.3145 (0.5560) D(x): 0.4750 D(G(z)): 0.4551 / 0.3546 Acc: 28.1250 (22.4198)\n",
      "[2/25][590/782] Loss_D: 0.2926 (0.6753) Loss_G: 0.1157 (0.5558) D(x): 0.5151 D(G(z)): 0.4153 / 0.4650 Acc: 25.0000 (22.4210)\n",
      "[2/25][591/782] Loss_D: 0.2673 (0.6751) Loss_G: 0.2171 (0.5556) D(x): 0.6503 D(G(z)): 0.5286 / 0.4256 Acc: 28.1250 (22.4236)\n",
      "[2/25][592/782] Loss_D: 0.3087 (0.6749) Loss_G: 0.5029 (0.5556) D(x): 0.5797 D(G(z)): 0.4337 / 0.3399 Acc: 21.8750 (22.4234)\n",
      "[2/25][593/782] Loss_D: -0.0011 (0.6746) Loss_G: 0.3821 (0.5555) D(x): 0.6043 D(G(z)): 0.3711 / 0.3560 Acc: 32.8125 (22.4282)\n",
      "[2/25][594/782] Loss_D: 0.3344 (0.6744) Loss_G: 0.1775 (0.5553) D(x): 0.4727 D(G(z)): 0.4396 / 0.4022 Acc: 31.2500 (22.4323)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/25][595/782] Loss_D: 0.3641 (0.6743) Loss_G: 0.1536 (0.5551) D(x): 0.5756 D(G(z)): 0.4966 / 0.4242 Acc: 20.3125 (22.4313)\n",
      "[2/25][596/782] Loss_D: 0.4324 (0.6742) Loss_G: 0.0299 (0.5549) D(x): 0.4673 D(G(z)): 0.4083 / 0.4915 Acc: 18.7500 (22.4296)\n",
      "[2/25][597/782] Loss_D: 0.2203 (0.6740) Loss_G: 0.1817 (0.5547) D(x): 0.6491 D(G(z)): 0.5548 / 0.4059 Acc: 35.9375 (22.4358)\n",
      "[2/25][598/782] Loss_D: 0.3208 (0.6738) Loss_G: 0.2369 (0.5546) D(x): 0.5324 D(G(z)): 0.4440 / 0.4051 Acc: 25.0000 (22.4370)\n",
      "[2/25][599/782] Loss_D: 0.3243 (0.6736) Loss_G: 0.1590 (0.5544) D(x): 0.5552 D(G(z)): 0.4367 / 0.4251 Acc: 21.8750 (22.4367)\n",
      "[2/25][600/782] Loss_D: 0.5001 (0.6736) Loss_G: 0.0564 (0.5542) D(x): 0.5094 D(G(z)): 0.4633 / 0.5083 Acc: 23.4375 (22.4372)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[2/25][601/782] Loss_D: 0.3932 (0.6734) Loss_G: 0.0032 (0.5539) D(x): 0.5157 D(G(z)): 0.5147 / 0.4422 Acc: 23.4375 (22.4377)\n",
      "[2/25][602/782] Loss_D: 0.6577 (0.6734) Loss_G: 0.1316 (0.5537) D(x): 0.5075 D(G(z)): 0.5462 / 0.4416 Acc: 21.8750 (22.4374)\n",
      "[2/25][603/782] Loss_D: 0.2550 (0.6732) Loss_G: 0.0980 (0.5535) D(x): 0.5219 D(G(z)): 0.4280 / 0.4360 Acc: 23.4375 (22.4379)\n",
      "[2/25][604/782] Loss_D: 0.4292 (0.6731) Loss_G: 0.1065 (0.5533) D(x): 0.4959 D(G(z)): 0.4816 / 0.4443 Acc: 26.5625 (22.4398)\n",
      "[2/25][605/782] Loss_D: 0.3714 (0.6730) Loss_G: -0.0435 (0.5530) D(x): 0.5490 D(G(z)): 0.5234 / 0.5084 Acc: 28.1250 (22.4424)\n",
      "[2/25][606/782] Loss_D: 0.4462 (0.6729) Loss_G: 0.0967 (0.5528) D(x): 0.4819 D(G(z)): 0.4497 / 0.4513 Acc: 25.0000 (22.4436)\n",
      "[2/25][607/782] Loss_D: 0.2060 (0.6727) Loss_G: -0.0697 (0.5525) D(x): 0.5143 D(G(z)): 0.4665 / 0.4965 Acc: 35.9375 (22.4498)\n",
      "[2/25][608/782] Loss_D: 0.2718 (0.6725) Loss_G: 0.1765 (0.5524) D(x): 0.5838 D(G(z)): 0.5069 / 0.4126 Acc: 31.2500 (22.4538)\n",
      "[2/25][609/782] Loss_D: 0.2894 (0.6723) Loss_G: 0.3740 (0.5523) D(x): 0.5594 D(G(z)): 0.4920 / 0.3679 Acc: 34.3750 (22.4593)\n",
      "[2/25][610/782] Loss_D: 0.2076 (0.6721) Loss_G: 0.2584 (0.5521) D(x): 0.4793 D(G(z)): 0.3375 / 0.4208 Acc: 28.1250 (22.4619)\n",
      "[2/25][611/782] Loss_D: 0.2002 (0.6719) Loss_G: 0.0834 (0.5519) D(x): 0.5773 D(G(z)): 0.4678 / 0.4248 Acc: 23.4375 (22.4624)\n",
      "[2/25][612/782] Loss_D: 0.1668 (0.6716) Loss_G: 0.0577 (0.5517) D(x): 0.5869 D(G(z)): 0.4883 / 0.4539 Acc: 31.2500 (22.4664)\n",
      "[2/25][613/782] Loss_D: 0.3670 (0.6715) Loss_G: 0.2612 (0.5516) D(x): 0.5216 D(G(z)): 0.4636 / 0.3928 Acc: 23.4375 (22.4669)\n",
      "[2/25][614/782] Loss_D: 0.1407 (0.6713) Loss_G: 0.1053 (0.5514) D(x): 0.5148 D(G(z)): 0.3778 / 0.4336 Acc: 26.5625 (22.4687)\n",
      "[2/25][615/782] Loss_D: 0.5697 (0.6712) Loss_G: 0.4510 (0.5513) D(x): 0.5467 D(G(z)): 0.5023 / 0.3529 Acc: 18.7500 (22.4670)\n",
      "[2/25][616/782] Loss_D: 0.1121 (0.6710) Loss_G: 0.1393 (0.5511) D(x): 0.5293 D(G(z)): 0.4020 / 0.4224 Acc: 31.2500 (22.4711)\n",
      "[2/25][617/782] Loss_D: 0.1647 (0.6707) Loss_G: 0.1754 (0.5510) D(x): 0.5177 D(G(z)): 0.4108 / 0.3767 Acc: 25.0000 (22.4722)\n",
      "[2/25][618/782] Loss_D: 0.3206 (0.6706) Loss_G: 0.0977 (0.5507) D(x): 0.5545 D(G(z)): 0.4700 / 0.4506 Acc: 25.0000 (22.4734)\n",
      "[2/25][619/782] Loss_D: 0.5621 (0.6705) Loss_G: 0.1867 (0.5506) D(x): 0.4792 D(G(z)): 0.5056 / 0.4293 Acc: 29.6875 (22.4767)\n",
      "[2/25][620/782] Loss_D: 0.2077 (0.6703) Loss_G: 0.5953 (0.5506) D(x): 0.6020 D(G(z)): 0.5071 / 0.2904 Acc: 39.0625 (22.4843)\n",
      "[2/25][621/782] Loss_D: 0.3118 (0.6701) Loss_G: 0.1206 (0.5504) D(x): 0.4774 D(G(z)): 0.3771 / 0.4641 Acc: 28.1250 (22.4868)\n",
      "[2/25][622/782] Loss_D: 0.3944 (0.6700) Loss_G: 0.1579 (0.5502) D(x): 0.5033 D(G(z)): 0.4371 / 0.4383 Acc: 23.4375 (22.4873)\n",
      "[2/25][623/782] Loss_D: 0.4263 (0.6699) Loss_G: 0.4366 (0.5502) D(x): 0.5483 D(G(z)): 0.5511 / 0.3272 Acc: 31.2500 (22.4913)\n",
      "[2/25][624/782] Loss_D: 0.3284 (0.6697) Loss_G: 0.1661 (0.5500) D(x): 0.4734 D(G(z)): 0.4462 / 0.4343 Acc: 39.0625 (22.4989)\n",
      "[2/25][625/782] Loss_D: 0.3024 (0.6696) Loss_G: 0.1191 (0.5498) D(x): 0.4950 D(G(z)): 0.4491 / 0.4418 Acc: 34.3750 (22.5043)\n",
      "[2/25][626/782] Loss_D: 0.4371 (0.6695) Loss_G: 0.1871 (0.5496) D(x): 0.5342 D(G(z)): 0.5431 / 0.4418 Acc: 35.9375 (22.5104)\n",
      "[2/25][627/782] Loss_D: 0.3252 (0.6693) Loss_G: 0.2225 (0.5495) D(x): 0.5349 D(G(z)): 0.4645 / 0.4118 Acc: 29.6875 (22.5137)\n",
      "[2/25][628/782] Loss_D: 0.5503 (0.6693) Loss_G: 0.0251 (0.5492) D(x): 0.4667 D(G(z)): 0.4806 / 0.4893 Acc: 23.4375 (22.5141)\n",
      "[2/25][629/782] Loss_D: 0.5817 (0.6692) Loss_G: 0.0567 (0.5490) D(x): 0.5170 D(G(z)): 0.5583 / 0.5081 Acc: 34.3750 (22.5195)\n",
      "[2/25][630/782] Loss_D: 0.6679 (0.6692) Loss_G: 0.1014 (0.5488) D(x): 0.5030 D(G(z)): 0.5449 / 0.4997 Acc: 28.1250 (22.5221)\n",
      "[2/25][631/782] Loss_D: 0.3209 (0.6691) Loss_G: 0.0256 (0.5486) D(x): 0.5520 D(G(z)): 0.5145 / 0.4561 Acc: 29.6875 (22.5253)\n",
      "[2/25][632/782] Loss_D: 0.4114 (0.6689) Loss_G: 0.1093 (0.5484) D(x): 0.5126 D(G(z)): 0.4622 / 0.4301 Acc: 25.0000 (22.5265)\n",
      "[2/25][633/782] Loss_D: 0.4509 (0.6688) Loss_G: 0.1147 (0.5482) D(x): 0.5216 D(G(z)): 0.5059 / 0.4423 Acc: 28.1250 (22.5290)\n",
      "[2/25][634/782] Loss_D: 0.5519 (0.6688) Loss_G: 0.0118 (0.5479) D(x): 0.4326 D(G(z)): 0.4538 / 0.4554 Acc: 18.7500 (22.5273)\n",
      "[2/25][635/782] Loss_D: 0.4654 (0.6687) Loss_G: 0.0926 (0.5477) D(x): 0.5927 D(G(z)): 0.5231 / 0.4673 Acc: 18.7500 (22.5256)\n",
      "[2/25][636/782] Loss_D: 0.0461 (0.6684) Loss_G: 0.0569 (0.5475) D(x): 0.5682 D(G(z)): 0.3899 / 0.4433 Acc: 31.2500 (22.5295)\n",
      "[2/25][637/782] Loss_D: 0.3969 (0.6683) Loss_G: 0.1204 (0.5473) D(x): 0.4779 D(G(z)): 0.4653 / 0.4574 Acc: 34.3750 (22.5349)\n",
      "[2/25][638/782] Loss_D: 0.3771 (0.6682) Loss_G: 0.3306 (0.5472) D(x): 0.5653 D(G(z)): 0.5199 / 0.3755 Acc: 28.1250 (22.5374)\n",
      "[2/25][639/782] Loss_D: 0.3693 (0.6680) Loss_G: 0.3078 (0.5471) D(x): 0.5095 D(G(z)): 0.4199 / 0.3856 Acc: 20.3125 (22.5364)\n",
      "[2/25][640/782] Loss_D: 0.3197 (0.6679) Loss_G: 0.1527 (0.5469) D(x): 0.5469 D(G(z)): 0.4656 / 0.4176 Acc: 25.0000 (22.5376)\n",
      "[2/25][641/782] Loss_D: 0.1816 (0.6676) Loss_G: 0.0926 (0.5467) D(x): 0.5489 D(G(z)): 0.4529 / 0.4129 Acc: 25.0000 (22.5387)\n",
      "[2/25][642/782] Loss_D: 0.3617 (0.6675) Loss_G: 0.1080 (0.5465) D(x): 0.5370 D(G(z)): 0.4896 / 0.4374 Acc: 25.0000 (22.5398)\n",
      "[2/25][643/782] Loss_D: 0.1502 (0.6673) Loss_G: 0.1153 (0.5463) D(x): 0.5212 D(G(z)): 0.4221 / 0.4310 Acc: 37.5000 (22.5466)\n",
      "[2/25][644/782] Loss_D: 0.1025 (0.6670) Loss_G: 0.0925 (0.5461) D(x): 0.6037 D(G(z)): 0.4465 / 0.4457 Acc: 29.6875 (22.5498)\n",
      "[2/25][645/782] Loss_D: 0.2886 (0.6668) Loss_G: 0.2252 (0.5460) D(x): 0.5654 D(G(z)): 0.4695 / 0.3974 Acc: 23.4375 (22.5502)\n",
      "[2/25][646/782] Loss_D: 0.4486 (0.6667) Loss_G: 0.1604 (0.5458) D(x): 0.5111 D(G(z)): 0.4762 / 0.3978 Acc: 17.1875 (22.5478)\n",
      "[2/25][647/782] Loss_D: 0.3004 (0.6666) Loss_G: 0.1998 (0.5457) D(x): 0.4901 D(G(z)): 0.4128 / 0.4112 Acc: 28.1250 (22.5503)\n",
      "[2/25][648/782] Loss_D: 0.3386 (0.6664) Loss_G: 0.0409 (0.5454) D(x): 0.5941 D(G(z)): 0.5327 / 0.4643 Acc: 26.5625 (22.5521)\n",
      "[2/25][649/782] Loss_D: 0.4113 (0.6663) Loss_G: 0.1807 (0.5453) D(x): 0.4713 D(G(z)): 0.4994 / 0.4135 Acc: 39.0625 (22.5596)\n",
      "[2/25][650/782] Loss_D: 0.3011 (0.6662) Loss_G: 0.3408 (0.5452) D(x): 0.5633 D(G(z)): 0.4763 / 0.3774 Acc: 28.1250 (22.5621)\n",
      "[2/25][651/782] Loss_D: 0.7251 (0.6662) Loss_G: 0.1682 (0.5450) D(x): 0.4182 D(G(z)): 0.5116 / 0.4482 Acc: 29.6875 (22.5653)\n",
      "[2/25][652/782] Loss_D: 0.4881 (0.6661) Loss_G: 0.1272 (0.5448) D(x): 0.5217 D(G(z)): 0.5069 / 0.4659 Acc: 26.5625 (22.5671)\n",
      "[2/25][653/782] Loss_D: 0.4297 (0.6660) Loss_G: 0.0123 (0.5446) D(x): 0.5458 D(G(z)): 0.5093 / 0.5063 Acc: 29.6875 (22.5703)\n",
      "[2/25][654/782] Loss_D: 0.2359 (0.6658) Loss_G: 0.2672 (0.5444) D(x): 0.6463 D(G(z)): 0.5023 / 0.4029 Acc: 28.1250 (22.5728)\n",
      "[2/25][655/782] Loss_D: 0.3382 (0.6657) Loss_G: 0.1268 (0.5443) D(x): 0.5153 D(G(z)): 0.4532 / 0.4253 Acc: 28.1250 (22.5753)\n",
      "[2/25][656/782] Loss_D: 0.2804 (0.6655) Loss_G: 0.2101 (0.5441) D(x): 0.5391 D(G(z)): 0.4322 / 0.3992 Acc: 23.4375 (22.5757)\n",
      "[2/25][657/782] Loss_D: 0.3166 (0.6653) Loss_G: 0.1438 (0.5439) D(x): 0.5165 D(G(z)): 0.4453 / 0.4325 Acc: 25.0000 (22.5768)\n",
      "[2/25][658/782] Loss_D: 0.1356 (0.6651) Loss_G: 0.1684 (0.5438) D(x): 0.6071 D(G(z)): 0.4534 / 0.4030 Acc: 23.4375 (22.5772)\n",
      "[2/25][659/782] Loss_D: 0.1629 (0.6649) Loss_G: 0.3083 (0.5436) D(x): 0.5849 D(G(z)): 0.4418 / 0.3613 Acc: 23.4375 (22.5776)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/25][660/782] Loss_D: 0.3956 (0.6647) Loss_G: 0.4154 (0.5436) D(x): 0.4872 D(G(z)): 0.4065 / 0.3679 Acc: 21.8750 (22.5772)\n",
      "[2/25][661/782] Loss_D: -0.0242 (0.6644) Loss_G: 0.0987 (0.5434) D(x): 0.5911 D(G(z)): 0.4023 / 0.4289 Acc: 35.9375 (22.5832)\n",
      "[2/25][662/782] Loss_D: 0.1280 (0.6642) Loss_G: 0.0929 (0.5432) D(x): 0.5938 D(G(z)): 0.4797 / 0.4463 Acc: 35.9375 (22.5892)\n",
      "[2/25][663/782] Loss_D: 0.4547 (0.6641) Loss_G: 0.0213 (0.5430) D(x): 0.4522 D(G(z)): 0.4599 / 0.4493 Acc: 29.6875 (22.5924)\n",
      "[2/25][664/782] Loss_D: 0.3290 (0.6639) Loss_G: 0.2937 (0.5428) D(x): 0.6143 D(G(z)): 0.5242 / 0.3680 Acc: 23.4375 (22.5928)\n",
      "[2/25][665/782] Loss_D: 0.0947 (0.6637) Loss_G: 0.2519 (0.5427) D(x): 0.5717 D(G(z)): 0.4321 / 0.3678 Acc: 25.0000 (22.5939)\n",
      "[2/25][666/782] Loss_D: 0.0645 (0.6634) Loss_G: 0.2930 (0.5426) D(x): 0.4922 D(G(z)): 0.3148 / 0.3687 Acc: 29.6875 (22.5971)\n",
      "[2/25][667/782] Loss_D: 0.1797 (0.6632) Loss_G: 0.1091 (0.5424) D(x): 0.5625 D(G(z)): 0.4426 / 0.4859 Acc: 35.9375 (22.6030)\n",
      "[2/25][668/782] Loss_D: 0.6166 (0.6632) Loss_G: -0.0710 (0.5421) D(x): 0.4811 D(G(z)): 0.5390 / 0.5423 Acc: 29.6875 (22.6062)\n",
      "[2/25][669/782] Loss_D: 0.3296 (0.6630) Loss_G: 0.1760 (0.5420) D(x): 0.6286 D(G(z)): 0.5420 / 0.4366 Acc: 31.2500 (22.6101)\n",
      "[2/25][670/782] Loss_D: 0.4011 (0.6629) Loss_G: 0.4179 (0.5419) D(x): 0.5604 D(G(z)): 0.4736 / 0.3370 Acc: 21.8750 (22.6098)\n",
      "[2/25][671/782] Loss_D: 0.5477 (0.6629) Loss_G: 0.0887 (0.5417) D(x): 0.3561 D(G(z)): 0.3665 / 0.4226 Acc: 32.8125 (22.6143)\n",
      "[2/25][672/782] Loss_D: 0.6363 (0.6628) Loss_G: -0.0116 (0.5415) D(x): 0.4720 D(G(z)): 0.4740 / 0.5248 Acc: 20.3125 (22.6133)\n",
      "[2/25][673/782] Loss_D: 0.3441 (0.6627) Loss_G: -0.0118 (0.5412) D(x): 0.5999 D(G(z)): 0.5204 / 0.4707 Acc: 18.7500 (22.6116)\n",
      "[2/25][674/782] Loss_D: 0.1441 (0.6625) Loss_G: 0.2486 (0.5411) D(x): 0.5469 D(G(z)): 0.4441 / 0.3685 Acc: 29.6875 (22.6147)\n",
      "[2/25][675/782] Loss_D: 0.0074 (0.6622) Loss_G: 0.2740 (0.5410) D(x): 0.5487 D(G(z)): 0.3796 / 0.3702 Acc: 32.8125 (22.6193)\n",
      "[2/25][676/782] Loss_D: 0.2419 (0.6620) Loss_G: 0.1106 (0.5408) D(x): 0.5043 D(G(z)): 0.4091 / 0.4265 Acc: 26.5625 (22.6210)\n",
      "[2/25][677/782] Loss_D: 0.4326 (0.6619) Loss_G: -0.0057 (0.5405) D(x): 0.4878 D(G(z)): 0.4874 / 0.5075 Acc: 31.2500 (22.6249)\n",
      "[2/25][678/782] Loss_D: 0.0892 (0.6616) Loss_G: 0.1384 (0.5403) D(x): 0.6489 D(G(z)): 0.4556 / 0.4269 Acc: 29.6875 (22.6280)\n",
      "[2/25][679/782] Loss_D: 0.1583 (0.6614) Loss_G: 0.2036 (0.5402) D(x): 0.5794 D(G(z)): 0.4442 / 0.4021 Acc: 28.1250 (22.6305)\n",
      "[2/25][680/782] Loss_D: 0.4573 (0.6613) Loss_G: 0.5486 (0.5402) D(x): 0.5453 D(G(z)): 0.5004 / 0.3269 Acc: 29.6875 (22.6336)\n",
      "[2/25][681/782] Loss_D: 0.4450 (0.6612) Loss_G: -0.2132 (0.5399) D(x): 0.4169 D(G(z)): 0.3955 / 0.5661 Acc: 29.6875 (22.6368)\n",
      "[2/25][682/782] Loss_D: 0.3737 (0.6611) Loss_G: 0.0441 (0.5396) D(x): 0.6414 D(G(z)): 0.5946 / 0.4689 Acc: 29.6875 (22.6399)\n",
      "[2/25][683/782] Loss_D: 0.1787 (0.6609) Loss_G: 0.3595 (0.5396) D(x): 0.5534 D(G(z)): 0.4373 / 0.3506 Acc: 25.0000 (22.6410)\n",
      "[2/25][684/782] Loss_D: 0.4191 (0.6608) Loss_G: 0.1259 (0.5394) D(x): 0.4392 D(G(z)): 0.4028 / 0.4747 Acc: 28.1250 (22.6434)\n",
      "[2/25][685/782] Loss_D: 0.4351 (0.6607) Loss_G: 0.1637 (0.5392) D(x): 0.4746 D(G(z)): 0.4383 / 0.4296 Acc: 21.8750 (22.6431)\n",
      "[2/25][686/782] Loss_D: 0.1640 (0.6605) Loss_G: 0.3212 (0.5391) D(x): 0.6923 D(G(z)): 0.4974 / 0.3709 Acc: 20.3125 (22.6420)\n",
      "[2/25][687/782] Loss_D: 0.3384 (0.6603) Loss_G: 0.2434 (0.5390) D(x): 0.4462 D(G(z)): 0.3999 / 0.3769 Acc: 25.0000 (22.6431)\n",
      "[2/25][688/782] Loss_D: 0.2771 (0.6601) Loss_G: -0.1569 (0.5387) D(x): 0.4046 D(G(z)): 0.4031 / 0.5201 Acc: 35.9375 (22.6490)\n",
      "[2/25][689/782] Loss_D: 0.5256 (0.6601) Loss_G: 0.1131 (0.5385) D(x): 0.5662 D(G(z)): 0.5898 / 0.4455 Acc: 28.1250 (22.6514)\n",
      "[2/25][690/782] Loss_D: 0.6292 (0.6601) Loss_G: 0.1191 (0.5383) D(x): 0.4819 D(G(z)): 0.5429 / 0.4239 Acc: 25.0000 (22.6524)\n",
      "[2/25][691/782] Loss_D: 0.6116 (0.6600) Loss_G: 0.2295 (0.5382) D(x): 0.4355 D(G(z)): 0.4803 / 0.4225 Acc: 28.1250 (22.6549)\n",
      "[2/25][692/782] Loss_D: 0.3229 (0.6599) Loss_G: 0.1157 (0.5380) D(x): 0.4551 D(G(z)): 0.3840 / 0.4352 Acc: 31.2500 (22.6587)\n",
      "[2/25][693/782] Loss_D: 0.4929 (0.6598) Loss_G: 0.2979 (0.5379) D(x): 0.5661 D(G(z)): 0.5041 / 0.3864 Acc: 17.1875 (22.6563)\n",
      "[2/25][694/782] Loss_D: 0.4128 (0.6597) Loss_G: 0.1841 (0.5377) D(x): 0.5024 D(G(z)): 0.4553 / 0.4533 Acc: 28.1250 (22.6587)\n",
      "[2/25][695/782] Loss_D: 0.2649 (0.6595) Loss_G: 0.2313 (0.5376) D(x): 0.5784 D(G(z)): 0.4827 / 0.4162 Acc: 29.6875 (22.6618)\n",
      "[2/25][696/782] Loss_D: 0.3020 (0.6594) Loss_G: 0.3070 (0.5375) D(x): 0.5865 D(G(z)): 0.4646 / 0.4113 Acc: 28.1250 (22.6642)\n",
      "[2/25][697/782] Loss_D: 0.2632 (0.6592) Loss_G: 0.3092 (0.5374) D(x): 0.4959 D(G(z)): 0.4351 / 0.3783 Acc: 32.8125 (22.6687)\n",
      "[2/25][698/782] Loss_D: 0.4648 (0.6591) Loss_G: 0.0476 (0.5372) D(x): 0.4401 D(G(z)): 0.4223 / 0.4662 Acc: 28.1250 (22.6711)\n",
      "[2/25][699/782] Loss_D: 0.5867 (0.6591) Loss_G: -0.0746 (0.5369) D(x): 0.5283 D(G(z)): 0.5742 / 0.5143 Acc: 23.4375 (22.6714)\n",
      "[2/25][700/782] Loss_D: 0.4116 (0.6590) Loss_G: 0.1752 (0.5367) D(x): 0.5976 D(G(z)): 0.5421 / 0.4342 Acc: 26.5625 (22.6732)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[2/25][701/782] Loss_D: 0.5331 (0.6589) Loss_G: 0.1106 (0.5365) D(x): 0.4469 D(G(z)): 0.4856 / 0.4426 Acc: 34.3750 (22.6783)\n",
      "[2/25][702/782] Loss_D: 0.1379 (0.6587) Loss_G: 0.1768 (0.5364) D(x): 0.5450 D(G(z)): 0.4430 / 0.4249 Acc: 43.7500 (22.6876)\n",
      "[2/25][703/782] Loss_D: 0.5657 (0.6587) Loss_G: 0.1029 (0.5362) D(x): 0.4919 D(G(z)): 0.4842 / 0.4596 Acc: 23.4375 (22.6879)\n",
      "[2/25][704/782] Loss_D: 0.4887 (0.6586) Loss_G: 0.1486 (0.5360) D(x): 0.5280 D(G(z)): 0.4955 / 0.4464 Acc: 21.8750 (22.6876)\n",
      "[2/25][705/782] Loss_D: 0.3191 (0.6584) Loss_G: 0.0398 (0.5358) D(x): 0.5181 D(G(z)): 0.4654 / 0.4714 Acc: 31.2500 (22.6914)\n",
      "[2/25][706/782] Loss_D: 0.2344 (0.6582) Loss_G: 0.2134 (0.5357) D(x): 0.5855 D(G(z)): 0.4752 / 0.4350 Acc: 29.6875 (22.6944)\n",
      "[2/25][707/782] Loss_D: 0.2618 (0.6581) Loss_G: 0.2226 (0.5355) D(x): 0.5696 D(G(z)): 0.4553 / 0.3927 Acc: 25.0000 (22.6955)\n",
      "[2/25][708/782] Loss_D: 0.4688 (0.6580) Loss_G: 0.1698 (0.5354) D(x): 0.4845 D(G(z)): 0.4703 / 0.4204 Acc: 25.0000 (22.6965)\n",
      "[2/25][709/782] Loss_D: 0.4315 (0.6579) Loss_G: 0.2191 (0.5352) D(x): 0.5121 D(G(z)): 0.4078 / 0.4328 Acc: 21.8750 (22.6961)\n",
      "[2/25][710/782] Loss_D: 0.2873 (0.6577) Loss_G: 0.0530 (0.5350) D(x): 0.5822 D(G(z)): 0.4432 / 0.4648 Acc: 17.1875 (22.6937)\n",
      "[2/25][711/782] Loss_D: 0.0589 (0.6575) Loss_G: 0.1268 (0.5348) D(x): 0.5786 D(G(z)): 0.4702 / 0.4084 Acc: 37.5000 (22.7002)\n",
      "[2/25][712/782] Loss_D: 0.3215 (0.6573) Loss_G: 0.2169 (0.5347) D(x): 0.5536 D(G(z)): 0.5124 / 0.4010 Acc: 34.3750 (22.7053)\n",
      "[2/25][713/782] Loss_D: 0.3709 (0.6572) Loss_G: 0.2639 (0.5346) D(x): 0.5017 D(G(z)): 0.4172 / 0.3991 Acc: 23.4375 (22.7056)\n",
      "[2/25][714/782] Loss_D: 0.4408 (0.6571) Loss_G: 0.2402 (0.5344) D(x): 0.5164 D(G(z)): 0.4557 / 0.4218 Acc: 23.4375 (22.7060)\n",
      "[2/25][715/782] Loss_D: 0.3928 (0.6570) Loss_G: 0.0022 (0.5342) D(x): 0.5314 D(G(z)): 0.5015 / 0.4810 Acc: 25.0000 (22.7070)\n",
      "[2/25][716/782] Loss_D: 0.4417 (0.6569) Loss_G: 0.1191 (0.5340) D(x): 0.5136 D(G(z)): 0.4850 / 0.4432 Acc: 21.8750 (22.7066)\n",
      "[2/25][717/782] Loss_D: 0.4033 (0.6568) Loss_G: 0.1669 (0.5339) D(x): 0.5142 D(G(z)): 0.5076 / 0.4441 Acc: 32.8125 (22.7110)\n",
      "[2/25][718/782] Loss_D: 0.3614 (0.6566) Loss_G: 0.1167 (0.5337) D(x): 0.4633 D(G(z)): 0.4384 / 0.4610 Acc: 35.9375 (22.7168)\n",
      "[2/25][719/782] Loss_D: 0.3996 (0.6565) Loss_G: 0.0925 (0.5335) D(x): 0.5273 D(G(z)): 0.5283 / 0.4588 Acc: 32.8125 (22.7212)\n",
      "[2/25][720/782] Loss_D: 0.5611 (0.6565) Loss_G: -0.0040 (0.5333) D(x): 0.4855 D(G(z)): 0.5255 / 0.5002 Acc: 32.8125 (22.7257)\n",
      "[2/25][721/782] Loss_D: 0.3358 (0.6563) Loss_G: 0.0938 (0.5331) D(x): 0.5472 D(G(z)): 0.5117 / 0.4472 Acc: 28.1250 (22.7280)\n",
      "[2/25][722/782] Loss_D: 0.5320 (0.6563) Loss_G: 0.0931 (0.5329) D(x): 0.4575 D(G(z)): 0.4925 / 0.4505 Acc: 25.0000 (22.7290)\n",
      "[2/25][723/782] Loss_D: 0.1442 (0.6561) Loss_G: 0.0887 (0.5327) D(x): 0.5517 D(G(z)): 0.4666 / 0.4242 Acc: 32.8125 (22.7334)\n",
      "[2/25][724/782] Loss_D: 0.1104 (0.6558) Loss_G: 0.0019 (0.5324) D(x): 0.5611 D(G(z)): 0.4463 / 0.4805 Acc: 34.3750 (22.7385)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/25][725/782] Loss_D: 0.2251 (0.6556) Loss_G: 0.0183 (0.5322) D(x): 0.5379 D(G(z)): 0.4693 / 0.4572 Acc: 31.2500 (22.7422)\n",
      "[2/25][726/782] Loss_D: 0.4514 (0.6556) Loss_G: 0.1544 (0.5321) D(x): 0.5637 D(G(z)): 0.4878 / 0.4225 Acc: 10.9375 (22.7371)\n",
      "[2/25][727/782] Loss_D: 0.2539 (0.6554) Loss_G: 0.1769 (0.5319) D(x): 0.5263 D(G(z)): 0.4694 / 0.4044 Acc: 32.8125 (22.7415)\n",
      "[2/25][728/782] Loss_D: 0.2715 (0.6552) Loss_G: 0.1001 (0.5317) D(x): 0.4956 D(G(z)): 0.4254 / 0.4187 Acc: 25.0000 (22.7424)\n",
      "[2/25][729/782] Loss_D: 0.1454 (0.6550) Loss_G: -0.0409 (0.5315) D(x): 0.5156 D(G(z)): 0.4161 / 0.4650 Acc: 28.1250 (22.7448)\n",
      "[2/25][730/782] Loss_D: 0.2664 (0.6548) Loss_G: 0.1110 (0.5313) D(x): 0.5598 D(G(z)): 0.4850 / 0.4488 Acc: 32.8125 (22.7492)\n",
      "[2/25][731/782] Loss_D: 0.2105 (0.6546) Loss_G: 0.2390 (0.5312) D(x): 0.5428 D(G(z)): 0.4758 / 0.4049 Acc: 39.0625 (22.7563)\n",
      "[2/25][732/782] Loss_D: 0.6047 (0.6546) Loss_G: 0.2111 (0.5310) D(x): 0.5039 D(G(z)): 0.5152 / 0.4605 Acc: 29.6875 (22.7593)\n",
      "[2/25][733/782] Loss_D: 0.3549 (0.6545) Loss_G: 0.1064 (0.5308) D(x): 0.5329 D(G(z)): 0.4525 / 0.4491 Acc: 18.7500 (22.7576)\n",
      "[2/25][734/782] Loss_D: 0.3527 (0.6543) Loss_G: 0.0665 (0.5306) D(x): 0.5083 D(G(z)): 0.4695 / 0.4615 Acc: 31.2500 (22.7613)\n",
      "[2/25][735/782] Loss_D: 0.2607 (0.6542) Loss_G: 0.2569 (0.5305) D(x): 0.5130 D(G(z)): 0.4514 / 0.3820 Acc: 31.2500 (22.7649)\n",
      "[2/25][736/782] Loss_D: 0.1369 (0.6539) Loss_G: 0.0464 (0.5303) D(x): 0.5622 D(G(z)): 0.4757 / 0.4496 Acc: 37.5000 (22.7713)\n",
      "[2/25][737/782] Loss_D: 0.5057 (0.6539) Loss_G: 0.1008 (0.5301) D(x): 0.5073 D(G(z)): 0.4992 / 0.4412 Acc: 17.1875 (22.7689)\n",
      "[2/25][738/782] Loss_D: 0.3086 (0.6537) Loss_G: 0.1100 (0.5299) D(x): 0.4741 D(G(z)): 0.4569 / 0.4187 Acc: 32.8125 (22.7733)\n",
      "[2/25][739/782] Loss_D: 0.2230 (0.6535) Loss_G: 0.0190 (0.5297) D(x): 0.5274 D(G(z)): 0.4723 / 0.4648 Acc: 31.2500 (22.7770)\n",
      "[2/25][740/782] Loss_D: 0.2457 (0.6534) Loss_G: 0.1127 (0.5295) D(x): 0.5450 D(G(z)): 0.5012 / 0.4331 Acc: 34.3750 (22.7820)\n",
      "[2/25][741/782] Loss_D: 0.3596 (0.6532) Loss_G: 0.3625 (0.5295) D(x): 0.5374 D(G(z)): 0.4315 / 0.3606 Acc: 17.1875 (22.7796)\n",
      "[2/25][742/782] Loss_D: 0.2146 (0.6530) Loss_G: 0.2133 (0.5293) D(x): 0.5034 D(G(z)): 0.4128 / 0.4042 Acc: 35.9375 (22.7853)\n",
      "[2/25][743/782] Loss_D: 0.2715 (0.6529) Loss_G: 0.0877 (0.5291) D(x): 0.5145 D(G(z)): 0.4674 / 0.4542 Acc: 37.5000 (22.7916)\n",
      "[2/25][744/782] Loss_D: 0.4107 (0.6528) Loss_G: 0.1383 (0.5290) D(x): 0.5616 D(G(z)): 0.5344 / 0.4478 Acc: 28.1250 (22.7940)\n",
      "[2/25][745/782] Loss_D: 0.2757 (0.6526) Loss_G: 0.1114 (0.5288) D(x): 0.5484 D(G(z)): 0.4731 / 0.4235 Acc: 21.8750 (22.7936)\n",
      "[2/25][746/782] Loss_D: 0.1789 (0.6524) Loss_G: 0.1976 (0.5286) D(x): 0.5313 D(G(z)): 0.4221 / 0.4131 Acc: 39.0625 (22.8006)\n",
      "[2/25][747/782] Loss_D: 0.1775 (0.6522) Loss_G: 0.0313 (0.5284) D(x): 0.5138 D(G(z)): 0.4437 / 0.4350 Acc: 32.8125 (22.8049)\n",
      "[2/25][748/782] Loss_D: 0.2404 (0.6520) Loss_G: 0.0166 (0.5282) D(x): 0.5622 D(G(z)): 0.4544 / 0.4775 Acc: 28.1250 (22.8072)\n",
      "[2/25][749/782] Loss_D: 0.4256 (0.6519) Loss_G: -0.0423 (0.5280) D(x): 0.5038 D(G(z)): 0.5155 / 0.4605 Acc: 21.8750 (22.8068)\n",
      "[2/25][750/782] Loss_D: 0.5022 (0.6519) Loss_G: 0.2443 (0.5278) D(x): 0.5409 D(G(z)): 0.5043 / 0.4219 Acc: 20.3125 (22.8058)\n",
      "[2/25][751/782] Loss_D: 0.1900 (0.6517) Loss_G: -0.0849 (0.5276) D(x): 0.5522 D(G(z)): 0.4743 / 0.4762 Acc: 31.2500 (22.8094)\n",
      "[2/25][752/782] Loss_D: 0.2659 (0.6515) Loss_G: -0.0215 (0.5273) D(x): 0.4803 D(G(z)): 0.4086 / 0.4704 Acc: 28.1250 (22.8117)\n",
      "[2/25][753/782] Loss_D: 0.3901 (0.6514) Loss_G: -0.0480 (0.5271) D(x): 0.5118 D(G(z)): 0.5122 / 0.5072 Acc: 29.6875 (22.8147)\n",
      "[2/25][754/782] Loss_D: 0.4215 (0.6513) Loss_G: 0.1067 (0.5269) D(x): 0.5178 D(G(z)): 0.5056 / 0.4528 Acc: 29.6875 (22.8176)\n",
      "[2/25][755/782] Loss_D: 0.4342 (0.6512) Loss_G: 0.2881 (0.5268) D(x): 0.5644 D(G(z)): 0.5630 / 0.3729 Acc: 23.4375 (22.8179)\n",
      "[2/25][756/782] Loss_D: 0.5573 (0.6512) Loss_G: 0.3262 (0.5267) D(x): 0.4765 D(G(z)): 0.4250 / 0.4193 Acc: 23.4375 (22.8182)\n",
      "[2/25][757/782] Loss_D: 0.4469 (0.6511) Loss_G: 0.2398 (0.5266) D(x): 0.5010 D(G(z)): 0.4563 / 0.4520 Acc: 31.2500 (22.8218)\n",
      "[2/25][758/782] Loss_D: 0.2926 (0.6509) Loss_G: 0.2798 (0.5265) D(x): 0.5326 D(G(z)): 0.4500 / 0.3960 Acc: 32.8125 (22.8261)\n",
      "[2/25][759/782] Loss_D: 0.3121 (0.6508) Loss_G: 0.0578 (0.5263) D(x): 0.5135 D(G(z)): 0.4600 / 0.4620 Acc: 28.1250 (22.8284)\n",
      "[2/25][760/782] Loss_D: 0.3393 (0.6506) Loss_G: 0.0351 (0.5261) D(x): 0.5819 D(G(z)): 0.5124 / 0.4903 Acc: 29.6875 (22.8313)\n",
      "[2/25][761/782] Loss_D: 0.2975 (0.6505) Loss_G: 0.1829 (0.5259) D(x): 0.5260 D(G(z)): 0.4655 / 0.4201 Acc: 32.8125 (22.8356)\n",
      "[2/25][762/782] Loss_D: 0.3877 (0.6504) Loss_G: 0.3015 (0.5258) D(x): 0.5455 D(G(z)): 0.5214 / 0.3888 Acc: 32.8125 (22.8399)\n",
      "[2/25][763/782] Loss_D: 0.2934 (0.6502) Loss_G: -0.0260 (0.5256) D(x): 0.4821 D(G(z)): 0.4182 / 0.4670 Acc: 25.0000 (22.8408)\n",
      "[2/25][764/782] Loss_D: 0.2404 (0.6500) Loss_G: 0.0344 (0.5254) D(x): 0.5317 D(G(z)): 0.4386 / 0.4537 Acc: 21.8750 (22.8404)\n",
      "[2/25][765/782] Loss_D: 0.2263 (0.6499) Loss_G: 0.1912 (0.5252) D(x): 0.5381 D(G(z)): 0.4326 / 0.4391 Acc: 32.8125 (22.8447)\n",
      "[2/25][766/782] Loss_D: 0.2756 (0.6497) Loss_G: 0.0590 (0.5250) D(x): 0.5718 D(G(z)): 0.4605 / 0.4816 Acc: 20.3125 (22.8436)\n",
      "[2/25][767/782] Loss_D: 0.2429 (0.6495) Loss_G: 0.0608 (0.5248) D(x): 0.5463 D(G(z)): 0.4732 / 0.4657 Acc: 29.6875 (22.8465)\n",
      "[2/25][768/782] Loss_D: 0.2632 (0.6494) Loss_G: 0.1330 (0.5247) D(x): 0.5833 D(G(z)): 0.4753 / 0.4231 Acc: 23.4375 (22.8468)\n",
      "[2/25][769/782] Loss_D: 0.0959 (0.6491) Loss_G: 0.1728 (0.5245) D(x): 0.5644 D(G(z)): 0.4225 / 0.4127 Acc: 31.2500 (22.8504)\n",
      "[2/25][770/782] Loss_D: 0.3725 (0.6490) Loss_G: 0.2350 (0.5244) D(x): 0.5490 D(G(z)): 0.4618 / 0.4258 Acc: 29.6875 (22.8533)\n",
      "[2/25][771/782] Loss_D: 0.2344 (0.6488) Loss_G: 0.0976 (0.5242) D(x): 0.5425 D(G(z)): 0.4309 / 0.4663 Acc: 29.6875 (22.8562)\n",
      "[2/25][772/782] Loss_D: 0.4973 (0.6488) Loss_G: 0.2496 (0.5241) D(x): 0.5097 D(G(z)): 0.5087 / 0.4142 Acc: 23.4375 (22.8565)\n",
      "[2/25][773/782] Loss_D: 0.2926 (0.6486) Loss_G: 0.1687 (0.5239) D(x): 0.5421 D(G(z)): 0.4423 / 0.4491 Acc: 29.6875 (22.8594)\n",
      "[2/25][774/782] Loss_D: 0.3556 (0.6485) Loss_G: 0.1588 (0.5238) D(x): 0.4873 D(G(z)): 0.4400 / 0.4058 Acc: 20.3125 (22.8583)\n",
      "[2/25][775/782] Loss_D: 0.2127 (0.6483) Loss_G: 0.0799 (0.5236) D(x): 0.5642 D(G(z)): 0.4752 / 0.4551 Acc: 35.9375 (22.8639)\n",
      "[2/25][776/782] Loss_D: 0.2358 (0.6481) Loss_G: 0.0895 (0.5234) D(x): 0.5828 D(G(z)): 0.4620 / 0.4321 Acc: 17.1875 (22.8615)\n",
      "[2/25][777/782] Loss_D: 0.1920 (0.6479) Loss_G: 0.4065 (0.5234) D(x): 0.5518 D(G(z)): 0.4448 / 0.3594 Acc: 37.5000 (22.8677)\n",
      "[2/25][778/782] Loss_D: 0.0208 (0.6477) Loss_G: 0.1943 (0.5232) D(x): 0.5243 D(G(z)): 0.3824 / 0.4158 Acc: 42.1875 (22.8760)\n",
      "[2/25][779/782] Loss_D: 0.1505 (0.6474) Loss_G: 0.0204 (0.5230) D(x): 0.5370 D(G(z)): 0.4363 / 0.4559 Acc: 32.8125 (22.8802)\n",
      "[2/25][780/782] Loss_D: 0.0495 (0.6472) Loss_G: 0.2264 (0.5229) D(x): 0.5869 D(G(z)): 0.4517 / 0.4030 Acc: 37.5000 (22.8865)\n",
      "[2/25][781/782] Loss_D: 0.7454 (0.6472) Loss_G: 0.2765 (0.5228) D(x): 0.4128 D(G(z)): 0.4970 / 0.4663 Acc: 37.5000 (22.8927)\n",
      "[3/25][0/782] Loss_D: 0.2787 (0.6471) Loss_G: 0.2642 (0.5227) D(x): 0.6081 D(G(z)): 0.5303 / 0.3901 Acc: 32.8125 (22.8969)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[3/25][1/782] Loss_D: 0.2473 (0.6469) Loss_G: 0.3000 (0.5226) D(x): 0.5225 D(G(z)): 0.4465 / 0.3888 Acc: 32.8125 (22.9011)\n",
      "[3/25][2/782] Loss_D: 0.1792 (0.6467) Loss_G: 0.0975 (0.5224) D(x): 0.5166 D(G(z)): 0.4131 / 0.4466 Acc: 35.9375 (22.9067)\n",
      "[3/25][3/782] Loss_D: 0.3542 (0.6466) Loss_G: 0.2370 (0.5223) D(x): 0.5756 D(G(z)): 0.5039 / 0.4119 Acc: 31.2500 (22.9102)\n",
      "[3/25][4/782] Loss_D: 0.4718 (0.6465) Loss_G: 0.0899 (0.5221) D(x): 0.5054 D(G(z)): 0.4315 / 0.4702 Acc: 15.6250 (22.9071)\n",
      "[3/25][5/782] Loss_D: 0.0950 (0.6463) Loss_G: 0.0572 (0.5219) D(x): 0.5192 D(G(z)): 0.3800 / 0.4486 Acc: 32.8125 (22.9114)\n",
      "[3/25][6/782] Loss_D: 0.3577 (0.6461) Loss_G: 0.0354 (0.5217) D(x): 0.5523 D(G(z)): 0.4982 / 0.4714 Acc: 26.5625 (22.9129)\n",
      "[3/25][7/782] Loss_D: 0.2311 (0.6460) Loss_G: 0.1813 (0.5215) D(x): 0.5800 D(G(z)): 0.4800 / 0.4186 Acc: 28.1250 (22.9151)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/25][8/782] Loss_D: 0.1932 (0.6458) Loss_G: 0.1909 (0.5214) D(x): 0.5384 D(G(z)): 0.4376 / 0.3997 Acc: 23.4375 (22.9153)\n",
      "[3/25][9/782] Loss_D: 0.4214 (0.6457) Loss_G: 0.0470 (0.5212) D(x): 0.5214 D(G(z)): 0.4500 / 0.4592 Acc: 12.5000 (22.9109)\n",
      "[3/25][10/782] Loss_D: 0.3240 (0.6455) Loss_G: 0.1235 (0.5210) D(x): 0.5193 D(G(z)): 0.4300 / 0.4650 Acc: 26.5625 (22.9125)\n",
      "[3/25][11/782] Loss_D: 0.2859 (0.6454) Loss_G: 0.0932 (0.5208) D(x): 0.5633 D(G(z)): 0.4806 / 0.4294 Acc: 23.4375 (22.9127)\n",
      "[3/25][12/782] Loss_D: 0.2879 (0.6452) Loss_G: 0.0773 (0.5206) D(x): 0.5266 D(G(z)): 0.4968 / 0.4717 Acc: 37.5000 (22.9189)\n",
      "[3/25][13/782] Loss_D: 0.1748 (0.6450) Loss_G: 0.2271 (0.5205) D(x): 0.5532 D(G(z)): 0.4660 / 0.3892 Acc: 34.3750 (22.9237)\n",
      "[3/25][14/782] Loss_D: 0.3578 (0.6449) Loss_G: 0.2345 (0.5204) D(x): 0.5516 D(G(z)): 0.4611 / 0.4309 Acc: 29.6875 (22.9266)\n",
      "[3/25][15/782] Loss_D: 0.0875 (0.6447) Loss_G: 0.2379 (0.5203) D(x): 0.5807 D(G(z)): 0.4111 / 0.3826 Acc: 25.0000 (22.9275)\n",
      "[3/25][16/782] Loss_D: 0.1145 (0.6445) Loss_G: 0.0878 (0.5201) D(x): 0.5233 D(G(z)): 0.4019 / 0.4258 Acc: 35.9375 (22.9330)\n",
      "[3/25][17/782] Loss_D: 0.2246 (0.6443) Loss_G: 0.1932 (0.5200) D(x): 0.5627 D(G(z)): 0.4349 / 0.4188 Acc: 28.1250 (22.9352)\n",
      "[3/25][18/782] Loss_D: 0.2279 (0.6441) Loss_G: 0.1966 (0.5198) D(x): 0.5524 D(G(z)): 0.4609 / 0.4094 Acc: 29.6875 (22.9380)\n",
      "[3/25][19/782] Loss_D: 0.3462 (0.6440) Loss_G: 0.1210 (0.5197) D(x): 0.5208 D(G(z)): 0.4379 / 0.4491 Acc: 25.0000 (22.9389)\n",
      "[3/25][20/782] Loss_D: 0.1064 (0.6438) Loss_G: -0.0333 (0.5194) D(x): 0.5652 D(G(z)): 0.4598 / 0.4871 Acc: 37.5000 (22.9451)\n",
      "[3/25][21/782] Loss_D: 0.3368 (0.6436) Loss_G: 0.0871 (0.5192) D(x): 0.5530 D(G(z)): 0.4917 / 0.4482 Acc: 26.5625 (22.9466)\n",
      "[3/25][22/782] Loss_D: 0.3963 (0.6435) Loss_G: 0.1531 (0.5191) D(x): 0.5490 D(G(z)): 0.5213 / 0.4445 Acc: 34.3750 (22.9514)\n",
      "[3/25][23/782] Loss_D: 0.3506 (0.6434) Loss_G: 0.1922 (0.5189) D(x): 0.5380 D(G(z)): 0.4545 / 0.4090 Acc: 23.4375 (22.9516)\n",
      "[3/25][24/782] Loss_D: 0.3743 (0.6433) Loss_G: 0.0601 (0.5188) D(x): 0.5188 D(G(z)): 0.4826 / 0.4761 Acc: 29.6875 (22.9544)\n",
      "[3/25][25/782] Loss_D: 0.5369 (0.6432) Loss_G: 0.2699 (0.5187) D(x): 0.5151 D(G(z)): 0.4799 / 0.3945 Acc: 14.0625 (22.9507)\n",
      "[3/25][26/782] Loss_D: 0.3978 (0.6431) Loss_G: 0.2064 (0.5185) D(x): 0.5328 D(G(z)): 0.4655 / 0.4301 Acc: 26.5625 (22.9522)\n",
      "[3/25][27/782] Loss_D: 0.5111 (0.6431) Loss_G: 0.0249 (0.5183) D(x): 0.5145 D(G(z)): 0.4975 / 0.5019 Acc: 21.8750 (22.9518)\n",
      "[3/25][28/782] Loss_D: 0.3795 (0.6430) Loss_G: 0.0856 (0.5181) D(x): 0.4707 D(G(z)): 0.4647 / 0.4376 Acc: 31.2500 (22.9553)\n",
      "[3/25][29/782] Loss_D: 0.4693 (0.6429) Loss_G: 0.0907 (0.5179) D(x): 0.5142 D(G(z)): 0.5215 / 0.4672 Acc: 32.8125 (22.9594)\n",
      "[3/25][30/782] Loss_D: 0.5972 (0.6429) Loss_G: 0.1833 (0.5178) D(x): 0.4422 D(G(z)): 0.5088 / 0.4541 Acc: 35.9375 (22.9649)\n",
      "[3/25][31/782] Loss_D: 0.4411 (0.6428) Loss_G: 0.0161 (0.5176) D(x): 0.4825 D(G(z)): 0.4840 / 0.4909 Acc: 26.5625 (22.9664)\n",
      "[3/25][32/782] Loss_D: 0.4313 (0.6427) Loss_G: 0.0070 (0.5174) D(x): 0.5282 D(G(z)): 0.5165 / 0.5130 Acc: 31.2500 (22.9699)\n",
      "[3/25][33/782] Loss_D: 0.4032 (0.6426) Loss_G: 0.2241 (0.5173) D(x): 0.5078 D(G(z)): 0.4596 / 0.4228 Acc: 29.6875 (22.9727)\n",
      "[3/25][34/782] Loss_D: 0.2939 (0.6425) Loss_G: 0.2424 (0.5171) D(x): 0.5247 D(G(z)): 0.4311 / 0.3931 Acc: 26.5625 (22.9742)\n",
      "[3/25][35/782] Loss_D: 0.2204 (0.6423) Loss_G: 0.0909 (0.5170) D(x): 0.5519 D(G(z)): 0.4347 / 0.4347 Acc: 26.5625 (22.9757)\n",
      "[3/25][36/782] Loss_D: 0.1979 (0.6421) Loss_G: 0.0631 (0.5168) D(x): 0.5519 D(G(z)): 0.4527 / 0.4295 Acc: 26.5625 (22.9772)\n",
      "[3/25][37/782] Loss_D: 0.3407 (0.6420) Loss_G: 0.2176 (0.5166) D(x): 0.5592 D(G(z)): 0.5125 / 0.4046 Acc: 29.6875 (22.9800)\n",
      "[3/25][38/782] Loss_D: 0.2023 (0.6418) Loss_G: 0.1986 (0.5165) D(x): 0.5517 D(G(z)): 0.4509 / 0.4145 Acc: 34.3750 (22.9848)\n",
      "[3/25][39/782] Loss_D: 0.2552 (0.6416) Loss_G: 0.1779 (0.5164) D(x): 0.5013 D(G(z)): 0.4211 / 0.4370 Acc: 34.3750 (22.9896)\n",
      "[3/25][40/782] Loss_D: 0.0852 (0.6414) Loss_G: 0.2282 (0.5163) D(x): 0.5549 D(G(z)): 0.3861 / 0.3946 Acc: 26.5625 (22.9911)\n",
      "[3/25][41/782] Loss_D: 0.2837 (0.6412) Loss_G: 0.0521 (0.5161) D(x): 0.5580 D(G(z)): 0.4835 / 0.4776 Acc: 25.0000 (22.9919)\n",
      "[3/25][42/782] Loss_D: 0.1651 (0.6410) Loss_G: 0.1554 (0.5159) D(x): 0.6060 D(G(z)): 0.4693 / 0.4322 Acc: 29.6875 (22.9947)\n",
      "[3/25][43/782] Loss_D: 0.1666 (0.6408) Loss_G: 0.2035 (0.5158) D(x): 0.5504 D(G(z)): 0.4349 / 0.3838 Acc: 25.0000 (22.9956)\n",
      "[3/25][44/782] Loss_D: 0.3305 (0.6407) Loss_G: 0.2237 (0.5157) D(x): 0.5115 D(G(z)): 0.4223 / 0.4034 Acc: 21.8750 (22.9951)\n",
      "[3/25][45/782] Loss_D: 0.2568 (0.6405) Loss_G: 0.1413 (0.5155) D(x): 0.5579 D(G(z)): 0.4448 / 0.4556 Acc: 37.5000 (23.0011)\n",
      "[3/25][46/782] Loss_D: 0.4123 (0.6405) Loss_G: 0.1184 (0.5153) D(x): 0.5076 D(G(z)): 0.4583 / 0.4782 Acc: 28.1250 (23.0033)\n",
      "[3/25][47/782] Loss_D: 0.3266 (0.6403) Loss_G: 0.0985 (0.5152) D(x): 0.5276 D(G(z)): 0.4537 / 0.4543 Acc: 34.3750 (23.0080)\n",
      "[3/25][48/782] Loss_D: 0.3036 (0.6402) Loss_G: 0.2644 (0.5151) D(x): 0.5730 D(G(z)): 0.4846 / 0.4107 Acc: 29.6875 (23.0108)\n",
      "[3/25][49/782] Loss_D: 0.4471 (0.6401) Loss_G: 0.2547 (0.5149) D(x): 0.5945 D(G(z)): 0.5184 / 0.3928 Acc: 17.1875 (23.0084)\n",
      "[3/25][50/782] Loss_D: 0.1762 (0.6399) Loss_G: 0.0478 (0.5148) D(x): 0.4893 D(G(z)): 0.4021 / 0.4221 Acc: 28.1250 (23.0105)\n",
      "[3/25][51/782] Loss_D: 0.3064 (0.6398) Loss_G: 0.0910 (0.5146) D(x): 0.5777 D(G(z)): 0.4786 / 0.4431 Acc: 20.3125 (23.0094)\n",
      "[3/25][52/782] Loss_D: 0.3377 (0.6396) Loss_G: 0.0760 (0.5144) D(x): 0.4928 D(G(z)): 0.4691 / 0.4488 Acc: 28.1250 (23.0115)\n",
      "[3/25][53/782] Loss_D: 0.4667 (0.6396) Loss_G: 0.0825 (0.5142) D(x): 0.4889 D(G(z)): 0.4981 / 0.4809 Acc: 34.3750 (23.0163)\n",
      "[3/25][54/782] Loss_D: 0.6110 (0.6396) Loss_G: -0.0169 (0.5140) D(x): 0.5032 D(G(z)): 0.5869 / 0.5226 Acc: 32.8125 (23.0204)\n",
      "[3/25][55/782] Loss_D: 0.3815 (0.6394) Loss_G: -0.0123 (0.5138) D(x): 0.5244 D(G(z)): 0.5128 / 0.4719 Acc: 28.1250 (23.0225)\n",
      "[3/25][56/782] Loss_D: 0.3642 (0.6393) Loss_G: 0.0483 (0.5136) D(x): 0.5011 D(G(z)): 0.4409 / 0.4883 Acc: 31.2500 (23.0259)\n",
      "[3/25][57/782] Loss_D: 0.3598 (0.6392) Loss_G: 0.0368 (0.5134) D(x): 0.4973 D(G(z)): 0.3867 / 0.4978 Acc: 20.3125 (23.0248)\n",
      "[3/25][58/782] Loss_D: 0.2138 (0.6390) Loss_G: 0.1830 (0.5132) D(x): 0.5646 D(G(z)): 0.4598 / 0.4268 Acc: 29.6875 (23.0275)\n",
      "[3/25][59/782] Loss_D: 0.5608 (0.6390) Loss_G: -0.0325 (0.5130) D(x): 0.4816 D(G(z)): 0.5343 / 0.5032 Acc: 28.1250 (23.0297)\n",
      "[3/25][60/782] Loss_D: 0.4379 (0.6389) Loss_G: 0.2125 (0.5129) D(x): 0.5531 D(G(z)): 0.5050 / 0.4552 Acc: 25.0000 (23.0305)\n",
      "[3/25][61/782] Loss_D: 0.3469 (0.6388) Loss_G: 0.0299 (0.5127) D(x): 0.5796 D(G(z)): 0.5185 / 0.4613 Acc: 17.1875 (23.0281)\n",
      "[3/25][62/782] Loss_D: 0.1410 (0.6386) Loss_G: 0.0387 (0.5125) D(x): 0.5160 D(G(z)): 0.4099 / 0.4572 Acc: 32.8125 (23.0321)\n",
      "[3/25][63/782] Loss_D: 0.3726 (0.6385) Loss_G: -0.0942 (0.5122) D(x): 0.4298 D(G(z)): 0.5009 / 0.4758 Acc: 37.5000 (23.0381)\n",
      "[3/25][64/782] Loss_D: 0.1220 (0.6383) Loss_G: 0.0186 (0.5120) D(x): 0.5670 D(G(z)): 0.4602 / 0.4637 Acc: 31.2500 (23.0415)\n",
      "[3/25][65/782] Loss_D: 0.4582 (0.6382) Loss_G: -0.0688 (0.5118) D(x): 0.4865 D(G(z)): 0.4931 / 0.5221 Acc: 26.5625 (23.0430)\n",
      "[3/25][66/782] Loss_D: 0.3534 (0.6381) Loss_G: 0.1131 (0.5116) D(x): 0.5913 D(G(z)): 0.5427 / 0.4497 Acc: 28.1250 (23.0451)\n",
      "[3/25][67/782] Loss_D: 0.3023 (0.6379) Loss_G: 0.1124 (0.5115) D(x): 0.4697 D(G(z)): 0.4407 / 0.4436 Acc: 35.9375 (23.0504)\n",
      "[3/25][68/782] Loss_D: 0.2773 (0.6378) Loss_G: 0.1833 (0.5113) D(x): 0.5321 D(G(z)): 0.4743 / 0.4477 Acc: 35.9375 (23.0558)\n",
      "[3/25][69/782] Loss_D: 0.4405 (0.6377) Loss_G: 0.0817 (0.5112) D(x): 0.5003 D(G(z)): 0.4928 / 0.4761 Acc: 34.3750 (23.0605)\n",
      "[3/25][70/782] Loss_D: 0.6186 (0.6377) Loss_G: -0.0196 (0.5109) D(x): 0.4395 D(G(z)): 0.5270 / 0.4998 Acc: 29.6875 (23.0632)\n",
      "[3/25][71/782] Loss_D: 0.3694 (0.6376) Loss_G: -0.1100 (0.5107) D(x): 0.5239 D(G(z)): 0.4822 / 0.5040 Acc: 20.3125 (23.0621)\n",
      "[3/25][72/782] Loss_D: 0.2658 (0.6374) Loss_G: 0.0407 (0.5105) D(x): 0.5348 D(G(z)): 0.4581 / 0.4448 Acc: 23.4375 (23.0622)\n",
      "[3/25][73/782] Loss_D: 0.3277 (0.6373) Loss_G: 0.0766 (0.5103) D(x): 0.5666 D(G(z)): 0.5122 / 0.4328 Acc: 25.0000 (23.0630)\n",
      "[3/25][74/782] Loss_D: 0.3439 (0.6372) Loss_G: 0.2164 (0.5102) D(x): 0.5195 D(G(z)): 0.4493 / 0.4042 Acc: 25.0000 (23.0638)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/25][75/782] Loss_D: 0.1149 (0.6370) Loss_G: 0.1627 (0.5100) D(x): 0.5516 D(G(z)): 0.4432 / 0.4186 Acc: 32.8125 (23.0678)\n",
      "[3/25][76/782] Loss_D: 0.3215 (0.6368) Loss_G: 0.1532 (0.5099) D(x): 0.4861 D(G(z)): 0.4470 / 0.4331 Acc: 40.6250 (23.0751)\n",
      "[3/25][77/782] Loss_D: 0.1964 (0.6367) Loss_G: 0.0373 (0.5097) D(x): 0.4830 D(G(z)): 0.4180 / 0.4620 Acc: 39.0625 (23.0817)\n",
      "[3/25][78/782] Loss_D: 0.0959 (0.6364) Loss_G: 0.0331 (0.5095) D(x): 0.5948 D(G(z)): 0.4844 / 0.4816 Acc: 42.1875 (23.0896)\n",
      "[3/25][79/782] Loss_D: 0.4125 (0.6363) Loss_G: 0.0929 (0.5093) D(x): 0.5772 D(G(z)): 0.5561 / 0.4332 Acc: 25.0000 (23.0903)\n",
      "[3/25][80/782] Loss_D: 0.1697 (0.6362) Loss_G: 0.2398 (0.5092) D(x): 0.5095 D(G(z)): 0.3628 / 0.3800 Acc: 26.5625 (23.0918)\n",
      "[3/25][81/782] Loss_D: 0.3872 (0.6361) Loss_G: 0.2075 (0.5091) D(x): 0.5344 D(G(z)): 0.4475 / 0.4253 Acc: 26.5625 (23.0932)\n",
      "[3/25][82/782] Loss_D: 0.3516 (0.6359) Loss_G: 0.1706 (0.5090) D(x): 0.4968 D(G(z)): 0.4563 / 0.4074 Acc: 25.0000 (23.0940)\n",
      "[3/25][83/782] Loss_D: 0.2363 (0.6358) Loss_G: 0.1129 (0.5088) D(x): 0.6273 D(G(z)): 0.5168 / 0.4370 Acc: 26.5625 (23.0954)\n",
      "[3/25][84/782] Loss_D: 0.2060 (0.6356) Loss_G: 0.3554 (0.5087) D(x): 0.5797 D(G(z)): 0.4386 / 0.3518 Acc: 23.4375 (23.0956)\n",
      "[3/25][85/782] Loss_D: 0.2602 (0.6354) Loss_G: 0.0685 (0.5085) D(x): 0.5147 D(G(z)): 0.4171 / 0.4792 Acc: 29.6875 (23.0983)\n",
      "[3/25][86/782] Loss_D: 0.1875 (0.6353) Loss_G: 0.0317 (0.5083) D(x): 0.5589 D(G(z)): 0.4570 / 0.4639 Acc: 26.5625 (23.0997)\n",
      "[3/25][87/782] Loss_D: 0.1974 (0.6351) Loss_G: 0.3641 (0.5083) D(x): 0.5777 D(G(z)): 0.4452 / 0.3587 Acc: 25.0000 (23.1005)\n",
      "[3/25][88/782] Loss_D: 0.2218 (0.6349) Loss_G: 0.2367 (0.5082) D(x): 0.5010 D(G(z)): 0.4024 / 0.4109 Acc: 35.9375 (23.1057)\n",
      "[3/25][89/782] Loss_D: 0.5655 (0.6349) Loss_G: -0.0010 (0.5080) D(x): 0.4857 D(G(z)): 0.4516 / 0.5460 Acc: 20.3125 (23.1046)\n",
      "[3/25][90/782] Loss_D: 0.2493 (0.6347) Loss_G: 0.0868 (0.5078) D(x): 0.6017 D(G(z)): 0.4797 / 0.4748 Acc: 32.8125 (23.1086)\n",
      "[3/25][91/782] Loss_D: 0.2557 (0.6346) Loss_G: 0.1051 (0.5076) D(x): 0.5060 D(G(z)): 0.4445 / 0.4226 Acc: 29.6875 (23.1113)\n",
      "[3/25][92/782] Loss_D: 0.1985 (0.6344) Loss_G: 0.2102 (0.5075) D(x): 0.5643 D(G(z)): 0.4525 / 0.4163 Acc: 32.8125 (23.1153)\n",
      "[3/25][93/782] Loss_D: 0.1782 (0.6342) Loss_G: 0.0661 (0.5073) D(x): 0.5245 D(G(z)): 0.4291 / 0.4110 Acc: 23.4375 (23.1154)\n",
      "[3/25][94/782] Loss_D: 0.3229 (0.6341) Loss_G: 0.1873 (0.5072) D(x): 0.5295 D(G(z)): 0.4242 / 0.4249 Acc: 20.3125 (23.1142)\n",
      "[3/25][95/782] Loss_D: 0.2578 (0.6339) Loss_G: 0.2430 (0.5071) D(x): 0.5597 D(G(z)): 0.4938 / 0.4093 Acc: 34.3750 (23.1189)\n",
      "[3/25][96/782] Loss_D: 0.1047 (0.6337) Loss_G: 0.1194 (0.5069) D(x): 0.5748 D(G(z)): 0.4249 / 0.4459 Acc: 29.6875 (23.1215)\n",
      "[3/25][97/782] Loss_D: 0.3412 (0.6336) Loss_G: 0.1148 (0.5068) D(x): 0.5625 D(G(z)): 0.4891 / 0.4393 Acc: 25.0000 (23.1223)\n",
      "[3/25][98/782] Loss_D: 0.2612 (0.6334) Loss_G: 0.1482 (0.5066) D(x): 0.5676 D(G(z)): 0.4546 / 0.4466 Acc: 31.2500 (23.1256)\n",
      "[3/25][99/782] Loss_D: 0.2403 (0.6333) Loss_G: 0.3675 (0.5066) D(x): 0.5540 D(G(z)): 0.4832 / 0.3354 Acc: 31.2500 (23.1290)\n",
      "[3/25][100/782] Loss_D: 0.4313 (0.6332) Loss_G: 0.1096 (0.5064) D(x): 0.4253 D(G(z)): 0.3715 / 0.4285 Acc: 18.7500 (23.1272)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[3/25][101/782] Loss_D: 0.2487 (0.6330) Loss_G: 0.0591 (0.5062) D(x): 0.5361 D(G(z)): 0.4791 / 0.4829 Acc: 34.3750 (23.1318)\n",
      "[3/25][102/782] Loss_D: 0.3238 (0.6329) Loss_G: -0.0439 (0.5060) D(x): 0.5264 D(G(z)): 0.4930 / 0.4771 Acc: 25.0000 (23.1325)\n",
      "[3/25][103/782] Loss_D: 0.4693 (0.6328) Loss_G: 0.0205 (0.5058) D(x): 0.5225 D(G(z)): 0.5171 / 0.4773 Acc: 25.0000 (23.1333)\n",
      "[3/25][104/782] Loss_D: 0.4745 (0.6328) Loss_G: -0.0492 (0.5056) D(x): 0.5422 D(G(z)): 0.5318 / 0.5015 Acc: 26.5625 (23.1347)\n",
      "[3/25][105/782] Loss_D: 0.2832 (0.6326) Loss_G: 0.1323 (0.5054) D(x): 0.5348 D(G(z)): 0.4816 / 0.4261 Acc: 31.2500 (23.1380)\n",
      "[3/25][106/782] Loss_D: 0.1094 (0.6324) Loss_G: 0.2030 (0.5053) D(x): 0.5553 D(G(z)): 0.4320 / 0.4013 Acc: 34.3750 (23.1426)\n",
      "[3/25][107/782] Loss_D: 0.2147 (0.6322) Loss_G: 0.1055 (0.5051) D(x): 0.4993 D(G(z)): 0.3939 / 0.4190 Acc: 26.5625 (23.1440)\n",
      "[3/25][108/782] Loss_D: 0.0044 (0.6320) Loss_G: 0.0608 (0.5050) D(x): 0.5956 D(G(z)): 0.4357 / 0.4472 Acc: 35.9375 (23.1492)\n",
      "[3/25][109/782] Loss_D: 0.3130 (0.6319) Loss_G: 0.0855 (0.5048) D(x): 0.5410 D(G(z)): 0.4975 / 0.4626 Acc: 31.2500 (23.1525)\n",
      "[3/25][110/782] Loss_D: 0.3597 (0.6317) Loss_G: 0.1911 (0.5047) D(x): 0.4691 D(G(z)): 0.4398 / 0.4032 Acc: 32.8125 (23.1564)\n",
      "[3/25][111/782] Loss_D: 0.4996 (0.6317) Loss_G: -0.1277 (0.5044) D(x): 0.5349 D(G(z)): 0.5924 / 0.5483 Acc: 37.5000 (23.1623)\n",
      "[3/25][112/782] Loss_D: 0.6242 (0.6317) Loss_G: 0.0837 (0.5042) D(x): 0.4513 D(G(z)): 0.4931 / 0.4635 Acc: 20.3125 (23.1611)\n",
      "[3/25][113/782] Loss_D: 0.5875 (0.6317) Loss_G: 0.1315 (0.5041) D(x): 0.4853 D(G(z)): 0.5108 / 0.4881 Acc: 26.5625 (23.1625)\n",
      "[3/25][114/782] Loss_D: 0.6715 (0.6317) Loss_G: 0.0230 (0.5039) D(x): 0.4995 D(G(z)): 0.5656 / 0.5114 Acc: 26.5625 (23.1639)\n",
      "[3/25][115/782] Loss_D: 0.5624 (0.6317) Loss_G: -0.0474 (0.5037) D(x): 0.4790 D(G(z)): 0.4890 / 0.5583 Acc: 25.0000 (23.1646)\n",
      "[3/25][116/782] Loss_D: 0.3330 (0.6315) Loss_G: -0.1786 (0.5034) D(x): 0.5762 D(G(z)): 0.5812 / 0.4996 Acc: 28.1250 (23.1666)\n",
      "[3/25][117/782] Loss_D: 0.5828 (0.6315) Loss_G: -0.0671 (0.5031) D(x): 0.4553 D(G(z)): 0.4977 / 0.5020 Acc: 20.3125 (23.1655)\n",
      "[3/25][118/782] Loss_D: 0.4295 (0.6314) Loss_G: 0.1002 (0.5030) D(x): 0.4800 D(G(z)): 0.5010 / 0.4450 Acc: 34.3750 (23.1700)\n",
      "[3/25][119/782] Loss_D: 0.2106 (0.6313) Loss_G: -0.1809 (0.5027) D(x): 0.5060 D(G(z)): 0.4602 / 0.5222 Acc: 34.3750 (23.1745)\n",
      "[3/25][120/782] Loss_D: 0.4229 (0.6312) Loss_G: -0.0062 (0.5025) D(x): 0.5198 D(G(z)): 0.5294 / 0.4800 Acc: 32.8125 (23.1785)\n",
      "[3/25][121/782] Loss_D: 0.4980 (0.6311) Loss_G: 0.1345 (0.5023) D(x): 0.5005 D(G(z)): 0.4783 / 0.4231 Acc: 18.7500 (23.1767)\n",
      "[3/25][122/782] Loss_D: 0.3888 (0.6310) Loss_G: 0.0240 (0.5022) D(x): 0.5017 D(G(z)): 0.4735 / 0.4994 Acc: 29.6875 (23.1793)\n",
      "[3/25][123/782] Loss_D: 0.4637 (0.6310) Loss_G: 0.0258 (0.5020) D(x): 0.5486 D(G(z)): 0.5265 / 0.4924 Acc: 28.1250 (23.1813)\n",
      "[3/25][124/782] Loss_D: 0.3748 (0.6309) Loss_G: 0.0190 (0.5018) D(x): 0.5103 D(G(z)): 0.4764 / 0.4677 Acc: 23.4375 (23.1814)\n",
      "[3/25][125/782] Loss_D: 0.3512 (0.6307) Loss_G: -0.0102 (0.5016) D(x): 0.5271 D(G(z)): 0.4889 / 0.4808 Acc: 29.6875 (23.1840)\n",
      "[3/25][126/782] Loss_D: 0.2729 (0.6306) Loss_G: 0.0416 (0.5014) D(x): 0.5075 D(G(z)): 0.4607 / 0.4771 Acc: 31.2500 (23.1873)\n",
      "[3/25][127/782] Loss_D: 0.4415 (0.6305) Loss_G: 0.1226 (0.5012) D(x): 0.5235 D(G(z)): 0.5110 / 0.4417 Acc: 23.4375 (23.1874)\n",
      "[3/25][128/782] Loss_D: 0.4002 (0.6304) Loss_G: 0.0010 (0.5010) D(x): 0.4868 D(G(z)): 0.4412 / 0.4669 Acc: 25.0000 (23.1881)\n",
      "[3/25][129/782] Loss_D: 0.2893 (0.6303) Loss_G: 0.1097 (0.5009) D(x): 0.5322 D(G(z)): 0.4549 / 0.4515 Acc: 26.5625 (23.1895)\n",
      "[3/25][130/782] Loss_D: 0.4747 (0.6302) Loss_G: 0.0783 (0.5007) D(x): 0.5058 D(G(z)): 0.4984 / 0.4566 Acc: 18.7500 (23.1877)\n",
      "[3/25][131/782] Loss_D: 0.4996 (0.6302) Loss_G: 0.1090 (0.5005) D(x): 0.5145 D(G(z)): 0.5616 / 0.4469 Acc: 32.8125 (23.1916)\n",
      "[3/25][132/782] Loss_D: 0.3927 (0.6301) Loss_G: 0.0290 (0.5003) D(x): 0.4848 D(G(z)): 0.4635 / 0.4630 Acc: 25.0000 (23.1923)\n",
      "[3/25][133/782] Loss_D: 0.1778 (0.6299) Loss_G: 0.1328 (0.5002) D(x): 0.5195 D(G(z)): 0.4165 / 0.4321 Acc: 29.6875 (23.1949)\n",
      "[3/25][134/782] Loss_D: 0.4150 (0.6298) Loss_G: 0.0563 (0.5000) D(x): 0.4876 D(G(z)): 0.5064 / 0.4547 Acc: 29.6875 (23.1976)\n",
      "[3/25][135/782] Loss_D: 0.4372 (0.6297) Loss_G: 0.0807 (0.4998) D(x): 0.5298 D(G(z)): 0.5074 / 0.4636 Acc: 29.6875 (23.2002)\n",
      "[3/25][136/782] Loss_D: 0.2641 (0.6296) Loss_G: 0.0334 (0.4997) D(x): 0.5238 D(G(z)): 0.4608 / 0.4765 Acc: 32.8125 (23.2040)\n",
      "[3/25][137/782] Loss_D: 0.4801 (0.6295) Loss_G: 0.0960 (0.4995) D(x): 0.5000 D(G(z)): 0.4952 / 0.4665 Acc: 29.6875 (23.2066)\n",
      "[3/25][138/782] Loss_D: 0.4875 (0.6295) Loss_G: -0.0437 (0.4993) D(x): 0.5051 D(G(z)): 0.4922 / 0.4983 Acc: 20.3125 (23.2055)\n",
      "[3/25][139/782] Loss_D: 0.4806 (0.6294) Loss_G: 0.1478 (0.4991) D(x): 0.5118 D(G(z)): 0.4868 / 0.4246 Acc: 20.3125 (23.2043)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/25][140/782] Loss_D: 0.2657 (0.6293) Loss_G: -0.0461 (0.4989) D(x): 0.5097 D(G(z)): 0.4965 / 0.4923 Acc: 39.0625 (23.2107)\n",
      "[3/25][141/782] Loss_D: 0.4299 (0.6292) Loss_G: 0.1097 (0.4988) D(x): 0.5054 D(G(z)): 0.4746 / 0.4319 Acc: 21.8750 (23.2102)\n",
      "[3/25][142/782] Loss_D: 0.2927 (0.6290) Loss_G: 0.2271 (0.4986) D(x): 0.5814 D(G(z)): 0.5121 / 0.4113 Acc: 34.3750 (23.2146)\n",
      "[3/25][143/782] Loss_D: 0.1174 (0.6288) Loss_G: 0.1928 (0.4985) D(x): 0.5173 D(G(z)): 0.3669 / 0.4131 Acc: 32.8125 (23.2185)\n",
      "[3/25][144/782] Loss_D: 0.2404 (0.6287) Loss_G: 0.0126 (0.4983) D(x): 0.5738 D(G(z)): 0.4931 / 0.4434 Acc: 21.8750 (23.2180)\n",
      "[3/25][145/782] Loss_D: 0.3263 (0.6286) Loss_G: 0.0947 (0.4982) D(x): 0.5206 D(G(z)): 0.4564 / 0.4213 Acc: 20.3125 (23.2168)\n",
      "[3/25][146/782] Loss_D: 0.0234 (0.6283) Loss_G: 0.2592 (0.4981) D(x): 0.5888 D(G(z)): 0.4157 / 0.3620 Acc: 31.2500 (23.2200)\n",
      "[3/25][147/782] Loss_D: 0.1938 (0.6281) Loss_G: 0.1503 (0.4979) D(x): 0.5662 D(G(z)): 0.4657 / 0.4357 Acc: 32.8125 (23.2239)\n",
      "[3/25][148/782] Loss_D: 0.0168 (0.6279) Loss_G: 0.1845 (0.4978) D(x): 0.5598 D(G(z)): 0.4253 / 0.4045 Acc: 40.6250 (23.2308)\n",
      "[3/25][149/782] Loss_D: 0.3066 (0.6278) Loss_G: 0.0999 (0.4976) D(x): 0.5117 D(G(z)): 0.4475 / 0.4389 Acc: 23.4375 (23.2309)\n",
      "[3/25][150/782] Loss_D: 0.1998 (0.6276) Loss_G: 0.2245 (0.4975) D(x): 0.5619 D(G(z)): 0.4667 / 0.4133 Acc: 40.6250 (23.2379)\n",
      "[3/25][151/782] Loss_D: 0.2388 (0.6274) Loss_G: 0.1057 (0.4974) D(x): 0.5616 D(G(z)): 0.4481 / 0.4345 Acc: 26.5625 (23.2392)\n",
      "[3/25][152/782] Loss_D: 0.2081 (0.6273) Loss_G: 0.2205 (0.4973) D(x): 0.5256 D(G(z)): 0.4579 / 0.3911 Acc: 32.8125 (23.2430)\n",
      "[3/25][153/782] Loss_D: 0.3616 (0.6272) Loss_G: 0.1809 (0.4971) D(x): 0.4941 D(G(z)): 0.4539 / 0.4344 Acc: 31.2500 (23.2463)\n",
      "[3/25][154/782] Loss_D: 0.3024 (0.6270) Loss_G: 0.2156 (0.4970) D(x): 0.5534 D(G(z)): 0.4676 / 0.4495 Acc: 34.3750 (23.2507)\n",
      "[3/25][155/782] Loss_D: 0.0988 (0.6268) Loss_G: -0.0030 (0.4968) D(x): 0.5410 D(G(z)): 0.4060 / 0.4562 Acc: 26.5625 (23.2520)\n",
      "[3/25][156/782] Loss_D: 0.1861 (0.6267) Loss_G: 0.1280 (0.4967) D(x): 0.5970 D(G(z)): 0.4561 / 0.4315 Acc: 26.5625 (23.2533)\n",
      "[3/25][157/782] Loss_D: 0.1707 (0.6265) Loss_G: 0.2470 (0.4966) D(x): 0.5775 D(G(z)): 0.4328 / 0.4111 Acc: 34.3750 (23.2578)\n",
      "[3/25][158/782] Loss_D: 0.3133 (0.6263) Loss_G: 0.3212 (0.4965) D(x): 0.5594 D(G(z)): 0.5006 / 0.3791 Acc: 35.9375 (23.2628)\n",
      "[3/25][159/782] Loss_D: 0.1714 (0.6262) Loss_G: 0.1506 (0.4964) D(x): 0.4762 D(G(z)): 0.3985 / 0.4077 Acc: 34.3750 (23.2673)\n",
      "[3/25][160/782] Loss_D: 0.2891 (0.6260) Loss_G: -0.0937 (0.4961) D(x): 0.4701 D(G(z)): 0.4311 / 0.4869 Acc: 26.5625 (23.2686)\n",
      "[3/25][161/782] Loss_D: 0.2929 (0.6259) Loss_G: 0.1955 (0.4960) D(x): 0.5625 D(G(z)): 0.4972 / 0.4254 Acc: 34.3750 (23.2730)\n",
      "[3/25][162/782] Loss_D: 0.2338 (0.6257) Loss_G: 0.0915 (0.4959) D(x): 0.5329 D(G(z)): 0.4737 / 0.4337 Acc: 31.2500 (23.2762)\n",
      "[3/25][163/782] Loss_D: 0.2303 (0.6256) Loss_G: 0.1831 (0.4957) D(x): 0.5473 D(G(z)): 0.4510 / 0.4092 Acc: 31.2500 (23.2794)\n",
      "[3/25][164/782] Loss_D: 0.1553 (0.6254) Loss_G: 0.1058 (0.4956) D(x): 0.5479 D(G(z)): 0.4451 / 0.4125 Acc: 29.6875 (23.2819)\n",
      "[3/25][165/782] Loss_D: 0.1709 (0.6252) Loss_G: 0.0266 (0.4954) D(x): 0.5659 D(G(z)): 0.4576 / 0.4366 Acc: 21.8750 (23.2814)\n",
      "[3/25][166/782] Loss_D: 0.1941 (0.6250) Loss_G: 0.0565 (0.4952) D(x): 0.5422 D(G(z)): 0.4533 / 0.4534 Acc: 32.8125 (23.2852)\n",
      "[3/25][167/782] Loss_D: 0.4103 (0.6250) Loss_G: 0.1916 (0.4951) D(x): 0.5207 D(G(z)): 0.4962 / 0.4169 Acc: 25.0000 (23.2858)\n",
      "[3/25][168/782] Loss_D: 0.3174 (0.6248) Loss_G: -0.0553 (0.4949) D(x): 0.5056 D(G(z)): 0.4621 / 0.4759 Acc: 25.0000 (23.2865)\n",
      "[3/25][169/782] Loss_D: 0.4929 (0.6248) Loss_G: 0.1598 (0.4947) D(x): 0.4892 D(G(z)): 0.4993 / 0.4221 Acc: 29.6875 (23.2891)\n",
      "[3/25][170/782] Loss_D: 0.4412 (0.6247) Loss_G: 0.2437 (0.4946) D(x): 0.4735 D(G(z)): 0.4409 / 0.4161 Acc: 25.0000 (23.2898)\n",
      "[3/25][171/782] Loss_D: 0.3919 (0.6246) Loss_G: 0.0411 (0.4945) D(x): 0.5335 D(G(z)): 0.4977 / 0.4661 Acc: 20.3125 (23.2886)\n",
      "[3/25][172/782] Loss_D: 0.0888 (0.6244) Loss_G: 0.1013 (0.4943) D(x): 0.5236 D(G(z)): 0.4198 / 0.4038 Acc: 25.0000 (23.2893)\n",
      "[3/25][173/782] Loss_D: 0.3126 (0.6243) Loss_G: 0.0483 (0.4941) D(x): 0.5176 D(G(z)): 0.4881 / 0.4844 Acc: 37.5000 (23.2949)\n",
      "[3/25][174/782] Loss_D: 0.3595 (0.6242) Loss_G: 0.0394 (0.4940) D(x): 0.5530 D(G(z)): 0.5296 / 0.4725 Acc: 31.2500 (23.2980)\n",
      "[3/25][175/782] Loss_D: 0.2825 (0.6240) Loss_G: 0.1385 (0.4938) D(x): 0.5272 D(G(z)): 0.4316 / 0.4317 Acc: 23.4375 (23.2981)\n",
      "[3/25][176/782] Loss_D: 0.1564 (0.6239) Loss_G: 0.1923 (0.4937) D(x): 0.5724 D(G(z)): 0.4594 / 0.4088 Acc: 29.6875 (23.3006)\n",
      "[3/25][177/782] Loss_D: 0.4388 (0.6238) Loss_G: 0.0765 (0.4935) D(x): 0.4907 D(G(z)): 0.4611 / 0.4727 Acc: 25.0000 (23.3013)\n",
      "[3/25][178/782] Loss_D: 0.3425 (0.6237) Loss_G: 0.0675 (0.4934) D(x): 0.5019 D(G(z)): 0.4869 / 0.4666 Acc: 37.5000 (23.3069)\n",
      "[3/25][179/782] Loss_D: 0.2666 (0.6235) Loss_G: 0.1231 (0.4932) D(x): 0.5646 D(G(z)): 0.4841 / 0.4415 Acc: 29.6875 (23.3095)\n",
      "[3/25][180/782] Loss_D: 0.3465 (0.6234) Loss_G: 0.0630 (0.4930) D(x): 0.5225 D(G(z)): 0.4553 / 0.4593 Acc: 26.5625 (23.3107)\n",
      "[3/25][181/782] Loss_D: 0.2535 (0.6233) Loss_G: 0.1391 (0.4929) D(x): 0.5976 D(G(z)): 0.5159 / 0.4380 Acc: 34.3750 (23.3151)\n",
      "[3/25][182/782] Loss_D: 0.3074 (0.6232) Loss_G: 0.0865 (0.4927) D(x): 0.5143 D(G(z)): 0.4649 / 0.4489 Acc: 31.2500 (23.3183)\n",
      "[3/25][183/782] Loss_D: 0.3384 (0.6230) Loss_G: 0.1326 (0.4926) D(x): 0.5266 D(G(z)): 0.4898 / 0.4472 Acc: 35.9375 (23.3232)\n",
      "[3/25][184/782] Loss_D: 0.1331 (0.6228) Loss_G: 0.0479 (0.4924) D(x): 0.5385 D(G(z)): 0.4189 / 0.4505 Acc: 34.3750 (23.3276)\n",
      "[3/25][185/782] Loss_D: 0.3530 (0.6227) Loss_G: 0.0704 (0.4923) D(x): 0.5046 D(G(z)): 0.4489 / 0.4606 Acc: 28.1250 (23.3295)\n",
      "[3/25][186/782] Loss_D: 0.2733 (0.6226) Loss_G: 0.0445 (0.4921) D(x): 0.5376 D(G(z)): 0.4555 / 0.4710 Acc: 26.5625 (23.3308)\n",
      "[3/25][187/782] Loss_D: 0.4912 (0.6226) Loss_G: 0.0521 (0.4919) D(x): 0.5630 D(G(z)): 0.5456 / 0.4661 Acc: 21.8750 (23.3302)\n",
      "[3/25][188/782] Loss_D: 0.4256 (0.6225) Loss_G: 0.0965 (0.4918) D(x): 0.5060 D(G(z)): 0.4845 / 0.4433 Acc: 25.0000 (23.3309)\n",
      "[3/25][189/782] Loss_D: 0.1064 (0.6223) Loss_G: 0.0367 (0.4916) D(x): 0.5416 D(G(z)): 0.4173 / 0.4204 Acc: 23.4375 (23.3309)\n",
      "[3/25][190/782] Loss_D: 0.4796 (0.6222) Loss_G: 0.1872 (0.4915) D(x): 0.4741 D(G(z)): 0.4662 / 0.4244 Acc: 21.8750 (23.3303)\n",
      "[3/25][191/782] Loss_D: 0.3293 (0.6221) Loss_G: 0.0773 (0.4913) D(x): 0.5189 D(G(z)): 0.4612 / 0.4530 Acc: 28.1250 (23.3322)\n",
      "[3/25][192/782] Loss_D: 0.2162 (0.6219) Loss_G: 0.0228 (0.4911) D(x): 0.5681 D(G(z)): 0.4790 / 0.4549 Acc: 31.2500 (23.3353)\n",
      "[3/25][193/782] Loss_D: 0.4854 (0.6219) Loss_G: 0.1387 (0.4910) D(x): 0.4871 D(G(z)): 0.4677 / 0.4667 Acc: 31.2500 (23.3385)\n",
      "[3/25][194/782] Loss_D: 0.3229 (0.6218) Loss_G: 0.1576 (0.4908) D(x): 0.5506 D(G(z)): 0.4985 / 0.4279 Acc: 31.2500 (23.3416)\n",
      "[3/25][195/782] Loss_D: 0.4224 (0.6217) Loss_G: 0.1584 (0.4907) D(x): 0.5098 D(G(z)): 0.4593 / 0.4442 Acc: 25.0000 (23.3422)\n",
      "[3/25][196/782] Loss_D: 0.0313 (0.6215) Loss_G: 0.1291 (0.4906) D(x): 0.5582 D(G(z)): 0.4010 / 0.4157 Acc: 31.2500 (23.3453)\n",
      "[3/25][197/782] Loss_D: 0.2376 (0.6213) Loss_G: 0.1766 (0.4904) D(x): 0.5388 D(G(z)): 0.4219 / 0.4346 Acc: 26.5625 (23.3466)\n",
      "[3/25][198/782] Loss_D: 0.1398 (0.6211) Loss_G: 0.2250 (0.4903) D(x): 0.6000 D(G(z)): 0.4709 / 0.4347 Acc: 37.5000 (23.3522)\n",
      "[3/25][199/782] Loss_D: 0.2428 (0.6210) Loss_G: 0.2326 (0.4902) D(x): 0.5835 D(G(z)): 0.4619 / 0.3952 Acc: 28.1250 (23.3540)\n",
      "[3/25][200/782] Loss_D: 0.1144 (0.6208) Loss_G: 0.2074 (0.4901) D(x): 0.5775 D(G(z)): 0.4469 / 0.3879 Acc: 29.6875 (23.3565)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[3/25][201/782] Loss_D: 0.3371 (0.6207) Loss_G: 0.0494 (0.4899) D(x): 0.4649 D(G(z)): 0.4243 / 0.4367 Acc: 26.5625 (23.3578)\n",
      "[3/25][202/782] Loss_D: 0.3580 (0.6206) Loss_G: 0.2002 (0.4898) D(x): 0.5559 D(G(z)): 0.4836 / 0.4336 Acc: 34.3750 (23.3621)\n",
      "[3/25][203/782] Loss_D: 0.4020 (0.6205) Loss_G: 0.0653 (0.4897) D(x): 0.4707 D(G(z)): 0.4768 / 0.4646 Acc: 35.9375 (23.3670)\n",
      "[3/25][204/782] Loss_D: 0.1727 (0.6203) Loss_G: -0.0191 (0.4895) D(x): 0.5270 D(G(z)): 0.4396 / 0.4728 Acc: 35.9375 (23.3720)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/25][205/782] Loss_D: 0.5886 (0.6203) Loss_G: 0.0234 (0.4893) D(x): 0.5300 D(G(z)): 0.5490 / 0.4813 Acc: 23.4375 (23.3720)\n",
      "[3/25][206/782] Loss_D: 0.4486 (0.6202) Loss_G: 0.2169 (0.4892) D(x): 0.5071 D(G(z)): 0.5115 / 0.3935 Acc: 28.1250 (23.3738)\n",
      "[3/25][207/782] Loss_D: 0.4262 (0.6201) Loss_G: 0.1424 (0.4890) D(x): 0.5028 D(G(z)): 0.4270 / 0.4484 Acc: 20.3125 (23.3727)\n",
      "[3/25][208/782] Loss_D: 0.3332 (0.6200) Loss_G: 0.0004 (0.4889) D(x): 0.5211 D(G(z)): 0.4561 / 0.4831 Acc: 28.1250 (23.3745)\n",
      "[3/25][209/782] Loss_D: 0.2213 (0.6199) Loss_G: 0.0500 (0.4887) D(x): 0.5387 D(G(z)): 0.4609 / 0.4554 Acc: 31.2500 (23.3776)\n",
      "[3/25][210/782] Loss_D: 0.2610 (0.6197) Loss_G: -0.0009 (0.4885) D(x): 0.5667 D(G(z)): 0.5001 / 0.4498 Acc: 26.5625 (23.3788)\n",
      "[3/25][211/782] Loss_D: 0.1336 (0.6195) Loss_G: 0.1856 (0.4884) D(x): 0.5655 D(G(z)): 0.4407 / 0.4436 Acc: 35.9375 (23.3837)\n",
      "[3/25][212/782] Loss_D: 0.4403 (0.6195) Loss_G: 0.2111 (0.4883) D(x): 0.4862 D(G(z)): 0.4447 / 0.4139 Acc: 21.8750 (23.3832)\n",
      "[3/25][213/782] Loss_D: 0.1803 (0.6193) Loss_G: 0.0910 (0.4881) D(x): 0.5745 D(G(z)): 0.4833 / 0.4386 Acc: 35.9375 (23.3881)\n",
      "[3/25][214/782] Loss_D: 0.2167 (0.6191) Loss_G: 0.2369 (0.4880) D(x): 0.5950 D(G(z)): 0.4435 / 0.4098 Acc: 26.5625 (23.3893)\n",
      "[3/25][215/782] Loss_D: 0.2643 (0.6190) Loss_G: 0.3258 (0.4879) D(x): 0.5146 D(G(z)): 0.4378 / 0.3479 Acc: 29.6875 (23.3918)\n",
      "[3/25][216/782] Loss_D: 0.3954 (0.6189) Loss_G: 0.1889 (0.4878) D(x): 0.4553 D(G(z)): 0.3946 / 0.4567 Acc: 32.8125 (23.3954)\n",
      "[3/25][217/782] Loss_D: 0.2011 (0.6188) Loss_G: -0.0763 (0.4876) D(x): 0.5715 D(G(z)): 0.4740 / 0.5355 Acc: 34.3750 (23.3997)\n",
      "[3/25][218/782] Loss_D: 0.5732 (0.6187) Loss_G: 0.2182 (0.4875) D(x): 0.5563 D(G(z)): 0.5393 / 0.4501 Acc: 25.0000 (23.4003)\n",
      "[3/25][219/782] Loss_D: 0.2794 (0.6186) Loss_G: 0.4130 (0.4875) D(x): 0.5466 D(G(z)): 0.5114 / 0.3464 Acc: 40.6250 (23.4071)\n",
      "[3/25][220/782] Loss_D: 0.1809 (0.6184) Loss_G: 0.2553 (0.4874) D(x): 0.5180 D(G(z)): 0.4151 / 0.3924 Acc: 31.2500 (23.4101)\n",
      "[3/25][221/782] Loss_D: 0.4278 (0.6184) Loss_G: 0.1790 (0.4873) D(x): 0.4930 D(G(z)): 0.4577 / 0.4050 Acc: 21.8750 (23.4095)\n",
      "[3/25][222/782] Loss_D: 0.1173 (0.6182) Loss_G: 0.2429 (0.4872) D(x): 0.5531 D(G(z)): 0.4534 / 0.3640 Acc: 28.1250 (23.4113)\n",
      "[3/25][223/782] Loss_D: 0.2898 (0.6180) Loss_G: 0.0664 (0.4870) D(x): 0.5050 D(G(z)): 0.4476 / 0.4530 Acc: 26.5625 (23.4126)\n",
      "[3/25][224/782] Loss_D: 0.2547 (0.6179) Loss_G: 0.0819 (0.4868) D(x): 0.5156 D(G(z)): 0.4564 / 0.4352 Acc: 28.1250 (23.4144)\n",
      "[3/25][225/782] Loss_D: 0.4473 (0.6178) Loss_G: 0.1972 (0.4867) D(x): 0.5145 D(G(z)): 0.4752 / 0.4189 Acc: 23.4375 (23.4144)\n",
      "[3/25][226/782] Loss_D: 0.2045 (0.6177) Loss_G: 0.1746 (0.4866) D(x): 0.5341 D(G(z)): 0.4577 / 0.4041 Acc: 32.8125 (23.4181)\n",
      "[3/25][227/782] Loss_D: 0.2233 (0.6175) Loss_G: 0.1917 (0.4865) D(x): 0.5258 D(G(z)): 0.4433 / 0.4297 Acc: 35.9375 (23.4229)\n",
      "[3/25][228/782] Loss_D: 0.2877 (0.6174) Loss_G: 0.0681 (0.4863) D(x): 0.5228 D(G(z)): 0.4652 / 0.4362 Acc: 31.2500 (23.4260)\n",
      "[3/25][229/782] Loss_D: 0.1971 (0.6172) Loss_G: 0.0652 (0.4862) D(x): 0.5097 D(G(z)): 0.4604 / 0.4294 Acc: 34.3750 (23.4302)\n",
      "[3/25][230/782] Loss_D: 0.2151 (0.6171) Loss_G: -0.0768 (0.4860) D(x): 0.4955 D(G(z)): 0.4405 / 0.5074 Acc: 32.8125 (23.4339)\n",
      "[3/25][231/782] Loss_D: 0.3260 (0.6170) Loss_G: 0.1097 (0.4858) D(x): 0.5458 D(G(z)): 0.4714 / 0.4309 Acc: 21.8750 (23.4333)\n",
      "[3/25][232/782] Loss_D: 0.2938 (0.6168) Loss_G: 0.1262 (0.4857) D(x): 0.5564 D(G(z)): 0.4795 / 0.4285 Acc: 26.5625 (23.4345)\n",
      "[3/25][233/782] Loss_D: 0.2100 (0.6167) Loss_G: 0.1056 (0.4855) D(x): 0.5268 D(G(z)): 0.4284 / 0.4289 Acc: 26.5625 (23.4357)\n",
      "[3/25][234/782] Loss_D: 0.1309 (0.6165) Loss_G: 0.0783 (0.4854) D(x): 0.5442 D(G(z)): 0.4223 / 0.4443 Acc: 29.6875 (23.4381)\n",
      "[3/25][235/782] Loss_D: 0.2992 (0.6164) Loss_G: 0.2041 (0.4853) D(x): 0.5676 D(G(z)): 0.4658 / 0.3897 Acc: 21.8750 (23.4375)\n",
      "[3/25][236/782] Loss_D: 0.2254 (0.6162) Loss_G: 0.1739 (0.4851) D(x): 0.5374 D(G(z)): 0.4484 / 0.4194 Acc: 26.5625 (23.4387)\n",
      "[3/25][237/782] Loss_D: 0.3555 (0.6161) Loss_G: 0.1365 (0.4850) D(x): 0.5085 D(G(z)): 0.4581 / 0.4464 Acc: 31.2500 (23.4417)\n",
      "[3/25][238/782] Loss_D: 0.0640 (0.6159) Loss_G: 0.0365 (0.4848) D(x): 0.5596 D(G(z)): 0.4441 / 0.4364 Acc: 31.2500 (23.4448)\n",
      "[3/25][239/782] Loss_D: 0.2648 (0.6158) Loss_G: 0.0173 (0.4846) D(x): 0.5234 D(G(z)): 0.4479 / 0.4676 Acc: 28.1250 (23.4466)\n",
      "[3/25][240/782] Loss_D: 0.1590 (0.6156) Loss_G: -0.0372 (0.4844) D(x): 0.5429 D(G(z)): 0.4677 / 0.4585 Acc: 34.3750 (23.4508)\n",
      "[3/25][241/782] Loss_D: 0.2193 (0.6154) Loss_G: -0.0244 (0.4842) D(x): 0.5548 D(G(z)): 0.4968 / 0.4748 Acc: 31.2500 (23.4538)\n",
      "[3/25][242/782] Loss_D: 0.3649 (0.6153) Loss_G: 0.1647 (0.4841) D(x): 0.4898 D(G(z)): 0.4300 / 0.4348 Acc: 26.5625 (23.4550)\n",
      "[3/25][243/782] Loss_D: 0.2682 (0.6152) Loss_G: 0.0146 (0.4839) D(x): 0.5349 D(G(z)): 0.4606 / 0.4885 Acc: 31.2500 (23.4580)\n",
      "[3/25][244/782] Loss_D: 0.1669 (0.6150) Loss_G: 0.1838 (0.4838) D(x): 0.5979 D(G(z)): 0.4806 / 0.4266 Acc: 32.8125 (23.4616)\n",
      "[3/25][245/782] Loss_D: 0.4785 (0.6150) Loss_G: 0.1180 (0.4837) D(x): 0.5354 D(G(z)): 0.5160 / 0.4466 Acc: 28.1250 (23.4634)\n",
      "[3/25][246/782] Loss_D: 0.1854 (0.6148) Loss_G: 0.3315 (0.4836) D(x): 0.5568 D(G(z)): 0.4450 / 0.3708 Acc: 29.6875 (23.4658)\n",
      "[3/25][247/782] Loss_D: 0.2680 (0.6147) Loss_G: 0.0642 (0.4835) D(x): 0.4921 D(G(z)): 0.4331 / 0.4541 Acc: 26.5625 (23.4670)\n",
      "[3/25][248/782] Loss_D: 0.2761 (0.6145) Loss_G: -0.0067 (0.4833) D(x): 0.5106 D(G(z)): 0.4537 / 0.4809 Acc: 29.6875 (23.4694)\n",
      "[3/25][249/782] Loss_D: 0.3028 (0.6144) Loss_G: 0.2425 (0.4832) D(x): 0.5645 D(G(z)): 0.4877 / 0.4087 Acc: 37.5000 (23.4748)\n",
      "[3/25][250/782] Loss_D: 0.4372 (0.6144) Loss_G: 0.3145 (0.4831) D(x): 0.5604 D(G(z)): 0.5138 / 0.4111 Acc: 29.6875 (23.4772)\n",
      "[3/25][251/782] Loss_D: 0.2050 (0.6142) Loss_G: 0.1394 (0.4830) D(x): 0.5031 D(G(z)): 0.4183 / 0.4252 Acc: 32.8125 (23.4808)\n",
      "[3/25][252/782] Loss_D: 0.3846 (0.6141) Loss_G: 0.1491 (0.4829) D(x): 0.4976 D(G(z)): 0.4362 / 0.4520 Acc: 29.6875 (23.4832)\n",
      "[3/25][253/782] Loss_D: 0.2809 (0.6140) Loss_G: 0.2464 (0.4828) D(x): 0.5875 D(G(z)): 0.5122 / 0.3977 Acc: 32.8125 (23.4868)\n",
      "[3/25][254/782] Loss_D: 0.3107 (0.6139) Loss_G: 0.4181 (0.4827) D(x): 0.5355 D(G(z)): 0.4884 / 0.3422 Acc: 35.9375 (23.4916)\n",
      "[3/25][255/782] Loss_D: 0.2661 (0.6137) Loss_G: 0.1351 (0.4826) D(x): 0.4539 D(G(z)): 0.3818 / 0.4331 Acc: 29.6875 (23.4939)\n",
      "[3/25][256/782] Loss_D: 0.2302 (0.6136) Loss_G: 0.0677 (0.4824) D(x): 0.5408 D(G(z)): 0.4585 / 0.4554 Acc: 34.3750 (23.4981)\n",
      "[3/25][257/782] Loss_D: 0.2490 (0.6134) Loss_G: 0.1246 (0.4823) D(x): 0.5726 D(G(z)): 0.4690 / 0.4512 Acc: 32.8125 (23.5017)\n",
      "[3/25][258/782] Loss_D: 0.3010 (0.6133) Loss_G: 0.1702 (0.4822) D(x): 0.5780 D(G(z)): 0.5153 / 0.4319 Acc: 26.5625 (23.5029)\n",
      "[3/25][259/782] Loss_D: 0.2577 (0.6132) Loss_G: 0.1726 (0.4821) D(x): 0.5208 D(G(z)): 0.4167 / 0.4160 Acc: 25.0000 (23.5035)\n",
      "[3/25][260/782] Loss_D: 0.3075 (0.6131) Loss_G: 0.1662 (0.4820) D(x): 0.5459 D(G(z)): 0.4763 / 0.4386 Acc: 32.8125 (23.5070)\n",
      "[3/25][261/782] Loss_D: 0.0969 (0.6129) Loss_G: 0.1398 (0.4818) D(x): 0.5549 D(G(z)): 0.4497 / 0.4141 Acc: 34.3750 (23.5112)\n",
      "[3/25][262/782] Loss_D: 0.2260 (0.6127) Loss_G: 0.0728 (0.4817) D(x): 0.5430 D(G(z)): 0.4608 / 0.4606 Acc: 28.1250 (23.5130)\n",
      "[3/25][263/782] Loss_D: 0.2298 (0.6126) Loss_G: 0.1588 (0.4815) D(x): 0.6081 D(G(z)): 0.4773 / 0.4448 Acc: 26.5625 (23.5141)\n",
      "[3/25][264/782] Loss_D: 0.3383 (0.6125) Loss_G: 0.1136 (0.4814) D(x): 0.5072 D(G(z)): 0.4753 / 0.4493 Acc: 34.3750 (23.5183)\n",
      "[3/25][265/782] Loss_D: 0.2874 (0.6123) Loss_G: 0.2060 (0.4813) D(x): 0.5242 D(G(z)): 0.4052 / 0.4316 Acc: 25.0000 (23.5189)\n",
      "[3/25][266/782] Loss_D: 0.2696 (0.6122) Loss_G: 0.1768 (0.4812) D(x): 0.5563 D(G(z)): 0.5004 / 0.3901 Acc: 26.5625 (23.5200)\n",
      "[3/25][267/782] Loss_D: 0.2080 (0.6121) Loss_G: 0.3402 (0.4811) D(x): 0.5533 D(G(z)): 0.4275 / 0.3584 Acc: 21.8750 (23.5194)\n",
      "[3/25][268/782] Loss_D: 0.0616 (0.6118) Loss_G: 0.2890 (0.4811) D(x): 0.5562 D(G(z)): 0.3682 / 0.3753 Acc: 34.3750 (23.5235)\n",
      "[3/25][269/782] Loss_D: 0.2374 (0.6117) Loss_G: -0.0527 (0.4808) D(x): 0.5128 D(G(z)): 0.4330 / 0.5297 Acc: 32.8125 (23.5271)\n",
      "[3/25][270/782] Loss_D: 0.4865 (0.6117) Loss_G: 0.2524 (0.4808) D(x): 0.6838 D(G(z)): 0.6264 / 0.4132 Acc: 23.4375 (23.5271)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/25][271/782] Loss_D: 0.2809 (0.6115) Loss_G: 0.2637 (0.4807) D(x): 0.4544 D(G(z)): 0.3890 / 0.3698 Acc: 26.5625 (23.5282)\n",
      "[3/25][272/782] Loss_D: 0.3539 (0.6114) Loss_G: 0.0271 (0.4805) D(x): 0.5057 D(G(z)): 0.4414 / 0.4882 Acc: 28.1250 (23.5300)\n",
      "[3/25][273/782] Loss_D: 0.2201 (0.6113) Loss_G: 0.1518 (0.4804) D(x): 0.5719 D(G(z)): 0.4584 / 0.4275 Acc: 28.1250 (23.5317)\n",
      "[3/25][274/782] Loss_D: 0.3029 (0.6112) Loss_G: 0.3507 (0.4803) D(x): 0.5599 D(G(z)): 0.5323 / 0.3646 Acc: 39.0625 (23.5377)\n",
      "[3/25][275/782] Loss_D: 0.4638 (0.6111) Loss_G: 0.1532 (0.4802) D(x): 0.4776 D(G(z)): 0.4540 / 0.4543 Acc: 25.0000 (23.5382)\n",
      "[3/25][276/782] Loss_D: 0.3230 (0.6110) Loss_G: -0.0666 (0.4800) D(x): 0.4711 D(G(z)): 0.4705 / 0.4948 Acc: 29.6875 (23.5406)\n",
      "[3/25][277/782] Loss_D: 0.4251 (0.6109) Loss_G: 0.0215 (0.4798) D(x): 0.5320 D(G(z)): 0.5320 / 0.4583 Acc: 29.6875 (23.5429)\n",
      "[3/25][278/782] Loss_D: 0.3130 (0.6108) Loss_G: 0.0256 (0.4796) D(x): 0.5212 D(G(z)): 0.4205 / 0.4886 Acc: 23.4375 (23.5429)\n",
      "[3/25][279/782] Loss_D: 0.5045 (0.6108) Loss_G: -0.1665 (0.4794) D(x): 0.4419 D(G(z)): 0.5058 / 0.5230 Acc: 28.1250 (23.5446)\n",
      "[3/25][280/782] Loss_D: 0.2940 (0.6107) Loss_G: -0.1420 (0.4792) D(x): 0.5274 D(G(z)): 0.5383 / 0.5142 Acc: 35.9375 (23.5493)\n",
      "[3/25][281/782] Loss_D: 0.3204 (0.6105) Loss_G: 0.0985 (0.4790) D(x): 0.5588 D(G(z)): 0.5231 / 0.4426 Acc: 29.6875 (23.5517)\n",
      "[3/25][282/782] Loss_D: 0.4077 (0.6105) Loss_G: -0.0285 (0.4788) D(x): 0.5007 D(G(z)): 0.4556 / 0.4945 Acc: 17.1875 (23.5492)\n",
      "[3/25][283/782] Loss_D: 0.3384 (0.6104) Loss_G: 0.0536 (0.4787) D(x): 0.5512 D(G(z)): 0.5231 / 0.4442 Acc: 31.2500 (23.5522)\n",
      "[3/25][284/782] Loss_D: 0.3203 (0.6103) Loss_G: 0.0934 (0.4785) D(x): 0.4972 D(G(z)): 0.4650 / 0.4649 Acc: 35.9375 (23.5569)\n",
      "[3/25][285/782] Loss_D: 0.3844 (0.6102) Loss_G: 0.0472 (0.4784) D(x): 0.4829 D(G(z)): 0.4675 / 0.4623 Acc: 28.1250 (23.5586)\n",
      "[3/25][286/782] Loss_D: 0.3610 (0.6101) Loss_G: -0.0832 (0.4781) D(x): 0.4873 D(G(z)): 0.4848 / 0.5272 Acc: 34.3750 (23.5627)\n",
      "[3/25][287/782] Loss_D: 0.3587 (0.6100) Loss_G: 0.0354 (0.4780) D(x): 0.5392 D(G(z)): 0.5414 / 0.4758 Acc: 35.9375 (23.5674)\n",
      "[3/25][288/782] Loss_D: 0.3090 (0.6099) Loss_G: 0.0902 (0.4778) D(x): 0.5895 D(G(z)): 0.5001 / 0.4484 Acc: 25.0000 (23.5680)\n",
      "[3/25][289/782] Loss_D: 0.2274 (0.6097) Loss_G: 0.0363 (0.4777) D(x): 0.5002 D(G(z)): 0.4447 / 0.4357 Acc: 29.6875 (23.5703)\n",
      "[3/25][290/782] Loss_D: 0.5083 (0.6097) Loss_G: -0.0361 (0.4775) D(x): 0.4542 D(G(z)): 0.5133 / 0.5137 Acc: 34.3750 (23.5744)\n",
      "[3/25][291/782] Loss_D: 0.4735 (0.6096) Loss_G: -0.0791 (0.4773) D(x): 0.5335 D(G(z)): 0.5174 / 0.5176 Acc: 23.4375 (23.5743)\n",
      "[3/25][292/782] Loss_D: 0.1191 (0.6094) Loss_G: -0.0823 (0.4770) D(x): 0.5795 D(G(z)): 0.4753 / 0.5050 Acc: 37.5000 (23.5796)\n",
      "[3/25][293/782] Loss_D: 0.1918 (0.6093) Loss_G: 0.0803 (0.4769) D(x): 0.5690 D(G(z)): 0.4639 / 0.4403 Acc: 32.8125 (23.5831)\n",
      "[3/25][294/782] Loss_D: -0.0008 (0.6091) Loss_G: 0.0042 (0.4767) D(x): 0.5730 D(G(z)): 0.4550 / 0.4460 Acc: 34.3750 (23.5872)\n",
      "[3/25][295/782] Loss_D: 0.2249 (0.6089) Loss_G: -0.0471 (0.4765) D(x): 0.5072 D(G(z)): 0.4382 / 0.4722 Acc: 28.1250 (23.5889)\n",
      "[3/25][296/782] Loss_D: 0.1941 (0.6087) Loss_G: 0.0465 (0.4764) D(x): 0.5353 D(G(z)): 0.4944 / 0.4582 Acc: 39.0625 (23.5948)\n",
      "[3/25][297/782] Loss_D: 0.4193 (0.6087) Loss_G: 0.0160 (0.4762) D(x): 0.4800 D(G(z)): 0.5140 / 0.4655 Acc: 37.5000 (23.6000)\n",
      "[3/25][298/782] Loss_D: 0.3224 (0.6086) Loss_G: 0.0306 (0.4760) D(x): 0.5526 D(G(z)): 0.4897 / 0.4642 Acc: 28.1250 (23.6017)\n",
      "[3/25][299/782] Loss_D: 0.2908 (0.6084) Loss_G: -0.0330 (0.4758) D(x): 0.5345 D(G(z)): 0.4877 / 0.4946 Acc: 31.2500 (23.6046)\n",
      "[3/25][300/782] Loss_D: 0.2397 (0.6083) Loss_G: 0.0969 (0.4757) D(x): 0.5671 D(G(z)): 0.4848 / 0.4417 Acc: 26.5625 (23.6057)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[3/25][301/782] Loss_D: 0.3419 (0.6082) Loss_G: 0.2358 (0.4756) D(x): 0.5151 D(G(z)): 0.4474 / 0.4277 Acc: 34.3750 (23.6098)\n",
      "[3/25][302/782] Loss_D: 0.2640 (0.6081) Loss_G: 0.0299 (0.4754) D(x): 0.5139 D(G(z)): 0.4537 / 0.4660 Acc: 34.3750 (23.6139)\n",
      "[3/25][303/782] Loss_D: 0.3283 (0.6080) Loss_G: -0.0283 (0.4752) D(x): 0.5365 D(G(z)): 0.4867 / 0.4721 Acc: 25.0000 (23.6144)\n",
      "[3/25][304/782] Loss_D: 0.2717 (0.6078) Loss_G: -0.0218 (0.4750) D(x): 0.5710 D(G(z)): 0.5065 / 0.4767 Acc: 28.1250 (23.6161)\n",
      "[3/25][305/782] Loss_D: 0.2129 (0.6077) Loss_G: 0.1090 (0.4749) D(x): 0.5609 D(G(z)): 0.4712 / 0.4305 Acc: 28.1250 (23.6178)\n",
      "[3/25][306/782] Loss_D: 0.2507 (0.6076) Loss_G: 0.1269 (0.4748) D(x): 0.5511 D(G(z)): 0.5001 / 0.4216 Acc: 37.5000 (23.6230)\n",
      "[3/25][307/782] Loss_D: 0.2452 (0.6074) Loss_G: -0.0020 (0.4746) D(x): 0.4716 D(G(z)): 0.4332 / 0.4563 Acc: 31.2500 (23.6259)\n",
      "[3/25][308/782] Loss_D: 0.2259 (0.6073) Loss_G: 0.0170 (0.4744) D(x): 0.5436 D(G(z)): 0.4779 / 0.4660 Acc: 37.5000 (23.6311)\n",
      "[3/25][309/782] Loss_D: 0.1493 (0.6071) Loss_G: 0.0744 (0.4743) D(x): 0.5567 D(G(z)): 0.4472 / 0.4487 Acc: 31.2500 (23.6340)\n",
      "[3/25][310/782] Loss_D: 0.2181 (0.6070) Loss_G: 0.1093 (0.4741) D(x): 0.5097 D(G(z)): 0.4418 / 0.4246 Acc: 32.8125 (23.6374)\n",
      "[3/25][311/782] Loss_D: 0.3400 (0.6069) Loss_G: 0.2106 (0.4740) D(x): 0.5631 D(G(z)): 0.5045 / 0.4434 Acc: 35.9375 (23.6421)\n",
      "[3/25][312/782] Loss_D: 0.2041 (0.6067) Loss_G: 0.0881 (0.4739) D(x): 0.5633 D(G(z)): 0.4549 / 0.4371 Acc: 28.1250 (23.6438)\n",
      "[3/25][313/782] Loss_D: 0.4122 (0.6066) Loss_G: 0.1853 (0.4738) D(x): 0.5254 D(G(z)): 0.4837 / 0.4306 Acc: 29.6875 (23.6460)\n",
      "[3/25][314/782] Loss_D: 0.1003 (0.6064) Loss_G: 0.1414 (0.4736) D(x): 0.4921 D(G(z)): 0.4141 / 0.4382 Acc: 46.8750 (23.6548)\n",
      "[3/25][315/782] Loss_D: 0.2197 (0.6063) Loss_G: -0.0121 (0.4735) D(x): 0.6085 D(G(z)): 0.4996 / 0.4923 Acc: 26.5625 (23.6559)\n",
      "[3/25][316/782] Loss_D: 0.4116 (0.6062) Loss_G: 0.3806 (0.4734) D(x): 0.5478 D(G(z)): 0.5050 / 0.3499 Acc: 18.7500 (23.6540)\n",
      "[3/25][317/782] Loss_D: 0.3593 (0.6061) Loss_G: 0.1675 (0.4733) D(x): 0.5068 D(G(z)): 0.4922 / 0.4151 Acc: 29.6875 (23.6563)\n",
      "[3/25][318/782] Loss_D: 0.1915 (0.6060) Loss_G: 0.1963 (0.4732) D(x): 0.5211 D(G(z)): 0.4420 / 0.4069 Acc: 29.6875 (23.6585)\n",
      "[3/25][319/782] Loss_D: 0.3782 (0.6059) Loss_G: 0.0512 (0.4731) D(x): 0.5249 D(G(z)): 0.4815 / 0.4595 Acc: 23.4375 (23.6585)\n",
      "[3/25][320/782] Loss_D: 0.6357 (0.6059) Loss_G: 0.0042 (0.4729) D(x): 0.4474 D(G(z)): 0.5103 / 0.5095 Acc: 21.8750 (23.6578)\n",
      "[3/25][321/782] Loss_D: 0.4239 (0.6058) Loss_G: 0.0023 (0.4727) D(x): 0.4421 D(G(z)): 0.4572 / 0.4711 Acc: 34.3750 (23.6618)\n",
      "[3/25][322/782] Loss_D: 0.3336 (0.6057) Loss_G: 0.0368 (0.4725) D(x): 0.5434 D(G(z)): 0.5274 / 0.4409 Acc: 29.6875 (23.6641)\n",
      "[3/25][323/782] Loss_D: 0.3841 (0.6057) Loss_G: 0.0604 (0.4724) D(x): 0.5159 D(G(z)): 0.5053 / 0.4661 Acc: 28.1250 (23.6657)\n",
      "[3/25][324/782] Loss_D: 0.2280 (0.6055) Loss_G: 0.0693 (0.4722) D(x): 0.5375 D(G(z)): 0.4568 / 0.4318 Acc: 29.6875 (23.6680)\n",
      "[3/25][325/782] Loss_D: 0.2049 (0.6054) Loss_G: 0.1156 (0.4721) D(x): 0.4874 D(G(z)): 0.4348 / 0.4185 Acc: 34.3750 (23.6720)\n",
      "[3/25][326/782] Loss_D: 0.5288 (0.6053) Loss_G: -0.0120 (0.4719) D(x): 0.4545 D(G(z)): 0.4774 / 0.5141 Acc: 28.1250 (23.6737)\n",
      "[3/25][327/782] Loss_D: 0.3466 (0.6052) Loss_G: 0.1303 (0.4718) D(x): 0.5729 D(G(z)): 0.5210 / 0.4614 Acc: 31.2500 (23.6765)\n",
      "[3/25][328/782] Loss_D: 0.2945 (0.6051) Loss_G: 0.0942 (0.4717) D(x): 0.4872 D(G(z)): 0.4870 / 0.4090 Acc: 32.8125 (23.6799)\n",
      "[3/25][329/782] Loss_D: 0.4491 (0.6051) Loss_G: 0.0157 (0.4715) D(x): 0.4765 D(G(z)): 0.4815 / 0.4748 Acc: 28.1250 (23.6816)\n",
      "[3/25][330/782] Loss_D: 0.2959 (0.6049) Loss_G: 0.1024 (0.4713) D(x): 0.5426 D(G(z)): 0.4499 / 0.4600 Acc: 26.5625 (23.6826)\n",
      "[3/25][331/782] Loss_D: 0.1419 (0.6048) Loss_G: 0.1194 (0.4712) D(x): 0.5448 D(G(z)): 0.4925 / 0.4184 Acc: 40.6250 (23.6890)\n",
      "[3/25][332/782] Loss_D: 0.1876 (0.6046) Loss_G: 0.0439 (0.4711) D(x): 0.5929 D(G(z)): 0.4967 / 0.4367 Acc: 25.0000 (23.6895)\n",
      "[3/25][333/782] Loss_D: 0.3195 (0.6045) Loss_G: 0.2485 (0.4710) D(x): 0.5399 D(G(z)): 0.4781 / 0.4051 Acc: 35.9375 (23.6940)\n",
      "[3/25][334/782] Loss_D: 0.1550 (0.6043) Loss_G: 0.0370 (0.4708) D(x): 0.5173 D(G(z)): 0.4295 / 0.4526 Acc: 32.8125 (23.6974)\n",
      "[3/25][335/782] Loss_D: 0.3171 (0.6042) Loss_G: 0.0102 (0.4706) D(x): 0.4593 D(G(z)): 0.4379 / 0.4755 Acc: 31.2500 (23.7002)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/25][336/782] Loss_D: 0.3269 (0.6041) Loss_G: 0.0615 (0.4705) D(x): 0.5785 D(G(z)): 0.4959 / 0.4781 Acc: 25.0000 (23.7007)\n",
      "[3/25][337/782] Loss_D: 0.1971 (0.6040) Loss_G: 0.2063 (0.4704) D(x): 0.6184 D(G(z)): 0.4863 / 0.4370 Acc: 28.1250 (23.7024)\n",
      "[3/25][338/782] Loss_D: 0.2476 (0.6039) Loss_G: 0.0731 (0.4702) D(x): 0.5160 D(G(z)): 0.4928 / 0.4364 Acc: 37.5000 (23.7075)\n",
      "[3/25][339/782] Loss_D: 0.3776 (0.6038) Loss_G: 0.2012 (0.4701) D(x): 0.4949 D(G(z)): 0.4308 / 0.4268 Acc: 25.0000 (23.7080)\n",
      "[3/25][340/782] Loss_D: 0.1310 (0.6036) Loss_G: 0.1616 (0.4700) D(x): 0.6192 D(G(z)): 0.4408 / 0.4313 Acc: 25.0000 (23.7085)\n",
      "[3/25][341/782] Loss_D: 0.2901 (0.6035) Loss_G: 0.0575 (0.4699) D(x): 0.5355 D(G(z)): 0.4684 / 0.4422 Acc: 26.5625 (23.7095)\n",
      "[3/25][342/782] Loss_D: 0.4759 (0.6034) Loss_G: 0.1626 (0.4698) D(x): 0.5063 D(G(z)): 0.5041 / 0.4609 Acc: 32.8125 (23.7129)\n",
      "[3/25][343/782] Loss_D: 0.2613 (0.6033) Loss_G: 0.0614 (0.4696) D(x): 0.4707 D(G(z)): 0.4804 / 0.4238 Acc: 42.1875 (23.7198)\n",
      "[3/25][344/782] Loss_D: 0.2378 (0.6032) Loss_G: 0.0528 (0.4694) D(x): 0.5178 D(G(z)): 0.4664 / 0.4445 Acc: 32.8125 (23.7232)\n",
      "[3/25][345/782] Loss_D: 0.4325 (0.6031) Loss_G: 0.0287 (0.4693) D(x): 0.4881 D(G(z)): 0.4680 / 0.4830 Acc: 26.5625 (23.7242)\n",
      "[3/25][346/782] Loss_D: 0.3372 (0.6030) Loss_G: -0.0375 (0.4691) D(x): 0.5046 D(G(z)): 0.5205 / 0.4899 Acc: 39.0625 (23.7299)\n",
      "[3/25][347/782] Loss_D: 0.3110 (0.6029) Loss_G: 0.1231 (0.4690) D(x): 0.5751 D(G(z)): 0.5194 / 0.4244 Acc: 29.6875 (23.7321)\n",
      "[3/25][348/782] Loss_D: 0.5255 (0.6029) Loss_G: 0.1613 (0.4689) D(x): 0.4956 D(G(z)): 0.4650 / 0.4381 Acc: 15.6250 (23.7291)\n",
      "[3/25][349/782] Loss_D: 0.3443 (0.6028) Loss_G: 0.1566 (0.4687) D(x): 0.4869 D(G(z)): 0.4567 / 0.4247 Acc: 29.6875 (23.7313)\n",
      "[3/25][350/782] Loss_D: 0.4222 (0.6027) Loss_G: 0.0856 (0.4686) D(x): 0.4654 D(G(z)): 0.4112 / 0.4876 Acc: 26.5625 (23.7324)\n",
      "[3/25][351/782] Loss_D: 0.3317 (0.6026) Loss_G: -0.0857 (0.4684) D(x): 0.5326 D(G(z)): 0.4826 / 0.5191 Acc: 23.4375 (23.7323)\n",
      "[3/25][352/782] Loss_D: 0.3851 (0.6025) Loss_G: 0.0686 (0.4682) D(x): 0.5447 D(G(z)): 0.4794 / 0.5190 Acc: 26.5625 (23.7333)\n",
      "[3/25][353/782] Loss_D: 0.1182 (0.6023) Loss_G: -0.0059 (0.4681) D(x): 0.5584 D(G(z)): 0.4520 / 0.4735 Acc: 32.8125 (23.7367)\n",
      "[3/25][354/782] Loss_D: 0.1962 (0.6022) Loss_G: 0.0902 (0.4679) D(x): 0.5635 D(G(z)): 0.5041 / 0.4526 Acc: 37.5000 (23.7418)\n",
      "[3/25][355/782] Loss_D: 0.1989 (0.6020) Loss_G: 0.0082 (0.4678) D(x): 0.5175 D(G(z)): 0.4877 / 0.4515 Acc: 35.9375 (23.7463)\n",
      "[3/25][356/782] Loss_D: 0.2451 (0.6019) Loss_G: 0.2573 (0.4677) D(x): 0.5715 D(G(z)): 0.5022 / 0.4016 Acc: 32.8125 (23.7497)\n",
      "[3/25][357/782] Loss_D: 0.1962 (0.6018) Loss_G: 0.0779 (0.4675) D(x): 0.5361 D(G(z)): 0.4327 / 0.4320 Acc: 25.0000 (23.7501)\n",
      "[3/25][358/782] Loss_D: 0.2038 (0.6016) Loss_G: 0.0745 (0.4674) D(x): 0.4853 D(G(z)): 0.4092 / 0.4477 Acc: 32.8125 (23.7535)\n",
      "[3/25][359/782] Loss_D: 0.3612 (0.6015) Loss_G: 0.0456 (0.4672) D(x): 0.5414 D(G(z)): 0.5033 / 0.4606 Acc: 31.2500 (23.7562)\n",
      "[3/25][360/782] Loss_D: 0.4001 (0.6014) Loss_G: 0.1823 (0.4671) D(x): 0.5617 D(G(z)): 0.5274 / 0.4225 Acc: 28.1250 (23.7579)\n",
      "[3/25][361/782] Loss_D: 0.2054 (0.6013) Loss_G: 0.2107 (0.4670) D(x): 0.5207 D(G(z)): 0.4340 / 0.3818 Acc: 29.6875 (23.7600)\n",
      "[3/25][362/782] Loss_D: 0.2463 (0.6012) Loss_G: -0.0322 (0.4668) D(x): 0.4630 D(G(z)): 0.3982 / 0.4793 Acc: 29.6875 (23.7622)\n",
      "[3/25][363/782] Loss_D: 0.3150 (0.6011) Loss_G: 0.0299 (0.4667) D(x): 0.5404 D(G(z)): 0.4780 / 0.5011 Acc: 31.2500 (23.7650)\n",
      "[3/25][364/782] Loss_D: 0.3306 (0.6010) Loss_G: 0.1386 (0.4666) D(x): 0.5099 D(G(z)): 0.5264 / 0.4305 Acc: 40.6250 (23.7712)\n",
      "[3/25][365/782] Loss_D: 0.2546 (0.6008) Loss_G: 0.1552 (0.4665) D(x): 0.5483 D(G(z)): 0.4713 / 0.4261 Acc: 32.8125 (23.7745)\n",
      "[3/25][366/782] Loss_D: 0.1993 (0.6007) Loss_G: 0.0964 (0.4663) D(x): 0.5514 D(G(z)): 0.4598 / 0.4294 Acc: 28.1250 (23.7761)\n",
      "[3/25][367/782] Loss_D: 0.1581 (0.6005) Loss_G: 0.0929 (0.4662) D(x): 0.5072 D(G(z)): 0.4067 / 0.4572 Acc: 32.8125 (23.7795)\n",
      "[3/25][368/782] Loss_D: 0.3399 (0.6004) Loss_G: 0.0257 (0.4660) D(x): 0.4684 D(G(z)): 0.4694 / 0.4731 Acc: 34.3750 (23.7834)\n",
      "[3/25][369/782] Loss_D: 0.3765 (0.6003) Loss_G: -0.0345 (0.4658) D(x): 0.4869 D(G(z)): 0.4538 / 0.4998 Acc: 26.5625 (23.7844)\n",
      "[3/25][370/782] Loss_D: 0.3109 (0.6002) Loss_G: 0.1502 (0.4657) D(x): 0.5562 D(G(z)): 0.5038 / 0.4475 Acc: 35.9375 (23.7889)\n",
      "[3/25][371/782] Loss_D: 0.2109 (0.6001) Loss_G: 0.1623 (0.4656) D(x): 0.5674 D(G(z)): 0.4647 / 0.4257 Acc: 26.5625 (23.7899)\n",
      "[3/25][372/782] Loss_D: 0.2322 (0.6000) Loss_G: 0.1303 (0.4655) D(x): 0.4888 D(G(z)): 0.4241 / 0.4285 Acc: 34.3750 (23.7938)\n",
      "[3/25][373/782] Loss_D: 0.3500 (0.5999) Loss_G: -0.0392 (0.4653) D(x): 0.4881 D(G(z)): 0.4723 / 0.4808 Acc: 29.6875 (23.7960)\n",
      "[3/25][374/782] Loss_D: 0.0785 (0.5997) Loss_G: 0.0417 (0.4651) D(x): 0.5912 D(G(z)): 0.4563 / 0.4483 Acc: 31.2500 (23.7987)\n",
      "[3/25][375/782] Loss_D: 0.1393 (0.5995) Loss_G: 0.1643 (0.4650) D(x): 0.5640 D(G(z)): 0.4591 / 0.4012 Acc: 34.3750 (23.8026)\n",
      "[3/25][376/782] Loss_D: 0.1789 (0.5994) Loss_G: 0.1810 (0.4649) D(x): 0.5359 D(G(z)): 0.4468 / 0.4134 Acc: 34.3750 (23.8065)\n",
      "[3/25][377/782] Loss_D: 0.2107 (0.5992) Loss_G: 0.2079 (0.4648) D(x): 0.5539 D(G(z)): 0.4375 / 0.4187 Acc: 31.2500 (23.8092)\n",
      "[3/25][378/782] Loss_D: 0.1299 (0.5990) Loss_G: 0.0893 (0.4647) D(x): 0.5491 D(G(z)): 0.4458 / 0.4144 Acc: 29.6875 (23.8114)\n",
      "[3/25][379/782] Loss_D: 0.2301 (0.5989) Loss_G: 0.1520 (0.4646) D(x): 0.5604 D(G(z)): 0.4592 / 0.4197 Acc: 29.6875 (23.8135)\n",
      "[3/25][380/782] Loss_D: 0.1822 (0.5988) Loss_G: 0.0074 (0.4644) D(x): 0.5475 D(G(z)): 0.4269 / 0.4538 Acc: 28.1250 (23.8151)\n",
      "[3/25][381/782] Loss_D: 0.2704 (0.5986) Loss_G: 0.2402 (0.4643) D(x): 0.5550 D(G(z)): 0.4863 / 0.3930 Acc: 29.6875 (23.8172)\n",
      "[3/25][382/782] Loss_D: 0.2679 (0.5985) Loss_G: 0.1050 (0.4642) D(x): 0.4804 D(G(z)): 0.4573 / 0.4439 Acc: 35.9375 (23.8217)\n",
      "[3/25][383/782] Loss_D: -0.0140 (0.5983) Loss_G: 0.0323 (0.4640) D(x): 0.6077 D(G(z)): 0.4381 / 0.4444 Acc: 32.8125 (23.8250)\n",
      "[3/25][384/782] Loss_D: 0.3976 (0.5982) Loss_G: 0.2438 (0.4640) D(x): 0.5374 D(G(z)): 0.4895 / 0.3999 Acc: 21.8750 (23.8243)\n",
      "[3/25][385/782] Loss_D: 0.3125 (0.5981) Loss_G: 0.0148 (0.4638) D(x): 0.4894 D(G(z)): 0.4531 / 0.4907 Acc: 35.9375 (23.8287)\n",
      "[3/25][386/782] Loss_D: 0.2008 (0.5980) Loss_G: 0.1317 (0.4637) D(x): 0.5826 D(G(z)): 0.4430 / 0.4247 Acc: 20.3125 (23.8274)\n",
      "[3/25][387/782] Loss_D: 0.1563 (0.5978) Loss_G: 0.1370 (0.4636) D(x): 0.5615 D(G(z)): 0.4606 / 0.4065 Acc: 28.1250 (23.8290)\n",
      "[3/25][388/782] Loss_D: 0.3411 (0.5977) Loss_G: 0.1581 (0.4634) D(x): 0.4487 D(G(z)): 0.4245 / 0.3993 Acc: 25.0000 (23.8294)\n",
      "[3/25][389/782] Loss_D: 0.2132 (0.5976) Loss_G: 0.2505 (0.4634) D(x): 0.5640 D(G(z)): 0.4658 / 0.4236 Acc: 39.0625 (23.8350)\n",
      "[3/25][390/782] Loss_D: 0.0376 (0.5974) Loss_G: 0.1539 (0.4632) D(x): 0.6096 D(G(z)): 0.4269 / 0.4251 Acc: 26.5625 (23.8360)\n",
      "[3/25][391/782] Loss_D: 0.0525 (0.5972) Loss_G: 0.1774 (0.4631) D(x): 0.5879 D(G(z)): 0.4046 / 0.4042 Acc: 26.5625 (23.8370)\n",
      "[3/25][392/782] Loss_D: 0.0867 (0.5970) Loss_G: 0.2090 (0.4631) D(x): 0.5757 D(G(z)): 0.4345 / 0.3827 Acc: 26.5625 (23.8380)\n",
      "[3/25][393/782] Loss_D: 0.2071 (0.5968) Loss_G: 0.1099 (0.4629) D(x): 0.5055 D(G(z)): 0.4295 / 0.4334 Acc: 35.9375 (23.8424)\n",
      "[3/25][394/782] Loss_D: 0.5168 (0.5968) Loss_G: 0.1175 (0.4628) D(x): 0.5262 D(G(z)): 0.5104 / 0.4480 Acc: 18.7500 (23.8405)\n",
      "[3/25][395/782] Loss_D: 0.3005 (0.5967) Loss_G: 0.1068 (0.4627) D(x): 0.5891 D(G(z)): 0.5138 / 0.4166 Acc: 23.4375 (23.8404)\n",
      "[3/25][396/782] Loss_D: 0.2453 (0.5966) Loss_G: 0.2314 (0.4626) D(x): 0.5131 D(G(z)): 0.4289 / 0.3905 Acc: 26.5625 (23.8414)\n",
      "[3/25][397/782] Loss_D: 0.4369 (0.5965) Loss_G: -0.0640 (0.4624) D(x): 0.4488 D(G(z)): 0.4448 / 0.5069 Acc: 28.1250 (23.8429)\n",
      "[3/25][398/782] Loss_D: 0.3065 (0.5964) Loss_G: 0.2383 (0.4623) D(x): 0.5606 D(G(z)): 0.4862 / 0.4197 Acc: 32.8125 (23.8462)\n",
      "[3/25][399/782] Loss_D: -0.1166 (0.5961) Loss_G: 0.0143 (0.4621) D(x): 0.5703 D(G(z)): 0.4197 / 0.4572 Acc: 46.8750 (23.8546)\n",
      "[3/25][400/782] Loss_D: 0.3462 (0.5961) Loss_G: 0.1054 (0.4620) D(x): 0.5235 D(G(z)): 0.4930 / 0.4631 Acc: 34.3750 (23.8584)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/25][401/782] Loss_D: 0.1272 (0.5959) Loss_G: 0.0986 (0.4619) D(x): 0.5440 D(G(z)): 0.4499 / 0.4322 Acc: 35.9375 (23.8628)\n",
      "[3/25][402/782] Loss_D: 0.2232 (0.5957) Loss_G: 0.1716 (0.4618) D(x): 0.5966 D(G(z)): 0.4746 / 0.4069 Acc: 21.8750 (23.8621)\n",
      "[3/25][403/782] Loss_D: 0.1737 (0.5956) Loss_G: 0.1666 (0.4617) D(x): 0.5429 D(G(z)): 0.4052 / 0.4324 Acc: 29.6875 (23.8642)\n",
      "[3/25][404/782] Loss_D: 0.1757 (0.5954) Loss_G: 0.0586 (0.4615) D(x): 0.5293 D(G(z)): 0.4723 / 0.4278 Acc: 32.8125 (23.8675)\n",
      "[3/25][405/782] Loss_D: 0.3421 (0.5954) Loss_G: 0.3193 (0.4615) D(x): 0.5713 D(G(z)): 0.4942 / 0.3869 Acc: 29.6875 (23.8696)\n",
      "[3/25][406/782] Loss_D: 0.1159 (0.5952) Loss_G: 0.1327 (0.4614) D(x): 0.5055 D(G(z)): 0.4216 / 0.3897 Acc: 31.2500 (23.8723)\n",
      "[3/25][407/782] Loss_D: 0.1948 (0.5950) Loss_G: 0.0943 (0.4612) D(x): 0.5090 D(G(z)): 0.4280 / 0.4444 Acc: 39.0625 (23.8778)\n",
      "[3/25][408/782] Loss_D: 0.3271 (0.5949) Loss_G: 0.1317 (0.4611) D(x): 0.5107 D(G(z)): 0.4476 / 0.4560 Acc: 29.6875 (23.8799)\n",
      "[3/25][409/782] Loss_D: 0.0493 (0.5947) Loss_G: 0.2374 (0.4610) D(x): 0.6000 D(G(z)): 0.4515 / 0.4031 Acc: 40.6250 (23.8860)\n",
      "[3/25][410/782] Loss_D: 0.2445 (0.5946) Loss_G: 0.1734 (0.4609) D(x): 0.5454 D(G(z)): 0.4867 / 0.4002 Acc: 29.6875 (23.8881)\n",
      "[3/25][411/782] Loss_D: 0.3077 (0.5945) Loss_G: 0.0135 (0.4608) D(x): 0.5203 D(G(z)): 0.4589 / 0.4764 Acc: 26.5625 (23.8890)\n",
      "[3/25][412/782] Loss_D: 0.4778 (0.5945) Loss_G: 0.2623 (0.4607) D(x): 0.4966 D(G(z)): 0.4826 / 0.4034 Acc: 25.0000 (23.8894)\n",
      "[3/25][413/782] Loss_D: 0.1931 (0.5943) Loss_G: 0.1166 (0.4606) D(x): 0.5302 D(G(z)): 0.4241 / 0.4313 Acc: 29.6875 (23.8915)\n",
      "[3/25][414/782] Loss_D: 0.2496 (0.5942) Loss_G: 0.0835 (0.4604) D(x): 0.5319 D(G(z)): 0.4654 / 0.4201 Acc: 23.4375 (23.8914)\n",
      "[3/25][415/782] Loss_D: 0.2366 (0.5941) Loss_G: 0.0070 (0.4603) D(x): 0.5085 D(G(z)): 0.4720 / 0.4851 Acc: 40.6250 (23.8974)\n",
      "[3/25][416/782] Loss_D: 0.4359 (0.5940) Loss_G: 0.4148 (0.4602) D(x): 0.5988 D(G(z)): 0.5394 / 0.3486 Acc: 25.0000 (23.8978)\n",
      "[3/25][417/782] Loss_D: 0.2359 (0.5939) Loss_G: 0.2715 (0.4602) D(x): 0.4998 D(G(z)): 0.3648 / 0.4221 Acc: 28.1250 (23.8994)\n",
      "[3/25][418/782] Loss_D: 0.4464 (0.5938) Loss_G: -0.0987 (0.4600) D(x): 0.4718 D(G(z)): 0.4650 / 0.5312 Acc: 23.4375 (23.8992)\n",
      "[3/25][419/782] Loss_D: 0.3594 (0.5937) Loss_G: 0.0295 (0.4598) D(x): 0.6158 D(G(z)): 0.5169 / 0.4629 Acc: 15.6250 (23.8962)\n",
      "[3/25][420/782] Loss_D: 0.3456 (0.5936) Loss_G: 0.0475 (0.4597) D(x): 0.5258 D(G(z)): 0.4916 / 0.4801 Acc: 31.2500 (23.8989)\n",
      "[3/25][421/782] Loss_D: 0.1320 (0.5935) Loss_G: -0.0029 (0.4595) D(x): 0.6209 D(G(z)): 0.4927 / 0.4546 Acc: 32.8125 (23.9021)\n",
      "[3/25][422/782] Loss_D: 0.2427 (0.5934) Loss_G: 0.1439 (0.4594) D(x): 0.5385 D(G(z)): 0.4885 / 0.4102 Acc: 37.5000 (23.9070)\n",
      "[3/25][423/782] Loss_D: 0.3591 (0.5933) Loss_G: 0.0583 (0.4592) D(x): 0.5143 D(G(z)): 0.4673 / 0.4691 Acc: 29.6875 (23.9091)\n",
      "[3/25][424/782] Loss_D: 0.3973 (0.5932) Loss_G: 0.1482 (0.4591) D(x): 0.5130 D(G(z)): 0.4401 / 0.4290 Acc: 17.1875 (23.9066)\n",
      "[3/25][425/782] Loss_D: 0.0535 (0.5930) Loss_G: 0.0537 (0.4590) D(x): 0.5960 D(G(z)): 0.4387 / 0.4602 Acc: 32.8125 (23.9099)\n",
      "[3/25][426/782] Loss_D: 0.3172 (0.5929) Loss_G: 0.0809 (0.4588) D(x): 0.5338 D(G(z)): 0.4803 / 0.4430 Acc: 26.5625 (23.9108)\n",
      "[3/25][427/782] Loss_D: -0.0077 (0.5927) Loss_G: 0.1707 (0.4587) D(x): 0.6020 D(G(z)): 0.5059 / 0.3806 Acc: 43.7500 (23.9180)\n",
      "[3/25][428/782] Loss_D: 0.2803 (0.5926) Loss_G: 0.2656 (0.4587) D(x): 0.5250 D(G(z)): 0.4930 / 0.3739 Acc: 39.0625 (23.9234)\n",
      "[3/25][429/782] Loss_D: 0.2585 (0.5925) Loss_G: 0.0977 (0.4585) D(x): 0.4831 D(G(z)): 0.4410 / 0.4475 Acc: 32.8125 (23.9266)\n",
      "[3/25][430/782] Loss_D: 0.2448 (0.5923) Loss_G: 0.1902 (0.4584) D(x): 0.5458 D(G(z)): 0.4876 / 0.4057 Acc: 31.2500 (23.9293)\n",
      "[3/25][431/782] Loss_D: 0.4308 (0.5923) Loss_G: 0.2413 (0.4584) D(x): 0.4982 D(G(z)): 0.4994 / 0.4007 Acc: 29.6875 (23.9313)\n",
      "[3/25][432/782] Loss_D: 0.3396 (0.5922) Loss_G: 0.1385 (0.4582) D(x): 0.4584 D(G(z)): 0.4233 / 0.4297 Acc: 31.2500 (23.9340)\n",
      "[3/25][433/782] Loss_D: 0.1630 (0.5920) Loss_G: 0.0534 (0.4581) D(x): 0.5607 D(G(z)): 0.4439 / 0.4434 Acc: 28.1250 (23.9355)\n",
      "[3/25][434/782] Loss_D: 0.3977 (0.5920) Loss_G: 0.2511 (0.4580) D(x): 0.5726 D(G(z)): 0.5103 / 0.3940 Acc: 21.8750 (23.9347)\n",
      "[3/25][435/782] Loss_D: 0.2531 (0.5918) Loss_G: 0.4919 (0.4580) D(x): 0.5518 D(G(z)): 0.4853 / 0.3254 Acc: 39.0625 (23.9402)\n",
      "[3/25][436/782] Loss_D: 0.4547 (0.5918) Loss_G: 0.1213 (0.4579) D(x): 0.3743 D(G(z)): 0.3893 / 0.4537 Acc: 39.0625 (23.9456)\n",
      "[3/25][437/782] Loss_D: 0.1205 (0.5916) Loss_G: 0.0621 (0.4578) D(x): 0.6603 D(G(z)): 0.5211 / 0.4340 Acc: 29.6875 (23.9477)\n",
      "[3/25][438/782] Loss_D: 0.2702 (0.5915) Loss_G: 0.1773 (0.4577) D(x): 0.5450 D(G(z)): 0.4458 / 0.4222 Acc: 25.0000 (23.9480)\n",
      "[3/25][439/782] Loss_D: 0.2588 (0.5914) Loss_G: 0.1616 (0.4576) D(x): 0.5042 D(G(z)): 0.4308 / 0.4086 Acc: 26.5625 (23.9490)\n",
      "[3/25][440/782] Loss_D: 0.3610 (0.5913) Loss_G: 0.0453 (0.4574) D(x): 0.4979 D(G(z)): 0.4528 / 0.4749 Acc: 28.1250 (23.9505)\n",
      "[3/25][441/782] Loss_D: 0.4024 (0.5912) Loss_G: 0.1307 (0.4573) D(x): 0.5242 D(G(z)): 0.5457 / 0.4181 Acc: 31.2500 (23.9531)\n",
      "[3/25][442/782] Loss_D: 0.1462 (0.5911) Loss_G: 0.0861 (0.4572) D(x): 0.4646 D(G(z)): 0.3948 / 0.4486 Acc: 42.1875 (23.9596)\n",
      "[3/25][443/782] Loss_D: 0.5120 (0.5910) Loss_G: 0.1978 (0.4571) D(x): 0.5305 D(G(z)): 0.5463 / 0.4387 Acc: 26.5625 (23.9606)\n",
      "[3/25][444/782] Loss_D: 0.4421 (0.5910) Loss_G: -0.0444 (0.4569) D(x): 0.4969 D(G(z)): 0.5110 / 0.5175 Acc: 32.8125 (23.9637)\n",
      "[3/25][445/782] Loss_D: 0.2482 (0.5909) Loss_G: -0.0268 (0.4567) D(x): 0.4976 D(G(z)): 0.4673 / 0.4770 Acc: 37.5000 (23.9686)\n",
      "[3/25][446/782] Loss_D: 0.1049 (0.5907) Loss_G: 0.0807 (0.4566) D(x): 0.5403 D(G(z)): 0.4618 / 0.4568 Acc: 43.7500 (23.9757)\n",
      "[3/25][447/782] Loss_D: 0.2475 (0.5906) Loss_G: 0.1394 (0.4565) D(x): 0.5214 D(G(z)): 0.4634 / 0.4127 Acc: 34.3750 (23.9794)\n",
      "[3/25][448/782] Loss_D: 0.2262 (0.5904) Loss_G: 0.0317 (0.4563) D(x): 0.5975 D(G(z)): 0.4709 / 0.4542 Acc: 20.3125 (23.9781)\n",
      "[3/25][449/782] Loss_D: 0.1654 (0.5903) Loss_G: 0.2386 (0.4562) D(x): 0.5771 D(G(z)): 0.4548 / 0.4131 Acc: 32.8125 (23.9812)\n",
      "[3/25][450/782] Loss_D: 0.1650 (0.5901) Loss_G: 0.2599 (0.4562) D(x): 0.5689 D(G(z)): 0.4648 / 0.3684 Acc: 31.2500 (23.9838)\n",
      "[3/25][451/782] Loss_D: 0.1514 (0.5900) Loss_G: 0.2784 (0.4561) D(x): 0.5403 D(G(z)): 0.4320 / 0.4091 Acc: 40.6250 (23.9898)\n",
      "[3/25][452/782] Loss_D: 0.2376 (0.5899) Loss_G: 0.1664 (0.4560) D(x): 0.5329 D(G(z)): 0.4460 / 0.4085 Acc: 31.2500 (23.9924)\n",
      "[3/25][453/782] Loss_D: 0.1727 (0.5897) Loss_G: -0.0576 (0.4558) D(x): 0.5448 D(G(z)): 0.4933 / 0.4712 Acc: 32.8125 (23.9955)\n",
      "[3/25][454/782] Loss_D: 0.0010 (0.5895) Loss_G: 0.0734 (0.4557) D(x): 0.5509 D(G(z)): 0.4055 / 0.4407 Acc: 35.9375 (23.9998)\n",
      "[3/25][455/782] Loss_D: 0.3273 (0.5894) Loss_G: 0.3672 (0.4557) D(x): 0.5651 D(G(z)): 0.4566 / 0.4376 Acc: 40.6250 (24.0057)\n",
      "[3/25][456/782] Loss_D: 0.1638 (0.5893) Loss_G: 0.2320 (0.4556) D(x): 0.5604 D(G(z)): 0.4707 / 0.4014 Acc: 37.5000 (24.0105)\n",
      "[3/25][457/782] Loss_D: 0.1172 (0.5891) Loss_G: 0.2017 (0.4555) D(x): 0.5767 D(G(z)): 0.4524 / 0.3925 Acc: 32.8125 (24.0137)\n",
      "[3/25][458/782] Loss_D: 0.2188 (0.5889) Loss_G: 0.4594 (0.4555) D(x): 0.6123 D(G(z)): 0.4512 / 0.3461 Acc: 26.5625 (24.0146)\n",
      "[3/25][459/782] Loss_D: 0.4478 (0.5889) Loss_G: 0.0011 (0.4553) D(x): 0.4187 D(G(z)): 0.4520 / 0.4612 Acc: 31.2500 (24.0172)\n",
      "[3/25][460/782] Loss_D: 0.3743 (0.5888) Loss_G: 0.1012 (0.4552) D(x): 0.4744 D(G(z)): 0.4556 / 0.4659 Acc: 35.9375 (24.0214)\n",
      "[3/25][461/782] Loss_D: 0.1131 (0.5887) Loss_G: 0.1451 (0.4551) D(x): 0.6297 D(G(z)): 0.5131 / 0.4326 Acc: 32.8125 (24.0246)\n",
      "[3/25][462/782] Loss_D: 0.4848 (0.5886) Loss_G: 0.1111 (0.4550) D(x): 0.5342 D(G(z)): 0.5664 / 0.4354 Acc: 34.3750 (24.0282)\n",
      "[3/25][463/782] Loss_D: 0.2747 (0.5885) Loss_G: 0.0551 (0.4548) D(x): 0.5083 D(G(z)): 0.4644 / 0.4633 Acc: 35.9375 (24.0325)\n",
      "[3/25][464/782] Loss_D: 0.2910 (0.5884) Loss_G: 0.0131 (0.4547) D(x): 0.5616 D(G(z)): 0.4723 / 0.4715 Acc: 28.1250 (24.0339)\n",
      "[3/25][465/782] Loss_D: 0.2646 (0.5883) Loss_G: 0.2256 (0.4546) D(x): 0.5539 D(G(z)): 0.4914 / 0.4148 Acc: 40.6250 (24.0398)\n",
      "[3/25][466/782] Loss_D: 0.2946 (0.5882) Loss_G: 0.2456 (0.4545) D(x): 0.5405 D(G(z)): 0.4730 / 0.3818 Acc: 28.1250 (24.0413)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/25][467/782] Loss_D: 0.2327 (0.5881) Loss_G: 0.1509 (0.4544) D(x): 0.5087 D(G(z)): 0.4468 / 0.4153 Acc: 31.2500 (24.0438)\n",
      "[3/25][468/782] Loss_D: 0.1948 (0.5879) Loss_G: 0.1828 (0.4543) D(x): 0.6173 D(G(z)): 0.4617 / 0.4069 Acc: 23.4375 (24.0436)\n",
      "[3/25][469/782] Loss_D: 0.1479 (0.5878) Loss_G: 0.1406 (0.4542) D(x): 0.5679 D(G(z)): 0.4438 / 0.4154 Acc: 26.5625 (24.0445)\n",
      "[3/25][470/782] Loss_D: 0.1635 (0.5876) Loss_G: 0.0644 (0.4541) D(x): 0.5774 D(G(z)): 0.4682 / 0.4733 Acc: 35.9375 (24.0487)\n",
      "[3/25][471/782] Loss_D: 0.2764 (0.5875) Loss_G: 0.1218 (0.4539) D(x): 0.5350 D(G(z)): 0.4778 / 0.4402 Acc: 32.8125 (24.0519)\n",
      "[3/25][472/782] Loss_D: 0.2367 (0.5874) Loss_G: 0.1431 (0.4538) D(x): 0.5980 D(G(z)): 0.4982 / 0.4434 Acc: 28.1250 (24.0533)\n",
      "[3/25][473/782] Loss_D: 0.2583 (0.5873) Loss_G: 0.2342 (0.4538) D(x): 0.5433 D(G(z)): 0.5017 / 0.3983 Acc: 37.5000 (24.0581)\n",
      "[3/25][474/782] Loss_D: 0.2729 (0.5871) Loss_G: 0.1227 (0.4536) D(x): 0.4929 D(G(z)): 0.4157 / 0.4394 Acc: 29.6875 (24.0601)\n",
      "[3/25][475/782] Loss_D: 0.2269 (0.5870) Loss_G: -0.0381 (0.4535) D(x): 0.5046 D(G(z)): 0.4854 / 0.4644 Acc: 39.0625 (24.0654)\n",
      "[3/25][476/782] Loss_D: 0.1887 (0.5869) Loss_G: 0.2299 (0.4534) D(x): 0.5867 D(G(z)): 0.4873 / 0.3939 Acc: 34.3750 (24.0690)\n",
      "[3/25][477/782] Loss_D: 0.1920 (0.5867) Loss_G: 0.2858 (0.4533) D(x): 0.5331 D(G(z)): 0.4275 / 0.3724 Acc: 29.6875 (24.0710)\n",
      "[3/25][478/782] Loss_D: 0.3662 (0.5867) Loss_G: 0.1823 (0.4532) D(x): 0.5022 D(G(z)): 0.4754 / 0.4254 Acc: 35.9375 (24.0752)\n",
      "[3/25][479/782] Loss_D: 0.3893 (0.5866) Loss_G: 0.0146 (0.4531) D(x): 0.4805 D(G(z)): 0.4744 / 0.4619 Acc: 32.8125 (24.0783)\n",
      "[3/25][480/782] Loss_D: 0.2034 (0.5865) Loss_G: 0.2522 (0.4530) D(x): 0.5368 D(G(z)): 0.4669 / 0.3959 Acc: 35.9375 (24.0825)\n",
      "[3/25][481/782] Loss_D: 0.4417 (0.5864) Loss_G: 0.1794 (0.4529) D(x): 0.4956 D(G(z)): 0.5206 / 0.4096 Acc: 31.2500 (24.0850)\n",
      "[3/25][482/782] Loss_D: 0.5481 (0.5864) Loss_G: 0.1723 (0.4528) D(x): 0.4971 D(G(z)): 0.5184 / 0.4187 Acc: 21.8750 (24.0843)\n",
      "[3/25][483/782] Loss_D: 0.6064 (0.5864) Loss_G: 0.1470 (0.4527) D(x): 0.4015 D(G(z)): 0.4379 / 0.4570 Acc: 29.6875 (24.0862)\n",
      "[3/25][484/782] Loss_D: 0.7197 (0.5864) Loss_G: 0.1322 (0.4526) D(x): 0.4252 D(G(z)): 0.5279 / 0.4455 Acc: 31.2500 (24.0888)\n",
      "[3/25][485/782] Loss_D: 0.4346 (0.5864) Loss_G: 0.1988 (0.4525) D(x): 0.4990 D(G(z)): 0.5060 / 0.4288 Acc: 34.3750 (24.0924)\n",
      "[3/25][486/782] Loss_D: 0.3710 (0.5863) Loss_G: 0.1031 (0.4524) D(x): 0.4824 D(G(z)): 0.4635 / 0.4440 Acc: 31.2500 (24.0949)\n",
      "[3/25][487/782] Loss_D: 0.1620 (0.5862) Loss_G: 0.0755 (0.4522) D(x): 0.5725 D(G(z)): 0.4592 / 0.4708 Acc: 35.9375 (24.0991)\n",
      "[3/25][488/782] Loss_D: 0.2194 (0.5860) Loss_G: 0.0938 (0.4521) D(x): 0.5419 D(G(z)): 0.4728 / 0.4078 Acc: 28.1250 (24.1005)\n",
      "[3/25][489/782] Loss_D: 0.2705 (0.5859) Loss_G: 0.2551 (0.4520) D(x): 0.4930 D(G(z)): 0.4362 / 0.3729 Acc: 29.6875 (24.1025)\n",
      "[3/25][490/782] Loss_D: 0.1926 (0.5858) Loss_G: 0.4568 (0.4520) D(x): 0.5196 D(G(z)): 0.4107 / 0.3317 Acc: 32.8125 (24.1056)\n",
      "[3/25][491/782] Loss_D: 0.1207 (0.5856) Loss_G: 0.1635 (0.4519) D(x): 0.5036 D(G(z)): 0.3836 / 0.4123 Acc: 29.6875 (24.1075)\n",
      "[3/25][492/782] Loss_D: 0.3250 (0.5855) Loss_G: 0.1036 (0.4518) D(x): 0.5347 D(G(z)): 0.4765 / 0.4366 Acc: 26.5625 (24.1084)\n",
      "[3/25][493/782] Loss_D: 0.0868 (0.5854) Loss_G: 0.1529 (0.4517) D(x): 0.6329 D(G(z)): 0.4612 / 0.4001 Acc: 32.8125 (24.1115)\n",
      "[3/25][494/782] Loss_D: 0.2250 (0.5852) Loss_G: 0.2808 (0.4517) D(x): 0.5746 D(G(z)): 0.4789 / 0.3803 Acc: 31.2500 (24.1140)\n",
      "[3/25][495/782] Loss_D: 0.2060 (0.5851) Loss_G: 0.2101 (0.4516) D(x): 0.5447 D(G(z)): 0.4627 / 0.3786 Acc: 26.5625 (24.1148)\n",
      "[3/25][496/782] Loss_D: 0.2488 (0.5850) Loss_G: 0.1756 (0.4515) D(x): 0.4874 D(G(z)): 0.3887 / 0.4342 Acc: 34.3750 (24.1184)\n",
      "[3/25][497/782] Loss_D: 0.0967 (0.5848) Loss_G: 0.2111 (0.4514) D(x): 0.5917 D(G(z)): 0.4098 / 0.3911 Acc: 26.5625 (24.1193)\n",
      "[3/25][498/782] Loss_D: 0.3070 (0.5847) Loss_G: 0.0220 (0.4512) D(x): 0.4824 D(G(z)): 0.4243 / 0.4907 Acc: 35.9375 (24.1235)\n",
      "[3/25][499/782] Loss_D: 0.4718 (0.5847) Loss_G: 0.1445 (0.4511) D(x): 0.6035 D(G(z)): 0.5682 / 0.4494 Acc: 31.2500 (24.1260)\n",
      "[3/25][500/782] Loss_D: 0.4642 (0.5846) Loss_G: 0.1350 (0.4510) D(x): 0.4709 D(G(z)): 0.4679 / 0.4294 Acc: 25.0000 (24.1263)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[3/25][501/782] Loss_D: 0.2441 (0.5845) Loss_G: 0.0574 (0.4509) D(x): 0.4611 D(G(z)): 0.4353 / 0.4583 Acc: 35.9375 (24.1304)\n",
      "[3/25][502/782] Loss_D: 0.4759 (0.5845) Loss_G: -0.0654 (0.4507) D(x): 0.5166 D(G(z)): 0.5201 / 0.5144 Acc: 31.2500 (24.1329)\n",
      "[3/25][503/782] Loss_D: 0.2911 (0.5844) Loss_G: 0.1164 (0.4506) D(x): 0.5041 D(G(z)): 0.4760 / 0.4296 Acc: 37.5000 (24.1376)\n",
      "[3/25][504/782] Loss_D: 0.3919 (0.5843) Loss_G: 0.1977 (0.4505) D(x): 0.5326 D(G(z)): 0.4895 / 0.4229 Acc: 29.6875 (24.1396)\n",
      "[3/25][505/782] Loss_D: 0.0708 (0.5841) Loss_G: 0.2839 (0.4504) D(x): 0.6025 D(G(z)): 0.4263 / 0.3483 Acc: 26.5625 (24.1404)\n",
      "[3/25][506/782] Loss_D: 0.3973 (0.5840) Loss_G: 0.3918 (0.4504) D(x): 0.5325 D(G(z)): 0.4753 / 0.3872 Acc: 29.6875 (24.1424)\n",
      "[3/25][507/782] Loss_D: 0.5185 (0.5840) Loss_G: 0.1942 (0.4503) D(x): 0.4632 D(G(z)): 0.4678 / 0.4434 Acc: 26.5625 (24.1432)\n",
      "[3/25][508/782] Loss_D: 0.3655 (0.5839) Loss_G: -0.0343 (0.4502) D(x): 0.5134 D(G(z)): 0.5127 / 0.4892 Acc: 34.3750 (24.1468)\n",
      "[3/25][509/782] Loss_D: 0.3072 (0.5839) Loss_G: 0.1172 (0.4500) D(x): 0.5703 D(G(z)): 0.5042 / 0.4393 Acc: 26.5625 (24.1476)\n",
      "[3/25][510/782] Loss_D: 0.1922 (0.5837) Loss_G: 0.1222 (0.4499) D(x): 0.5084 D(G(z)): 0.4292 / 0.4053 Acc: 32.8125 (24.1507)\n",
      "[3/25][511/782] Loss_D: 0.4236 (0.5837) Loss_G: 0.0670 (0.4498) D(x): 0.4912 D(G(z)): 0.4796 / 0.4734 Acc: 29.6875 (24.1526)\n",
      "[3/25][512/782] Loss_D: 0.3989 (0.5836) Loss_G: 0.0956 (0.4497) D(x): 0.4993 D(G(z)): 0.4881 / 0.4436 Acc: 28.1250 (24.1540)\n",
      "[3/25][513/782] Loss_D: 0.3549 (0.5835) Loss_G: 0.0934 (0.4495) D(x): 0.4994 D(G(z)): 0.4456 / 0.4490 Acc: 31.2500 (24.1565)\n",
      "[3/25][514/782] Loss_D: 0.2666 (0.5834) Loss_G: 0.1052 (0.4494) D(x): 0.6134 D(G(z)): 0.5177 / 0.4256 Acc: 21.8750 (24.1557)\n",
      "[3/25][515/782] Loss_D: 0.2883 (0.5833) Loss_G: 0.3153 (0.4494) D(x): 0.5771 D(G(z)): 0.4746 / 0.3708 Acc: 25.0000 (24.1560)\n",
      "[3/25][516/782] Loss_D: 0.1667 (0.5832) Loss_G: 0.3347 (0.4493) D(x): 0.5419 D(G(z)): 0.4247 / 0.3666 Acc: 32.8125 (24.1590)\n",
      "[3/25][517/782] Loss_D: 0.1282 (0.5830) Loss_G: 0.0757 (0.4492) D(x): 0.4993 D(G(z)): 0.3784 / 0.4301 Acc: 25.0000 (24.1593)\n",
      "[3/25][518/782] Loss_D: 0.1405 (0.5828) Loss_G: 0.0515 (0.4491) D(x): 0.5551 D(G(z)): 0.4633 / 0.4364 Acc: 26.5625 (24.1601)\n",
      "[3/25][519/782] Loss_D: 0.3078 (0.5827) Loss_G: 0.1296 (0.4490) D(x): 0.5667 D(G(z)): 0.4642 / 0.4441 Acc: 29.6875 (24.1621)\n",
      "[3/25][520/782] Loss_D: 0.4272 (0.5827) Loss_G: 0.2356 (0.4489) D(x): 0.5501 D(G(z)): 0.5422 / 0.4015 Acc: 37.5000 (24.1667)\n",
      "[3/25][521/782] Loss_D: 0.3117 (0.5826) Loss_G: 0.1681 (0.4488) D(x): 0.4848 D(G(z)): 0.4432 / 0.4124 Acc: 31.2500 (24.1692)\n",
      "[3/25][522/782] Loss_D: 0.2227 (0.5825) Loss_G: 0.1052 (0.4487) D(x): 0.5051 D(G(z)): 0.4281 / 0.4378 Acc: 35.9375 (24.1733)\n",
      "[3/25][523/782] Loss_D: 0.2456 (0.5824) Loss_G: -0.0718 (0.4485) D(x): 0.5087 D(G(z)): 0.4574 / 0.5126 Acc: 39.0625 (24.1785)\n",
      "[3/25][524/782] Loss_D: 0.4855 (0.5823) Loss_G: 0.1031 (0.4484) D(x): 0.5540 D(G(z)): 0.5447 / 0.4354 Acc: 23.4375 (24.1782)\n",
      "[3/25][525/782] Loss_D: 0.4463 (0.5823) Loss_G: 0.2055 (0.4483) D(x): 0.5217 D(G(z)): 0.5131 / 0.4107 Acc: 25.0000 (24.1785)\n",
      "[3/25][526/782] Loss_D: 0.4730 (0.5822) Loss_G: 0.2402 (0.4482) D(x): 0.5061 D(G(z)): 0.4943 / 0.4078 Acc: 29.6875 (24.1804)\n",
      "[3/25][527/782] Loss_D: 0.3029 (0.5821) Loss_G: -0.0014 (0.4480) D(x): 0.4496 D(G(z)): 0.4078 / 0.4583 Acc: 26.5625 (24.1812)\n",
      "[3/25][528/782] Loss_D: 0.4300 (0.5821) Loss_G: -0.0328 (0.4479) D(x): 0.5183 D(G(z)): 0.4985 / 0.5005 Acc: 25.0000 (24.1815)\n",
      "[3/25][529/782] Loss_D: 0.2890 (0.5820) Loss_G: 0.0477 (0.4477) D(x): 0.5922 D(G(z)): 0.5539 / 0.4549 Acc: 32.8125 (24.1845)\n",
      "[3/25][530/782] Loss_D: 0.3491 (0.5819) Loss_G: 0.3364 (0.4477) D(x): 0.5257 D(G(z)): 0.4827 / 0.3814 Acc: 35.9375 (24.1886)\n",
      "[3/25][531/782] Loss_D: 0.1847 (0.5818) Loss_G: 0.0892 (0.4476) D(x): 0.4912 D(G(z)): 0.4040 / 0.4220 Acc: 31.2500 (24.1911)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/25][532/782] Loss_D: 0.1989 (0.5816) Loss_G: 0.1295 (0.4475) D(x): 0.5687 D(G(z)): 0.4811 / 0.4393 Acc: 37.5000 (24.1957)\n",
      "[3/25][533/782] Loss_D: 0.3860 (0.5816) Loss_G: 0.1837 (0.4474) D(x): 0.5182 D(G(z)): 0.4748 / 0.4117 Acc: 23.4375 (24.1954)\n",
      "[3/25][534/782] Loss_D: 0.3307 (0.5815) Loss_G: 0.1107 (0.4473) D(x): 0.5273 D(G(z)): 0.4535 / 0.4418 Acc: 26.5625 (24.1962)\n",
      "[3/25][535/782] Loss_D: 0.1297 (0.5813) Loss_G: 0.0241 (0.4471) D(x): 0.5342 D(G(z)): 0.4025 / 0.4439 Acc: 31.2500 (24.1987)\n",
      "[3/25][536/782] Loss_D: 0.1367 (0.5812) Loss_G: 0.0719 (0.4470) D(x): 0.5824 D(G(z)): 0.4908 / 0.4586 Acc: 39.0625 (24.2038)\n",
      "[3/25][537/782] Loss_D: 0.1896 (0.5810) Loss_G: 0.3313 (0.4469) D(x): 0.5846 D(G(z)): 0.4650 / 0.3519 Acc: 26.5625 (24.2047)\n",
      "[3/25][538/782] Loss_D: 0.1321 (0.5809) Loss_G: 0.5021 (0.4470) D(x): 0.5297 D(G(z)): 0.3839 / 0.3094 Acc: 26.5625 (24.2055)\n",
      "[3/25][539/782] Loss_D: 0.1731 (0.5807) Loss_G: 0.2737 (0.4469) D(x): 0.5531 D(G(z)): 0.4250 / 0.3974 Acc: 31.2500 (24.2079)\n",
      "[3/25][540/782] Loss_D: 0.1050 (0.5806) Loss_G: 0.2474 (0.4468) D(x): 0.5177 D(G(z)): 0.3814 / 0.3654 Acc: 25.0000 (24.2082)\n",
      "[3/25][541/782] Loss_D: 0.1154 (0.5804) Loss_G: -0.0222 (0.4467) D(x): 0.5472 D(G(z)): 0.4204 / 0.4678 Acc: 29.6875 (24.2101)\n",
      "[3/25][542/782] Loss_D: 0.1420 (0.5803) Loss_G: 0.1725 (0.4466) D(x): 0.6645 D(G(z)): 0.5356 / 0.4008 Acc: 31.2500 (24.2125)\n",
      "[3/25][543/782] Loss_D: 0.1746 (0.5801) Loss_G: 0.3203 (0.4465) D(x): 0.5536 D(G(z)): 0.4842 / 0.3702 Acc: 40.6250 (24.2182)\n",
      "[3/25][544/782] Loss_D: 0.0339 (0.5799) Loss_G: 0.3825 (0.4465) D(x): 0.6086 D(G(z)): 0.4205 / 0.3275 Acc: 26.5625 (24.2190)\n",
      "[3/25][545/782] Loss_D: 0.3002 (0.5798) Loss_G: 0.2572 (0.4464) D(x): 0.5002 D(G(z)): 0.3891 / 0.3991 Acc: 28.1250 (24.2204)\n",
      "[3/25][546/782] Loss_D: 0.0759 (0.5797) Loss_G: 0.1162 (0.4463) D(x): 0.5447 D(G(z)): 0.3898 / 0.4484 Acc: 34.3750 (24.2239)\n",
      "[3/25][547/782] Loss_D: 0.1797 (0.5795) Loss_G: 0.0157 (0.4462) D(x): 0.5409 D(G(z)): 0.4550 / 0.4716 Acc: 31.2500 (24.2263)\n",
      "[3/25][548/782] Loss_D: 0.0151 (0.5793) Loss_G: 0.2250 (0.4461) D(x): 0.6705 D(G(z)): 0.4952 / 0.3872 Acc: 31.2500 (24.2287)\n",
      "[3/25][549/782] Loss_D: 0.1638 (0.5792) Loss_G: 0.2515 (0.4460) D(x): 0.5122 D(G(z)): 0.4090 / 0.4071 Acc: 39.0625 (24.2339)\n",
      "[3/25][550/782] Loss_D: 0.3145 (0.5791) Loss_G: 0.2453 (0.4460) D(x): 0.5117 D(G(z)): 0.4460 / 0.3714 Acc: 31.2500 (24.2363)\n",
      "[3/25][551/782] Loss_D: 0.0650 (0.5789) Loss_G: 0.2035 (0.4459) D(x): 0.5272 D(G(z)): 0.4056 / 0.3904 Acc: 34.3750 (24.2398)\n",
      "[3/25][552/782] Loss_D: 0.1308 (0.5788) Loss_G: 0.1195 (0.4458) D(x): 0.5655 D(G(z)): 0.4480 / 0.4171 Acc: 35.9375 (24.2438)\n",
      "[3/25][553/782] Loss_D: 0.2355 (0.5786) Loss_G: 0.1745 (0.4457) D(x): 0.5905 D(G(z)): 0.5134 / 0.4065 Acc: 29.6875 (24.2457)\n",
      "[3/25][554/782] Loss_D: 0.3792 (0.5786) Loss_G: 0.3421 (0.4456) D(x): 0.4757 D(G(z)): 0.4564 / 0.3480 Acc: 32.8125 (24.2486)\n",
      "[3/25][555/782] Loss_D: 0.5334 (0.5786) Loss_G: 0.3819 (0.4456) D(x): 0.5102 D(G(z)): 0.5296 / 0.3597 Acc: 31.2500 (24.2511)\n",
      "[3/25][556/782] Loss_D: 0.5432 (0.5785) Loss_G: 0.0113 (0.4455) D(x): 0.3825 D(G(z)): 0.4665 / 0.4408 Acc: 31.2500 (24.2535)\n",
      "[3/25][557/782] Loss_D: 0.4706 (0.5785) Loss_G: 0.0178 (0.4453) D(x): 0.4578 D(G(z)): 0.5290 / 0.4613 Acc: 34.3750 (24.2570)\n",
      "[3/25][558/782] Loss_D: 0.4186 (0.5784) Loss_G: 0.0831 (0.4452) D(x): 0.4810 D(G(z)): 0.5131 / 0.4481 Acc: 34.3750 (24.2604)\n",
      "[3/25][559/782] Loss_D: 0.4698 (0.5784) Loss_G: 0.0988 (0.4451) D(x): 0.5126 D(G(z)): 0.5006 / 0.4766 Acc: 29.6875 (24.2623)\n",
      "[3/25][560/782] Loss_D: 0.4872 (0.5784) Loss_G: 0.0727 (0.4449) D(x): 0.4872 D(G(z)): 0.5298 / 0.4466 Acc: 34.3750 (24.2658)\n",
      "[3/25][561/782] Loss_D: 0.3639 (0.5783) Loss_G: 0.2810 (0.4449) D(x): 0.5072 D(G(z)): 0.4288 / 0.3897 Acc: 26.5625 (24.2666)\n",
      "[3/25][562/782] Loss_D: 0.2840 (0.5782) Loss_G: 0.1822 (0.4448) D(x): 0.5096 D(G(z)): 0.4733 / 0.4201 Acc: 34.3750 (24.2700)\n",
      "[3/25][563/782] Loss_D: 0.3270 (0.5781) Loss_G: 0.0013 (0.4446) D(x): 0.5004 D(G(z)): 0.4676 / 0.4754 Acc: 31.2500 (24.2724)\n",
      "[3/25][564/782] Loss_D: 0.4290 (0.5781) Loss_G: -0.0559 (0.4445) D(x): 0.5100 D(G(z)): 0.5243 / 0.5088 Acc: 29.6875 (24.2743)\n",
      "[3/25][565/782] Loss_D: 0.3988 (0.5780) Loss_G: 0.0575 (0.4443) D(x): 0.5306 D(G(z)): 0.5053 / 0.4754 Acc: 31.2500 (24.2767)\n",
      "[3/25][566/782] Loss_D: 0.4025 (0.5779) Loss_G: -0.0262 (0.4442) D(x): 0.5636 D(G(z)): 0.4780 / 0.5081 Acc: 14.0625 (24.2732)\n",
      "[3/25][567/782] Loss_D: 0.1745 (0.5778) Loss_G: -0.0691 (0.4440) D(x): 0.5588 D(G(z)): 0.4988 / 0.4889 Acc: 34.3750 (24.2767)\n",
      "[3/25][568/782] Loss_D: 0.4506 (0.5778) Loss_G: 0.1991 (0.4439) D(x): 0.5651 D(G(z)): 0.5499 / 0.4402 Acc: 35.9375 (24.2807)\n",
      "[3/25][569/782] Loss_D: 0.4208 (0.5777) Loss_G: 0.1249 (0.4438) D(x): 0.4770 D(G(z)): 0.4627 / 0.4225 Acc: 28.1250 (24.2820)\n",
      "[3/25][570/782] Loss_D: 0.7455 (0.5778) Loss_G: -0.1302 (0.4436) D(x): 0.3709 D(G(z)): 0.5036 / 0.5721 Acc: 34.3750 (24.2854)\n",
      "[3/25][571/782] Loss_D: 0.3103 (0.5777) Loss_G: 0.0240 (0.4435) D(x): 0.6032 D(G(z)): 0.5402 / 0.5125 Acc: 37.5000 (24.2900)\n",
      "[3/25][572/782] Loss_D: 0.4708 (0.5776) Loss_G: 0.0251 (0.4433) D(x): 0.4545 D(G(z)): 0.4905 / 0.4612 Acc: 35.9375 (24.2940)\n",
      "[3/25][573/782] Loss_D: 0.5206 (0.5776) Loss_G: -0.0357 (0.4432) D(x): 0.5151 D(G(z)): 0.5436 / 0.4788 Acc: 23.4375 (24.2937)\n",
      "[3/25][574/782] Loss_D: 0.2098 (0.5775) Loss_G: 0.0570 (0.4430) D(x): 0.5977 D(G(z)): 0.5095 / 0.4555 Acc: 31.2500 (24.2960)\n",
      "[3/25][575/782] Loss_D: 0.4650 (0.5775) Loss_G: 0.0467 (0.4429) D(x): 0.4653 D(G(z)): 0.4931 / 0.4647 Acc: 34.3750 (24.2995)\n",
      "[3/25][576/782] Loss_D: 0.5395 (0.5774) Loss_G: -0.1474 (0.4427) D(x): 0.3849 D(G(z)): 0.4720 / 0.5104 Acc: 34.3750 (24.3029)\n",
      "[3/25][577/782] Loss_D: 0.2961 (0.5773) Loss_G: -0.0263 (0.4425) D(x): 0.5506 D(G(z)): 0.4949 / 0.5031 Acc: 29.6875 (24.3048)\n",
      "[3/25][578/782] Loss_D: 0.4487 (0.5773) Loss_G: 0.0445 (0.4424) D(x): 0.5405 D(G(z)): 0.5087 / 0.5000 Acc: 23.4375 (24.3045)\n",
      "[3/25][579/782] Loss_D: 0.3600 (0.5772) Loss_G: 0.0587 (0.4423) D(x): 0.5704 D(G(z)): 0.5502 / 0.4773 Acc: 32.8125 (24.3074)\n",
      "[3/25][580/782] Loss_D: 0.1792 (0.5771) Loss_G: 0.1022 (0.4422) D(x): 0.5444 D(G(z)): 0.4738 / 0.4246 Acc: 32.8125 (24.3103)\n",
      "[3/25][581/782] Loss_D: 0.3742 (0.5770) Loss_G: 0.0863 (0.4420) D(x): 0.4849 D(G(z)): 0.4326 / 0.4294 Acc: 20.3125 (24.3089)\n",
      "[3/25][582/782] Loss_D: 0.1710 (0.5769) Loss_G: 0.1406 (0.4419) D(x): 0.5701 D(G(z)): 0.4918 / 0.4158 Acc: 39.0625 (24.3140)\n",
      "[3/25][583/782] Loss_D: 0.2066 (0.5768) Loss_G: -0.0136 (0.4418) D(x): 0.5168 D(G(z)): 0.4668 / 0.4490 Acc: 31.2500 (24.3163)\n",
      "[3/25][584/782] Loss_D: 0.2039 (0.5766) Loss_G: 0.0434 (0.4416) D(x): 0.6013 D(G(z)): 0.4636 / 0.4942 Acc: 35.9375 (24.3203)\n",
      "[3/25][585/782] Loss_D: 0.2377 (0.5765) Loss_G: 0.2263 (0.4416) D(x): 0.5839 D(G(z)): 0.5124 / 0.3941 Acc: 32.8125 (24.3232)\n",
      "[3/25][586/782] Loss_D: 0.5235 (0.5765) Loss_G: 0.1098 (0.4415) D(x): 0.4999 D(G(z)): 0.5068 / 0.4498 Acc: 23.4375 (24.3229)\n",
      "[3/25][587/782] Loss_D: 0.3631 (0.5764) Loss_G: 0.1415 (0.4413) D(x): 0.5085 D(G(z)): 0.4574 / 0.4480 Acc: 26.5625 (24.3237)\n",
      "[3/25][588/782] Loss_D: 0.1930 (0.5763) Loss_G: 0.2266 (0.4413) D(x): 0.5837 D(G(z)): 0.4886 / 0.3748 Acc: 28.1250 (24.3250)\n",
      "[3/25][589/782] Loss_D: 0.2870 (0.5762) Loss_G: 0.1216 (0.4412) D(x): 0.4455 D(G(z)): 0.3883 / 0.4219 Acc: 29.6875 (24.3268)\n",
      "[3/25][590/782] Loss_D: 0.2737 (0.5761) Loss_G: -0.0386 (0.4410) D(x): 0.5273 D(G(z)): 0.5073 / 0.4548 Acc: 28.1250 (24.3281)\n",
      "[3/25][591/782] Loss_D: 0.2777 (0.5760) Loss_G: 0.2970 (0.4410) D(x): 0.5736 D(G(z)): 0.4824 / 0.3791 Acc: 28.1250 (24.3294)\n",
      "[3/25][592/782] Loss_D: 0.2124 (0.5759) Loss_G: 0.2611 (0.4409) D(x): 0.5250 D(G(z)): 0.4056 / 0.3788 Acc: 28.1250 (24.3307)\n",
      "[3/25][593/782] Loss_D: 0.1710 (0.5757) Loss_G: 0.0089 (0.4407) D(x): 0.4705 D(G(z)): 0.4032 / 0.4402 Acc: 31.2500 (24.3330)\n",
      "[3/25][594/782] Loss_D: 0.1433 (0.5756) Loss_G: 0.1902 (0.4407) D(x): 0.6383 D(G(z)): 0.4962 / 0.3838 Acc: 20.3125 (24.3316)\n",
      "[3/25][595/782] Loss_D: 0.4144 (0.5755) Loss_G: 0.4225 (0.4407) D(x): 0.5245 D(G(z)): 0.4874 / 0.3399 Acc: 25.0000 (24.3319)\n",
      "[3/25][596/782] Loss_D: 0.3548 (0.5755) Loss_G: 0.3468 (0.4406) D(x): 0.4890 D(G(z)): 0.3955 / 0.3946 Acc: 32.8125 (24.3348)\n",
      "[3/25][597/782] Loss_D: 0.2872 (0.5754) Loss_G: 0.0906 (0.4405) D(x): 0.4595 D(G(z)): 0.3662 / 0.4319 Acc: 23.4375 (24.3345)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/25][598/782] Loss_D: 0.1412 (0.5752) Loss_G: -0.0411 (0.4403) D(x): 0.5469 D(G(z)): 0.4672 / 0.4834 Acc: 35.9375 (24.3384)\n",
      "[3/25][599/782] Loss_D: 0.3116 (0.5751) Loss_G: 0.1024 (0.4402) D(x): 0.5570 D(G(z)): 0.5151 / 0.4570 Acc: 31.2500 (24.3407)\n",
      "[3/25][600/782] Loss_D: 0.2902 (0.5750) Loss_G: 0.1363 (0.4401) D(x): 0.4891 D(G(z)): 0.4765 / 0.4267 Acc: 40.6250 (24.3463)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[3/25][601/782] Loss_D: 0.2363 (0.5749) Loss_G: 0.1072 (0.4400) D(x): 0.5532 D(G(z)): 0.5165 / 0.4301 Acc: 34.3750 (24.3497)\n",
      "[3/25][602/782] Loss_D: 0.2436 (0.5748) Loss_G: 0.1998 (0.4399) D(x): 0.4947 D(G(z)): 0.4426 / 0.4164 Acc: 42.1875 (24.3557)\n",
      "[3/25][603/782] Loss_D: 0.3534 (0.5747) Loss_G: 0.1810 (0.4398) D(x): 0.5151 D(G(z)): 0.4054 / 0.4587 Acc: 28.1250 (24.3570)\n",
      "[3/25][604/782] Loss_D: 0.3344 (0.5746) Loss_G: 0.1879 (0.4398) D(x): 0.5972 D(G(z)): 0.4960 / 0.4290 Acc: 20.3125 (24.3556)\n",
      "[3/25][605/782] Loss_D: 0.2874 (0.5745) Loss_G: 0.0391 (0.4396) D(x): 0.5503 D(G(z)): 0.4876 / 0.4378 Acc: 23.4375 (24.3553)\n",
      "[3/25][606/782] Loss_D: 0.2434 (0.5744) Loss_G: 0.1112 (0.4395) D(x): 0.5291 D(G(z)): 0.4264 / 0.4436 Acc: 25.0000 (24.3555)\n",
      "[3/25][607/782] Loss_D: 0.0693 (0.5743) Loss_G: 0.0561 (0.4394) D(x): 0.5679 D(G(z)): 0.4748 / 0.4467 Acc: 37.5000 (24.3600)\n",
      "[3/25][608/782] Loss_D: 0.1704 (0.5741) Loss_G: 0.0889 (0.4393) D(x): 0.5202 D(G(z)): 0.4638 / 0.4206 Acc: 37.5000 (24.3644)\n",
      "[3/25][609/782] Loss_D: 0.0776 (0.5740) Loss_G: 0.2595 (0.4392) D(x): 0.5534 D(G(z)): 0.4092 / 0.3639 Acc: 34.3750 (24.3678)\n",
      "[3/25][610/782] Loss_D: 0.2516 (0.5738) Loss_G: 0.1882 (0.4391) D(x): 0.5143 D(G(z)): 0.4453 / 0.4210 Acc: 35.9375 (24.3717)\n",
      "[3/25][611/782] Loss_D: 0.3374 (0.5738) Loss_G: 0.0409 (0.4390) D(x): 0.5458 D(G(z)): 0.5047 / 0.4523 Acc: 26.5625 (24.3725)\n",
      "[3/25][612/782] Loss_D: 0.2280 (0.5736) Loss_G: 0.2487 (0.4389) D(x): 0.5424 D(G(z)): 0.4642 / 0.3857 Acc: 31.2500 (24.3748)\n",
      "[3/25][613/782] Loss_D: 0.2662 (0.5735) Loss_G: 0.1200 (0.4388) D(x): 0.5126 D(G(z)): 0.4345 / 0.4206 Acc: 23.4375 (24.3745)\n",
      "[3/25][614/782] Loss_D: 0.1562 (0.5734) Loss_G: 0.0570 (0.4387) D(x): 0.5420 D(G(z)): 0.4310 / 0.4742 Acc: 32.8125 (24.3773)\n",
      "[3/25][615/782] Loss_D: 0.5155 (0.5734) Loss_G: 0.1684 (0.4386) D(x): 0.5572 D(G(z)): 0.5394 / 0.4429 Acc: 28.1250 (24.3786)\n",
      "[3/25][616/782] Loss_D: 0.2378 (0.5733) Loss_G: 0.2233 (0.4385) D(x): 0.5189 D(G(z)): 0.4514 / 0.3787 Acc: 25.0000 (24.3788)\n",
      "[3/25][617/782] Loss_D: 0.2464 (0.5732) Loss_G: 0.0220 (0.4384) D(x): 0.5207 D(G(z)): 0.4367 / 0.4766 Acc: 29.6875 (24.3806)\n",
      "[3/25][618/782] Loss_D: 0.1410 (0.5730) Loss_G: 0.0022 (0.4382) D(x): 0.5282 D(G(z)): 0.4514 / 0.4624 Acc: 34.3750 (24.3840)\n",
      "[3/25][619/782] Loss_D: -0.0781 (0.5728) Loss_G: -0.0272 (0.4381) D(x): 0.5804 D(G(z)): 0.4337 / 0.4641 Acc: 42.1875 (24.3900)\n",
      "[3/25][620/782] Loss_D: 0.5054 (0.5728) Loss_G: 0.2793 (0.4380) D(x): 0.5368 D(G(z)): 0.5318 / 0.4294 Acc: 29.6875 (24.3917)\n",
      "[3/25][621/782] Loss_D: 0.2796 (0.5727) Loss_G: -0.0090 (0.4379) D(x): 0.4891 D(G(z)): 0.4591 / 0.4822 Acc: 39.0625 (24.3967)\n",
      "[3/25][622/782] Loss_D: 0.3318 (0.5726) Loss_G: -0.0045 (0.4377) D(x): 0.4996 D(G(z)): 0.4519 / 0.5038 Acc: 28.1250 (24.3979)\n",
      "[3/25][623/782] Loss_D: 0.4128 (0.5725) Loss_G: -0.0355 (0.4376) D(x): 0.5619 D(G(z)): 0.5374 / 0.4808 Acc: 26.5625 (24.3987)\n",
      "[3/25][624/782] Loss_D: 0.2897 (0.5724) Loss_G: -0.0424 (0.4374) D(x): 0.5161 D(G(z)): 0.5160 / 0.4826 Acc: 37.5000 (24.4031)\n",
      "[3/25][625/782] Loss_D: 0.3312 (0.5724) Loss_G: 0.1206 (0.4373) D(x): 0.4955 D(G(z)): 0.4664 / 0.4365 Acc: 31.2500 (24.4054)\n",
      "[3/25][626/782] Loss_D: 0.2007 (0.5722) Loss_G: -0.0256 (0.4371) D(x): 0.5346 D(G(z)): 0.4849 / 0.5171 Acc: 43.7500 (24.4119)\n",
      "[3/25][627/782] Loss_D: 0.3080 (0.5721) Loss_G: 0.0413 (0.4370) D(x): 0.5226 D(G(z)): 0.4783 / 0.4592 Acc: 35.9375 (24.4158)\n",
      "[3/25][628/782] Loss_D: 0.2536 (0.5720) Loss_G: -0.0628 (0.4368) D(x): 0.5377 D(G(z)): 0.4657 / 0.4898 Acc: 25.0000 (24.4160)\n",
      "[3/25][629/782] Loss_D: 0.4309 (0.5720) Loss_G: 0.0536 (0.4367) D(x): 0.5466 D(G(z)): 0.4950 / 0.4817 Acc: 21.8750 (24.4151)\n",
      "[3/25][630/782] Loss_D: 0.1783 (0.5719) Loss_G: 0.1581 (0.4366) D(x): 0.5607 D(G(z)): 0.4785 / 0.4142 Acc: 34.3750 (24.4185)\n",
      "[3/25][631/782] Loss_D: 0.3354 (0.5718) Loss_G: 0.2325 (0.4365) D(x): 0.5258 D(G(z)): 0.4780 / 0.4094 Acc: 34.3750 (24.4218)\n",
      "[3/25][632/782] Loss_D: 0.3370 (0.5717) Loss_G: 0.0545 (0.4364) D(x): 0.5259 D(G(z)): 0.5401 / 0.4317 Acc: 32.8125 (24.4246)\n",
      "[3/25][633/782] Loss_D: 0.2111 (0.5716) Loss_G: 0.0634 (0.4363) D(x): 0.5263 D(G(z)): 0.4047 / 0.4641 Acc: 26.5625 (24.4253)\n",
      "[3/25][634/782] Loss_D: 0.5517 (0.5716) Loss_G: 0.3473 (0.4363) D(x): 0.5494 D(G(z)): 0.5061 / 0.4036 Acc: 18.7500 (24.4234)\n",
      "[3/25][635/782] Loss_D: 0.1334 (0.5714) Loss_G: 0.0908 (0.4361) D(x): 0.5188 D(G(z)): 0.4300 / 0.4127 Acc: 34.3750 (24.4268)\n",
      "[3/25][636/782] Loss_D: 0.2007 (0.5713) Loss_G: -0.0168 (0.4360) D(x): 0.4820 D(G(z)): 0.4369 / 0.4571 Acc: 32.8125 (24.4296)\n",
      "[3/25][637/782] Loss_D: 0.3013 (0.5712) Loss_G: 0.0935 (0.4359) D(x): 0.5235 D(G(z)): 0.4805 / 0.4434 Acc: 29.6875 (24.4313)\n",
      "[3/25][638/782] Loss_D: 0.3360 (0.5711) Loss_G: 0.2128 (0.4358) D(x): 0.5033 D(G(z)): 0.4479 / 0.4091 Acc: 28.1250 (24.4326)\n",
      "[3/25][639/782] Loss_D: 0.2702 (0.5710) Loss_G: 0.1634 (0.4357) D(x): 0.5210 D(G(z)): 0.4985 / 0.4107 Acc: 39.0625 (24.4375)\n",
      "[3/25][640/782] Loss_D: 0.4878 (0.5710) Loss_G: 0.1198 (0.4356) D(x): 0.4677 D(G(z)): 0.4944 / 0.4728 Acc: 37.5000 (24.4419)\n",
      "[3/25][641/782] Loss_D: 0.4121 (0.5709) Loss_G: 0.2121 (0.4355) D(x): 0.5274 D(G(z)): 0.5210 / 0.4224 Acc: 34.3750 (24.4452)\n",
      "[3/25][642/782] Loss_D: 0.4623 (0.5709) Loss_G: 0.1097 (0.4354) D(x): 0.5031 D(G(z)): 0.5123 / 0.4081 Acc: 20.3125 (24.4438)\n",
      "[3/25][643/782] Loss_D: 0.2076 (0.5708) Loss_G: 0.1076 (0.4353) D(x): 0.5118 D(G(z)): 0.4496 / 0.4329 Acc: 35.9375 (24.4476)\n",
      "[3/25][644/782] Loss_D: 0.3557 (0.5707) Loss_G: 0.0435 (0.4352) D(x): 0.4837 D(G(z)): 0.4596 / 0.4702 Acc: 32.8125 (24.4504)\n",
      "[3/25][645/782] Loss_D: 0.4051 (0.5707) Loss_G: 0.1228 (0.4351) D(x): 0.5229 D(G(z)): 0.5165 / 0.4498 Acc: 31.2500 (24.4527)\n",
      "[3/25][646/782] Loss_D: 0.2391 (0.5706) Loss_G: 0.0145 (0.4349) D(x): 0.5698 D(G(z)): 0.4987 / 0.4589 Acc: 29.6875 (24.4545)\n",
      "[3/25][647/782] Loss_D: 0.2933 (0.5705) Loss_G: 0.1032 (0.4348) D(x): 0.4741 D(G(z)): 0.4674 / 0.4465 Acc: 40.6250 (24.4599)\n",
      "[3/25][648/782] Loss_D: 0.2328 (0.5703) Loss_G: 0.1752 (0.4347) D(x): 0.5828 D(G(z)): 0.5245 / 0.4082 Acc: 37.5000 (24.4642)\n",
      "[3/25][649/782] Loss_D: 0.4550 (0.5703) Loss_G: 0.1411 (0.4346) D(x): 0.4269 D(G(z)): 0.4599 / 0.4373 Acc: 35.9375 (24.4680)\n",
      "[3/25][650/782] Loss_D: 0.2396 (0.5702) Loss_G: -0.0518 (0.4345) D(x): 0.5611 D(G(z)): 0.4850 / 0.5053 Acc: 31.2500 (24.4703)\n",
      "[3/25][651/782] Loss_D: 0.2638 (0.5701) Loss_G: 0.1726 (0.4344) D(x): 0.5552 D(G(z)): 0.4573 / 0.4275 Acc: 28.1250 (24.4715)\n",
      "[3/25][652/782] Loss_D: 0.2883 (0.5700) Loss_G: 0.0644 (0.4343) D(x): 0.4582 D(G(z)): 0.4490 / 0.4394 Acc: 39.0625 (24.4764)\n",
      "[3/25][653/782] Loss_D: 0.4083 (0.5699) Loss_G: 0.0577 (0.4341) D(x): 0.5104 D(G(z)): 0.5310 / 0.4893 Acc: 40.6250 (24.4818)\n",
      "[3/25][654/782] Loss_D: 0.2888 (0.5699) Loss_G: 0.0952 (0.4340) D(x): 0.5616 D(G(z)): 0.5058 / 0.4487 Acc: 31.2500 (24.4840)\n",
      "[3/25][655/782] Loss_D: 0.0591 (0.5697) Loss_G: 0.1625 (0.4339) D(x): 0.5870 D(G(z)): 0.4581 / 0.4324 Acc: 42.1875 (24.4899)\n",
      "[3/25][656/782] Loss_D: 0.3029 (0.5696) Loss_G: 0.2767 (0.4339) D(x): 0.4835 D(G(z)): 0.4047 / 0.3834 Acc: 26.5625 (24.4906)\n",
      "[3/25][657/782] Loss_D: 0.4564 (0.5696) Loss_G: 0.0563 (0.4338) D(x): 0.4606 D(G(z)): 0.4601 / 0.4933 Acc: 35.9375 (24.4944)\n",
      "[3/25][658/782] Loss_D: 0.2221 (0.5694) Loss_G: -0.0211 (0.4336) D(x): 0.5686 D(G(z)): 0.5061 / 0.4821 Acc: 31.2500 (24.4967)\n",
      "[3/25][659/782] Loss_D: 0.2839 (0.5693) Loss_G: 0.2569 (0.4335) D(x): 0.6316 D(G(z)): 0.5002 / 0.4463 Acc: 32.8125 (24.4994)\n",
      "[3/25][660/782] Loss_D: 0.0525 (0.5692) Loss_G: 0.2110 (0.4335) D(x): 0.5984 D(G(z)): 0.4411 / 0.3970 Acc: 26.5625 (24.5001)\n",
      "[3/25][661/782] Loss_D: 0.0952 (0.5690) Loss_G: 0.1261 (0.4334) D(x): 0.5170 D(G(z)): 0.4211 / 0.4216 Acc: 35.9375 (24.5039)\n",
      "[3/25][662/782] Loss_D: 0.2252 (0.5689) Loss_G: 0.1701 (0.4333) D(x): 0.5414 D(G(z)): 0.4547 / 0.4236 Acc: 31.2500 (24.5062)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/25][663/782] Loss_D: 0.3842 (0.5688) Loss_G: 0.3540 (0.4333) D(x): 0.4878 D(G(z)): 0.4402 / 0.3967 Acc: 28.1250 (24.5074)\n",
      "[3/25][664/782] Loss_D: 0.2958 (0.5688) Loss_G: 0.2052 (0.4332) D(x): 0.5746 D(G(z)): 0.4793 / 0.4313 Acc: 29.6875 (24.5091)\n",
      "[3/25][665/782] Loss_D: 0.2223 (0.5686) Loss_G: 0.1344 (0.4331) D(x): 0.5391 D(G(z)): 0.4885 / 0.4161 Acc: 32.8125 (24.5118)\n",
      "[3/25][666/782] Loss_D: 0.3681 (0.5686) Loss_G: 0.1373 (0.4330) D(x): 0.4718 D(G(z)): 0.4511 / 0.4152 Acc: 23.4375 (24.5115)\n",
      "[3/25][667/782] Loss_D: 0.1203 (0.5684) Loss_G: 0.1570 (0.4329) D(x): 0.5428 D(G(z)): 0.3900 / 0.4322 Acc: 31.2500 (24.5137)\n",
      "[3/25][668/782] Loss_D: 0.3753 (0.5684) Loss_G: -0.0455 (0.4327) D(x): 0.5555 D(G(z)): 0.5640 / 0.4695 Acc: 35.9375 (24.5175)\n",
      "[3/25][669/782] Loss_D: 0.2313 (0.5682) Loss_G: 0.1809 (0.4327) D(x): 0.5462 D(G(z)): 0.4697 / 0.4222 Acc: 32.8125 (24.5203)\n",
      "[3/25][670/782] Loss_D: 0.4140 (0.5682) Loss_G: 0.1773 (0.4326) D(x): 0.5225 D(G(z)): 0.4619 / 0.4526 Acc: 28.1250 (24.5215)\n",
      "[3/25][671/782] Loss_D: 0.2678 (0.5681) Loss_G: 0.0418 (0.4324) D(x): 0.4803 D(G(z)): 0.4529 / 0.4529 Acc: 31.2500 (24.5237)\n",
      "[3/25][672/782] Loss_D: -0.0442 (0.5679) Loss_G: -0.1273 (0.4323) D(x): 0.5268 D(G(z)): 0.4394 / 0.4928 Acc: 48.4375 (24.5316)\n",
      "[3/25][673/782] Loss_D: 0.3109 (0.5678) Loss_G: 0.0804 (0.4321) D(x): 0.5204 D(G(z)): 0.5024 / 0.4188 Acc: 29.6875 (24.5333)\n",
      "[3/25][674/782] Loss_D: 0.2109 (0.5677) Loss_G: 0.0808 (0.4320) D(x): 0.5067 D(G(z)): 0.5042 / 0.4170 Acc: 40.6250 (24.5386)\n",
      "[3/25][675/782] Loss_D: 0.2989 (0.5676) Loss_G: -0.0804 (0.4318) D(x): 0.4418 D(G(z)): 0.4358 / 0.5008 Acc: 35.9375 (24.5424)\n",
      "[3/25][676/782] Loss_D: 0.3510 (0.5675) Loss_G: 0.1627 (0.4318) D(x): 0.5614 D(G(z)): 0.5011 / 0.4396 Acc: 28.1250 (24.5436)\n",
      "[3/25][677/782] Loss_D: 0.2969 (0.5674) Loss_G: 0.1874 (0.4317) D(x): 0.5163 D(G(z)): 0.4424 / 0.4420 Acc: 34.3750 (24.5469)\n",
      "[3/25][678/782] Loss_D: 0.3478 (0.5674) Loss_G: 0.1231 (0.4316) D(x): 0.5346 D(G(z)): 0.4951 / 0.4497 Acc: 32.8125 (24.5496)\n",
      "[3/25][679/782] Loss_D: 0.1634 (0.5672) Loss_G: 0.1703 (0.4315) D(x): 0.5760 D(G(z)): 0.4932 / 0.4174 Acc: 37.5000 (24.5539)\n",
      "[3/25][680/782] Loss_D: 0.2513 (0.5671) Loss_G: 0.1860 (0.4314) D(x): 0.4952 D(G(z)): 0.4304 / 0.4094 Acc: 35.9375 (24.5576)\n",
      "[3/25][681/782] Loss_D: 0.3704 (0.5671) Loss_G: 0.2176 (0.4313) D(x): 0.5090 D(G(z)): 0.4860 / 0.4128 Acc: 37.5000 (24.5619)\n",
      "[3/25][682/782] Loss_D: 0.2763 (0.5670) Loss_G: 0.1082 (0.4312) D(x): 0.4826 D(G(z)): 0.4521 / 0.4426 Acc: 40.6250 (24.5672)\n",
      "[3/25][683/782] Loss_D: 0.2322 (0.5669) Loss_G: 0.1299 (0.4311) D(x): 0.5326 D(G(z)): 0.4579 / 0.4306 Acc: 32.8125 (24.5699)\n",
      "[3/25][684/782] Loss_D: 0.3924 (0.5668) Loss_G: 0.0641 (0.4310) D(x): 0.4951 D(G(z)): 0.4751 / 0.4570 Acc: 31.2500 (24.5721)\n",
      "[3/25][685/782] Loss_D: 0.1759 (0.5667) Loss_G: 0.0610 (0.4309) D(x): 0.5259 D(G(z)): 0.4617 / 0.4593 Acc: 42.1875 (24.5779)\n",
      "[3/25][686/782] Loss_D: 0.1562 (0.5665) Loss_G: -0.0356 (0.4307) D(x): 0.5400 D(G(z)): 0.4913 / 0.4609 Acc: 34.3750 (24.5812)\n",
      "[3/25][687/782] Loss_D: 0.2199 (0.5664) Loss_G: 0.1312 (0.4306) D(x): 0.5384 D(G(z)): 0.4779 / 0.4055 Acc: 31.2500 (24.5834)\n",
      "[3/25][688/782] Loss_D: 0.2911 (0.5663) Loss_G: -0.0173 (0.4305) D(x): 0.4613 D(G(z)): 0.4315 / 0.4892 Acc: 37.5000 (24.5876)\n",
      "[3/25][689/782] Loss_D: 0.3489 (0.5663) Loss_G: 0.1276 (0.4304) D(x): 0.5214 D(G(z)): 0.4948 / 0.3940 Acc: 21.8750 (24.5867)\n",
      "[3/25][690/782] Loss_D: 0.4598 (0.5662) Loss_G: 0.1343 (0.4303) D(x): 0.5013 D(G(z)): 0.5221 / 0.4462 Acc: 37.5000 (24.5910)\n",
      "[3/25][691/782] Loss_D: 0.2920 (0.5661) Loss_G: 0.2571 (0.4302) D(x): 0.5336 D(G(z)): 0.4743 / 0.3894 Acc: 35.9375 (24.5947)\n",
      "[3/25][692/782] Loss_D: 0.2747 (0.5660) Loss_G: 0.1557 (0.4301) D(x): 0.5350 D(G(z)): 0.4259 / 0.4298 Acc: 25.0000 (24.5949)\n",
      "[3/25][693/782] Loss_D: 0.4347 (0.5660) Loss_G: 0.2013 (0.4301) D(x): 0.4882 D(G(z)): 0.4724 / 0.4041 Acc: 25.0000 (24.5950)\n",
      "[3/25][694/782] Loss_D: 0.4059 (0.5659) Loss_G: 0.1608 (0.4300) D(x): 0.4769 D(G(z)): 0.4128 / 0.4597 Acc: 31.2500 (24.5972)\n",
      "[3/25][695/782] Loss_D: 0.2815 (0.5658) Loss_G: 0.1170 (0.4299) D(x): 0.5928 D(G(z)): 0.4896 / 0.4587 Acc: 26.5625 (24.5978)\n",
      "[3/25][696/782] Loss_D: 0.5616 (0.5658) Loss_G: -0.0046 (0.4297) D(x): 0.4787 D(G(z)): 0.5567 / 0.4759 Acc: 32.8125 (24.6005)\n",
      "[3/25][697/782] Loss_D: 0.5720 (0.5658) Loss_G: 0.0484 (0.4296) D(x): 0.5069 D(G(z)): 0.4963 / 0.4920 Acc: 18.7500 (24.5986)\n",
      "[3/25][698/782] Loss_D: 0.5366 (0.5658) Loss_G: 0.0914 (0.4295) D(x): 0.4997 D(G(z)): 0.4785 / 0.4596 Acc: 18.7500 (24.5967)\n",
      "[3/25][699/782] Loss_D: 0.3278 (0.5658) Loss_G: 0.0459 (0.4294) D(x): 0.5368 D(G(z)): 0.4853 / 0.4926 Acc: 31.2500 (24.5989)\n",
      "[3/25][700/782] Loss_D: 0.6077 (0.5658) Loss_G: 0.0140 (0.4292) D(x): 0.4642 D(G(z)): 0.5027 / 0.5035 Acc: 25.0000 (24.5990)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[3/25][701/782] Loss_D: 0.1215 (0.5656) Loss_G: 0.1299 (0.4291) D(x): 0.5602 D(G(z)): 0.4749 / 0.4216 Acc: 37.5000 (24.6032)\n",
      "[3/25][702/782] Loss_D: 0.1044 (0.5655) Loss_G: 0.4383 (0.4291) D(x): 0.6056 D(G(z)): 0.4579 / 0.3411 Acc: 28.1250 (24.6044)\n",
      "[3/25][703/782] Loss_D: 0.3011 (0.5654) Loss_G: 0.2063 (0.4291) D(x): 0.5062 D(G(z)): 0.4299 / 0.4108 Acc: 28.1250 (24.6055)\n",
      "[3/25][704/782] Loss_D: 0.3388 (0.5653) Loss_G: 0.0122 (0.4289) D(x): 0.4652 D(G(z)): 0.4360 / 0.4701 Acc: 28.1250 (24.6067)\n",
      "[3/25][705/782] Loss_D: 0.4350 (0.5653) Loss_G: -0.1290 (0.4287) D(x): 0.4815 D(G(z)): 0.5004 / 0.5126 Acc: 29.6875 (24.6084)\n",
      "[3/25][706/782] Loss_D: 0.4227 (0.5652) Loss_G: -0.0456 (0.4286) D(x): 0.5417 D(G(z)): 0.5123 / 0.5085 Acc: 20.3125 (24.6069)\n",
      "[3/25][707/782] Loss_D: 0.2622 (0.5651) Loss_G: 0.0810 (0.4285) D(x): 0.5263 D(G(z)): 0.4919 / 0.4512 Acc: 42.1875 (24.6127)\n",
      "[3/25][708/782] Loss_D: 0.1800 (0.5650) Loss_G: 0.2094 (0.4284) D(x): 0.5780 D(G(z)): 0.4217 / 0.4200 Acc: 28.1250 (24.6139)\n",
      "[3/25][709/782] Loss_D: 0.4294 (0.5650) Loss_G: 0.0980 (0.4283) D(x): 0.5208 D(G(z)): 0.5363 / 0.4283 Acc: 31.2500 (24.6160)\n",
      "[3/25][710/782] Loss_D: 0.1259 (0.5648) Loss_G: 0.1149 (0.4282) D(x): 0.5556 D(G(z)): 0.4417 / 0.4124 Acc: 32.8125 (24.6187)\n",
      "[3/25][711/782] Loss_D: 0.5047 (0.5648) Loss_G: 0.3016 (0.4282) D(x): 0.4486 D(G(z)): 0.4701 / 0.3772 Acc: 34.3750 (24.6219)\n",
      "[3/25][712/782] Loss_D: 0.3981 (0.5647) Loss_G: 0.1444 (0.4281) D(x): 0.5063 D(G(z)): 0.4633 / 0.4345 Acc: 31.2500 (24.6241)\n",
      "[3/25][713/782] Loss_D: 0.1730 (0.5646) Loss_G: 0.0480 (0.4279) D(x): 0.5376 D(G(z)): 0.4079 / 0.4698 Acc: 28.1250 (24.6252)\n",
      "[3/25][714/782] Loss_D: 0.2724 (0.5645) Loss_G: 0.1870 (0.4279) D(x): 0.5827 D(G(z)): 0.4748 / 0.4376 Acc: 29.6875 (24.6269)\n",
      "[3/25][715/782] Loss_D: 0.1170 (0.5644) Loss_G: 0.1203 (0.4278) D(x): 0.5381 D(G(z)): 0.4061 / 0.4432 Acc: 32.8125 (24.6295)\n",
      "[3/25][716/782] Loss_D: 0.2926 (0.5643) Loss_G: 0.1063 (0.4277) D(x): 0.5556 D(G(z)): 0.4606 / 0.4465 Acc: 25.0000 (24.6297)\n",
      "[3/25][717/782] Loss_D: 0.3588 (0.5642) Loss_G: 0.0362 (0.4275) D(x): 0.5230 D(G(z)): 0.5007 / 0.4624 Acc: 29.6875 (24.6313)\n",
      "[3/25][718/782] Loss_D: 0.1985 (0.5641) Loss_G: 0.0569 (0.4274) D(x): 0.5438 D(G(z)): 0.4650 / 0.4459 Acc: 29.6875 (24.6330)\n",
      "[3/25][719/782] Loss_D: 0.1966 (0.5640) Loss_G: 0.1492 (0.4273) D(x): 0.5283 D(G(z)): 0.4492 / 0.4145 Acc: 35.9375 (24.6366)\n",
      "[3/25][720/782] Loss_D: 0.2581 (0.5639) Loss_G: 0.2529 (0.4273) D(x): 0.5846 D(G(z)): 0.5266 / 0.3907 Acc: 34.3750 (24.6398)\n",
      "[3/25][721/782] Loss_D: 0.3054 (0.5638) Loss_G: 0.2189 (0.4272) D(x): 0.4957 D(G(z)): 0.4446 / 0.4078 Acc: 32.8125 (24.6425)\n",
      "[3/25][722/782] Loss_D: 0.5392 (0.5638) Loss_G: 0.2516 (0.4271) D(x): 0.5111 D(G(z)): 0.4831 / 0.4271 Acc: 25.0000 (24.6426)\n",
      "[3/25][723/782] Loss_D: 0.2143 (0.5637) Loss_G: 0.1008 (0.4270) D(x): 0.5600 D(G(z)): 0.4743 / 0.4469 Acc: 32.8125 (24.6453)\n",
      "[3/25][724/782] Loss_D: 0.0420 (0.5635) Loss_G: -0.0450 (0.4269) D(x): 0.5561 D(G(z)): 0.4371 / 0.4691 Acc: 34.3750 (24.6484)\n",
      "[3/25][725/782] Loss_D: 0.2299 (0.5634) Loss_G: 0.0360 (0.4267) D(x): 0.5722 D(G(z)): 0.4509 / 0.4745 Acc: 25.0000 (24.6485)\n",
      "[3/25][726/782] Loss_D: 0.2729 (0.5633) Loss_G: -0.0983 (0.4266) D(x): 0.5461 D(G(z)): 0.5026 / 0.4803 Acc: 23.4375 (24.6481)\n",
      "[3/25][727/782] Loss_D: 0.1206 (0.5632) Loss_G: 0.2010 (0.4265) D(x): 0.5702 D(G(z)): 0.4822 / 0.3770 Acc: 32.8125 (24.6508)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/25][728/782] Loss_D: 0.2461 (0.5631) Loss_G: 0.2686 (0.4265) D(x): 0.5085 D(G(z)): 0.4582 / 0.3692 Acc: 31.2500 (24.6529)\n",
      "[3/25][729/782] Loss_D: 0.3786 (0.5630) Loss_G: 0.1124 (0.4263) D(x): 0.4907 D(G(z)): 0.4644 / 0.4275 Acc: 21.8750 (24.6520)\n",
      "[3/25][730/782] Loss_D: 0.3298 (0.5629) Loss_G: 0.0229 (0.4262) D(x): 0.5301 D(G(z)): 0.4944 / 0.4796 Acc: 29.6875 (24.6537)\n",
      "[3/25][731/782] Loss_D: 0.3485 (0.5628) Loss_G: 0.1369 (0.4261) D(x): 0.5122 D(G(z)): 0.4636 / 0.4487 Acc: 28.1250 (24.6548)\n",
      "[3/25][732/782] Loss_D: 0.2375 (0.5627) Loss_G: 0.0738 (0.4260) D(x): 0.5323 D(G(z)): 0.4747 / 0.4413 Acc: 34.3750 (24.6580)\n",
      "[3/25][733/782] Loss_D: 0.3743 (0.5627) Loss_G: 0.0236 (0.4259) D(x): 0.4964 D(G(z)): 0.4609 / 0.4648 Acc: 29.6875 (24.6596)\n",
      "[3/25][734/782] Loss_D: 0.2751 (0.5626) Loss_G: 0.0546 (0.4258) D(x): 0.5268 D(G(z)): 0.4588 / 0.4491 Acc: 29.6875 (24.6612)\n",
      "[3/25][735/782] Loss_D: -0.0239 (0.5624) Loss_G: 0.1704 (0.4257) D(x): 0.6072 D(G(z)): 0.4344 / 0.4119 Acc: 37.5000 (24.6654)\n",
      "[3/25][736/782] Loss_D: 0.3702 (0.5623) Loss_G: 0.1775 (0.4256) D(x): 0.5182 D(G(z)): 0.4620 / 0.4426 Acc: 26.5625 (24.6660)\n",
      "[3/25][737/782] Loss_D: 0.3235 (0.5623) Loss_G: 0.2343 (0.4255) D(x): 0.5682 D(G(z)): 0.5346 / 0.3830 Acc: 28.1250 (24.6671)\n",
      "[3/25][738/782] Loss_D: 0.3540 (0.5622) Loss_G: 0.3474 (0.4255) D(x): 0.5172 D(G(z)): 0.4627 / 0.3705 Acc: 28.1250 (24.6683)\n",
      "[3/25][739/782] Loss_D: 0.4671 (0.5622) Loss_G: 0.2471 (0.4255) D(x): 0.4087 D(G(z)): 0.3926 / 0.4055 Acc: 29.6875 (24.6699)\n",
      "[3/25][740/782] Loss_D: 0.2445 (0.5621) Loss_G: -0.1262 (0.4253) D(x): 0.5236 D(G(z)): 0.4736 / 0.5230 Acc: 34.3750 (24.6730)\n",
      "[3/25][741/782] Loss_D: 0.4175 (0.5620) Loss_G: 0.1027 (0.4252) D(x): 0.5760 D(G(z)): 0.5361 / 0.4636 Acc: 26.5625 (24.6736)\n",
      "[3/25][742/782] Loss_D: 0.2641 (0.5619) Loss_G: 0.1741 (0.4251) D(x): 0.5258 D(G(z)): 0.4575 / 0.4305 Acc: 29.6875 (24.6753)\n",
      "[3/25][743/782] Loss_D: 0.4738 (0.5619) Loss_G: -0.0002 (0.4249) D(x): 0.4818 D(G(z)): 0.5137 / 0.4751 Acc: 31.2500 (24.6774)\n",
      "[3/25][744/782] Loss_D: 0.3413 (0.5618) Loss_G: 0.0952 (0.4248) D(x): 0.4710 D(G(z)): 0.4712 / 0.4480 Acc: 42.1875 (24.6831)\n",
      "[3/25][745/782] Loss_D: 0.3564 (0.5617) Loss_G: -0.0155 (0.4247) D(x): 0.5442 D(G(z)): 0.4938 / 0.4893 Acc: 28.1250 (24.6842)\n",
      "[3/25][746/782] Loss_D: 0.1623 (0.5616) Loss_G: -0.0264 (0.4246) D(x): 0.5466 D(G(z)): 0.4902 / 0.4798 Acc: 42.1875 (24.6898)\n",
      "[3/25][747/782] Loss_D: 0.3490 (0.5615) Loss_G: 0.1617 (0.4245) D(x): 0.5427 D(G(z)): 0.4923 / 0.4362 Acc: 31.2500 (24.6919)\n",
      "[3/25][748/782] Loss_D: 0.1230 (0.5614) Loss_G: 0.0193 (0.4243) D(x): 0.5058 D(G(z)): 0.4032 / 0.4501 Acc: 31.2500 (24.6941)\n",
      "[3/25][749/782] Loss_D: 0.2637 (0.5613) Loss_G: 0.1652 (0.4243) D(x): 0.5247 D(G(z)): 0.4644 / 0.4159 Acc: 29.6875 (24.6957)\n",
      "[3/25][750/782] Loss_D: 0.2393 (0.5612) Loss_G: 0.0513 (0.4241) D(x): 0.5385 D(G(z)): 0.4946 / 0.4460 Acc: 31.2500 (24.6978)\n",
      "[3/25][751/782] Loss_D: 0.1441 (0.5611) Loss_G: 0.0092 (0.4240) D(x): 0.5318 D(G(z)): 0.4653 / 0.4709 Acc: 40.6250 (24.7029)\n",
      "[3/25][752/782] Loss_D: 0.2562 (0.5610) Loss_G: 0.0869 (0.4239) D(x): 0.5486 D(G(z)): 0.4928 / 0.4338 Acc: 29.6875 (24.7045)\n",
      "[3/25][753/782] Loss_D: 0.1644 (0.5608) Loss_G: 0.0592 (0.4238) D(x): 0.5272 D(G(z)): 0.4206 / 0.4464 Acc: 28.1250 (24.7056)\n",
      "[3/25][754/782] Loss_D: 0.3032 (0.5608) Loss_G: -0.0046 (0.4236) D(x): 0.5330 D(G(z)): 0.4615 / 0.4901 Acc: 28.1250 (24.7067)\n",
      "[3/25][755/782] Loss_D: 0.2244 (0.5607) Loss_G: -0.0063 (0.4235) D(x): 0.5430 D(G(z)): 0.4795 / 0.4744 Acc: 29.6875 (24.7084)\n",
      "[3/25][756/782] Loss_D: 0.1280 (0.5605) Loss_G: 0.0770 (0.4234) D(x): 0.6370 D(G(z)): 0.5385 / 0.4136 Acc: 31.2500 (24.7105)\n",
      "[3/25][757/782] Loss_D: 0.2651 (0.5604) Loss_G: 0.3000 (0.4233) D(x): 0.5549 D(G(z)): 0.4558 / 0.3835 Acc: 28.1250 (24.7116)\n",
      "[3/25][758/782] Loss_D: 0.3424 (0.5603) Loss_G: 0.3725 (0.4233) D(x): 0.4875 D(G(z)): 0.4198 / 0.3553 Acc: 29.6875 (24.7132)\n",
      "[3/25][759/782] Loss_D: 0.3333 (0.5603) Loss_G: 0.0849 (0.4232) D(x): 0.4983 D(G(z)): 0.4596 / 0.4687 Acc: 32.8125 (24.7158)\n",
      "[3/25][760/782] Loss_D: 0.2848 (0.5602) Loss_G: 0.3432 (0.4232) D(x): 0.5849 D(G(z)): 0.4783 / 0.4224 Acc: 32.8125 (24.7184)\n",
      "[3/25][761/782] Loss_D: 0.2759 (0.5601) Loss_G: 0.1513 (0.4231) D(x): 0.5925 D(G(z)): 0.4724 / 0.4194 Acc: 31.2500 (24.7205)\n",
      "[3/25][762/782] Loss_D: 0.2775 (0.5600) Loss_G: 0.2314 (0.4230) D(x): 0.5684 D(G(z)): 0.4662 / 0.4152 Acc: 28.1250 (24.7216)\n",
      "[3/25][763/782] Loss_D: 0.2413 (0.5599) Loss_G: 0.2514 (0.4230) D(x): 0.5405 D(G(z)): 0.4285 / 0.3840 Acc: 29.6875 (24.7232)\n",
      "[3/25][764/782] Loss_D: 0.2500 (0.5598) Loss_G: -0.0313 (0.4228) D(x): 0.5173 D(G(z)): 0.4180 / 0.4867 Acc: 21.8750 (24.7223)\n",
      "[3/25][765/782] Loss_D: 0.0591 (0.5596) Loss_G: 0.2263 (0.4228) D(x): 0.6072 D(G(z)): 0.4259 / 0.4009 Acc: 32.8125 (24.7249)\n",
      "[3/25][766/782] Loss_D: 0.1194 (0.5595) Loss_G: 0.2344 (0.4227) D(x): 0.5726 D(G(z)): 0.4399 / 0.3861 Acc: 32.8125 (24.7275)\n",
      "[3/25][767/782] Loss_D: 0.4089 (0.5595) Loss_G: 0.1192 (0.4226) D(x): 0.4403 D(G(z)): 0.4554 / 0.4271 Acc: 31.2500 (24.7295)\n",
      "[3/25][768/782] Loss_D: 0.2533 (0.5594) Loss_G: 0.2501 (0.4226) D(x): 0.5743 D(G(z)): 0.5057 / 0.3746 Acc: 25.0000 (24.7296)\n",
      "[3/25][769/782] Loss_D: 0.0279 (0.5592) Loss_G: 0.2579 (0.4225) D(x): 0.5317 D(G(z)): 0.3684 / 0.4100 Acc: 32.8125 (24.7322)\n",
      "[3/25][770/782] Loss_D: 0.2106 (0.5591) Loss_G: 0.1996 (0.4224) D(x): 0.5264 D(G(z)): 0.3807 / 0.4391 Acc: 32.8125 (24.7348)\n",
      "[3/25][771/782] Loss_D: 0.1099 (0.5589) Loss_G: 0.0283 (0.4223) D(x): 0.5839 D(G(z)): 0.4796 / 0.4545 Acc: 35.9375 (24.7384)\n",
      "[3/25][772/782] Loss_D: 0.1748 (0.5588) Loss_G: 0.3760 (0.4223) D(x): 0.6182 D(G(z)): 0.4485 / 0.3658 Acc: 32.8125 (24.7410)\n",
      "[3/25][773/782] Loss_D: 0.2239 (0.5587) Loss_G: 0.3628 (0.4223) D(x): 0.5034 D(G(z)): 0.3934 / 0.3789 Acc: 31.2500 (24.7431)\n",
      "[3/25][774/782] Loss_D: 0.2021 (0.5586) Loss_G: 0.2787 (0.4222) D(x): 0.5122 D(G(z)): 0.4030 / 0.3762 Acc: 26.5625 (24.7437)\n",
      "[3/25][775/782] Loss_D: 0.1138 (0.5584) Loss_G: 0.1929 (0.4222) D(x): 0.5763 D(G(z)): 0.4549 / 0.4019 Acc: 35.9375 (24.7473)\n",
      "[3/25][776/782] Loss_D: 0.2713 (0.5583) Loss_G: 0.1011 (0.4221) D(x): 0.4948 D(G(z)): 0.4210 / 0.4579 Acc: 34.3750 (24.7503)\n",
      "[3/25][777/782] Loss_D: 0.1850 (0.5582) Loss_G: 0.2901 (0.4220) D(x): 0.5850 D(G(z)): 0.4723 / 0.3690 Acc: 23.4375 (24.7499)\n",
      "[3/25][778/782] Loss_D: 0.2810 (0.5581) Loss_G: 0.3654 (0.4220) D(x): 0.5293 D(G(z)): 0.4915 / 0.3774 Acc: 46.8750 (24.7570)\n",
      "[3/25][779/782] Loss_D: 0.3594 (0.5581) Loss_G: 0.2325 (0.4219) D(x): 0.4728 D(G(z)): 0.4191 / 0.4099 Acc: 28.1250 (24.7581)\n",
      "[3/25][780/782] Loss_D: 0.2030 (0.5580) Loss_G: 0.0659 (0.4218) D(x): 0.5791 D(G(z)): 0.4570 / 0.4634 Acc: 31.2500 (24.7602)\n",
      "[3/25][781/782] Loss_D: -0.0445 (0.5578) Loss_G: -0.0200 (0.4217) D(x): 0.5691 D(G(z)): 0.5114 / 0.4190 Acc: 43.7500 (24.7662)\n",
      "[4/25][0/782] Loss_D: 0.3348 (0.5577) Loss_G: 0.2185 (0.4216) D(x): 0.5595 D(G(z)): 0.4982 / 0.4163 Acc: 32.8125 (24.7688)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[4/25][1/782] Loss_D: 0.1787 (0.5576) Loss_G: 0.3458 (0.4216) D(x): 0.5667 D(G(z)): 0.4102 / 0.3512 Acc: 20.3125 (24.7674)\n",
      "[4/25][2/782] Loss_D: 0.0034 (0.5574) Loss_G: -0.0012 (0.4215) D(x): 0.5071 D(G(z)): 0.3931 / 0.4529 Acc: 40.6250 (24.7724)\n",
      "[4/25][3/782] Loss_D: 0.1584 (0.5573) Loss_G: 0.1755 (0.4214) D(x): 0.5966 D(G(z)): 0.4689 / 0.3966 Acc: 26.5625 (24.7730)\n",
      "[4/25][4/782] Loss_D: 0.2389 (0.5572) Loss_G: 0.1209 (0.4213) D(x): 0.5371 D(G(z)): 0.4851 / 0.4210 Acc: 35.9375 (24.7766)\n",
      "[4/25][5/782] Loss_D: 0.3651 (0.5571) Loss_G: 0.2031 (0.4212) D(x): 0.6022 D(G(z)): 0.5703 / 0.3862 Acc: 23.4375 (24.7761)\n",
      "[4/25][6/782] Loss_D: 0.4239 (0.5571) Loss_G: 0.1550 (0.4211) D(x): 0.4162 D(G(z)): 0.3959 / 0.4150 Acc: 29.6875 (24.7777)\n",
      "[4/25][7/782] Loss_D: 0.4403 (0.5570) Loss_G: 0.1275 (0.4210) D(x): 0.4648 D(G(z)): 0.4530 / 0.4288 Acc: 25.0000 (24.7778)\n",
      "[4/25][8/782] Loss_D: 0.4986 (0.5570) Loss_G: -0.0229 (0.4209) D(x): 0.4994 D(G(z)): 0.4997 / 0.5251 Acc: 34.3750 (24.7808)\n",
      "[4/25][9/782] Loss_D: 0.5368 (0.5570) Loss_G: -0.0518 (0.4207) D(x): 0.5334 D(G(z)): 0.5698 / 0.4818 Acc: 18.7500 (24.7789)\n",
      "[4/25][10/782] Loss_D: 0.4253 (0.5570) Loss_G: 0.2196 (0.4207) D(x): 0.4901 D(G(z)): 0.5145 / 0.4023 Acc: 35.9375 (24.7825)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/25][11/782] Loss_D: 0.3517 (0.5569) Loss_G: 0.0815 (0.4206) D(x): 0.5073 D(G(z)): 0.4731 / 0.4613 Acc: 32.8125 (24.7850)\n",
      "[4/25][12/782] Loss_D: 0.4155 (0.5569) Loss_G: -0.0264 (0.4204) D(x): 0.4726 D(G(z)): 0.4903 / 0.4753 Acc: 29.6875 (24.7866)\n",
      "[4/25][13/782] Loss_D: 0.6611 (0.5569) Loss_G: -0.0276 (0.4203) D(x): 0.4372 D(G(z)): 0.4846 / 0.5107 Acc: 21.8750 (24.7857)\n",
      "[4/25][14/782] Loss_D: 0.3958 (0.5568) Loss_G: -0.0306 (0.4201) D(x): 0.5272 D(G(z)): 0.5376 / 0.4883 Acc: 28.1250 (24.7867)\n",
      "[4/25][15/782] Loss_D: 0.3735 (0.5568) Loss_G: 0.3134 (0.4201) D(x): 0.5408 D(G(z)): 0.5142 / 0.4254 Acc: 37.5000 (24.7908)\n",
      "[4/25][16/782] Loss_D: 0.4535 (0.5567) Loss_G: 0.2135 (0.4200) D(x): 0.4619 D(G(z)): 0.4503 / 0.4374 Acc: 32.8125 (24.7933)\n",
      "[4/25][17/782] Loss_D: 0.3513 (0.5567) Loss_G: 0.2355 (0.4200) D(x): 0.5827 D(G(z)): 0.5101 / 0.4034 Acc: 21.8750 (24.7924)\n",
      "[4/25][18/782] Loss_D: 0.0967 (0.5565) Loss_G: 0.2168 (0.4199) D(x): 0.5186 D(G(z)): 0.4513 / 0.3837 Acc: 43.7500 (24.7984)\n",
      "[4/25][19/782] Loss_D: 0.3751 (0.5565) Loss_G: 0.2595 (0.4199) D(x): 0.5007 D(G(z)): 0.4659 / 0.4078 Acc: 34.3750 (24.8015)\n",
      "[4/25][20/782] Loss_D: 0.0169 (0.5563) Loss_G: 0.0259 (0.4197) D(x): 0.5469 D(G(z)): 0.4090 / 0.4377 Acc: 37.5000 (24.8055)\n",
      "[4/25][21/782] Loss_D: 0.2154 (0.5562) Loss_G: 0.0574 (0.4196) D(x): 0.5209 D(G(z)): 0.4726 / 0.4583 Acc: 39.0625 (24.8100)\n",
      "[4/25][22/782] Loss_D: 0.3999 (0.5561) Loss_G: -0.0372 (0.4195) D(x): 0.5333 D(G(z)): 0.5367 / 0.4838 Acc: 29.6875 (24.8116)\n",
      "[4/25][23/782] Loss_D: 0.1774 (0.5560) Loss_G: 0.0683 (0.4194) D(x): 0.5987 D(G(z)): 0.4978 / 0.4347 Acc: 31.2500 (24.8136)\n",
      "[4/25][24/782] Loss_D: 0.4038 (0.5560) Loss_G: 0.1416 (0.4193) D(x): 0.4743 D(G(z)): 0.4324 / 0.4448 Acc: 29.6875 (24.8152)\n",
      "[4/25][25/782] Loss_D: 0.2618 (0.5559) Loss_G: 0.1128 (0.4192) D(x): 0.5480 D(G(z)): 0.5048 / 0.4460 Acc: 39.0625 (24.8197)\n",
      "[4/25][26/782] Loss_D: 0.4701 (0.5559) Loss_G: 0.0433 (0.4191) D(x): 0.5405 D(G(z)): 0.5449 / 0.4582 Acc: 26.5625 (24.8202)\n",
      "[4/25][27/782] Loss_D: 0.2759 (0.5558) Loss_G: 0.1692 (0.4190) D(x): 0.5406 D(G(z)): 0.4924 / 0.4312 Acc: 35.9375 (24.8237)\n",
      "[4/25][28/782] Loss_D: 0.3998 (0.5557) Loss_G: 0.0184 (0.4189) D(x): 0.4973 D(G(z)): 0.5244 / 0.4694 Acc: 35.9375 (24.8273)\n",
      "[4/25][29/782] Loss_D: 0.2210 (0.5556) Loss_G: -0.0003 (0.4187) D(x): 0.5238 D(G(z)): 0.4390 / 0.4641 Acc: 29.6875 (24.8288)\n",
      "[4/25][30/782] Loss_D: 0.3462 (0.5555) Loss_G: 0.0162 (0.4186) D(x): 0.5150 D(G(z)): 0.5001 / 0.5120 Acc: 37.5000 (24.8328)\n",
      "[4/25][31/782] Loss_D: 0.5424 (0.5555) Loss_G: 0.0454 (0.4185) D(x): 0.5169 D(G(z)): 0.5488 / 0.5015 Acc: 31.2500 (24.8348)\n",
      "[4/25][32/782] Loss_D: 0.4912 (0.5555) Loss_G: 0.0425 (0.4184) D(x): 0.5239 D(G(z)): 0.5862 / 0.4411 Acc: 32.8125 (24.8374)\n",
      "[4/25][33/782] Loss_D: 0.1971 (0.5554) Loss_G: 0.0891 (0.4183) D(x): 0.5019 D(G(z)): 0.4476 / 0.4224 Acc: 31.2500 (24.8394)\n",
      "[4/25][34/782] Loss_D: 0.1656 (0.5553) Loss_G: 0.0920 (0.4182) D(x): 0.5394 D(G(z)): 0.4492 / 0.4335 Acc: 32.8125 (24.8419)\n",
      "[4/25][35/782] Loss_D: 0.2770 (0.5552) Loss_G: 0.1560 (0.4181) D(x): 0.5694 D(G(z)): 0.4952 / 0.4119 Acc: 28.1250 (24.8430)\n",
      "[4/25][36/782] Loss_D: 0.2945 (0.5551) Loss_G: 0.3046 (0.4180) D(x): 0.5657 D(G(z)): 0.4809 / 0.3727 Acc: 32.8125 (24.8455)\n",
      "[4/25][37/782] Loss_D: 0.1838 (0.5550) Loss_G: 0.0148 (0.4179) D(x): 0.5162 D(G(z)): 0.4269 / 0.4703 Acc: 34.3750 (24.8485)\n",
      "[4/25][38/782] Loss_D: 0.3784 (0.5549) Loss_G: 0.1440 (0.4178) D(x): 0.5509 D(G(z)): 0.4946 / 0.4216 Acc: 23.4375 (24.8480)\n",
      "[4/25][39/782] Loss_D: 0.2455 (0.5548) Loss_G: 0.2129 (0.4178) D(x): 0.5884 D(G(z)): 0.4668 / 0.3985 Acc: 26.5625 (24.8486)\n",
      "[4/25][40/782] Loss_D: 0.1833 (0.5547) Loss_G: 0.3159 (0.4177) D(x): 0.5645 D(G(z)): 0.4670 / 0.3745 Acc: 40.6250 (24.8536)\n",
      "[4/25][41/782] Loss_D: 0.2817 (0.5546) Loss_G: 0.2077 (0.4177) D(x): 0.5277 D(G(z)): 0.4722 / 0.4162 Acc: 34.3750 (24.8566)\n",
      "[4/25][42/782] Loss_D: 0.3740 (0.5546) Loss_G: 0.2031 (0.4176) D(x): 0.4990 D(G(z)): 0.4763 / 0.4217 Acc: 28.1250 (24.8576)\n",
      "[4/25][43/782] Loss_D: 0.3459 (0.5545) Loss_G: 0.2824 (0.4176) D(x): 0.5687 D(G(z)): 0.5096 / 0.3961 Acc: 34.3750 (24.8606)\n",
      "[4/25][44/782] Loss_D: 0.3669 (0.5545) Loss_G: 0.1846 (0.4175) D(x): 0.5069 D(G(z)): 0.4793 / 0.4262 Acc: 32.8125 (24.8631)\n",
      "[4/25][45/782] Loss_D: 0.2212 (0.5544) Loss_G: 0.0787 (0.4174) D(x): 0.4873 D(G(z)): 0.4332 / 0.4345 Acc: 35.9375 (24.8666)\n",
      "[4/25][46/782] Loss_D: 0.1571 (0.5542) Loss_G: 0.1074 (0.4173) D(x): 0.5577 D(G(z)): 0.4649 / 0.4388 Acc: 37.5000 (24.8706)\n",
      "[4/25][47/782] Loss_D: 0.1630 (0.5541) Loss_G: 0.2436 (0.4172) D(x): 0.5308 D(G(z)): 0.4796 / 0.3692 Acc: 37.5000 (24.8745)\n",
      "[4/25][48/782] Loss_D: 0.2585 (0.5540) Loss_G: 0.1226 (0.4171) D(x): 0.5218 D(G(z)): 0.4404 / 0.4366 Acc: 31.2500 (24.8766)\n",
      "[4/25][49/782] Loss_D: 0.4398 (0.5540) Loss_G: 0.2165 (0.4171) D(x): 0.5102 D(G(z)): 0.4624 / 0.4091 Acc: 17.1875 (24.8741)\n",
      "[4/25][50/782] Loss_D: 0.3593 (0.5539) Loss_G: 0.1341 (0.4170) D(x): 0.4877 D(G(z)): 0.4369 / 0.4293 Acc: 25.0000 (24.8742)\n",
      "[4/25][51/782] Loss_D: 0.0543 (0.5538) Loss_G: 0.2090 (0.4169) D(x): 0.5841 D(G(z)): 0.4307 / 0.4011 Acc: 31.2500 (24.8762)\n",
      "[4/25][52/782] Loss_D: 0.4122 (0.5537) Loss_G: -0.0711 (0.4168) D(x): 0.5485 D(G(z)): 0.4637 / 0.5294 Acc: 17.1875 (24.8738)\n",
      "[4/25][53/782] Loss_D: 0.1679 (0.5536) Loss_G: 0.0893 (0.4167) D(x): 0.5456 D(G(z)): 0.5087 / 0.4244 Acc: 42.1875 (24.8792)\n",
      "[4/25][54/782] Loss_D: 0.2787 (0.5535) Loss_G: 0.2684 (0.4166) D(x): 0.5256 D(G(z)): 0.4241 / 0.3811 Acc: 26.5625 (24.8797)\n",
      "[4/25][55/782] Loss_D: 0.3481 (0.5534) Loss_G: 0.0876 (0.4165) D(x): 0.4670 D(G(z)): 0.4362 / 0.4562 Acc: 29.6875 (24.8812)\n",
      "[4/25][56/782] Loss_D: 0.3149 (0.5534) Loss_G: 0.1218 (0.4164) D(x): 0.5467 D(G(z)): 0.4625 / 0.4441 Acc: 25.0000 (24.8813)\n",
      "[4/25][57/782] Loss_D: 0.3594 (0.5533) Loss_G: 0.0501 (0.4163) D(x): 0.5623 D(G(z)): 0.5283 / 0.4509 Acc: 29.6875 (24.8828)\n",
      "[4/25][58/782] Loss_D: 0.4315 (0.5533) Loss_G: 0.1199 (0.4162) D(x): 0.4793 D(G(z)): 0.4913 / 0.4342 Acc: 32.8125 (24.8853)\n",
      "[4/25][59/782] Loss_D: 0.1196 (0.5531) Loss_G: 0.1352 (0.4161) D(x): 0.5470 D(G(z)): 0.4608 / 0.4161 Acc: 35.9375 (24.8887)\n",
      "[4/25][60/782] Loss_D: 0.2599 (0.5530) Loss_G: 0.0298 (0.4160) D(x): 0.4663 D(G(z)): 0.4544 / 0.4510 Acc: 35.9375 (24.8922)\n",
      "[4/25][61/782] Loss_D: 0.2589 (0.5529) Loss_G: 0.0311 (0.4159) D(x): 0.5196 D(G(z)): 0.4913 / 0.4583 Acc: 31.2500 (24.8942)\n",
      "[4/25][62/782] Loss_D: 0.2799 (0.5529) Loss_G: 0.0090 (0.4157) D(x): 0.5126 D(G(z)): 0.4839 / 0.4584 Acc: 31.2500 (24.8962)\n",
      "[4/25][63/782] Loss_D: 0.3868 (0.5528) Loss_G: 0.0319 (0.4156) D(x): 0.4900 D(G(z)): 0.4900 / 0.4611 Acc: 28.1250 (24.8972)\n",
      "[4/25][64/782] Loss_D: 0.4353 (0.5528) Loss_G: 0.2621 (0.4156) D(x): 0.5034 D(G(z)): 0.4728 / 0.4252 Acc: 29.6875 (24.8987)\n",
      "[4/25][65/782] Loss_D: 0.2311 (0.5527) Loss_G: 0.2364 (0.4155) D(x): 0.5490 D(G(z)): 0.5037 / 0.3869 Acc: 35.9375 (24.9022)\n",
      "[4/25][66/782] Loss_D: 0.2658 (0.5526) Loss_G: 0.2804 (0.4155) D(x): 0.4692 D(G(z)): 0.4311 / 0.3982 Acc: 42.1875 (24.9076)\n",
      "[4/25][67/782] Loss_D: 0.1325 (0.5524) Loss_G: 0.2023 (0.4154) D(x): 0.5339 D(G(z)): 0.4374 / 0.4048 Acc: 37.5000 (24.9115)\n",
      "[4/25][68/782] Loss_D: 0.3369 (0.5524) Loss_G: 0.0132 (0.4153) D(x): 0.4893 D(G(z)): 0.5159 / 0.4493 Acc: 37.5000 (24.9154)\n",
      "[4/25][69/782] Loss_D: 0.4373 (0.5523) Loss_G: 0.0418 (0.4152) D(x): 0.4562 D(G(z)): 0.4175 / 0.4759 Acc: 25.0000 (24.9155)\n",
      "[4/25][70/782] Loss_D: 0.1886 (0.5522) Loss_G: -0.0289 (0.4150) D(x): 0.5724 D(G(z)): 0.4920 / 0.4746 Acc: 26.5625 (24.9160)\n",
      "[4/25][71/782] Loss_D: 0.4432 (0.5522) Loss_G: 0.0323 (0.4149) D(x): 0.5421 D(G(z)): 0.5058 / 0.4910 Acc: 25.0000 (24.9160)\n",
      "[4/25][72/782] Loss_D: 0.3267 (0.5521) Loss_G: 0.0506 (0.4148) D(x): 0.5383 D(G(z)): 0.4584 / 0.4342 Acc: 15.6250 (24.9131)\n",
      "[4/25][73/782] Loss_D: 0.3982 (0.5521) Loss_G: 0.0451 (0.4147) D(x): 0.5356 D(G(z)): 0.5248 / 0.4464 Acc: 29.6875 (24.9146)\n",
      "[4/25][74/782] Loss_D: 0.2865 (0.5520) Loss_G: 0.2455 (0.4146) D(x): 0.5481 D(G(z)): 0.4676 / 0.3955 Acc: 31.2500 (24.9166)\n",
      "[4/25][75/782] Loss_D: 0.2335 (0.5519) Loss_G: 0.1002 (0.4145) D(x): 0.4803 D(G(z)): 0.4563 / 0.4207 Acc: 39.0625 (24.9210)\n",
      "[4/25][76/782] Loss_D: 0.2848 (0.5518) Loss_G: 0.1929 (0.4145) D(x): 0.5238 D(G(z)): 0.4477 / 0.3946 Acc: 23.4375 (24.9205)\n",
      "[4/25][77/782] Loss_D: 0.3663 (0.5518) Loss_G: 0.1644 (0.4144) D(x): 0.5283 D(G(z)): 0.5021 / 0.4238 Acc: 26.5625 (24.9210)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/25][78/782] Loss_D: 0.4181 (0.5517) Loss_G: -0.0033 (0.4143) D(x): 0.4654 D(G(z)): 0.4571 / 0.4996 Acc: 29.6875 (24.9225)\n",
      "[4/25][79/782] Loss_D: 0.3752 (0.5517) Loss_G: -0.0893 (0.4141) D(x): 0.4554 D(G(z)): 0.4265 / 0.5036 Acc: 25.0000 (24.9226)\n",
      "[4/25][80/782] Loss_D: 0.4702 (0.5516) Loss_G: 0.1853 (0.4140) D(x): 0.5484 D(G(z)): 0.5056 / 0.4393 Acc: 23.4375 (24.9221)\n",
      "[4/25][81/782] Loss_D: 0.2678 (0.5515) Loss_G: 0.1410 (0.4139) D(x): 0.5191 D(G(z)): 0.4758 / 0.4225 Acc: 34.3750 (24.9250)\n",
      "[4/25][82/782] Loss_D: 0.3070 (0.5515) Loss_G: 0.3238 (0.4139) D(x): 0.4866 D(G(z)): 0.4280 / 0.3763 Acc: 29.6875 (24.9265)\n",
      "[4/25][83/782] Loss_D: 0.2511 (0.5514) Loss_G: 0.1448 (0.4138) D(x): 0.5364 D(G(z)): 0.4706 / 0.4240 Acc: 34.3750 (24.9295)\n",
      "[4/25][84/782] Loss_D: 0.4218 (0.5513) Loss_G: 0.2245 (0.4138) D(x): 0.4935 D(G(z)): 0.4322 / 0.4327 Acc: 23.4375 (24.9290)\n",
      "[4/25][85/782] Loss_D: 0.4377 (0.5513) Loss_G: -0.0065 (0.4136) D(x): 0.5290 D(G(z)): 0.5286 / 0.4633 Acc: 23.4375 (24.9285)\n",
      "[4/25][86/782] Loss_D: 0.3254 (0.5512) Loss_G: 0.0612 (0.4135) D(x): 0.4897 D(G(z)): 0.4578 / 0.4518 Acc: 32.8125 (24.9310)\n",
      "[4/25][87/782] Loss_D: 0.4145 (0.5512) Loss_G: 0.1366 (0.4134) D(x): 0.5135 D(G(z)): 0.4956 / 0.4311 Acc: 25.0000 (24.9310)\n",
      "[4/25][88/782] Loss_D: 0.1255 (0.5511) Loss_G: 0.0654 (0.4133) D(x): 0.5381 D(G(z)): 0.4385 / 0.4490 Acc: 35.9375 (24.9344)\n",
      "[4/25][89/782] Loss_D: 0.3180 (0.5510) Loss_G: 0.0108 (0.4132) D(x): 0.5435 D(G(z)): 0.4726 / 0.4575 Acc: 18.7500 (24.9325)\n",
      "[4/25][90/782] Loss_D: 0.3851 (0.5509) Loss_G: 0.2993 (0.4132) D(x): 0.5699 D(G(z)): 0.5055 / 0.4095 Acc: 29.6875 (24.9340)\n",
      "[4/25][91/782] Loss_D: 0.3711 (0.5509) Loss_G: 0.1284 (0.4131) D(x): 0.4932 D(G(z)): 0.4648 / 0.4353 Acc: 28.1250 (24.9350)\n",
      "[4/25][92/782] Loss_D: -0.0404 (0.5507) Loss_G: 0.0929 (0.4130) D(x): 0.5317 D(G(z)): 0.4107 / 0.4228 Acc: 45.3125 (24.9413)\n",
      "[4/25][93/782] Loss_D: 0.3213 (0.5506) Loss_G: 0.1110 (0.4129) D(x): 0.5057 D(G(z)): 0.4528 / 0.4546 Acc: 32.8125 (24.9437)\n",
      "[4/25][94/782] Loss_D: 0.4267 (0.5506) Loss_G: 0.0111 (0.4128) D(x): 0.5415 D(G(z)): 0.5640 / 0.4762 Acc: 32.8125 (24.9462)\n",
      "[4/25][95/782] Loss_D: 0.1903 (0.5505) Loss_G: -0.0496 (0.4126) D(x): 0.5606 D(G(z)): 0.5271 / 0.4781 Acc: 39.0625 (24.9506)\n",
      "[4/25][96/782] Loss_D: 0.3640 (0.5504) Loss_G: 0.0056 (0.4125) D(x): 0.4827 D(G(z)): 0.4515 / 0.4840 Acc: 29.6875 (24.9520)\n",
      "[4/25][97/782] Loss_D: 0.3310 (0.5503) Loss_G: 0.0285 (0.4124) D(x): 0.4897 D(G(z)): 0.4522 / 0.4640 Acc: 31.2500 (24.9540)\n",
      "[4/25][98/782] Loss_D: 0.2788 (0.5503) Loss_G: -0.0758 (0.4122) D(x): 0.5786 D(G(z)): 0.5396 / 0.4784 Acc: 28.1250 (24.9550)\n",
      "[4/25][99/782] Loss_D: 0.1606 (0.5501) Loss_G: -0.0457 (0.4121) D(x): 0.5185 D(G(z)): 0.4690 / 0.4782 Acc: 39.0625 (24.9593)\n",
      "[4/25][100/782] Loss_D: 0.2227 (0.5500) Loss_G: 0.0412 (0.4120) D(x): 0.5360 D(G(z)): 0.4810 / 0.4410 Acc: 32.8125 (24.9618)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[4/25][101/782] Loss_D: 0.2950 (0.5500) Loss_G: 0.0952 (0.4119) D(x): 0.5464 D(G(z)): 0.4498 / 0.4691 Acc: 26.5625 (24.9623)\n",
      "[4/25][102/782] Loss_D: 0.0704 (0.5498) Loss_G: -0.0143 (0.4117) D(x): 0.5094 D(G(z)): 0.4307 / 0.4670 Acc: 42.1875 (24.9676)\n",
      "[4/25][103/782] Loss_D: 0.2990 (0.5497) Loss_G: 0.1875 (0.4117) D(x): 0.5494 D(G(z)): 0.4929 / 0.4120 Acc: 32.8125 (24.9700)\n",
      "[4/25][104/782] Loss_D: 0.2870 (0.5497) Loss_G: 0.1661 (0.4116) D(x): 0.5305 D(G(z)): 0.4376 / 0.4395 Acc: 28.1250 (24.9710)\n",
      "[4/25][105/782] Loss_D: 0.1040 (0.5495) Loss_G: 0.1614 (0.4115) D(x): 0.5684 D(G(z)): 0.4337 / 0.4180 Acc: 31.2500 (24.9729)\n",
      "[4/25][106/782] Loss_D: 0.1921 (0.5494) Loss_G: 0.2329 (0.4115) D(x): 0.5499 D(G(z)): 0.4412 / 0.4107 Acc: 34.3750 (24.9759)\n",
      "[4/25][107/782] Loss_D: 0.0511 (0.5493) Loss_G: 0.1723 (0.4114) D(x): 0.5887 D(G(z)): 0.4552 / 0.4611 Acc: 46.8750 (24.9826)\n",
      "[4/25][108/782] Loss_D: 0.0670 (0.5491) Loss_G: 0.2676 (0.4113) D(x): 0.6077 D(G(z)): 0.4483 / 0.3800 Acc: 31.2500 (24.9846)\n",
      "[4/25][109/782] Loss_D: 0.1177 (0.5490) Loss_G: 0.3122 (0.4113) D(x): 0.5294 D(G(z)): 0.3866 / 0.3650 Acc: 31.2500 (24.9865)\n",
      "[4/25][110/782] Loss_D: 0.2089 (0.5489) Loss_G: 0.0765 (0.4112) D(x): 0.5513 D(G(z)): 0.4643 / 0.4475 Acc: 31.2500 (24.9884)\n",
      "[4/25][111/782] Loss_D: 0.3065 (0.5488) Loss_G: 0.1756 (0.4111) D(x): 0.5649 D(G(z)): 0.5183 / 0.4061 Acc: 25.0000 (24.9884)\n",
      "[4/25][112/782] Loss_D: 0.2287 (0.5487) Loss_G: 0.0303 (0.4110) D(x): 0.5224 D(G(z)): 0.4494 / 0.4603 Acc: 28.1250 (24.9894)\n",
      "[4/25][113/782] Loss_D: 0.2510 (0.5486) Loss_G: 0.2660 (0.4110) D(x): 0.5520 D(G(z)): 0.4533 / 0.3923 Acc: 31.2500 (24.9913)\n",
      "[4/25][114/782] Loss_D: 0.2245 (0.5485) Loss_G: 0.1992 (0.4109) D(x): 0.5397 D(G(z)): 0.4585 / 0.3921 Acc: 28.1250 (24.9923)\n",
      "[4/25][115/782] Loss_D: 0.2790 (0.5484) Loss_G: 0.0169 (0.4108) D(x): 0.5103 D(G(z)): 0.4832 / 0.4370 Acc: 28.1250 (24.9933)\n",
      "[4/25][116/782] Loss_D: 0.2375 (0.5483) Loss_G: -0.0181 (0.4107) D(x): 0.4949 D(G(z)): 0.4577 / 0.4566 Acc: 32.8125 (24.9957)\n",
      "[4/25][117/782] Loss_D: 0.3885 (0.5483) Loss_G: -0.0140 (0.4105) D(x): 0.5215 D(G(z)): 0.5111 / 0.4804 Acc: 26.5625 (24.9961)\n",
      "[4/25][118/782] Loss_D: 0.4967 (0.5483) Loss_G: 0.1431 (0.4104) D(x): 0.4890 D(G(z)): 0.5450 / 0.4459 Acc: 37.5000 (25.0000)\n",
      "[4/25][119/782] Loss_D: 0.3182 (0.5482) Loss_G: 0.3250 (0.4104) D(x): 0.4997 D(G(z)): 0.4662 / 0.3634 Acc: 32.8125 (25.0024)\n",
      "[4/25][120/782] Loss_D: 0.4897 (0.5482) Loss_G: 0.1455 (0.4103) D(x): 0.4173 D(G(z)): 0.4806 / 0.4059 Acc: 37.5000 (25.0063)\n",
      "[4/25][121/782] Loss_D: 0.3891 (0.5481) Loss_G: -0.0413 (0.4102) D(x): 0.4179 D(G(z)): 0.4744 / 0.4670 Acc: 37.5000 (25.0101)\n",
      "[4/25][122/782] Loss_D: 0.1611 (0.5480) Loss_G: 0.1702 (0.4101) D(x): 0.5286 D(G(z)): 0.4189 / 0.4223 Acc: 35.9375 (25.0135)\n",
      "[4/25][123/782] Loss_D: 0.3910 (0.5479) Loss_G: 0.2043 (0.4101) D(x): 0.5515 D(G(z)): 0.4955 / 0.4243 Acc: 25.0000 (25.0135)\n",
      "[4/25][124/782] Loss_D: 0.1859 (0.5478) Loss_G: 0.2448 (0.4100) D(x): 0.5912 D(G(z)): 0.4486 / 0.4295 Acc: 35.9375 (25.0168)\n",
      "[4/25][125/782] Loss_D: 0.0819 (0.5477) Loss_G: 0.3316 (0.4100) D(x): 0.6109 D(G(z)): 0.4454 / 0.3522 Acc: 26.5625 (25.0173)\n",
      "[4/25][126/782] Loss_D: 0.0669 (0.5475) Loss_G: 0.1322 (0.4099) D(x): 0.5298 D(G(z)): 0.3975 / 0.4058 Acc: 29.6875 (25.0187)\n",
      "[4/25][127/782] Loss_D: 0.1915 (0.5474) Loss_G: -0.1059 (0.4097) D(x): 0.4976 D(G(z)): 0.4204 / 0.4956 Acc: 28.1250 (25.0197)\n",
      "[4/25][128/782] Loss_D: 0.2337 (0.5473) Loss_G: 0.1109 (0.4097) D(x): 0.5874 D(G(z)): 0.4557 / 0.4564 Acc: 26.5625 (25.0201)\n",
      "[4/25][129/782] Loss_D: 0.2952 (0.5473) Loss_G: -0.0077 (0.4095) D(x): 0.5223 D(G(z)): 0.4612 / 0.4840 Acc: 31.2500 (25.0221)\n",
      "[4/25][130/782] Loss_D: 0.3696 (0.5472) Loss_G: 0.0823 (0.4094) D(x): 0.5535 D(G(z)): 0.5265 / 0.4620 Acc: 34.3750 (25.0249)\n",
      "[4/25][131/782] Loss_D: 0.2084 (0.5471) Loss_G: 0.1285 (0.4093) D(x): 0.5565 D(G(z)): 0.4450 / 0.4326 Acc: 26.5625 (25.0254)\n",
      "[4/25][132/782] Loss_D: 0.3849 (0.5471) Loss_G: 0.1172 (0.4092) D(x): 0.4872 D(G(z)): 0.4929 / 0.4250 Acc: 28.1250 (25.0264)\n",
      "[4/25][133/782] Loss_D: 0.0830 (0.5469) Loss_G: 0.3152 (0.4092) D(x): 0.5879 D(G(z)): 0.4364 / 0.3665 Acc: 34.3750 (25.0292)\n",
      "[4/25][134/782] Loss_D: 0.4130 (0.5469) Loss_G: 0.1324 (0.4091) D(x): 0.4911 D(G(z)): 0.4398 / 0.4757 Acc: 26.5625 (25.0297)\n",
      "[4/25][135/782] Loss_D: 0.1781 (0.5468) Loss_G: 0.0514 (0.4090) D(x): 0.5131 D(G(z)): 0.4665 / 0.4622 Acc: 40.6250 (25.0345)\n",
      "[4/25][136/782] Loss_D: 0.2686 (0.5467) Loss_G: 0.1133 (0.4089) D(x): 0.5523 D(G(z)): 0.5142 / 0.4123 Acc: 31.2500 (25.0364)\n",
      "[4/25][137/782] Loss_D: 0.4210 (0.5466) Loss_G: 0.0563 (0.4088) D(x): 0.4894 D(G(z)): 0.4449 / 0.4344 Acc: 18.7500 (25.0344)\n",
      "[4/25][138/782] Loss_D: 0.2823 (0.5466) Loss_G: 0.1490 (0.4087) D(x): 0.5108 D(G(z)): 0.4763 / 0.4302 Acc: 39.0625 (25.0387)\n",
      "[4/25][139/782] Loss_D: 0.3833 (0.5465) Loss_G: 0.0978 (0.4086) D(x): 0.5236 D(G(z)): 0.5178 / 0.4430 Acc: 29.6875 (25.0402)\n",
      "[4/25][140/782] Loss_D: 0.0614 (0.5464) Loss_G: 0.0186 (0.4085) D(x): 0.5776 D(G(z)): 0.4440 / 0.4524 Acc: 28.1250 (25.0411)\n",
      "[4/25][141/782] Loss_D: 0.2022 (0.5463) Loss_G: 0.1383 (0.4084) D(x): 0.5364 D(G(z)): 0.4687 / 0.4339 Acc: 35.9375 (25.0444)\n",
      "[4/25][142/782] Loss_D: 0.1505 (0.5461) Loss_G: 0.2320 (0.4084) D(x): 0.5892 D(G(z)): 0.4798 / 0.3956 Acc: 35.9375 (25.0478)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/25][143/782] Loss_D: 0.3007 (0.5461) Loss_G: 0.3220 (0.4084) D(x): 0.5225 D(G(z)): 0.4356 / 0.3779 Acc: 25.0000 (25.0478)\n",
      "[4/25][144/782] Loss_D: 0.1714 (0.5459) Loss_G: 0.2092 (0.4083) D(x): 0.5438 D(G(z)): 0.3975 / 0.4363 Acc: 32.8125 (25.0501)\n",
      "[4/25][145/782] Loss_D: 0.3175 (0.5459) Loss_G: 0.2387 (0.4083) D(x): 0.5380 D(G(z)): 0.4195 / 0.4107 Acc: 23.4375 (25.0496)\n",
      "[4/25][146/782] Loss_D: 0.0537 (0.5457) Loss_G: 0.1094 (0.4082) D(x): 0.6083 D(G(z)): 0.4639 / 0.4410 Acc: 37.5000 (25.0534)\n",
      "[4/25][147/782] Loss_D: 0.2363 (0.5456) Loss_G: 0.1533 (0.4081) D(x): 0.5654 D(G(z)): 0.5180 / 0.4288 Acc: 37.5000 (25.0572)\n",
      "[4/25][148/782] Loss_D: 0.0698 (0.5455) Loss_G: 0.0786 (0.4080) D(x): 0.5389 D(G(z)): 0.4216 / 0.4359 Acc: 37.5000 (25.0610)\n",
      "[4/25][149/782] Loss_D: 0.5197 (0.5455) Loss_G: 0.1418 (0.4079) D(x): 0.5071 D(G(z)): 0.4983 / 0.4684 Acc: 25.0000 (25.0610)\n",
      "[4/25][150/782] Loss_D: -0.0165 (0.5453) Loss_G: 0.2669 (0.4079) D(x): 0.6140 D(G(z)): 0.4393 / 0.3775 Acc: 39.0625 (25.0653)\n",
      "[4/25][151/782] Loss_D: 0.3189 (0.5452) Loss_G: 0.2511 (0.4078) D(x): 0.5085 D(G(z)): 0.4804 / 0.3802 Acc: 31.2500 (25.0672)\n",
      "[4/25][152/782] Loss_D: 0.2906 (0.5452) Loss_G: 0.1424 (0.4077) D(x): 0.4750 D(G(z)): 0.4883 / 0.4068 Acc: 40.6250 (25.0719)\n",
      "[4/25][153/782] Loss_D: 0.1432 (0.5450) Loss_G: 0.1185 (0.4076) D(x): 0.5004 D(G(z)): 0.4155 / 0.4289 Acc: 35.9375 (25.0752)\n",
      "[4/25][154/782] Loss_D: 0.1307 (0.5449) Loss_G: 0.1081 (0.4076) D(x): 0.5451 D(G(z)): 0.5102 / 0.4136 Acc: 40.6250 (25.0800)\n",
      "[4/25][155/782] Loss_D: 0.2991 (0.5448) Loss_G: 0.2209 (0.4075) D(x): 0.4980 D(G(z)): 0.4495 / 0.4080 Acc: 35.9375 (25.0833)\n",
      "[4/25][156/782] Loss_D: 0.4669 (0.5448) Loss_G: 0.1272 (0.4074) D(x): 0.5382 D(G(z)): 0.5212 / 0.4475 Acc: 23.4375 (25.0828)\n",
      "[4/25][157/782] Loss_D: 0.1413 (0.5447) Loss_G: 0.1053 (0.4073) D(x): 0.5539 D(G(z)): 0.4615 / 0.4285 Acc: 29.6875 (25.0842)\n",
      "[4/25][158/782] Loss_D: 0.1251 (0.5446) Loss_G: 0.1320 (0.4072) D(x): 0.5243 D(G(z)): 0.4517 / 0.4172 Acc: 42.1875 (25.0894)\n",
      "[4/25][159/782] Loss_D: 0.3870 (0.5445) Loss_G: 0.1267 (0.4071) D(x): 0.4373 D(G(z)): 0.4443 / 0.4222 Acc: 37.5000 (25.0931)\n",
      "[4/25][160/782] Loss_D: 0.2435 (0.5444) Loss_G: -0.0113 (0.4070) D(x): 0.5045 D(G(z)): 0.4333 / 0.4981 Acc: 31.2500 (25.0950)\n",
      "[4/25][161/782] Loss_D: 0.2909 (0.5443) Loss_G: 0.0430 (0.4069) D(x): 0.5861 D(G(z)): 0.5736 / 0.4683 Acc: 35.9375 (25.0983)\n",
      "[4/25][162/782] Loss_D: 0.2576 (0.5443) Loss_G: 0.0879 (0.4068) D(x): 0.5319 D(G(z)): 0.4731 / 0.4414 Acc: 35.9375 (25.1016)\n",
      "[4/25][163/782] Loss_D: 0.4840 (0.5442) Loss_G: 0.2283 (0.4068) D(x): 0.4548 D(G(z)): 0.4710 / 0.4127 Acc: 35.9375 (25.1049)\n",
      "[4/25][164/782] Loss_D: 0.4345 (0.5442) Loss_G: 0.2266 (0.4067) D(x): 0.5161 D(G(z)): 0.5263 / 0.4146 Acc: 32.8125 (25.1072)\n",
      "[4/25][165/782] Loss_D: 0.4619 (0.5442) Loss_G: 0.0242 (0.4066) D(x): 0.4601 D(G(z)): 0.4791 / 0.4804 Acc: 34.3750 (25.1100)\n",
      "[4/25][166/782] Loss_D: 0.4127 (0.5441) Loss_G: -0.0071 (0.4065) D(x): 0.4950 D(G(z)): 0.5300 / 0.4840 Acc: 34.3750 (25.1129)\n",
      "[4/25][167/782] Loss_D: 0.3852 (0.5441) Loss_G: 0.1614 (0.4064) D(x): 0.5401 D(G(z)): 0.4905 / 0.4482 Acc: 28.1250 (25.1138)\n",
      "[4/25][168/782] Loss_D: 0.4571 (0.5441) Loss_G: 0.1880 (0.4063) D(x): 0.4644 D(G(z)): 0.4723 / 0.4306 Acc: 32.8125 (25.1161)\n",
      "[4/25][169/782] Loss_D: 0.3132 (0.5440) Loss_G: 0.1277 (0.4062) D(x): 0.4916 D(G(z)): 0.4257 / 0.4398 Acc: 28.1250 (25.1170)\n",
      "[4/25][170/782] Loss_D: 0.3381 (0.5439) Loss_G: 0.0119 (0.4061) D(x): 0.5158 D(G(z)): 0.5022 / 0.4747 Acc: 32.8125 (25.1194)\n",
      "[4/25][171/782] Loss_D: 0.3007 (0.5439) Loss_G: -0.0855 (0.4060) D(x): 0.5225 D(G(z)): 0.5330 / 0.5213 Acc: 43.7500 (25.1250)\n",
      "[4/25][172/782] Loss_D: 0.4233 (0.5438) Loss_G: 0.1866 (0.4059) D(x): 0.5288 D(G(z)): 0.5439 / 0.4114 Acc: 32.8125 (25.1273)\n",
      "[4/25][173/782] Loss_D: 0.2792 (0.5437) Loss_G: 0.1311 (0.4058) D(x): 0.5125 D(G(z)): 0.4691 / 0.4289 Acc: 34.3750 (25.1301)\n",
      "[4/25][174/782] Loss_D: 0.2276 (0.5436) Loss_G: 0.0760 (0.4057) D(x): 0.5392 D(G(z)): 0.4728 / 0.4446 Acc: 32.8125 (25.1325)\n",
      "[4/25][175/782] Loss_D: 0.2650 (0.5436) Loss_G: 0.1046 (0.4056) D(x): 0.4983 D(G(z)): 0.4436 / 0.4249 Acc: 31.2500 (25.1343)\n",
      "[4/25][176/782] Loss_D: 0.5824 (0.5436) Loss_G: 0.0082 (0.4055) D(x): 0.4301 D(G(z)): 0.5106 / 0.4983 Acc: 37.5000 (25.1380)\n",
      "[4/25][177/782] Loss_D: 0.2785 (0.5435) Loss_G: 0.1339 (0.4054) D(x): 0.5321 D(G(z)): 0.4909 / 0.4309 Acc: 37.5000 (25.1418)\n",
      "[4/25][178/782] Loss_D: 0.3717 (0.5434) Loss_G: 0.2876 (0.4054) D(x): 0.5667 D(G(z)): 0.5004 / 0.4231 Acc: 32.8125 (25.1441)\n",
      "[4/25][179/782] Loss_D: 0.0567 (0.5433) Loss_G: 0.2097 (0.4053) D(x): 0.5413 D(G(z)): 0.3950 / 0.3791 Acc: 32.8125 (25.1464)\n",
      "[4/25][180/782] Loss_D: 0.2554 (0.5432) Loss_G: 0.1560 (0.4053) D(x): 0.5371 D(G(z)): 0.4414 / 0.4193 Acc: 23.4375 (25.1459)\n",
      "[4/25][181/782] Loss_D: 0.4136 (0.5432) Loss_G: 0.1174 (0.4052) D(x): 0.5292 D(G(z)): 0.5070 / 0.4422 Acc: 28.1250 (25.1468)\n",
      "[4/25][182/782] Loss_D: 0.1522 (0.5430) Loss_G: 0.1403 (0.4051) D(x): 0.5504 D(G(z)): 0.4692 / 0.4277 Acc: 39.0625 (25.1510)\n",
      "[4/25][183/782] Loss_D: 0.3040 (0.5430) Loss_G: 0.2533 (0.4050) D(x): 0.5370 D(G(z)): 0.4890 / 0.4012 Acc: 35.9375 (25.1543)\n",
      "[4/25][184/782] Loss_D: 0.1907 (0.5429) Loss_G: 0.1058 (0.4050) D(x): 0.5391 D(G(z)): 0.4671 / 0.4213 Acc: 34.3750 (25.1571)\n",
      "[4/25][185/782] Loss_D: 0.0561 (0.5427) Loss_G: 0.0771 (0.4049) D(x): 0.5624 D(G(z)): 0.4294 / 0.4213 Acc: 29.6875 (25.1584)\n",
      "[4/25][186/782] Loss_D: 0.4819 (0.5427) Loss_G: 0.0345 (0.4047) D(x): 0.5024 D(G(z)): 0.4860 / 0.4826 Acc: 21.8750 (25.1574)\n",
      "[4/25][187/782] Loss_D: 0.3080 (0.5426) Loss_G: 0.0093 (0.4046) D(x): 0.5327 D(G(z)): 0.5214 / 0.4420 Acc: 32.8125 (25.1597)\n",
      "[4/25][188/782] Loss_D: 0.2383 (0.5425) Loss_G: 0.0814 (0.4045) D(x): 0.5265 D(G(z)): 0.4389 / 0.4676 Acc: 34.3750 (25.1625)\n",
      "[4/25][189/782] Loss_D: 0.4780 (0.5425) Loss_G: -0.1309 (0.4044) D(x): 0.4820 D(G(z)): 0.5226 / 0.5386 Acc: 31.2500 (25.1643)\n",
      "[4/25][190/782] Loss_D: 0.2268 (0.5424) Loss_G: 0.0484 (0.4043) D(x): 0.6165 D(G(z)): 0.5280 / 0.4517 Acc: 31.2500 (25.1662)\n",
      "[4/25][191/782] Loss_D: 0.3118 (0.5424) Loss_G: 0.1864 (0.4042) D(x): 0.5043 D(G(z)): 0.4721 / 0.4091 Acc: 31.2500 (25.1680)\n",
      "[4/25][192/782] Loss_D: 0.3670 (0.5423) Loss_G: 0.0208 (0.4041) D(x): 0.4903 D(G(z)): 0.5076 / 0.4688 Acc: 40.6250 (25.1727)\n",
      "[4/25][193/782] Loss_D: 0.6424 (0.5423) Loss_G: 0.0161 (0.4040) D(x): 0.4262 D(G(z)): 0.5048 / 0.4978 Acc: 29.6875 (25.1740)\n",
      "[4/25][194/782] Loss_D: 0.4871 (0.5423) Loss_G: 0.0508 (0.4039) D(x): 0.5236 D(G(z)): 0.5202 / 0.4728 Acc: 23.4375 (25.1735)\n",
      "[4/25][195/782] Loss_D: 0.3381 (0.5423) Loss_G: -0.0704 (0.4037) D(x): 0.4994 D(G(z)): 0.4813 / 0.5129 Acc: 32.8125 (25.1758)\n",
      "[4/25][196/782] Loss_D: 0.2564 (0.5422) Loss_G: -0.0851 (0.4036) D(x): 0.5759 D(G(z)): 0.5391 / 0.5274 Acc: 39.0625 (25.1800)\n",
      "[4/25][197/782] Loss_D: 0.1192 (0.5420) Loss_G: 0.1012 (0.4035) D(x): 0.5206 D(G(z)): 0.4227 / 0.4239 Acc: 35.9375 (25.1832)\n",
      "[4/25][198/782] Loss_D: 0.1455 (0.5419) Loss_G: 0.1510 (0.4034) D(x): 0.5712 D(G(z)): 0.4101 / 0.4350 Acc: 28.1250 (25.1841)\n",
      "[4/25][199/782] Loss_D: 0.2068 (0.5418) Loss_G: 0.0121 (0.4033) D(x): 0.5698 D(G(z)): 0.4727 / 0.4813 Acc: 34.3750 (25.1869)\n",
      "[4/25][200/782] Loss_D: 0.1081 (0.5417) Loss_G: 0.3334 (0.4033) D(x): 0.5306 D(G(z)): 0.4328 / 0.3423 Acc: 35.9375 (25.1901)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[4/25][201/782] Loss_D: 0.0826 (0.5416) Loss_G: 0.2479 (0.4032) D(x): 0.5448 D(G(z)): 0.3951 / 0.3989 Acc: 34.3750 (25.1928)\n",
      "[4/25][202/782] Loss_D: 0.1465 (0.5414) Loss_G: 0.0211 (0.4031) D(x): 0.5645 D(G(z)): 0.4404 / 0.4546 Acc: 25.0000 (25.1928)\n",
      "[4/25][203/782] Loss_D: 0.2135 (0.5413) Loss_G: 0.1265 (0.4030) D(x): 0.5611 D(G(z)): 0.4583 / 0.4214 Acc: 28.1250 (25.1937)\n",
      "[4/25][204/782] Loss_D: 0.2855 (0.5413) Loss_G: 0.1974 (0.4030) D(x): 0.5553 D(G(z)): 0.4811 / 0.4074 Acc: 31.2500 (25.1955)\n",
      "[4/25][205/782] Loss_D: 0.2120 (0.5412) Loss_G: 0.0702 (0.4029) D(x): 0.5432 D(G(z)): 0.4878 / 0.4486 Acc: 34.3750 (25.1982)\n",
      "[4/25][206/782] Loss_D: 0.1933 (0.5411) Loss_G: 0.2224 (0.4028) D(x): 0.5105 D(G(z)): 0.4260 / 0.3985 Acc: 34.3750 (25.2010)\n",
      "[4/25][207/782] Loss_D: 0.0491 (0.5409) Loss_G: -0.0314 (0.4027) D(x): 0.5522 D(G(z)): 0.4211 / 0.4677 Acc: 29.6875 (25.2023)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/25][208/782] Loss_D: 0.1581 (0.5408) Loss_G: 0.0794 (0.4026) D(x): 0.5848 D(G(z)): 0.4962 / 0.4182 Acc: 32.8125 (25.2046)\n",
      "[4/25][209/782] Loss_D: 0.5152 (0.5408) Loss_G: 0.1509 (0.4025) D(x): 0.4816 D(G(z)): 0.5048 / 0.4737 Acc: 37.5000 (25.2083)\n",
      "[4/25][210/782] Loss_D: 0.2787 (0.5407) Loss_G: -0.0252 (0.4024) D(x): 0.5055 D(G(z)): 0.4618 / 0.4768 Acc: 29.6875 (25.2096)\n",
      "[4/25][211/782] Loss_D: 0.2165 (0.5406) Loss_G: 0.0178 (0.4023) D(x): 0.5306 D(G(z)): 0.4741 / 0.4881 Acc: 43.7500 (25.2152)\n",
      "[4/25][212/782] Loss_D: 0.2739 (0.5405) Loss_G: -0.1294 (0.4021) D(x): 0.5358 D(G(z)): 0.5366 / 0.5211 Acc: 39.0625 (25.2193)\n",
      "[4/25][213/782] Loss_D: 0.3111 (0.5405) Loss_G: -0.0750 (0.4020) D(x): 0.5384 D(G(z)): 0.5334 / 0.5076 Acc: 35.9375 (25.2225)\n",
      "[4/25][214/782] Loss_D: 0.3459 (0.5404) Loss_G: 0.1365 (0.4019) D(x): 0.5321 D(G(z)): 0.4695 / 0.4526 Acc: 32.8125 (25.2248)\n",
      "[4/25][215/782] Loss_D: 0.3708 (0.5404) Loss_G: 0.0877 (0.4018) D(x): 0.5273 D(G(z)): 0.4943 / 0.4650 Acc: 28.1250 (25.2257)\n",
      "[4/25][216/782] Loss_D: 0.1287 (0.5402) Loss_G: 0.0616 (0.4017) D(x): 0.5646 D(G(z)): 0.4641 / 0.4257 Acc: 29.6875 (25.2270)\n",
      "[4/25][217/782] Loss_D: 0.1869 (0.5401) Loss_G: 0.1352 (0.4016) D(x): 0.5238 D(G(z)): 0.4308 / 0.4115 Acc: 32.8125 (25.2293)\n",
      "[4/25][218/782] Loss_D: 0.2151 (0.5400) Loss_G: 0.0715 (0.4015) D(x): 0.5184 D(G(z)): 0.4884 / 0.4186 Acc: 39.0625 (25.2334)\n",
      "[4/25][219/782] Loss_D: 0.1700 (0.5399) Loss_G: 0.1786 (0.4014) D(x): 0.5657 D(G(z)): 0.4614 / 0.4201 Acc: 31.2500 (25.2352)\n",
      "[4/25][220/782] Loss_D: 0.0567 (0.5398) Loss_G: 0.0337 (0.4013) D(x): 0.5460 D(G(z)): 0.4463 / 0.4644 Acc: 45.3125 (25.2412)\n",
      "[4/25][221/782] Loss_D: 0.1439 (0.5397) Loss_G: 0.1245 (0.4012) D(x): 0.5276 D(G(z)): 0.4495 / 0.4461 Acc: 37.5000 (25.2449)\n",
      "[4/25][222/782] Loss_D: 0.3075 (0.5396) Loss_G: -0.0048 (0.4011) D(x): 0.5540 D(G(z)): 0.5275 / 0.4804 Acc: 37.5000 (25.2485)\n",
      "[4/25][223/782] Loss_D: 0.1148 (0.5395) Loss_G: 0.1049 (0.4010) D(x): 0.5212 D(G(z)): 0.4562 / 0.4151 Acc: 39.0625 (25.2526)\n",
      "[4/25][224/782] Loss_D: 0.4281 (0.5394) Loss_G: 0.0832 (0.4009) D(x): 0.4723 D(G(z)): 0.4889 / 0.4154 Acc: 25.0000 (25.2526)\n",
      "[4/25][225/782] Loss_D: 0.2010 (0.5393) Loss_G: 0.0982 (0.4008) D(x): 0.5615 D(G(z)): 0.4928 / 0.4183 Acc: 34.3750 (25.2553)\n",
      "[4/25][226/782] Loss_D: 0.2127 (0.5392) Loss_G: 0.1789 (0.4008) D(x): 0.4682 D(G(z)): 0.4276 / 0.4156 Acc: 42.1875 (25.2603)\n",
      "[4/25][227/782] Loss_D: 0.3523 (0.5392) Loss_G: 0.0973 (0.4007) D(x): 0.5173 D(G(z)): 0.4900 / 0.4399 Acc: 31.2500 (25.2621)\n",
      "[4/25][228/782] Loss_D: 0.2991 (0.5391) Loss_G: 0.1863 (0.4006) D(x): 0.5213 D(G(z)): 0.4481 / 0.4274 Acc: 28.1250 (25.2630)\n",
      "[4/25][229/782] Loss_D: 0.4220 (0.5391) Loss_G: 0.2024 (0.4006) D(x): 0.5124 D(G(z)): 0.4693 / 0.4223 Acc: 21.8750 (25.2620)\n",
      "[4/25][230/782] Loss_D: 0.3551 (0.5390) Loss_G: 0.2036 (0.4005) D(x): 0.4916 D(G(z)): 0.4416 / 0.4099 Acc: 28.1250 (25.2628)\n",
      "[4/25][231/782] Loss_D: 0.0994 (0.5389) Loss_G: 0.1442 (0.4004) D(x): 0.5411 D(G(z)): 0.4138 / 0.4287 Acc: 35.9375 (25.2660)\n",
      "[4/25][232/782] Loss_D: 0.3517 (0.5388) Loss_G: -0.0335 (0.4003) D(x): 0.5302 D(G(z)): 0.4903 / 0.4944 Acc: 23.4375 (25.2655)\n",
      "[4/25][233/782] Loss_D: 0.1505 (0.5387) Loss_G: -0.0374 (0.4002) D(x): 0.5811 D(G(z)): 0.4298 / 0.4614 Acc: 18.7500 (25.2635)\n",
      "[4/25][234/782] Loss_D: 0.3465 (0.5387) Loss_G: 0.2361 (0.4001) D(x): 0.5315 D(G(z)): 0.4790 / 0.4239 Acc: 34.3750 (25.2662)\n",
      "[4/25][235/782] Loss_D: 0.1263 (0.5385) Loss_G: 0.2896 (0.4001) D(x): 0.6027 D(G(z)): 0.4484 / 0.3830 Acc: 29.6875 (25.2675)\n",
      "[4/25][236/782] Loss_D: 0.2122 (0.5384) Loss_G: 0.1920 (0.4000) D(x): 0.5346 D(G(z)): 0.4856 / 0.3952 Acc: 34.3750 (25.2702)\n",
      "[4/25][237/782] Loss_D: 0.0679 (0.5383) Loss_G: 0.1633 (0.4000) D(x): 0.5313 D(G(z)): 0.4207 / 0.4079 Acc: 37.5000 (25.2739)\n",
      "[4/25][238/782] Loss_D: 0.1607 (0.5382) Loss_G: 0.1050 (0.3999) D(x): 0.5492 D(G(z)): 0.4607 / 0.4512 Acc: 35.9375 (25.2770)\n",
      "[4/25][239/782] Loss_D: 0.4175 (0.5381) Loss_G: 0.2164 (0.3998) D(x): 0.4744 D(G(z)): 0.4429 / 0.4157 Acc: 29.6875 (25.2784)\n",
      "[4/25][240/782] Loss_D: 0.2954 (0.5381) Loss_G: 0.1003 (0.3997) D(x): 0.5505 D(G(z)): 0.5039 / 0.4390 Acc: 32.8125 (25.2806)\n",
      "[4/25][241/782] Loss_D: 0.0378 (0.5379) Loss_G: -0.0428 (0.3996) D(x): 0.5762 D(G(z)): 0.4320 / 0.4708 Acc: 31.2500 (25.2824)\n",
      "[4/25][242/782] Loss_D: 0.3553 (0.5379) Loss_G: 0.1405 (0.3995) D(x): 0.5440 D(G(z)): 0.5406 / 0.4048 Acc: 28.1250 (25.2832)\n",
      "[4/25][243/782] Loss_D: 0.2603 (0.5378) Loss_G: 0.1792 (0.3995) D(x): 0.5397 D(G(z)): 0.4669 / 0.4133 Acc: 31.2500 (25.2850)\n",
      "[4/25][244/782] Loss_D: 0.3581 (0.5377) Loss_G: 0.0452 (0.3993) D(x): 0.5000 D(G(z)): 0.4887 / 0.4832 Acc: 31.2500 (25.2867)\n",
      "[4/25][245/782] Loss_D: 0.0566 (0.5376) Loss_G: 0.0317 (0.3992) D(x): 0.5942 D(G(z)): 0.4648 / 0.4605 Acc: 42.1875 (25.2918)\n",
      "[4/25][246/782] Loss_D: 0.4850 (0.5376) Loss_G: 0.0678 (0.3991) D(x): 0.4891 D(G(z)): 0.5318 / 0.4394 Acc: 31.2500 (25.2935)\n",
      "[4/25][247/782] Loss_D: 0.3760 (0.5375) Loss_G: 0.1427 (0.3991) D(x): 0.4954 D(G(z)): 0.5008 / 0.4264 Acc: 35.9375 (25.2967)\n",
      "[4/25][248/782] Loss_D: 0.2592 (0.5374) Loss_G: 0.1838 (0.3990) D(x): 0.5226 D(G(z)): 0.4482 / 0.4121 Acc: 32.8125 (25.2989)\n",
      "[4/25][249/782] Loss_D: 0.3909 (0.5374) Loss_G: 0.2303 (0.3990) D(x): 0.4862 D(G(z)): 0.4569 / 0.4028 Acc: 29.6875 (25.3002)\n",
      "[4/25][250/782] Loss_D: 0.4070 (0.5374) Loss_G: 0.1569 (0.3989) D(x): 0.4202 D(G(z)): 0.4509 / 0.4214 Acc: 40.6250 (25.3047)\n",
      "[4/25][251/782] Loss_D: 0.4136 (0.5373) Loss_G: 0.1272 (0.3988) D(x): 0.5798 D(G(z)): 0.5543 / 0.4535 Acc: 29.6875 (25.3060)\n",
      "[4/25][252/782] Loss_D: 0.2840 (0.5373) Loss_G: 0.0166 (0.3987) D(x): 0.5348 D(G(z)): 0.5226 / 0.4610 Acc: 37.5000 (25.3096)\n",
      "[4/25][253/782] Loss_D: 0.2527 (0.5372) Loss_G: 0.2153 (0.3986) D(x): 0.5420 D(G(z)): 0.4443 / 0.3858 Acc: 25.0000 (25.3095)\n",
      "[4/25][254/782] Loss_D: 0.1709 (0.5371) Loss_G: 0.0700 (0.3985) D(x): 0.5354 D(G(z)): 0.4196 / 0.4302 Acc: 25.0000 (25.3095)\n",
      "[4/25][255/782] Loss_D: 0.4664 (0.5370) Loss_G: -0.0508 (0.3984) D(x): 0.4755 D(G(z)): 0.5050 / 0.4828 Acc: 26.5625 (25.3098)\n",
      "[4/25][256/782] Loss_D: 0.3539 (0.5370) Loss_G: 0.1236 (0.3983) D(x): 0.5433 D(G(z)): 0.5008 / 0.4702 Acc: 35.9375 (25.3130)\n",
      "[4/25][257/782] Loss_D: 0.4336 (0.5370) Loss_G: 0.0284 (0.3982) D(x): 0.4579 D(G(z)): 0.4740 / 0.4723 Acc: 35.9375 (25.3161)\n",
      "[4/25][258/782] Loss_D: 0.3677 (0.5369) Loss_G: 0.0824 (0.3981) D(x): 0.5598 D(G(z)): 0.5254 / 0.4507 Acc: 29.6875 (25.3174)\n",
      "[4/25][259/782] Loss_D: 0.3295 (0.5368) Loss_G: 0.0073 (0.3980) D(x): 0.4834 D(G(z)): 0.4981 / 0.4531 Acc: 34.3750 (25.3201)\n",
      "[4/25][260/782] Loss_D: 0.0940 (0.5367) Loss_G: 0.0081 (0.3979) D(x): 0.5777 D(G(z)): 0.4805 / 0.4408 Acc: 35.9375 (25.3232)\n",
      "[4/25][261/782] Loss_D: 0.2555 (0.5366) Loss_G: 0.1442 (0.3978) D(x): 0.5661 D(G(z)): 0.4724 / 0.4210 Acc: 26.5625 (25.3236)\n",
      "[4/25][262/782] Loss_D: 0.2237 (0.5365) Loss_G: 0.2158 (0.3978) D(x): 0.5255 D(G(z)): 0.4593 / 0.3822 Acc: 28.1250 (25.3244)\n",
      "[4/25][263/782] Loss_D: 0.1070 (0.5364) Loss_G: 0.0930 (0.3977) D(x): 0.5691 D(G(z)): 0.4467 / 0.4535 Acc: 35.9375 (25.3275)\n",
      "[4/25][264/782] Loss_D: 0.2125 (0.5363) Loss_G: 0.1266 (0.3976) D(x): 0.5338 D(G(z)): 0.4425 / 0.4207 Acc: 28.1250 (25.3283)\n",
      "[4/25][265/782] Loss_D: 0.3182 (0.5363) Loss_G: -0.0117 (0.3975) D(x): 0.5254 D(G(z)): 0.4538 / 0.4785 Acc: 21.8750 (25.3273)\n",
      "[4/25][266/782] Loss_D: 0.2066 (0.5362) Loss_G: 0.1192 (0.3974) D(x): 0.5546 D(G(z)): 0.4952 / 0.4002 Acc: 29.6875 (25.3286)\n",
      "[4/25][267/782] Loss_D: 0.1202 (0.5360) Loss_G: 0.1776 (0.3973) D(x): 0.5610 D(G(z)): 0.4234 / 0.3991 Acc: 31.2500 (25.3304)\n",
      "[4/25][268/782] Loss_D: 0.1218 (0.5359) Loss_G: 0.0503 (0.3972) D(x): 0.5195 D(G(z)): 0.4455 / 0.4514 Acc: 40.6250 (25.3349)\n",
      "[4/25][269/782] Loss_D: 0.1682 (0.5358) Loss_G: 0.0682 (0.3971) D(x): 0.5156 D(G(z)): 0.4354 / 0.4408 Acc: 35.9375 (25.3380)\n",
      "[4/25][270/782] Loss_D: 0.2639 (0.5357) Loss_G: 0.1186 (0.3970) D(x): 0.5544 D(G(z)): 0.5404 / 0.4295 Acc: 43.7500 (25.3434)\n",
      "[4/25][271/782] Loss_D: 0.0319 (0.5356) Loss_G: 0.1722 (0.3970) D(x): 0.5515 D(G(z)): 0.4553 / 0.3704 Acc: 37.5000 (25.3470)\n",
      "[4/25][272/782] Loss_D: 0.2289 (0.5355) Loss_G: 0.0369 (0.3969) D(x): 0.4830 D(G(z)): 0.4284 / 0.4489 Acc: 35.9375 (25.3501)\n",
      "[4/25][273/782] Loss_D: 0.3130 (0.5354) Loss_G: 0.1205 (0.3968) D(x): 0.5787 D(G(z)): 0.4785 / 0.4403 Acc: 25.0000 (25.3500)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/25][274/782] Loss_D: 0.0784 (0.5353) Loss_G: -0.0463 (0.3967) D(x): 0.5729 D(G(z)): 0.5027 / 0.4742 Acc: 40.6250 (25.3545)\n",
      "[4/25][275/782] Loss_D: 0.3480 (0.5352) Loss_G: 0.1167 (0.3966) D(x): 0.4968 D(G(z)): 0.4871 / 0.4330 Acc: 37.5000 (25.3580)\n",
      "[4/25][276/782] Loss_D: 0.1345 (0.5351) Loss_G: 0.1339 (0.3965) D(x): 0.4988 D(G(z)): 0.4557 / 0.4077 Acc: 45.3125 (25.3639)\n",
      "[4/25][277/782] Loss_D: 0.3719 (0.5351) Loss_G: 0.0433 (0.3964) D(x): 0.4735 D(G(z)): 0.4771 / 0.4464 Acc: 34.3750 (25.3665)\n",
      "[4/25][278/782] Loss_D: 0.2810 (0.5350) Loss_G: -0.0585 (0.3963) D(x): 0.5031 D(G(z)): 0.4362 / 0.5207 Acc: 29.6875 (25.3678)\n",
      "[4/25][279/782] Loss_D: 0.2204 (0.5349) Loss_G: 0.0997 (0.3962) D(x): 0.5657 D(G(z)): 0.4693 / 0.4740 Acc: 34.3750 (25.3705)\n",
      "[4/25][280/782] Loss_D: 0.5057 (0.5349) Loss_G: 0.1191 (0.3961) D(x): 0.5133 D(G(z)): 0.5294 / 0.4401 Acc: 28.1250 (25.3713)\n",
      "[4/25][281/782] Loss_D: 0.2338 (0.5348) Loss_G: 0.1074 (0.3960) D(x): 0.4938 D(G(z)): 0.5140 / 0.4030 Acc: 42.1875 (25.3762)\n",
      "[4/25][282/782] Loss_D: 0.4328 (0.5348) Loss_G: 0.2116 (0.3960) D(x): 0.4770 D(G(z)): 0.4680 / 0.4218 Acc: 32.8125 (25.3784)\n",
      "[4/25][283/782] Loss_D: 0.3778 (0.5347) Loss_G: 0.1781 (0.3959) D(x): 0.5342 D(G(z)): 0.5151 / 0.4060 Acc: 32.8125 (25.3806)\n",
      "[4/25][284/782] Loss_D: 0.3592 (0.5347) Loss_G: 0.1222 (0.3958) D(x): 0.4735 D(G(z)): 0.4425 / 0.4365 Acc: 35.9375 (25.3836)\n",
      "[4/25][285/782] Loss_D: 0.1248 (0.5346) Loss_G: -0.0274 (0.3957) D(x): 0.5226 D(G(z)): 0.4425 / 0.4910 Acc: 37.5000 (25.3872)\n",
      "[4/25][286/782] Loss_D: 0.2624 (0.5345) Loss_G: 0.1214 (0.3956) D(x): 0.5400 D(G(z)): 0.5169 / 0.4285 Acc: 35.9375 (25.3903)\n",
      "[4/25][287/782] Loss_D: 0.1573 (0.5344) Loss_G: -0.0905 (0.3955) D(x): 0.5067 D(G(z)): 0.4475 / 0.4576 Acc: 26.5625 (25.3906)\n",
      "[4/25][288/782] Loss_D: 0.4686 (0.5343) Loss_G: 0.0911 (0.3954) D(x): 0.5245 D(G(z)): 0.5089 / 0.4604 Acc: 23.4375 (25.3901)\n",
      "[4/25][289/782] Loss_D: 0.0628 (0.5342) Loss_G: 0.0060 (0.3953) D(x): 0.5173 D(G(z)): 0.4064 / 0.4595 Acc: 39.0625 (25.3941)\n",
      "[4/25][290/782] Loss_D: 0.3308 (0.5341) Loss_G: 0.0291 (0.3952) D(x): 0.5302 D(G(z)): 0.5090 / 0.4468 Acc: 26.5625 (25.3944)\n",
      "[4/25][291/782] Loss_D: 0.2886 (0.5341) Loss_G: -0.0009 (0.3950) D(x): 0.5262 D(G(z)): 0.4622 / 0.4836 Acc: 26.5625 (25.3947)\n",
      "[4/25][292/782] Loss_D: 0.2875 (0.5340) Loss_G: 0.0250 (0.3949) D(x): 0.4824 D(G(z)): 0.4707 / 0.4586 Acc: 37.5000 (25.3983)\n",
      "[4/25][293/782] Loss_D: 0.1386 (0.5339) Loss_G: 0.2121 (0.3949) D(x): 0.5584 D(G(z)): 0.4456 / 0.4055 Acc: 35.9375 (25.4014)\n",
      "[4/25][294/782] Loss_D: 0.2292 (0.5338) Loss_G: -0.1011 (0.3947) D(x): 0.5254 D(G(z)): 0.4943 / 0.5081 Acc: 35.9375 (25.4044)\n",
      "[4/25][295/782] Loss_D: 0.0199 (0.5336) Loss_G: 0.1179 (0.3947) D(x): 0.5620 D(G(z)): 0.4372 / 0.4095 Acc: 37.5000 (25.4080)\n",
      "[4/25][296/782] Loss_D: 0.2502 (0.5336) Loss_G: 0.0383 (0.3945) D(x): 0.5160 D(G(z)): 0.4550 / 0.4748 Acc: 29.6875 (25.4092)\n",
      "[4/25][297/782] Loss_D: 0.3173 (0.5335) Loss_G: 0.1817 (0.3945) D(x): 0.5313 D(G(z)): 0.5196 / 0.4353 Acc: 35.9375 (25.4123)\n",
      "[4/25][298/782] Loss_D: 0.1195 (0.5334) Loss_G: 0.2388 (0.3944) D(x): 0.5487 D(G(z)): 0.4194 / 0.4043 Acc: 40.6250 (25.4167)\n",
      "[4/25][299/782] Loss_D: 0.1838 (0.5333) Loss_G: 0.0147 (0.3943) D(x): 0.5073 D(G(z)): 0.4295 / 0.4439 Acc: 29.6875 (25.4180)\n",
      "[4/25][300/782] Loss_D: 0.2224 (0.5332) Loss_G: 0.2348 (0.3943) D(x): 0.5888 D(G(z)): 0.4421 / 0.4227 Acc: 26.5625 (25.4183)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[4/25][301/782] Loss_D: 0.3337 (0.5331) Loss_G: 0.1163 (0.3942) D(x): 0.5397 D(G(z)): 0.4587 / 0.4396 Acc: 21.8750 (25.4173)\n",
      "[4/25][302/782] Loss_D: 0.1214 (0.5330) Loss_G: 0.0766 (0.3941) D(x): 0.5170 D(G(z)): 0.4803 / 0.4363 Acc: 45.3125 (25.4231)\n",
      "[4/25][303/782] Loss_D: 0.3531 (0.5330) Loss_G: 0.0528 (0.3940) D(x): 0.5001 D(G(z)): 0.4631 / 0.4555 Acc: 28.1250 (25.4239)\n",
      "[4/25][304/782] Loss_D: 0.3657 (0.5329) Loss_G: 0.0859 (0.3939) D(x): 0.5494 D(G(z)): 0.5199 / 0.4454 Acc: 26.5625 (25.4242)\n",
      "[4/25][305/782] Loss_D: 0.3034 (0.5328) Loss_G: 0.1293 (0.3938) D(x): 0.5351 D(G(z)): 0.5098 / 0.4484 Acc: 42.1875 (25.4291)\n",
      "[4/25][306/782] Loss_D: 0.3014 (0.5328) Loss_G: 0.0430 (0.3937) D(x): 0.4819 D(G(z)): 0.4694 / 0.4575 Acc: 42.1875 (25.4340)\n",
      "[4/25][307/782] Loss_D: 0.4270 (0.5327) Loss_G: 0.1615 (0.3937) D(x): 0.5285 D(G(z)): 0.4443 / 0.4592 Acc: 15.6250 (25.4311)\n",
      "[4/25][308/782] Loss_D: 0.4489 (0.5327) Loss_G: -0.0360 (0.3935) D(x): 0.5084 D(G(z)): 0.4856 / 0.4816 Acc: 21.8750 (25.4301)\n",
      "[4/25][309/782] Loss_D: 0.3810 (0.5327) Loss_G: 0.0828 (0.3935) D(x): 0.5355 D(G(z)): 0.5293 / 0.4718 Acc: 37.5000 (25.4336)\n",
      "[4/25][310/782] Loss_D: 0.2453 (0.5326) Loss_G: 0.1314 (0.3934) D(x): 0.5476 D(G(z)): 0.4040 / 0.4458 Acc: 25.0000 (25.4334)\n",
      "[4/25][311/782] Loss_D: 0.3822 (0.5325) Loss_G: 0.0227 (0.3933) D(x): 0.5210 D(G(z)): 0.4968 / 0.4629 Acc: 28.1250 (25.4342)\n",
      "[4/25][312/782] Loss_D: 0.1493 (0.5324) Loss_G: 0.0095 (0.3932) D(x): 0.5243 D(G(z)): 0.4552 / 0.4702 Acc: 39.0625 (25.4382)\n",
      "[4/25][313/782] Loss_D: 0.2111 (0.5323) Loss_G: 0.0831 (0.3931) D(x): 0.5598 D(G(z)): 0.4597 / 0.4555 Acc: 28.1250 (25.4390)\n",
      "[4/25][314/782] Loss_D: 0.1399 (0.5322) Loss_G: 0.1622 (0.3930) D(x): 0.5457 D(G(z)): 0.4531 / 0.4083 Acc: 31.2500 (25.4407)\n",
      "[4/25][315/782] Loss_D: 0.1391 (0.5321) Loss_G: 0.0725 (0.3929) D(x): 0.4955 D(G(z)): 0.4257 / 0.4250 Acc: 35.9375 (25.4437)\n",
      "[4/25][316/782] Loss_D: 0.2861 (0.5320) Loss_G: -0.0104 (0.3928) D(x): 0.5438 D(G(z)): 0.5140 / 0.4710 Acc: 34.3750 (25.4463)\n",
      "[4/25][317/782] Loss_D: 0.1894 (0.5319) Loss_G: -0.0580 (0.3927) D(x): 0.5126 D(G(z)): 0.4996 / 0.4760 Acc: 40.6250 (25.4507)\n",
      "[4/25][318/782] Loss_D: 0.0915 (0.5318) Loss_G: 0.0351 (0.3926) D(x): 0.5350 D(G(z)): 0.4617 / 0.4238 Acc: 35.9375 (25.4537)\n",
      "[4/25][319/782] Loss_D: 0.5010 (0.5318) Loss_G: -0.0473 (0.3924) D(x): 0.4870 D(G(z)): 0.4881 / 0.5451 Acc: 32.8125 (25.4559)\n",
      "[4/25][320/782] Loss_D: 0.1866 (0.5317) Loss_G: -0.0186 (0.3923) D(x): 0.5225 D(G(z)): 0.4391 / 0.4547 Acc: 23.4375 (25.4553)\n",
      "[4/25][321/782] Loss_D: 0.2249 (0.5316) Loss_G: 0.1889 (0.3923) D(x): 0.5547 D(G(z)): 0.4824 / 0.4237 Acc: 42.1875 (25.4601)\n",
      "[4/25][322/782] Loss_D: 0.0796 (0.5315) Loss_G: 0.0304 (0.3921) D(x): 0.5278 D(G(z)): 0.4248 / 0.4536 Acc: 40.6250 (25.4645)\n",
      "[4/25][323/782] Loss_D: 0.2378 (0.5314) Loss_G: 0.2058 (0.3921) D(x): 0.5911 D(G(z)): 0.4804 / 0.4276 Acc: 31.2500 (25.4662)\n",
      "[4/25][324/782] Loss_D: 0.2379 (0.5313) Loss_G: -0.0639 (0.3920) D(x): 0.4467 D(G(z)): 0.4230 / 0.4767 Acc: 39.0625 (25.4702)\n",
      "[4/25][325/782] Loss_D: 0.1654 (0.5312) Loss_G: 0.0843 (0.3919) D(x): 0.5326 D(G(z)): 0.5124 / 0.4262 Acc: 45.3125 (25.4759)\n",
      "[4/25][326/782] Loss_D: 0.4353 (0.5312) Loss_G: 0.0783 (0.3918) D(x): 0.4856 D(G(z)): 0.4756 / 0.4394 Acc: 23.4375 (25.4753)\n",
      "[4/25][327/782] Loss_D: 0.0833 (0.5311) Loss_G: 0.0953 (0.3917) D(x): 0.5179 D(G(z)): 0.4385 / 0.4279 Acc: 40.6250 (25.4797)\n",
      "[4/25][328/782] Loss_D: 0.1809 (0.5310) Loss_G: 0.0274 (0.3916) D(x): 0.4856 D(G(z)): 0.3808 / 0.4573 Acc: 29.6875 (25.4809)\n",
      "[4/25][329/782] Loss_D: 0.2626 (0.5309) Loss_G: 0.1704 (0.3915) D(x): 0.5831 D(G(z)): 0.4730 / 0.4701 Acc: 34.3750 (25.4835)\n",
      "[4/25][330/782] Loss_D: 0.2417 (0.5308) Loss_G: 0.0172 (0.3914) D(x): 0.5454 D(G(z)): 0.4954 / 0.4700 Acc: 40.6250 (25.4879)\n",
      "[4/25][331/782] Loss_D: 0.4043 (0.5308) Loss_G: 0.0891 (0.3913) D(x): 0.4731 D(G(z)): 0.4764 / 0.4224 Acc: 26.5625 (25.4882)\n",
      "[4/25][332/782] Loss_D: 0.2267 (0.5307) Loss_G: -0.0153 (0.3912) D(x): 0.4408 D(G(z)): 0.4093 / 0.4740 Acc: 40.6250 (25.4925)\n",
      "[4/25][333/782] Loss_D: 0.4415 (0.5306) Loss_G: -0.0630 (0.3911) D(x): 0.5169 D(G(z)): 0.5463 / 0.5069 Acc: 31.2500 (25.4942)\n",
      "[4/25][334/782] Loss_D: 0.2022 (0.5305) Loss_G: -0.0016 (0.3910) D(x): 0.5597 D(G(z)): 0.5218 / 0.4568 Acc: 37.5000 (25.4977)\n",
      "[4/25][335/782] Loss_D: 0.3145 (0.5305) Loss_G: 0.1316 (0.3909) D(x): 0.5066 D(G(z)): 0.4994 / 0.4224 Acc: 31.2500 (25.4993)\n",
      "[4/25][336/782] Loss_D: 0.2084 (0.5304) Loss_G: 0.0079 (0.3908) D(x): 0.5002 D(G(z)): 0.4775 / 0.4497 Acc: 35.9375 (25.5023)\n",
      "[4/25][337/782] Loss_D: 0.5629 (0.5304) Loss_G: 0.1051 (0.3907) D(x): 0.4782 D(G(z)): 0.4959 / 0.4610 Acc: 26.5625 (25.5027)\n",
      "[4/25][338/782] Loss_D: 0.2821 (0.5303) Loss_G: 0.0584 (0.3906) D(x): 0.5043 D(G(z)): 0.4474 / 0.4629 Acc: 29.6875 (25.5039)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/25][339/782] Loss_D: -0.0008 (0.5302) Loss_G: -0.0424 (0.3905) D(x): 0.5702 D(G(z)): 0.4307 / 0.4716 Acc: 35.9375 (25.5069)\n",
      "[4/25][340/782] Loss_D: 0.3026 (0.5301) Loss_G: -0.0611 (0.3904) D(x): 0.5136 D(G(z)): 0.4823 / 0.5042 Acc: 34.3750 (25.5094)\n",
      "[4/25][341/782] Loss_D: 0.1660 (0.5300) Loss_G: 0.0965 (0.3903) D(x): 0.5306 D(G(z)): 0.4379 / 0.4280 Acc: 29.6875 (25.5106)\n",
      "[4/25][342/782] Loss_D: 0.1368 (0.5299) Loss_G: 0.1353 (0.3902) D(x): 0.5555 D(G(z)): 0.4555 / 0.4043 Acc: 32.8125 (25.5127)\n",
      "[4/25][343/782] Loss_D: 0.0793 (0.5298) Loss_G: 0.2147 (0.3901) D(x): 0.5583 D(G(z)): 0.4433 / 0.3999 Acc: 40.6250 (25.5171)\n",
      "[4/25][344/782] Loss_D: 0.2606 (0.5297) Loss_G: 0.1732 (0.3901) D(x): 0.5346 D(G(z)): 0.4479 / 0.4457 Acc: 34.3750 (25.5196)\n",
      "[4/25][345/782] Loss_D: 0.1474 (0.5296) Loss_G: 0.1426 (0.3900) D(x): 0.5252 D(G(z)): 0.4277 / 0.4161 Acc: 31.2500 (25.5213)\n",
      "[4/25][346/782] Loss_D: 0.2361 (0.5295) Loss_G: 0.0453 (0.3899) D(x): 0.5300 D(G(z)): 0.4398 / 0.4682 Acc: 32.8125 (25.5234)\n",
      "[4/25][347/782] Loss_D: 0.2477 (0.5294) Loss_G: -0.0184 (0.3898) D(x): 0.5550 D(G(z)): 0.5249 / 0.5105 Acc: 32.8125 (25.5255)\n",
      "[4/25][348/782] Loss_D: 0.0807 (0.5293) Loss_G: 0.1553 (0.3897) D(x): 0.5762 D(G(z)): 0.4502 / 0.4211 Acc: 35.9375 (25.5285)\n",
      "[4/25][349/782] Loss_D: 0.1586 (0.5292) Loss_G: 0.1781 (0.3897) D(x): 0.5533 D(G(z)): 0.4457 / 0.4265 Acc: 34.3750 (25.5310)\n",
      "[4/25][350/782] Loss_D: 0.3662 (0.5291) Loss_G: 0.1102 (0.3896) D(x): 0.5227 D(G(z)): 0.4559 / 0.4419 Acc: 26.5625 (25.5313)\n",
      "[4/25][351/782] Loss_D: 0.1696 (0.5290) Loss_G: 0.0989 (0.3895) D(x): 0.5680 D(G(z)): 0.4797 / 0.4172 Acc: 31.2500 (25.5330)\n",
      "[4/25][352/782] Loss_D: 0.0642 (0.5289) Loss_G: 0.0762 (0.3894) D(x): 0.5129 D(G(z)): 0.3923 / 0.4561 Acc: 42.1875 (25.5377)\n",
      "[4/25][353/782] Loss_D: 0.2584 (0.5288) Loss_G: -0.0817 (0.3893) D(x): 0.5174 D(G(z)): 0.4767 / 0.5151 Acc: 35.9375 (25.5407)\n",
      "[4/25][354/782] Loss_D: 0.1321 (0.5287) Loss_G: 0.1109 (0.3892) D(x): 0.6042 D(G(z)): 0.4789 / 0.4370 Acc: 31.2500 (25.5424)\n",
      "[4/25][355/782] Loss_D: 0.1258 (0.5286) Loss_G: 0.0189 (0.3891) D(x): 0.5442 D(G(z)): 0.4870 / 0.4615 Acc: 45.3125 (25.5480)\n",
      "[4/25][356/782] Loss_D: 0.3071 (0.5285) Loss_G: 0.0542 (0.3890) D(x): 0.5012 D(G(z)): 0.4431 / 0.4611 Acc: 26.5625 (25.5483)\n",
      "[4/25][357/782] Loss_D: 0.1874 (0.5284) Loss_G: 0.0078 (0.3889) D(x): 0.5684 D(G(z)): 0.5029 / 0.4596 Acc: 37.5000 (25.5518)\n",
      "[4/25][358/782] Loss_D: 0.4565 (0.5284) Loss_G: 0.0473 (0.3888) D(x): 0.5006 D(G(z)): 0.5182 / 0.4758 Acc: 28.1250 (25.5525)\n",
      "[4/25][359/782] Loss_D: 0.3009 (0.5283) Loss_G: 0.1321 (0.3887) D(x): 0.5075 D(G(z)): 0.4850 / 0.4382 Acc: 40.6250 (25.5568)\n",
      "[4/25][360/782] Loss_D: 0.2009 (0.5282) Loss_G: 0.0822 (0.3886) D(x): 0.5410 D(G(z)): 0.5045 / 0.4265 Acc: 42.1875 (25.5616)\n",
      "[4/25][361/782] Loss_D: 0.2715 (0.5282) Loss_G: 0.1805 (0.3886) D(x): 0.5054 D(G(z)): 0.4713 / 0.3833 Acc: 28.1250 (25.5623)\n",
      "[4/25][362/782] Loss_D: 0.3482 (0.5281) Loss_G: 0.0228 (0.3885) D(x): 0.4947 D(G(z)): 0.5139 / 0.4740 Acc: 39.0625 (25.5662)\n",
      "[4/25][363/782] Loss_D: 0.2493 (0.5280) Loss_G: -0.0184 (0.3883) D(x): 0.4961 D(G(z)): 0.4687 / 0.4579 Acc: 29.6875 (25.5674)\n",
      "[4/25][364/782] Loss_D: 0.4367 (0.5280) Loss_G: 0.0056 (0.3882) D(x): 0.4841 D(G(z)): 0.4595 / 0.4945 Acc: 23.4375 (25.5668)\n",
      "[4/25][365/782] Loss_D: 0.2943 (0.5279) Loss_G: 0.2378 (0.3882) D(x): 0.5140 D(G(z)): 0.4874 / 0.4062 Acc: 40.6250 (25.5711)\n",
      "[4/25][366/782] Loss_D: 0.2566 (0.5279) Loss_G: -0.1494 (0.3880) D(x): 0.4677 D(G(z)): 0.4447 / 0.5292 Acc: 34.3750 (25.5736)\n",
      "[4/25][367/782] Loss_D: 0.1779 (0.5278) Loss_G: -0.0431 (0.3879) D(x): 0.6216 D(G(z)): 0.5397 / 0.4866 Acc: 29.6875 (25.5748)\n",
      "[4/25][368/782] Loss_D: 0.3470 (0.5277) Loss_G: 0.1955 (0.3879) D(x): 0.5378 D(G(z)): 0.4792 / 0.4164 Acc: 25.0000 (25.5746)\n",
      "[4/25][369/782] Loss_D: 0.4560 (0.5277) Loss_G: -0.0284 (0.3877) D(x): 0.4382 D(G(z)): 0.5013 / 0.4799 Acc: 35.9375 (25.5776)\n",
      "[4/25][370/782] Loss_D: 0.3855 (0.5277) Loss_G: -0.0393 (0.3876) D(x): 0.4862 D(G(z)): 0.4806 / 0.4863 Acc: 25.0000 (25.5774)\n",
      "[4/25][371/782] Loss_D: 0.3110 (0.5276) Loss_G: 0.0269 (0.3875) D(x): 0.5041 D(G(z)): 0.4948 / 0.4509 Acc: 29.6875 (25.5786)\n",
      "[4/25][372/782] Loss_D: 0.3166 (0.5275) Loss_G: 0.0915 (0.3874) D(x): 0.5219 D(G(z)): 0.5158 / 0.4464 Acc: 35.9375 (25.5815)\n",
      "[4/25][373/782] Loss_D: 0.3077 (0.5275) Loss_G: 0.0612 (0.3873) D(x): 0.4960 D(G(z)): 0.4476 / 0.4593 Acc: 29.6875 (25.5827)\n",
      "[4/25][374/782] Loss_D: 0.2245 (0.5274) Loss_G: 0.1139 (0.3873) D(x): 0.5797 D(G(z)): 0.4956 / 0.4105 Acc: 23.4375 (25.5821)\n",
      "[4/25][375/782] Loss_D: 0.4047 (0.5273) Loss_G: 0.1206 (0.3872) D(x): 0.5184 D(G(z)): 0.5025 / 0.4460 Acc: 32.8125 (25.5842)\n",
      "[4/25][376/782] Loss_D: 0.3259 (0.5273) Loss_G: 0.1496 (0.3871) D(x): 0.5122 D(G(z)): 0.4829 / 0.4365 Acc: 31.2500 (25.5858)\n",
      "[4/25][377/782] Loss_D: 0.2054 (0.5272) Loss_G: -0.0382 (0.3870) D(x): 0.4971 D(G(z)): 0.4652 / 0.4574 Acc: 32.8125 (25.5878)\n",
      "[4/25][378/782] Loss_D: 0.3923 (0.5272) Loss_G: 0.1002 (0.3869) D(x): 0.4670 D(G(z)): 0.4517 / 0.4811 Acc: 37.5000 (25.5912)\n",
      "[4/25][379/782] Loss_D: 0.2488 (0.5271) Loss_G: -0.0199 (0.3868) D(x): 0.5830 D(G(z)): 0.5247 / 0.4593 Acc: 28.1250 (25.5920)\n",
      "[4/25][380/782] Loss_D: 0.1322 (0.5270) Loss_G: 0.1244 (0.3867) D(x): 0.4891 D(G(z)): 0.4462 / 0.4275 Acc: 43.7500 (25.5971)\n",
      "[4/25][381/782] Loss_D: 0.1065 (0.5268) Loss_G: 0.2078 (0.3867) D(x): 0.5641 D(G(z)): 0.4121 / 0.4316 Acc: 39.0625 (25.6010)\n",
      "[4/25][382/782] Loss_D: -0.0343 (0.5267) Loss_G: 0.1633 (0.3866) D(x): 0.6440 D(G(z)): 0.4835 / 0.4147 Acc: 42.1875 (25.6057)\n",
      "[4/25][383/782] Loss_D: 0.0877 (0.5266) Loss_G: 0.1434 (0.3865) D(x): 0.5393 D(G(z)): 0.4436 / 0.4039 Acc: 37.5000 (25.6091)\n",
      "[4/25][384/782] Loss_D: 0.3694 (0.5265) Loss_G: 0.2203 (0.3865) D(x): 0.5334 D(G(z)): 0.4520 / 0.4408 Acc: 28.1250 (25.6098)\n",
      "[4/25][385/782] Loss_D: 0.0652 (0.5264) Loss_G: 0.1516 (0.3864) D(x): 0.5403 D(G(z)): 0.4465 / 0.4107 Acc: 34.3750 (25.6123)\n",
      "[4/25][386/782] Loss_D: 0.2293 (0.5263) Loss_G: 0.1105 (0.3863) D(x): 0.5484 D(G(z)): 0.4534 / 0.4265 Acc: 29.6875 (25.6134)\n",
      "[4/25][387/782] Loss_D: 0.3091 (0.5262) Loss_G: 0.1335 (0.3863) D(x): 0.5330 D(G(z)): 0.4710 / 0.4421 Acc: 28.1250 (25.6142)\n",
      "[4/25][388/782] Loss_D: 0.2696 (0.5262) Loss_G: -0.0640 (0.3861) D(x): 0.4923 D(G(z)): 0.4942 / 0.4999 Acc: 42.1875 (25.6189)\n",
      "[4/25][389/782] Loss_D: 0.3384 (0.5261) Loss_G: 0.0456 (0.3860) D(x): 0.4989 D(G(z)): 0.4659 / 0.4591 Acc: 31.2500 (25.6205)\n",
      "[4/25][390/782] Loss_D: 0.2522 (0.5260) Loss_G: 0.1477 (0.3860) D(x): 0.5409 D(G(z)): 0.4976 / 0.4273 Acc: 42.1875 (25.6252)\n",
      "[4/25][391/782] Loss_D: 0.3420 (0.5260) Loss_G: 0.0754 (0.3859) D(x): 0.5094 D(G(z)): 0.4627 / 0.4809 Acc: 32.8125 (25.6272)\n",
      "[4/25][392/782] Loss_D: 0.5913 (0.5260) Loss_G: 0.0047 (0.3858) D(x): 0.4801 D(G(z)): 0.5538 / 0.4736 Acc: 23.4375 (25.6266)\n",
      "[4/25][393/782] Loss_D: 0.5714 (0.5260) Loss_G: 0.1921 (0.3857) D(x): 0.4894 D(G(z)): 0.5082 / 0.4407 Acc: 26.5625 (25.6269)\n",
      "[4/25][394/782] Loss_D: 0.2944 (0.5259) Loss_G: 0.0756 (0.3856) D(x): 0.5018 D(G(z)): 0.4685 / 0.4273 Acc: 29.6875 (25.6280)\n",
      "[4/25][395/782] Loss_D: 0.3600 (0.5259) Loss_G: 0.1369 (0.3856) D(x): 0.4844 D(G(z)): 0.5048 / 0.4277 Acc: 32.8125 (25.6301)\n",
      "[4/25][396/782] Loss_D: 0.3179 (0.5258) Loss_G: 0.1667 (0.3855) D(x): 0.5513 D(G(z)): 0.4834 / 0.4258 Acc: 26.5625 (25.6303)\n",
      "[4/25][397/782] Loss_D: 0.2982 (0.5258) Loss_G: 0.1455 (0.3854) D(x): 0.4801 D(G(z)): 0.4631 / 0.4189 Acc: 37.5000 (25.6337)\n",
      "[4/25][398/782] Loss_D: 0.2551 (0.5257) Loss_G: 0.0474 (0.3853) D(x): 0.5015 D(G(z)): 0.4728 / 0.4524 Acc: 35.9375 (25.6366)\n",
      "[4/25][399/782] Loss_D: 0.3219 (0.5256) Loss_G: 0.0611 (0.3853) D(x): 0.4472 D(G(z)): 0.4666 / 0.4613 Acc: 40.6250 (25.6409)\n",
      "[4/25][400/782] Loss_D: 0.1143 (0.5255) Loss_G: -0.0623 (0.3851) D(x): 0.5439 D(G(z)): 0.4673 / 0.4871 Acc: 37.5000 (25.6442)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[4/25][401/782] Loss_D: 0.0801 (0.5254) Loss_G: 0.1551 (0.3851) D(x): 0.5458 D(G(z)): 0.4248 / 0.4343 Acc: 42.1875 (25.6489)\n",
      "[4/25][402/782] Loss_D: 0.1870 (0.5253) Loss_G: 0.0598 (0.3850) D(x): 0.5767 D(G(z)): 0.5071 / 0.4383 Acc: 29.6875 (25.6500)\n",
      "[4/25][403/782] Loss_D: 0.1727 (0.5252) Loss_G: 0.1348 (0.3849) D(x): 0.5323 D(G(z)): 0.4565 / 0.4011 Acc: 26.5625 (25.6503)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/25][404/782] Loss_D: 0.1527 (0.5251) Loss_G: 0.0806 (0.3848) D(x): 0.5371 D(G(z)): 0.4635 / 0.4273 Acc: 37.5000 (25.6537)\n",
      "[4/25][405/782] Loss_D: 0.0724 (0.5250) Loss_G: 0.0072 (0.3847) D(x): 0.4977 D(G(z)): 0.4096 / 0.4333 Acc: 34.3750 (25.6561)\n",
      "[4/25][406/782] Loss_D: 0.0994 (0.5249) Loss_G: 0.0807 (0.3846) D(x): 0.5652 D(G(z)): 0.4282 / 0.4445 Acc: 34.3750 (25.6586)\n",
      "[4/25][407/782] Loss_D: 0.2706 (0.5248) Loss_G: 0.0458 (0.3845) D(x): 0.5684 D(G(z)): 0.4918 / 0.4746 Acc: 31.2500 (25.6602)\n",
      "[4/25][408/782] Loss_D: 0.3378 (0.5247) Loss_G: 0.1682 (0.3845) D(x): 0.5982 D(G(z)): 0.5030 / 0.4387 Acc: 25.0000 (25.6600)\n",
      "[4/25][409/782] Loss_D: -0.0044 (0.5246) Loss_G: 0.2984 (0.3844) D(x): 0.5735 D(G(z)): 0.4589 / 0.3788 Acc: 51.5625 (25.6673)\n",
      "[4/25][410/782] Loss_D: 0.2443 (0.5245) Loss_G: 0.1433 (0.3844) D(x): 0.5332 D(G(z)): 0.4529 / 0.4320 Acc: 28.1250 (25.6680)\n",
      "[4/25][411/782] Loss_D: 0.2597 (0.5244) Loss_G: 0.0875 (0.3843) D(x): 0.5572 D(G(z)): 0.4769 / 0.4392 Acc: 31.2500 (25.6696)\n",
      "[4/25][412/782] Loss_D: 0.2139 (0.5243) Loss_G: 0.1315 (0.3842) D(x): 0.5160 D(G(z)): 0.4457 / 0.4099 Acc: 28.1250 (25.6703)\n",
      "[4/25][413/782] Loss_D: 0.2050 (0.5242) Loss_G: 0.1628 (0.3842) D(x): 0.5194 D(G(z)): 0.4333 / 0.4152 Acc: 32.8125 (25.6723)\n",
      "[4/25][414/782] Loss_D: 0.0700 (0.5241) Loss_G: 0.1148 (0.3841) D(x): 0.5373 D(G(z)): 0.4484 / 0.4150 Acc: 39.0625 (25.6761)\n",
      "[4/25][415/782] Loss_D: 0.1894 (0.5240) Loss_G: 0.0851 (0.3840) D(x): 0.5859 D(G(z)): 0.5135 / 0.4331 Acc: 34.3750 (25.6785)\n",
      "[4/25][416/782] Loss_D: 0.3547 (0.5240) Loss_G: 0.0119 (0.3839) D(x): 0.5229 D(G(z)): 0.5087 / 0.4781 Acc: 32.8125 (25.6805)\n",
      "[4/25][417/782] Loss_D: 0.3312 (0.5239) Loss_G: 0.1401 (0.3838) D(x): 0.5110 D(G(z)): 0.5337 / 0.4088 Acc: 37.5000 (25.6839)\n",
      "[4/25][418/782] Loss_D: 0.4107 (0.5239) Loss_G: -0.0083 (0.3837) D(x): 0.4710 D(G(z)): 0.4483 / 0.4947 Acc: 26.5625 (25.6841)\n",
      "[4/25][419/782] Loss_D: 0.3244 (0.5238) Loss_G: -0.0215 (0.3836) D(x): 0.4956 D(G(z)): 0.5280 / 0.4894 Acc: 43.7500 (25.6892)\n",
      "[4/25][420/782] Loss_D: 0.4173 (0.5238) Loss_G: 0.0829 (0.3835) D(x): 0.5315 D(G(z)): 0.5196 / 0.4673 Acc: 34.3750 (25.6917)\n",
      "[4/25][421/782] Loss_D: 0.3898 (0.5238) Loss_G: 0.2745 (0.3835) D(x): 0.4640 D(G(z)): 0.4636 / 0.4125 Acc: 39.0625 (25.6954)\n",
      "[4/25][422/782] Loss_D: 0.5800 (0.5238) Loss_G: -0.0384 (0.3834) D(x): 0.4354 D(G(z)): 0.5107 / 0.4864 Acc: 29.6875 (25.6965)\n",
      "[4/25][423/782] Loss_D: 0.4255 (0.5238) Loss_G: 0.0892 (0.3833) D(x): 0.5512 D(G(z)): 0.5583 / 0.4301 Acc: 28.1250 (25.6972)\n",
      "[4/25][424/782] Loss_D: 0.2893 (0.5237) Loss_G: -0.0056 (0.3832) D(x): 0.4639 D(G(z)): 0.4573 / 0.4712 Acc: 35.9375 (25.7001)\n",
      "[4/25][425/782] Loss_D: 0.2974 (0.5236) Loss_G: 0.0131 (0.3831) D(x): 0.5258 D(G(z)): 0.5017 / 0.4613 Acc: 34.3750 (25.7026)\n",
      "[4/25][426/782] Loss_D: 0.4270 (0.5236) Loss_G: 0.2174 (0.3830) D(x): 0.5238 D(G(z)): 0.4986 / 0.4131 Acc: 29.6875 (25.7037)\n",
      "[4/25][427/782] Loss_D: 0.3674 (0.5236) Loss_G: 0.0043 (0.3829) D(x): 0.4944 D(G(z)): 0.5016 / 0.4500 Acc: 29.6875 (25.7048)\n",
      "[4/25][428/782] Loss_D: 0.4584 (0.5235) Loss_G: -0.1397 (0.3828) D(x): 0.4498 D(G(z)): 0.4857 / 0.5102 Acc: 25.0000 (25.7046)\n",
      "[4/25][429/782] Loss_D: 0.4798 (0.5235) Loss_G: 0.0127 (0.3827) D(x): 0.4857 D(G(z)): 0.4923 / 0.4986 Acc: 29.6875 (25.7057)\n",
      "[4/25][430/782] Loss_D: 0.1938 (0.5234) Loss_G: 0.1048 (0.3826) D(x): 0.5821 D(G(z)): 0.5116 / 0.4178 Acc: 29.6875 (25.7068)\n",
      "[4/25][431/782] Loss_D: 0.2004 (0.5233) Loss_G: -0.0197 (0.3825) D(x): 0.5310 D(G(z)): 0.4769 / 0.4658 Acc: 34.3750 (25.7093)\n",
      "[4/25][432/782] Loss_D: 0.0731 (0.5232) Loss_G: 0.0527 (0.3824) D(x): 0.5184 D(G(z)): 0.4396 / 0.4210 Acc: 42.1875 (25.7139)\n",
      "[4/25][433/782] Loss_D: 0.1349 (0.5231) Loss_G: 0.0225 (0.3823) D(x): 0.5246 D(G(z)): 0.4795 / 0.4394 Acc: 39.0625 (25.7176)\n",
      "[4/25][434/782] Loss_D: 0.2850 (0.5230) Loss_G: 0.2628 (0.3822) D(x): 0.4974 D(G(z)): 0.4475 / 0.3913 Acc: 39.0625 (25.7214)\n",
      "[4/25][435/782] Loss_D: 0.1044 (0.5229) Loss_G: 0.1587 (0.3822) D(x): 0.5425 D(G(z)): 0.4480 / 0.4258 Acc: 40.6250 (25.7256)\n",
      "[4/25][436/782] Loss_D: 0.1736 (0.5228) Loss_G: -0.0510 (0.3821) D(x): 0.4834 D(G(z)): 0.4194 / 0.4842 Acc: 31.2500 (25.7271)\n",
      "[4/25][437/782] Loss_D: 0.1940 (0.5227) Loss_G: 0.2068 (0.3820) D(x): 0.5752 D(G(z)): 0.4776 / 0.4349 Acc: 37.5000 (25.7304)\n",
      "[4/25][438/782] Loss_D: 0.3174 (0.5227) Loss_G: 0.0333 (0.3819) D(x): 0.5391 D(G(z)): 0.5172 / 0.4504 Acc: 29.6875 (25.7315)\n",
      "[4/25][439/782] Loss_D: 0.1045 (0.5226) Loss_G: 0.1151 (0.3818) D(x): 0.5921 D(G(z)): 0.4881 / 0.3956 Acc: 28.1250 (25.7322)\n",
      "[4/25][440/782] Loss_D: 0.1361 (0.5224) Loss_G: 0.1365 (0.3818) D(x): 0.4998 D(G(z)): 0.3783 / 0.4127 Acc: 31.2500 (25.7337)\n",
      "[4/25][441/782] Loss_D: 0.2779 (0.5224) Loss_G: 0.1869 (0.3817) D(x): 0.5380 D(G(z)): 0.4571 / 0.4233 Acc: 31.2500 (25.7353)\n",
      "[4/25][442/782] Loss_D: 0.0146 (0.5222) Loss_G: 0.0033 (0.3816) D(x): 0.5858 D(G(z)): 0.4580 / 0.4462 Acc: 35.9375 (25.7382)\n",
      "[4/25][443/782] Loss_D: 0.1628 (0.5221) Loss_G: 0.2408 (0.3816) D(x): 0.5663 D(G(z)): 0.4526 / 0.3840 Acc: 31.2500 (25.7397)\n",
      "[4/25][444/782] Loss_D: 0.0587 (0.5220) Loss_G: 0.1578 (0.3815) D(x): 0.5332 D(G(z)): 0.4526 / 0.3984 Acc: 43.7500 (25.7447)\n",
      "[4/25][445/782] Loss_D: 0.0748 (0.5219) Loss_G: -0.0726 (0.3814) D(x): 0.4779 D(G(z)): 0.4362 / 0.4682 Acc: 46.8750 (25.7506)\n",
      "[4/25][446/782] Loss_D: 0.3000 (0.5218) Loss_G: 0.1006 (0.3813) D(x): 0.5422 D(G(z)): 0.4702 / 0.4708 Acc: 31.2500 (25.7522)\n",
      "[4/25][447/782] Loss_D: 0.3722 (0.5218) Loss_G: -0.0732 (0.3812) D(x): 0.4892 D(G(z)): 0.5333 / 0.5275 Acc: 45.3125 (25.7577)\n",
      "[4/25][448/782] Loss_D: 0.5972 (0.5218) Loss_G: 0.0890 (0.3811) D(x): 0.4639 D(G(z)): 0.5125 / 0.4540 Acc: 26.5625 (25.7579)\n",
      "[4/25][449/782] Loss_D: 0.3742 (0.5218) Loss_G: 0.1115 (0.3810) D(x): 0.4871 D(G(z)): 0.5009 / 0.4465 Acc: 32.8125 (25.7599)\n",
      "[4/25][450/782] Loss_D: 0.3813 (0.5217) Loss_G: 0.0234 (0.3809) D(x): 0.4829 D(G(z)): 0.4825 / 0.4762 Acc: 28.1250 (25.7605)\n",
      "[4/25][451/782] Loss_D: 0.2563 (0.5216) Loss_G: 0.0885 (0.3808) D(x): 0.5367 D(G(z)): 0.4537 / 0.4482 Acc: 25.0000 (25.7603)\n",
      "[4/25][452/782] Loss_D: 0.3922 (0.5216) Loss_G: 0.0412 (0.3807) D(x): 0.5112 D(G(z)): 0.5269 / 0.4440 Acc: 29.6875 (25.7614)\n",
      "[4/25][453/782] Loss_D: 0.2758 (0.5215) Loss_G: 0.0283 (0.3806) D(x): 0.5211 D(G(z)): 0.5053 / 0.4551 Acc: 34.3750 (25.7638)\n",
      "[4/25][454/782] Loss_D: 0.5182 (0.5215) Loss_G: 0.0636 (0.3805) D(x): 0.4295 D(G(z)): 0.4348 / 0.4565 Acc: 17.1875 (25.7614)\n",
      "[4/25][455/782] Loss_D: 0.3946 (0.5215) Loss_G: 0.0909 (0.3805) D(x): 0.5026 D(G(z)): 0.4727 / 0.4889 Acc: 34.3750 (25.7638)\n",
      "[4/25][456/782] Loss_D: 0.4892 (0.5215) Loss_G: 0.0796 (0.3804) D(x): 0.5226 D(G(z)): 0.5573 / 0.4468 Acc: 29.6875 (25.7649)\n",
      "[4/25][457/782] Loss_D: 0.1894 (0.5214) Loss_G: -0.0493 (0.3803) D(x): 0.5180 D(G(z)): 0.5247 / 0.4748 Acc: 45.3125 (25.7704)\n",
      "[4/25][458/782] Loss_D: 0.1296 (0.5213) Loss_G: 0.1285 (0.3802) D(x): 0.5335 D(G(z)): 0.4339 / 0.4316 Acc: 37.5000 (25.7736)\n",
      "[4/25][459/782] Loss_D: 0.0421 (0.5212) Loss_G: 0.0321 (0.3801) D(x): 0.5318 D(G(z)): 0.4346 / 0.4447 Acc: 42.1875 (25.7782)\n",
      "[4/25][460/782] Loss_D: 0.2224 (0.5211) Loss_G: 0.1746 (0.3800) D(x): 0.5423 D(G(z)): 0.5011 / 0.4179 Acc: 45.3125 (25.7836)\n",
      "[4/25][461/782] Loss_D: 0.2376 (0.5210) Loss_G: 0.0999 (0.3800) D(x): 0.4843 D(G(z)): 0.4236 / 0.4415 Acc: 34.3750 (25.7860)\n",
      "[4/25][462/782] Loss_D: 0.3469 (0.5209) Loss_G: 0.0468 (0.3799) D(x): 0.5296 D(G(z)): 0.5213 / 0.4699 Acc: 39.0625 (25.7897)\n",
      "[4/25][463/782] Loss_D: 0.1390 (0.5208) Loss_G: 0.1294 (0.3798) D(x): 0.5413 D(G(z)): 0.4819 / 0.4276 Acc: 40.6250 (25.7939)\n",
      "[4/25][464/782] Loss_D: 0.2156 (0.5208) Loss_G: 0.1058 (0.3797) D(x): 0.5267 D(G(z)): 0.4587 / 0.4243 Acc: 26.5625 (25.7941)\n",
      "[4/25][465/782] Loss_D: 0.2829 (0.5207) Loss_G: 0.1461 (0.3797) D(x): 0.5299 D(G(z)): 0.5112 / 0.4019 Acc: 35.9375 (25.7969)\n",
      "[4/25][466/782] Loss_D: 0.2552 (0.5206) Loss_G: 0.2261 (0.3796) D(x): 0.5516 D(G(z)): 0.4843 / 0.4110 Acc: 39.0625 (25.8006)\n",
      "[4/25][467/782] Loss_D: 0.4946 (0.5206) Loss_G: 0.0725 (0.3795) D(x): 0.4388 D(G(z)): 0.4110 / 0.4889 Acc: 25.0000 (25.8004)\n",
      "[4/25][468/782] Loss_D: 0.1632 (0.5205) Loss_G: -0.2553 (0.3794) D(x): 0.5370 D(G(z)): 0.4935 / 0.5490 Acc: 34.3750 (25.8028)\n",
      "[4/25][469/782] Loss_D: 0.3045 (0.5204) Loss_G: 0.0786 (0.3793) D(x): 0.6042 D(G(z)): 0.5245 / 0.4472 Acc: 26.5625 (25.8030)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/25][470/782] Loss_D: 0.1567 (0.5203) Loss_G: 0.0010 (0.3792) D(x): 0.5019 D(G(z)): 0.4331 / 0.4555 Acc: 39.0625 (25.8066)\n",
      "[4/25][471/782] Loss_D: 0.2228 (0.5203) Loss_G: -0.0021 (0.3791) D(x): 0.4824 D(G(z)): 0.4492 / 0.4826 Acc: 40.6250 (25.8108)\n",
      "[4/25][472/782] Loss_D: 0.2815 (0.5202) Loss_G: 0.0487 (0.3790) D(x): 0.5608 D(G(z)): 0.5030 / 0.4469 Acc: 28.1250 (25.8114)\n",
      "[4/25][473/782] Loss_D: -0.0234 (0.5200) Loss_G: 0.0607 (0.3789) D(x): 0.6030 D(G(z)): 0.4789 / 0.4088 Acc: 39.0625 (25.8151)\n",
      "[4/25][474/782] Loss_D: 0.1126 (0.5199) Loss_G: -0.0046 (0.3788) D(x): 0.5380 D(G(z)): 0.4516 / 0.4497 Acc: 35.9375 (25.8179)\n",
      "[4/25][475/782] Loss_D: 0.1196 (0.5198) Loss_G: -0.0288 (0.3787) D(x): 0.5067 D(G(z)): 0.4460 / 0.4806 Acc: 45.3125 (25.8233)\n",
      "[4/25][476/782] Loss_D: 0.0864 (0.5197) Loss_G: -0.1321 (0.3785) D(x): 0.5345 D(G(z)): 0.4297 / 0.4836 Acc: 31.2500 (25.8248)\n",
      "[4/25][477/782] Loss_D: 0.1593 (0.5196) Loss_G: 0.1515 (0.3785) D(x): 0.5989 D(G(z)): 0.4708 / 0.4463 Acc: 32.8125 (25.8267)\n",
      "[4/25][478/782] Loss_D: 0.0355 (0.5195) Loss_G: 0.0587 (0.3784) D(x): 0.5309 D(G(z)): 0.3778 / 0.4501 Acc: 34.3750 (25.8291)\n",
      "[4/25][479/782] Loss_D: 0.2372 (0.5194) Loss_G: 0.0290 (0.3783) D(x): 0.5810 D(G(z)): 0.5536 / 0.4664 Acc: 43.7500 (25.8341)\n",
      "[4/25][480/782] Loss_D: 0.1754 (0.5193) Loss_G: 0.2175 (0.3782) D(x): 0.5272 D(G(z)): 0.4675 / 0.4069 Acc: 43.7500 (25.8390)\n",
      "[4/25][481/782] Loss_D: 0.3018 (0.5192) Loss_G: 0.1749 (0.3782) D(x): 0.5226 D(G(z)): 0.4502 / 0.4190 Acc: 32.8125 (25.8410)\n",
      "[4/25][482/782] Loss_D: -0.0020 (0.5191) Loss_G: -0.1242 (0.3780) D(x): 0.4808 D(G(z)): 0.4247 / 0.4758 Acc: 45.3125 (25.8464)\n",
      "[4/25][483/782] Loss_D: 0.3088 (0.5190) Loss_G: 0.0741 (0.3779) D(x): 0.5288 D(G(z)): 0.4904 / 0.4536 Acc: 31.2500 (25.8479)\n",
      "[4/25][484/782] Loss_D: 0.2472 (0.5190) Loss_G: 0.0966 (0.3779) D(x): 0.5400 D(G(z)): 0.4620 / 0.4348 Acc: 31.2500 (25.8494)\n",
      "[4/25][485/782] Loss_D: 0.0817 (0.5188) Loss_G: 0.1397 (0.3778) D(x): 0.5380 D(G(z)): 0.4571 / 0.4166 Acc: 39.0625 (25.8530)\n",
      "[4/25][486/782] Loss_D: 0.1626 (0.5187) Loss_G: -0.0657 (0.3777) D(x): 0.5132 D(G(z)): 0.4603 / 0.4652 Acc: 32.8125 (25.8549)\n",
      "[4/25][487/782] Loss_D: 0.0864 (0.5186) Loss_G: 0.0097 (0.3776) D(x): 0.5350 D(G(z)): 0.4143 / 0.4525 Acc: 31.2500 (25.8564)\n",
      "[4/25][488/782] Loss_D: 0.1364 (0.5185) Loss_G: -0.0382 (0.3775) D(x): 0.5557 D(G(z)): 0.5086 / 0.4710 Acc: 42.1875 (25.8610)\n",
      "[4/25][489/782] Loss_D: 0.2726 (0.5184) Loss_G: 0.1573 (0.3774) D(x): 0.5203 D(G(z)): 0.5075 / 0.4180 Acc: 39.0625 (25.8646)\n",
      "[4/25][490/782] Loss_D: 0.3068 (0.5184) Loss_G: 0.2201 (0.3774) D(x): 0.5152 D(G(z)): 0.4152 / 0.4200 Acc: 28.1250 (25.8652)\n",
      "[4/25][491/782] Loss_D: 0.3018 (0.5183) Loss_G: 0.1524 (0.3773) D(x): 0.4885 D(G(z)): 0.3689 / 0.4631 Acc: 29.6875 (25.8663)\n",
      "[4/25][492/782] Loss_D: 0.3020 (0.5183) Loss_G: -0.0028 (0.3772) D(x): 0.5503 D(G(z)): 0.5249 / 0.4731 Acc: 29.6875 (25.8673)\n",
      "[4/25][493/782] Loss_D: 0.2221 (0.5182) Loss_G: 0.0891 (0.3771) D(x): 0.5544 D(G(z)): 0.4765 / 0.4899 Acc: 39.0625 (25.8710)\n",
      "[4/25][494/782] Loss_D: 0.2423 (0.5181) Loss_G: 0.0996 (0.3770) D(x): 0.5208 D(G(z)): 0.4419 / 0.4353 Acc: 31.2500 (25.8725)\n",
      "[4/25][495/782] Loss_D: 0.1054 (0.5180) Loss_G: 0.0531 (0.3769) D(x): 0.5420 D(G(z)): 0.4742 / 0.4396 Acc: 42.1875 (25.8770)\n",
      "[4/25][496/782] Loss_D: 0.2672 (0.5179) Loss_G: 0.1777 (0.3769) D(x): 0.5263 D(G(z)): 0.4309 / 0.4561 Acc: 37.5000 (25.8802)\n",
      "[4/25][497/782] Loss_D: 0.2634 (0.5179) Loss_G: 0.3007 (0.3769) D(x): 0.5696 D(G(z)): 0.4780 / 0.4069 Acc: 34.3750 (25.8825)\n",
      "[4/25][498/782] Loss_D: 0.2442 (0.5178) Loss_G: -0.0182 (0.3768) D(x): 0.4987 D(G(z)): 0.4664 / 0.4631 Acc: 28.1250 (25.8831)\n",
      "[4/25][499/782] Loss_D: 0.1161 (0.5177) Loss_G: 0.0564 (0.3767) D(x): 0.5069 D(G(z)): 0.4660 / 0.4615 Acc: 50.0000 (25.8898)\n",
      "[4/25][500/782] Loss_D: 0.1666 (0.5176) Loss_G: 0.2137 (0.3766) D(x): 0.5946 D(G(z)): 0.4514 / 0.4036 Acc: 26.5625 (25.8900)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[4/25][501/782] Loss_D: 0.0169 (0.5174) Loss_G: -0.0160 (0.3765) D(x): 0.5528 D(G(z)): 0.4389 / 0.4657 Acc: 39.0625 (25.8936)\n",
      "[4/25][502/782] Loss_D: 0.0382 (0.5173) Loss_G: 0.1624 (0.3765) D(x): 0.5698 D(G(z)): 0.4555 / 0.4012 Acc: 39.0625 (25.8972)\n",
      "[4/25][503/782] Loss_D: 0.3514 (0.5173) Loss_G: 0.0248 (0.3764) D(x): 0.5056 D(G(z)): 0.4874 / 0.4521 Acc: 32.8125 (25.8991)\n",
      "[4/25][504/782] Loss_D: 0.3022 (0.5172) Loss_G: 0.2029 (0.3763) D(x): 0.5354 D(G(z)): 0.4846 / 0.4284 Acc: 29.6875 (25.9002)\n",
      "[4/25][505/782] Loss_D: 0.3140 (0.5171) Loss_G: 0.0800 (0.3762) D(x): 0.5006 D(G(z)): 0.4635 / 0.4867 Acc: 40.6250 (25.9042)\n",
      "[4/25][506/782] Loss_D: 0.2411 (0.5171) Loss_G: 0.0927 (0.3762) D(x): 0.5260 D(G(z)): 0.4782 / 0.4474 Acc: 34.3750 (25.9066)\n",
      "[4/25][507/782] Loss_D: 0.1427 (0.5170) Loss_G: -0.0044 (0.3761) D(x): 0.4887 D(G(z)): 0.4414 / 0.4466 Acc: 34.3750 (25.9089)\n",
      "[4/25][508/782] Loss_D: 0.3687 (0.5169) Loss_G: -0.0263 (0.3759) D(x): 0.5124 D(G(z)): 0.5092 / 0.4898 Acc: 34.3750 (25.9112)\n",
      "[4/25][509/782] Loss_D: 0.3103 (0.5169) Loss_G: 0.1019 (0.3759) D(x): 0.5556 D(G(z)): 0.4794 / 0.4411 Acc: 28.1250 (25.9118)\n",
      "[4/25][510/782] Loss_D: 0.5731 (0.5169) Loss_G: 0.0028 (0.3758) D(x): 0.4723 D(G(z)): 0.5644 / 0.4840 Acc: 35.9375 (25.9146)\n",
      "[4/25][511/782] Loss_D: 0.4398 (0.5169) Loss_G: 0.0184 (0.3757) D(x): 0.5326 D(G(z)): 0.4996 / 0.4676 Acc: 18.7500 (25.9126)\n",
      "[4/25][512/782] Loss_D: 0.1890 (0.5168) Loss_G: -0.0830 (0.3755) D(x): 0.5244 D(G(z)): 0.4742 / 0.4879 Acc: 39.0625 (25.9162)\n",
      "[4/25][513/782] Loss_D: 0.2350 (0.5167) Loss_G: 0.1159 (0.3755) D(x): 0.5527 D(G(z)): 0.4874 / 0.4361 Acc: 32.8125 (25.9181)\n",
      "[4/25][514/782] Loss_D: 0.3318 (0.5166) Loss_G: 0.0321 (0.3754) D(x): 0.4935 D(G(z)): 0.4534 / 0.4920 Acc: 29.6875 (25.9191)\n",
      "[4/25][515/782] Loss_D: 0.4585 (0.5166) Loss_G: -0.0820 (0.3752) D(x): 0.5210 D(G(z)): 0.5227 / 0.5015 Acc: 18.7500 (25.9172)\n",
      "[4/25][516/782] Loss_D: 0.4300 (0.5166) Loss_G: 0.1403 (0.3752) D(x): 0.4534 D(G(z)): 0.5120 / 0.4467 Acc: 46.8750 (25.9229)\n",
      "[4/25][517/782] Loss_D: 0.3176 (0.5165) Loss_G: -0.0076 (0.3751) D(x): 0.5152 D(G(z)): 0.4544 / 0.4768 Acc: 23.4375 (25.9222)\n",
      "[4/25][518/782] Loss_D: 0.4237 (0.5165) Loss_G: -0.0091 (0.3750) D(x): 0.4975 D(G(z)): 0.5536 / 0.4623 Acc: 35.9375 (25.9250)\n",
      "[4/25][519/782] Loss_D: 0.4041 (0.5165) Loss_G: 0.1726 (0.3749) D(x): 0.5246 D(G(z)): 0.5145 / 0.4291 Acc: 31.2500 (25.9264)\n",
      "[4/25][520/782] Loss_D: 0.1913 (0.5164) Loss_G: 0.0663 (0.3748) D(x): 0.5369 D(G(z)): 0.5261 / 0.4220 Acc: 42.1875 (25.9309)\n",
      "[4/25][521/782] Loss_D: 0.2893 (0.5163) Loss_G: 0.1935 (0.3748) D(x): 0.5216 D(G(z)): 0.4649 / 0.3885 Acc: 28.1250 (25.9315)\n",
      "[4/25][522/782] Loss_D: 0.3359 (0.5163) Loss_G: 0.2210 (0.3747) D(x): 0.5239 D(G(z)): 0.4873 / 0.4195 Acc: 34.3750 (25.9338)\n",
      "[4/25][523/782] Loss_D: 0.4523 (0.5163) Loss_G: -0.0299 (0.3746) D(x): 0.4328 D(G(z)): 0.4461 / 0.4909 Acc: 28.1250 (25.9344)\n",
      "[4/25][524/782] Loss_D: 0.3183 (0.5162) Loss_G: 0.0797 (0.3745) D(x): 0.4874 D(G(z)): 0.5014 / 0.4548 Acc: 42.1875 (25.9389)\n",
      "[4/25][525/782] Loss_D: 0.3451 (0.5162) Loss_G: 0.0393 (0.3745) D(x): 0.5409 D(G(z)): 0.5191 / 0.4935 Acc: 31.2500 (25.9403)\n",
      "[4/25][526/782] Loss_D: 0.1292 (0.5161) Loss_G: 0.2451 (0.3744) D(x): 0.5810 D(G(z)): 0.4838 / 0.3925 Acc: 35.9375 (25.9431)\n",
      "[4/25][527/782] Loss_D: 0.1208 (0.5160) Loss_G: 0.1401 (0.3744) D(x): 0.5486 D(G(z)): 0.4196 / 0.4303 Acc: 31.2500 (25.9445)\n",
      "[4/25][528/782] Loss_D: 0.1479 (0.5159) Loss_G: 0.1505 (0.3743) D(x): 0.5373 D(G(z)): 0.4265 / 0.4402 Acc: 35.9375 (25.9472)\n",
      "[4/25][529/782] Loss_D: 0.1954 (0.5158) Loss_G: -0.0057 (0.3742) D(x): 0.5479 D(G(z)): 0.4604 / 0.4895 Acc: 32.8125 (25.9491)\n",
      "[4/25][530/782] Loss_D: 0.3665 (0.5157) Loss_G: -0.0205 (0.3741) D(x): 0.5223 D(G(z)): 0.4895 / 0.5090 Acc: 32.8125 (25.9510)\n",
      "[4/25][531/782] Loss_D: 0.2624 (0.5157) Loss_G: 0.0378 (0.3740) D(x): 0.5882 D(G(z)): 0.5197 / 0.4560 Acc: 28.1250 (25.9516)\n",
      "[4/25][532/782] Loss_D: 0.3660 (0.5156) Loss_G: 0.1085 (0.3739) D(x): 0.5046 D(G(z)): 0.5032 / 0.4341 Acc: 35.9375 (25.9543)\n",
      "[4/25][533/782] Loss_D: 0.2515 (0.5155) Loss_G: -0.0369 (0.3738) D(x): 0.5069 D(G(z)): 0.4531 / 0.5064 Acc: 32.8125 (25.9562)\n",
      "[4/25][534/782] Loss_D: 0.3612 (0.5155) Loss_G: 0.1848 (0.3738) D(x): 0.4974 D(G(z)): 0.4525 / 0.4045 Acc: 28.1250 (25.9568)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/25][535/782] Loss_D: -0.0185 (0.5154) Loss_G: 0.0541 (0.3737) D(x): 0.5670 D(G(z)): 0.4326 / 0.4499 Acc: 43.7500 (25.9616)\n",
      "[4/25][536/782] Loss_D: 0.1714 (0.5153) Loss_G: 0.1380 (0.3736) D(x): 0.5500 D(G(z)): 0.4613 / 0.4462 Acc: 37.5000 (25.9648)\n",
      "[4/25][537/782] Loss_D: 0.2794 (0.5152) Loss_G: 0.2045 (0.3736) D(x): 0.5723 D(G(z)): 0.5304 / 0.4102 Acc: 39.0625 (25.9684)\n",
      "[4/25][538/782] Loss_D: 0.2140 (0.5151) Loss_G: 0.0947 (0.3735) D(x): 0.4848 D(G(z)): 0.4855 / 0.4430 Acc: 46.8750 (25.9741)\n",
      "[4/25][539/782] Loss_D: 0.2420 (0.5150) Loss_G: 0.1789 (0.3734) D(x): 0.5105 D(G(z)): 0.4184 / 0.4077 Acc: 26.5625 (25.9742)\n",
      "[4/25][540/782] Loss_D: 0.0713 (0.5149) Loss_G: -0.0272 (0.3733) D(x): 0.4894 D(G(z)): 0.4413 / 0.4979 Acc: 50.0000 (25.9808)\n",
      "[4/25][541/782] Loss_D: 0.3619 (0.5149) Loss_G: -0.1648 (0.3732) D(x): 0.5448 D(G(z)): 0.5557 / 0.5378 Acc: 34.3750 (25.9831)\n",
      "[4/25][542/782] Loss_D: 0.4540 (0.5149) Loss_G: 0.1486 (0.3731) D(x): 0.5077 D(G(z)): 0.5150 / 0.4201 Acc: 25.0000 (25.9828)\n",
      "[4/25][543/782] Loss_D: 0.2963 (0.5148) Loss_G: 0.0537 (0.3730) D(x): 0.4810 D(G(z)): 0.4872 / 0.4338 Acc: 32.8125 (25.9846)\n",
      "[4/25][544/782] Loss_D: 0.2380 (0.5147) Loss_G: 0.0428 (0.3729) D(x): 0.5733 D(G(z)): 0.4876 / 0.4647 Acc: 28.1250 (25.9852)\n",
      "[4/25][545/782] Loss_D: 0.2205 (0.5146) Loss_G: -0.0281 (0.3728) D(x): 0.5180 D(G(z)): 0.4727 / 0.4496 Acc: 35.9375 (25.9879)\n",
      "[4/25][546/782] Loss_D: 0.3257 (0.5146) Loss_G: 0.0546 (0.3727) D(x): 0.4849 D(G(z)): 0.4862 / 0.4627 Acc: 39.0625 (25.9915)\n",
      "[4/25][547/782] Loss_D: 0.2256 (0.5145) Loss_G: -0.0150 (0.3726) D(x): 0.5610 D(G(z)): 0.4610 / 0.4843 Acc: 25.0000 (25.9912)\n",
      "[4/25][548/782] Loss_D: 0.3434 (0.5145) Loss_G: -0.0426 (0.3725) D(x): 0.5519 D(G(z)): 0.5459 / 0.4727 Acc: 29.6875 (25.9922)\n",
      "[4/25][549/782] Loss_D: 0.2596 (0.5144) Loss_G: 0.0868 (0.3724) D(x): 0.4876 D(G(z)): 0.4512 / 0.4491 Acc: 35.9375 (25.9949)\n",
      "[4/25][550/782] Loss_D: 0.1557 (0.5143) Loss_G: -0.0232 (0.3723) D(x): 0.5409 D(G(z)): 0.4430 / 0.4814 Acc: 28.1250 (25.9955)\n",
      "[4/25][551/782] Loss_D: 0.2833 (0.5142) Loss_G: -0.0398 (0.3722) D(x): 0.5131 D(G(z)): 0.4589 / 0.5020 Acc: 31.2500 (25.9969)\n",
      "[4/25][552/782] Loss_D: 0.1315 (0.5141) Loss_G: -0.1083 (0.3721) D(x): 0.5368 D(G(z)): 0.5051 / 0.4846 Acc: 35.9375 (25.9996)\n",
      "[4/25][553/782] Loss_D: 0.2086 (0.5141) Loss_G: -0.0301 (0.3720) D(x): 0.5401 D(G(z)): 0.4890 / 0.4480 Acc: 29.6875 (26.0006)\n",
      "[4/25][554/782] Loss_D: 0.2077 (0.5140) Loss_G: 0.0860 (0.3719) D(x): 0.5327 D(G(z)): 0.4630 / 0.4232 Acc: 32.8125 (26.0025)\n",
      "[4/25][555/782] Loss_D: 0.1333 (0.5139) Loss_G: 0.0324 (0.3718) D(x): 0.5563 D(G(z)): 0.4477 / 0.4577 Acc: 34.3750 (26.0048)\n",
      "[4/25][556/782] Loss_D: 0.2426 (0.5138) Loss_G: 0.1297 (0.3717) D(x): 0.5283 D(G(z)): 0.4355 / 0.4265 Acc: 28.1250 (26.0053)\n",
      "[4/25][557/782] Loss_D: 0.0860 (0.5137) Loss_G: 0.2299 (0.3717) D(x): 0.5523 D(G(z)): 0.4207 / 0.3951 Acc: 32.8125 (26.0072)\n",
      "[4/25][558/782] Loss_D: 0.1866 (0.5136) Loss_G: 0.0634 (0.3716) D(x): 0.5501 D(G(z)): 0.4605 / 0.4548 Acc: 34.3750 (26.0095)\n",
      "[4/25][559/782] Loss_D: 0.0270 (0.5135) Loss_G: 0.1091 (0.3716) D(x): 0.5555 D(G(z)): 0.4202 / 0.4227 Acc: 34.3750 (26.0117)\n",
      "[4/25][560/782] Loss_D: 0.2015 (0.5134) Loss_G: 0.1624 (0.3715) D(x): 0.5717 D(G(z)): 0.5021 / 0.4020 Acc: 29.6875 (26.0127)\n",
      "[4/25][561/782] Loss_D: 0.3231 (0.5133) Loss_G: 0.1291 (0.3714) D(x): 0.4918 D(G(z)): 0.4264 / 0.4310 Acc: 29.6875 (26.0137)\n",
      "[4/25][562/782] Loss_D: 0.2296 (0.5132) Loss_G: 0.0862 (0.3714) D(x): 0.5614 D(G(z)): 0.4949 / 0.4477 Acc: 34.3750 (26.0160)\n",
      "[4/25][563/782] Loss_D: 0.1766 (0.5132) Loss_G: 0.0138 (0.3713) D(x): 0.5474 D(G(z)): 0.4988 / 0.4303 Acc: 35.9375 (26.0187)\n",
      "[4/25][564/782] Loss_D: 0.3215 (0.5131) Loss_G: 0.3660 (0.3713) D(x): 0.5783 D(G(z)): 0.5142 / 0.3779 Acc: 39.0625 (26.0222)\n",
      "[4/25][565/782] Loss_D: 0.2342 (0.5130) Loss_G: 0.0591 (0.3712) D(x): 0.5188 D(G(z)): 0.4677 / 0.4475 Acc: 35.9375 (26.0249)\n",
      "[4/25][566/782] Loss_D: 0.5031 (0.5130) Loss_G: 0.2491 (0.3711) D(x): 0.4648 D(G(z)): 0.4591 / 0.4257 Acc: 25.0000 (26.0246)\n",
      "[4/25][567/782] Loss_D: 0.3286 (0.5130) Loss_G: -0.0226 (0.3710) D(x): 0.4446 D(G(z)): 0.4403 / 0.4917 Acc: 35.9375 (26.0273)\n",
      "[4/25][568/782] Loss_D: 0.2978 (0.5129) Loss_G: -0.0505 (0.3709) D(x): 0.5502 D(G(z)): 0.5376 / 0.4730 Acc: 31.2500 (26.0287)\n",
      "[4/25][569/782] Loss_D: 0.2189 (0.5128) Loss_G: 0.1073 (0.3708) D(x): 0.5277 D(G(z)): 0.4861 / 0.4436 Acc: 37.5000 (26.0318)\n",
      "[4/25][570/782] Loss_D: 0.1815 (0.5127) Loss_G: -0.0051 (0.3707) D(x): 0.5283 D(G(z)): 0.4859 / 0.4761 Acc: 39.0625 (26.0353)\n",
      "[4/25][571/782] Loss_D: 0.2666 (0.5127) Loss_G: 0.1482 (0.3707) D(x): 0.5158 D(G(z)): 0.4927 / 0.3921 Acc: 29.6875 (26.0363)\n",
      "[4/25][572/782] Loss_D: 0.5359 (0.5127) Loss_G: 0.1549 (0.3706) D(x): 0.4319 D(G(z)): 0.4812 / 0.4374 Acc: 34.3750 (26.0386)\n",
      "[4/25][573/782] Loss_D: 0.3807 (0.5127) Loss_G: 0.0185 (0.3705) D(x): 0.5200 D(G(z)): 0.5009 / 0.4767 Acc: 25.0000 (26.0383)\n",
      "[4/25][574/782] Loss_D: 0.3169 (0.5126) Loss_G: 0.1208 (0.3705) D(x): 0.5368 D(G(z)): 0.4567 / 0.4515 Acc: 28.1250 (26.0389)\n",
      "[4/25][575/782] Loss_D: 0.3535 (0.5126) Loss_G: 0.0604 (0.3704) D(x): 0.5049 D(G(z)): 0.4702 / 0.4388 Acc: 23.4375 (26.0382)\n",
      "[4/25][576/782] Loss_D: 0.4627 (0.5125) Loss_G: 0.0838 (0.3703) D(x): 0.5129 D(G(z)): 0.5398 / 0.4540 Acc: 32.8125 (26.0400)\n",
      "[4/25][577/782] Loss_D: 0.2785 (0.5125) Loss_G: 0.1114 (0.3702) D(x): 0.4681 D(G(z)): 0.4772 / 0.4348 Acc: 40.6250 (26.0439)\n",
      "[4/25][578/782] Loss_D: 0.3602 (0.5124) Loss_G: 0.0372 (0.3701) D(x): 0.5123 D(G(z)): 0.4883 / 0.4581 Acc: 26.5625 (26.0441)\n",
      "[4/25][579/782] Loss_D: 0.3136 (0.5124) Loss_G: 0.0833 (0.3701) D(x): 0.5488 D(G(z)): 0.4979 / 0.4601 Acc: 35.9375 (26.0467)\n",
      "[4/25][580/782] Loss_D: 0.2665 (0.5123) Loss_G: 0.2367 (0.3700) D(x): 0.5681 D(G(z)): 0.4954 / 0.3960 Acc: 29.6875 (26.0477)\n",
      "[4/25][581/782] Loss_D: 0.2034 (0.5122) Loss_G: 0.1019 (0.3700) D(x): 0.5129 D(G(z)): 0.4259 / 0.4474 Acc: 31.2500 (26.0491)\n",
      "[4/25][582/782] Loss_D: 0.1457 (0.5121) Loss_G: -0.0519 (0.3698) D(x): 0.4944 D(G(z)): 0.4423 / 0.4778 Acc: 32.8125 (26.0509)\n",
      "[4/25][583/782] Loss_D: 0.2374 (0.5121) Loss_G: 0.0348 (0.3698) D(x): 0.5689 D(G(z)): 0.5043 / 0.4904 Acc: 34.3750 (26.0532)\n",
      "[4/25][584/782] Loss_D: 0.1451 (0.5120) Loss_G: 0.0266 (0.3697) D(x): 0.5522 D(G(z)): 0.4953 / 0.4665 Acc: 43.7500 (26.0579)\n",
      "[4/25][585/782] Loss_D: 0.2235 (0.5119) Loss_G: 0.0912 (0.3696) D(x): 0.5128 D(G(z)): 0.5199 / 0.4109 Acc: 42.1875 (26.0623)\n",
      "[4/25][586/782] Loss_D: 0.2943 (0.5118) Loss_G: 0.0311 (0.3695) D(x): 0.4851 D(G(z)): 0.4711 / 0.4515 Acc: 31.2500 (26.0637)\n",
      "[4/25][587/782] Loss_D: 0.2180 (0.5117) Loss_G: 0.0810 (0.3694) D(x): 0.5468 D(G(z)): 0.4947 / 0.4159 Acc: 31.2500 (26.0651)\n",
      "[4/25][588/782] Loss_D: 0.2699 (0.5117) Loss_G: 0.0277 (0.3693) D(x): 0.5184 D(G(z)): 0.4796 / 0.4596 Acc: 32.8125 (26.0669)\n",
      "[4/25][589/782] Loss_D: 0.2717 (0.5116) Loss_G: -0.0242 (0.3692) D(x): 0.4943 D(G(z)): 0.4229 / 0.4831 Acc: 28.1250 (26.0674)\n",
      "[4/25][590/782] Loss_D: 0.3499 (0.5116) Loss_G: 0.0891 (0.3691) D(x): 0.5639 D(G(z)): 0.4992 / 0.4664 Acc: 25.0000 (26.0672)\n",
      "[4/25][591/782] Loss_D: 0.2714 (0.5115) Loss_G: -0.0043 (0.3690) D(x): 0.5489 D(G(z)): 0.5098 / 0.4599 Acc: 28.1250 (26.0677)\n",
      "[4/25][592/782] Loss_D: 0.4432 (0.5115) Loss_G: 0.1989 (0.3690) D(x): 0.4971 D(G(z)): 0.5318 / 0.4373 Acc: 39.0625 (26.0712)\n",
      "[4/25][593/782] Loss_D: 0.3188 (0.5114) Loss_G: 0.1094 (0.3689) D(x): 0.4653 D(G(z)): 0.4277 / 0.4461 Acc: 34.3750 (26.0734)\n",
      "[4/25][594/782] Loss_D: 0.1455 (0.5113) Loss_G: 0.0045 (0.3688) D(x): 0.5230 D(G(z)): 0.4585 / 0.4677 Acc: 37.5000 (26.0765)\n",
      "[4/25][595/782] Loss_D: 0.4048 (0.5113) Loss_G: 0.0552 (0.3687) D(x): 0.5376 D(G(z)): 0.5147 / 0.4823 Acc: 29.6875 (26.0775)\n",
      "[4/25][596/782] Loss_D: 0.1106 (0.5112) Loss_G: 0.0267 (0.3687) D(x): 0.5229 D(G(z)): 0.4769 / 0.4438 Acc: 45.3125 (26.0826)\n",
      "[4/25][597/782] Loss_D: 0.2189 (0.5111) Loss_G: 0.0628 (0.3686) D(x): 0.5248 D(G(z)): 0.4451 / 0.4507 Acc: 29.6875 (26.0836)\n",
      "[4/25][598/782] Loss_D: 0.4662 (0.5111) Loss_G: -0.0194 (0.3685) D(x): 0.4793 D(G(z)): 0.4680 / 0.4911 Acc: 23.4375 (26.0829)\n",
      "[4/25][599/782] Loss_D: 0.4647 (0.5111) Loss_G: 0.0375 (0.3684) D(x): 0.5384 D(G(z)): 0.5209 / 0.5064 Acc: 29.6875 (26.0839)\n",
      "[4/25][600/782] Loss_D: 0.3083 (0.5110) Loss_G: 0.0981 (0.3683) D(x): 0.5296 D(G(z)): 0.4875 / 0.4417 Acc: 29.6875 (26.0848)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/25][601/782] Loss_D: 0.2083 (0.5110) Loss_G: 0.2399 (0.3683) D(x): 0.5661 D(G(z)): 0.4688 / 0.3948 Acc: 31.2500 (26.0862)\n",
      "[4/25][602/782] Loss_D: 0.1535 (0.5109) Loss_G: 0.1777 (0.3682) D(x): 0.5375 D(G(z)): 0.4475 / 0.4023 Acc: 35.9375 (26.0889)\n",
      "[4/25][603/782] Loss_D: 0.2659 (0.5108) Loss_G: 0.0107 (0.3681) D(x): 0.4848 D(G(z)): 0.4511 / 0.4551 Acc: 31.2500 (26.0902)\n",
      "[4/25][604/782] Loss_D: -0.0741 (0.5106) Loss_G: 0.0339 (0.3680) D(x): 0.5653 D(G(z)): 0.4322 / 0.4557 Acc: 46.8750 (26.0958)\n",
      "[4/25][605/782] Loss_D: 0.2000 (0.5106) Loss_G: -0.0497 (0.3679) D(x): 0.5516 D(G(z)): 0.5223 / 0.4670 Acc: 39.0625 (26.0993)\n",
      "[4/25][606/782] Loss_D: 0.2379 (0.5105) Loss_G: -0.0585 (0.3678) D(x): 0.4970 D(G(z)): 0.4641 / 0.4609 Acc: 28.1250 (26.0998)\n",
      "[4/25][607/782] Loss_D: 0.2614 (0.5104) Loss_G: 0.1022 (0.3677) D(x): 0.5164 D(G(z)): 0.4616 / 0.4446 Acc: 29.6875 (26.1008)\n",
      "[4/25][608/782] Loss_D: 0.4300 (0.5104) Loss_G: 0.0907 (0.3677) D(x): 0.5392 D(G(z)): 0.5171 / 0.4584 Acc: 23.4375 (26.1001)\n",
      "[4/25][609/782] Loss_D: 0.1808 (0.5103) Loss_G: -0.0310 (0.3676) D(x): 0.5251 D(G(z)): 0.4431 / 0.4693 Acc: 31.2500 (26.1014)\n",
      "[4/25][610/782] Loss_D: 0.2537 (0.5102) Loss_G: 0.0350 (0.3675) D(x): 0.5066 D(G(z)): 0.4986 / 0.4834 Acc: 45.3125 (26.1066)\n",
      "[4/25][611/782] Loss_D: 0.2905 (0.5102) Loss_G: 0.0441 (0.3674) D(x): 0.5170 D(G(z)): 0.5030 / 0.4578 Acc: 35.9375 (26.1092)\n",
      "[4/25][612/782] Loss_D: 0.3585 (0.5101) Loss_G: 0.0853 (0.3673) D(x): 0.5153 D(G(z)): 0.4824 / 0.4560 Acc: 28.1250 (26.1097)\n",
      "[4/25][613/782] Loss_D: 0.6587 (0.5102) Loss_G: 0.0034 (0.3672) D(x): 0.4322 D(G(z)): 0.4880 / 0.4881 Acc: 28.1250 (26.1103)\n",
      "[4/25][614/782] Loss_D: 0.3117 (0.5101) Loss_G: 0.2113 (0.3672) D(x): 0.5172 D(G(z)): 0.4606 / 0.4120 Acc: 35.9375 (26.1129)\n",
      "[4/25][615/782] Loss_D: 0.2569 (0.5101) Loss_G: 0.1477 (0.3671) D(x): 0.5236 D(G(z)): 0.4866 / 0.4366 Acc: 43.7500 (26.1176)\n",
      "[4/25][616/782] Loss_D: 0.4156 (0.5100) Loss_G: 0.1118 (0.3670) D(x): 0.4868 D(G(z)): 0.4570 / 0.4408 Acc: 26.5625 (26.1177)\n",
      "[4/25][617/782] Loss_D: 0.2354 (0.5100) Loss_G: 0.1211 (0.3670) D(x): 0.5175 D(G(z)): 0.4705 / 0.4308 Acc: 37.5000 (26.1208)\n",
      "[4/25][618/782] Loss_D: 0.1417 (0.5099) Loss_G: 0.1390 (0.3669) D(x): 0.5439 D(G(z)): 0.4788 / 0.4124 Acc: 31.2500 (26.1221)\n",
      "[4/25][619/782] Loss_D: 0.2998 (0.5098) Loss_G: 0.0625 (0.3668) D(x): 0.5149 D(G(z)): 0.4780 / 0.4338 Acc: 28.1250 (26.1227)\n",
      "[4/25][620/782] Loss_D: 0.2517 (0.5097) Loss_G: 0.0636 (0.3668) D(x): 0.5473 D(G(z)): 0.4455 / 0.4408 Acc: 25.0000 (26.1224)\n",
      "[4/25][621/782] Loss_D: 0.2565 (0.5097) Loss_G: -0.0254 (0.3667) D(x): 0.5381 D(G(z)): 0.5037 / 0.4869 Acc: 35.9375 (26.1250)\n",
      "[4/25][622/782] Loss_D: 0.0638 (0.5096) Loss_G: 0.0408 (0.3666) D(x): 0.5718 D(G(z)): 0.4910 / 0.4376 Acc: 45.3125 (26.1301)\n",
      "[4/25][623/782] Loss_D: 0.1734 (0.5095) Loss_G: 0.3014 (0.3665) D(x): 0.5544 D(G(z)): 0.4550 / 0.3723 Acc: 32.8125 (26.1319)\n",
      "[4/25][624/782] Loss_D: 0.2849 (0.5094) Loss_G: 0.4102 (0.3666) D(x): 0.5357 D(G(z)): 0.4237 / 0.3559 Acc: 32.8125 (26.1337)\n",
      "[4/25][625/782] Loss_D: 0.3130 (0.5094) Loss_G: 0.0711 (0.3665) D(x): 0.4658 D(G(z)): 0.4240 / 0.4550 Acc: 32.8125 (26.1355)\n",
      "[4/25][626/782] Loss_D: 0.2037 (0.5093) Loss_G: 0.0572 (0.3664) D(x): 0.5233 D(G(z)): 0.4624 / 0.4629 Acc: 34.3750 (26.1376)\n",
      "[4/25][627/782] Loss_D: 0.1663 (0.5092) Loss_G: 0.2488 (0.3664) D(x): 0.5930 D(G(z)): 0.4962 / 0.3873 Acc: 34.3750 (26.1398)\n",
      "[4/25][628/782] Loss_D: 0.1049 (0.5091) Loss_G: 0.1747 (0.3663) D(x): 0.5892 D(G(z)): 0.4535 / 0.4007 Acc: 31.2500 (26.1412)\n",
      "[4/25][629/782] Loss_D: 0.3657 (0.5090) Loss_G: 0.1105 (0.3662) D(x): 0.4700 D(G(z)): 0.4341 / 0.4255 Acc: 25.0000 (26.1409)\n",
      "[4/25][630/782] Loss_D: 0.1157 (0.5089) Loss_G: 0.0026 (0.3661) D(x): 0.5347 D(G(z)): 0.4257 / 0.4954 Acc: 37.5000 (26.1439)\n",
      "[4/25][631/782] Loss_D: 0.1569 (0.5088) Loss_G: 0.1437 (0.3661) D(x): 0.5943 D(G(z)): 0.4992 / 0.4302 Acc: 32.8125 (26.1457)\n",
      "[4/25][632/782] Loss_D: 0.0961 (0.5087) Loss_G: 0.1427 (0.3660) D(x): 0.5764 D(G(z)): 0.4378 / 0.4265 Acc: 35.9375 (26.1483)\n",
      "[4/25][633/782] Loss_D: 0.3664 (0.5087) Loss_G: 0.1711 (0.3660) D(x): 0.5352 D(G(z)): 0.4734 / 0.4232 Acc: 23.4375 (26.1476)\n",
      "[4/25][634/782] Loss_D: 0.1503 (0.5086) Loss_G: 0.0692 (0.3659) D(x): 0.5145 D(G(z)): 0.4496 / 0.4360 Acc: 39.0625 (26.1510)\n",
      "[4/25][635/782] Loss_D: 0.2710 (0.5085) Loss_G: 0.1502 (0.3658) D(x): 0.5503 D(G(z)): 0.4559 / 0.4438 Acc: 34.3750 (26.1532)\n",
      "[4/25][636/782] Loss_D: 0.2300 (0.5085) Loss_G: 0.0112 (0.3657) D(x): 0.5434 D(G(z)): 0.4310 / 0.4737 Acc: 25.0000 (26.1529)\n",
      "[4/25][637/782] Loss_D: 0.1070 (0.5084) Loss_G: 0.0931 (0.3657) D(x): 0.5835 D(G(z)): 0.4728 / 0.4288 Acc: 34.3750 (26.1551)\n",
      "[4/25][638/782] Loss_D: 0.3127 (0.5083) Loss_G: 0.0085 (0.3656) D(x): 0.5574 D(G(z)): 0.4623 / 0.4668 Acc: 20.3125 (26.1535)\n",
      "[4/25][639/782] Loss_D: 0.2168 (0.5082) Loss_G: 0.1986 (0.3655) D(x): 0.5290 D(G(z)): 0.4491 / 0.3878 Acc: 28.1250 (26.1540)\n",
      "[4/25][640/782] Loss_D: 0.1575 (0.5081) Loss_G: 0.0552 (0.3655) D(x): 0.5047 D(G(z)): 0.4986 / 0.4491 Acc: 51.5625 (26.1608)\n",
      "[4/25][641/782] Loss_D: 0.3352 (0.5081) Loss_G: -0.0426 (0.3653) D(x): 0.4858 D(G(z)): 0.4375 / 0.4929 Acc: 28.1250 (26.1613)\n",
      "[4/25][642/782] Loss_D: 0.1988 (0.5080) Loss_G: 0.0974 (0.3653) D(x): 0.5616 D(G(z)): 0.4925 / 0.4310 Acc: 39.0625 (26.1647)\n",
      "[4/25][643/782] Loss_D: 0.4395 (0.5080) Loss_G: 0.0802 (0.3652) D(x): 0.5177 D(G(z)): 0.4910 / 0.4694 Acc: 23.4375 (26.1640)\n",
      "[4/25][644/782] Loss_D: 0.2781 (0.5079) Loss_G: 0.1522 (0.3651) D(x): 0.5057 D(G(z)): 0.4756 / 0.4064 Acc: 32.8125 (26.1658)\n",
      "[4/25][645/782] Loss_D: 0.1226 (0.5078) Loss_G: -0.0315 (0.3650) D(x): 0.5133 D(G(z)): 0.4645 / 0.4738 Acc: 39.0625 (26.1692)\n",
      "[4/25][646/782] Loss_D: 0.4235 (0.5078) Loss_G: 0.0747 (0.3650) D(x): 0.5468 D(G(z)): 0.4610 / 0.4753 Acc: 20.3125 (26.1676)\n",
      "[4/25][647/782] Loss_D: 0.1529 (0.5077) Loss_G: 0.1230 (0.3649) D(x): 0.5746 D(G(z)): 0.4663 / 0.4404 Acc: 32.8125 (26.1694)\n",
      "[4/25][648/782] Loss_D: 0.2263 (0.5076) Loss_G: 0.0253 (0.3648) D(x): 0.5483 D(G(z)): 0.4264 / 0.4839 Acc: 23.4375 (26.1687)\n",
      "[4/25][649/782] Loss_D: 0.3533 (0.5076) Loss_G: 0.0279 (0.3647) D(x): 0.4888 D(G(z)): 0.4664 / 0.4887 Acc: 31.2500 (26.1700)\n",
      "[4/25][650/782] Loss_D: 0.2495 (0.5075) Loss_G: 0.1249 (0.3647) D(x): 0.5192 D(G(z)): 0.4785 / 0.4435 Acc: 37.5000 (26.1730)\n",
      "[4/25][651/782] Loss_D: 0.2102 (0.5074) Loss_G: 0.0985 (0.3646) D(x): 0.5455 D(G(z)): 0.4496 / 0.4392 Acc: 29.6875 (26.1739)\n",
      "[4/25][652/782] Loss_D: 0.2885 (0.5074) Loss_G: 0.0061 (0.3645) D(x): 0.5149 D(G(z)): 0.4855 / 0.4997 Acc: 39.0625 (26.1774)\n",
      "[4/25][653/782] Loss_D: 0.3115 (0.5073) Loss_G: 0.0600 (0.3644) D(x): 0.5679 D(G(z)): 0.5594 / 0.4636 Acc: 40.6250 (26.1812)\n",
      "[4/25][654/782] Loss_D: 0.1720 (0.5072) Loss_G: 0.2826 (0.3644) D(x): 0.5158 D(G(z)): 0.4196 / 0.4067 Acc: 40.6250 (26.1850)\n",
      "[4/25][655/782] Loss_D: 0.3510 (0.5072) Loss_G: 0.1064 (0.3643) D(x): 0.5030 D(G(z)): 0.4982 / 0.4289 Acc: 32.8125 (26.1867)\n",
      "[4/25][656/782] Loss_D: 0.4698 (0.5072) Loss_G: 0.0289 (0.3642) D(x): 0.4286 D(G(z)): 0.4468 / 0.4976 Acc: 43.7500 (26.1914)\n",
      "[4/25][657/782] Loss_D: 0.5600 (0.5072) Loss_G: 0.1090 (0.3642) D(x): 0.5081 D(G(z)): 0.5353 / 0.4823 Acc: 31.2500 (26.1927)\n",
      "[4/25][658/782] Loss_D: 0.4580 (0.5072) Loss_G: 0.0366 (0.3641) D(x): 0.5357 D(G(z)): 0.5294 / 0.4856 Acc: 31.2500 (26.1941)\n",
      "[4/25][659/782] Loss_D: 0.3343 (0.5071) Loss_G: 0.1627 (0.3640) D(x): 0.5668 D(G(z)): 0.5291 / 0.4302 Acc: 37.5000 (26.1970)\n",
      "[4/25][660/782] Loss_D: 0.0867 (0.5070) Loss_G: 0.3281 (0.3640) D(x): 0.5396 D(G(z)): 0.3961 / 0.3921 Acc: 42.1875 (26.2013)\n",
      "[4/25][661/782] Loss_D: 0.3119 (0.5070) Loss_G: 0.0492 (0.3639) D(x): 0.4831 D(G(z)): 0.4773 / 0.4489 Acc: 35.9375 (26.2038)\n",
      "[4/25][662/782] Loss_D: 0.1943 (0.5069) Loss_G: 0.0976 (0.3639) D(x): 0.5262 D(G(z)): 0.4569 / 0.4260 Acc: 34.3750 (26.2060)\n",
      "[4/25][663/782] Loss_D: 0.1890 (0.5068) Loss_G: 0.1768 (0.3638) D(x): 0.5203 D(G(z)): 0.4665 / 0.4198 Acc: 40.6250 (26.2098)\n",
      "[4/25][664/782] Loss_D: 0.3298 (0.5068) Loss_G: 0.1472 (0.3638) D(x): 0.4863 D(G(z)): 0.5053 / 0.4024 Acc: 35.9375 (26.2123)\n",
      "[4/25][665/782] Loss_D: 0.3332 (0.5067) Loss_G: 0.2868 (0.3637) D(x): 0.4810 D(G(z)): 0.4494 / 0.3932 Acc: 34.3750 (26.2145)\n",
      "[4/25][666/782] Loss_D: 0.2516 (0.5067) Loss_G: 0.1067 (0.3637) D(x): 0.4880 D(G(z)): 0.4381 / 0.4299 Acc: 34.3750 (26.2167)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/25][667/782] Loss_D: 0.0845 (0.5066) Loss_G: 0.1131 (0.3636) D(x): 0.5050 D(G(z)): 0.4055 / 0.4176 Acc: 31.2500 (26.2180)\n",
      "[4/25][668/782] Loss_D: 0.3175 (0.5065) Loss_G: 0.0490 (0.3635) D(x): 0.5352 D(G(z)): 0.5128 / 0.4743 Acc: 31.2500 (26.2193)\n",
      "[4/25][669/782] Loss_D: 0.1736 (0.5064) Loss_G: 0.0879 (0.3634) D(x): 0.6002 D(G(z)): 0.4903 / 0.4308 Acc: 25.0000 (26.2190)\n",
      "[4/25][670/782] Loss_D: 0.1609 (0.5063) Loss_G: 0.1516 (0.3634) D(x): 0.5374 D(G(z)): 0.4603 / 0.4079 Acc: 34.3750 (26.2211)\n",
      "[4/25][671/782] Loss_D: 0.3083 (0.5063) Loss_G: 0.1340 (0.3633) D(x): 0.4673 D(G(z)): 0.4094 / 0.4503 Acc: 34.3750 (26.2233)\n",
      "[4/25][672/782] Loss_D: 0.1802 (0.5062) Loss_G: 0.1063 (0.3633) D(x): 0.5885 D(G(z)): 0.5332 / 0.4147 Acc: 35.9375 (26.2258)\n",
      "[4/25][673/782] Loss_D: 0.3823 (0.5062) Loss_G: 0.1435 (0.3632) D(x): 0.4943 D(G(z)): 0.4594 / 0.4404 Acc: 26.5625 (26.2259)\n",
      "[4/25][674/782] Loss_D: 0.3230 (0.5061) Loss_G: 0.1116 (0.3631) D(x): 0.5430 D(G(z)): 0.5107 / 0.4250 Acc: 28.1250 (26.2264)\n",
      "[4/25][675/782] Loss_D: 0.4792 (0.5061) Loss_G: 0.2469 (0.3631) D(x): 0.4812 D(G(z)): 0.4695 / 0.4213 Acc: 31.2500 (26.2277)\n",
      "[4/25][676/782] Loss_D: 0.1837 (0.5060) Loss_G: 0.0996 (0.3630) D(x): 0.5427 D(G(z)): 0.4601 / 0.4521 Acc: 42.1875 (26.2319)\n",
      "[4/25][677/782] Loss_D: 0.1163 (0.5059) Loss_G: 0.0758 (0.3630) D(x): 0.5603 D(G(z)): 0.4851 / 0.4183 Acc: 37.5000 (26.2349)\n",
      "[4/25][678/782] Loss_D: 0.1880 (0.5058) Loss_G: 0.1496 (0.3629) D(x): 0.5227 D(G(z)): 0.4570 / 0.4093 Acc: 34.3750 (26.2370)\n",
      "[4/25][679/782] Loss_D: 0.1147 (0.5057) Loss_G: 0.1348 (0.3628) D(x): 0.5855 D(G(z)): 0.4792 / 0.4100 Acc: 37.5000 (26.2400)\n",
      "[4/25][680/782] Loss_D: 0.1509 (0.5056) Loss_G: 0.1070 (0.3628) D(x): 0.5097 D(G(z)): 0.4081 / 0.4398 Acc: 37.5000 (26.2429)\n",
      "[4/25][681/782] Loss_D: 0.0562 (0.5055) Loss_G: 0.1021 (0.3627) D(x): 0.5331 D(G(z)): 0.4156 / 0.4587 Acc: 50.0000 (26.2492)\n",
      "[4/25][682/782] Loss_D: 0.1860 (0.5054) Loss_G: 0.2475 (0.3627) D(x): 0.5973 D(G(z)): 0.4800 / 0.3905 Acc: 35.9375 (26.2517)\n",
      "[4/25][683/782] Loss_D: 0.4674 (0.5054) Loss_G: 0.1302 (0.3626) D(x): 0.5215 D(G(z)): 0.4887 / 0.4557 Acc: 23.4375 (26.2510)\n",
      "[4/25][684/782] Loss_D: 0.3905 (0.5054) Loss_G: 0.1582 (0.3626) D(x): 0.5260 D(G(z)): 0.5238 / 0.4169 Acc: 31.2500 (26.2523)\n",
      "[4/25][685/782] Loss_D: 0.3894 (0.5054) Loss_G: 0.1584 (0.3625) D(x): 0.4526 D(G(z)): 0.4347 / 0.4358 Acc: 28.1250 (26.2528)\n",
      "[4/25][686/782] Loss_D: 0.5029 (0.5054) Loss_G: -0.0298 (0.3624) D(x): 0.4627 D(G(z)): 0.4820 / 0.5132 Acc: 28.1250 (26.2533)\n",
      "[4/25][687/782] Loss_D: 0.3266 (0.5053) Loss_G: -0.1459 (0.3623) D(x): 0.5220 D(G(z)): 0.5540 / 0.5137 Acc: 37.5000 (26.2562)\n",
      "[4/25][688/782] Loss_D: 0.5873 (0.5053) Loss_G: 0.0814 (0.3622) D(x): 0.4667 D(G(z)): 0.5587 / 0.4839 Acc: 42.1875 (26.2604)\n",
      "[4/25][689/782] Loss_D: 0.3905 (0.5053) Loss_G: 0.1803 (0.3622) D(x): 0.5122 D(G(z)): 0.5060 / 0.4117 Acc: 32.8125 (26.2621)\n",
      "[4/25][690/782] Loss_D: 0.2773 (0.5052) Loss_G: 0.0997 (0.3621) D(x): 0.4849 D(G(z)): 0.4244 / 0.4430 Acc: 34.3750 (26.2642)\n",
      "[4/25][691/782] Loss_D: 0.2054 (0.5052) Loss_G: 0.0520 (0.3620) D(x): 0.5528 D(G(z)): 0.4652 / 0.4682 Acc: 34.3750 (26.2664)\n",
      "[4/25][692/782] Loss_D: 0.3723 (0.5051) Loss_G: 0.2131 (0.3620) D(x): 0.5366 D(G(z)): 0.4571 / 0.4329 Acc: 21.8750 (26.2652)\n",
      "[4/25][693/782] Loss_D: 0.0957 (0.5050) Loss_G: 0.1544 (0.3619) D(x): 0.5180 D(G(z)): 0.4523 / 0.4069 Acc: 45.3125 (26.2702)\n",
      "[4/25][694/782] Loss_D: 0.1145 (0.5049) Loss_G: 0.0973 (0.3618) D(x): 0.5732 D(G(z)): 0.4348 / 0.4444 Acc: 34.3750 (26.2723)\n",
      "[4/25][695/782] Loss_D: 0.2519 (0.5049) Loss_G: 0.1140 (0.3618) D(x): 0.5976 D(G(z)): 0.5003 / 0.4572 Acc: 32.8125 (26.2740)\n",
      "[4/25][696/782] Loss_D: 0.1945 (0.5048) Loss_G: 0.1574 (0.3617) D(x): 0.5235 D(G(z)): 0.4400 / 0.4078 Acc: 31.2500 (26.2753)\n",
      "[4/25][697/782] Loss_D: 0.3046 (0.5047) Loss_G: 0.0944 (0.3617) D(x): 0.5023 D(G(z)): 0.4699 / 0.4425 Acc: 37.5000 (26.2783)\n",
      "[4/25][698/782] Loss_D: -0.0464 (0.5046) Loss_G: 0.0727 (0.3616) D(x): 0.6082 D(G(z)): 0.4476 / 0.4046 Acc: 34.3750 (26.2804)\n",
      "[4/25][699/782] Loss_D: 0.1938 (0.5045) Loss_G: 0.2766 (0.3616) D(x): 0.5215 D(G(z)): 0.4555 / 0.3744 Acc: 39.0625 (26.2837)\n",
      "[4/25][700/782] Loss_D: 0.1242 (0.5044) Loss_G: 0.2007 (0.3615) D(x): 0.5545 D(G(z)): 0.4371 / 0.3972 Acc: 35.9375 (26.2862)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[4/25][701/782] Loss_D: 0.2154 (0.5043) Loss_G: 0.0380 (0.3614) D(x): 0.5619 D(G(z)): 0.4419 / 0.4748 Acc: 23.4375 (26.2855)\n",
      "[4/25][702/782] Loss_D: 0.1510 (0.5042) Loss_G: 0.0439 (0.3613) D(x): 0.5191 D(G(z)): 0.4348 / 0.4663 Acc: 34.3750 (26.2876)\n",
      "[4/25][703/782] Loss_D: 0.2075 (0.5041) Loss_G: 0.0437 (0.3613) D(x): 0.5363 D(G(z)): 0.4479 / 0.4692 Acc: 35.9375 (26.2901)\n",
      "[4/25][704/782] Loss_D: 0.1336 (0.5041) Loss_G: 0.0563 (0.3612) D(x): 0.5741 D(G(z)): 0.4964 / 0.4381 Acc: 40.6250 (26.2939)\n",
      "[4/25][705/782] Loss_D: 0.0640 (0.5039) Loss_G: 0.1263 (0.3611) D(x): 0.5749 D(G(z)): 0.4705 / 0.4050 Acc: 35.9375 (26.2964)\n",
      "[4/25][706/782] Loss_D: 0.3581 (0.5039) Loss_G: 0.2816 (0.3611) D(x): 0.5060 D(G(z)): 0.4460 / 0.4061 Acc: 31.2500 (26.2977)\n",
      "[4/25][707/782] Loss_D: 0.0204 (0.5038) Loss_G: 0.1905 (0.3611) D(x): 0.5556 D(G(z)): 0.4469 / 0.3803 Acc: 39.0625 (26.3010)\n",
      "[4/25][708/782] Loss_D: 0.4172 (0.5038) Loss_G: 0.1275 (0.3610) D(x): 0.4824 D(G(z)): 0.4660 / 0.4586 Acc: 28.1250 (26.3015)\n",
      "[4/25][709/782] Loss_D: 0.1913 (0.5037) Loss_G: 0.0179 (0.3609) D(x): 0.5302 D(G(z)): 0.4900 / 0.4431 Acc: 31.2500 (26.3028)\n",
      "[4/25][710/782] Loss_D: 0.2361 (0.5036) Loss_G: -0.0051 (0.3608) D(x): 0.5265 D(G(z)): 0.5232 / 0.4505 Acc: 40.6250 (26.3065)\n",
      "[4/25][711/782] Loss_D: 0.1877 (0.5035) Loss_G: 0.0570 (0.3607) D(x): 0.4993 D(G(z)): 0.4616 / 0.4211 Acc: 40.6250 (26.3102)\n",
      "[4/25][712/782] Loss_D: 0.2432 (0.5035) Loss_G: 0.0784 (0.3607) D(x): 0.4915 D(G(z)): 0.4464 / 0.4517 Acc: 37.5000 (26.3131)\n",
      "[4/25][713/782] Loss_D: 0.2990 (0.5034) Loss_G: -0.0225 (0.3606) D(x): 0.5426 D(G(z)): 0.4827 / 0.4975 Acc: 28.1250 (26.3136)\n",
      "[4/25][714/782] Loss_D: 0.1179 (0.5033) Loss_G: -0.0351 (0.3605) D(x): 0.5737 D(G(z)): 0.5054 / 0.4555 Acc: 39.0625 (26.3169)\n",
      "[4/25][715/782] Loss_D: 0.3196 (0.5032) Loss_G: -0.0181 (0.3604) D(x): 0.5004 D(G(z)): 0.5019 / 0.4586 Acc: 28.1250 (26.3174)\n",
      "[4/25][716/782] Loss_D: 0.1940 (0.5032) Loss_G: -0.0714 (0.3602) D(x): 0.5518 D(G(z)): 0.5212 / 0.4578 Acc: 35.9375 (26.3199)\n",
      "[4/25][717/782] Loss_D: 0.4174 (0.5031) Loss_G: -0.0627 (0.3601) D(x): 0.4607 D(G(z)): 0.4641 / 0.4786 Acc: 21.8750 (26.3187)\n",
      "[4/25][718/782] Loss_D: 0.3403 (0.5031) Loss_G: -0.0465 (0.3600) D(x): 0.4898 D(G(z)): 0.4816 / 0.4566 Acc: 28.1250 (26.3192)\n",
      "[4/25][719/782] Loss_D: 0.4739 (0.5031) Loss_G: -0.1049 (0.3599) D(x): 0.4576 D(G(z)): 0.5149 / 0.4951 Acc: 25.0000 (26.3189)\n",
      "[4/25][720/782] Loss_D: 0.4853 (0.5031) Loss_G: -0.0483 (0.3598) D(x): 0.5160 D(G(z)): 0.5577 / 0.4760 Acc: 28.1250 (26.3193)\n",
      "[4/25][721/782] Loss_D: 0.3080 (0.5030) Loss_G: 0.0092 (0.3597) D(x): 0.4842 D(G(z)): 0.5131 / 0.4296 Acc: 35.9375 (26.3218)\n",
      "[4/25][722/782] Loss_D: 0.2568 (0.5030) Loss_G: 0.0493 (0.3596) D(x): 0.4949 D(G(z)): 0.4995 / 0.4271 Acc: 34.3750 (26.3239)\n",
      "[4/25][723/782] Loss_D: 0.4158 (0.5030) Loss_G: 0.0821 (0.3596) D(x): 0.4942 D(G(z)): 0.4792 / 0.4424 Acc: 25.0000 (26.3236)\n",
      "[4/25][724/782] Loss_D: 0.2805 (0.5029) Loss_G: -0.0143 (0.3595) D(x): 0.5136 D(G(z)): 0.5020 / 0.4600 Acc: 39.0625 (26.3269)\n",
      "[4/25][725/782] Loss_D: 0.3423 (0.5029) Loss_G: 0.0708 (0.3594) D(x): 0.4688 D(G(z)): 0.4727 / 0.4374 Acc: 34.3750 (26.3290)\n",
      "[4/25][726/782] Loss_D: 0.3512 (0.5028) Loss_G: -0.1175 (0.3593) D(x): 0.4739 D(G(z)): 0.4716 / 0.5112 Acc: 29.6875 (26.3298)\n",
      "[4/25][727/782] Loss_D: 0.1623 (0.5027) Loss_G: 0.0297 (0.3592) D(x): 0.5370 D(G(z)): 0.5146 / 0.4414 Acc: 40.6250 (26.3336)\n",
      "[4/25][728/782] Loss_D: 0.2008 (0.5026) Loss_G: 0.1618 (0.3591) D(x): 0.5187 D(G(z)): 0.4578 / 0.4080 Acc: 35.9375 (26.3360)\n",
      "[4/25][729/782] Loss_D: 0.0673 (0.5025) Loss_G: 0.1713 (0.3591) D(x): 0.5286 D(G(z)): 0.4674 / 0.3902 Acc: 51.5625 (26.3426)\n",
      "[4/25][730/782] Loss_D: 0.2388 (0.5025) Loss_G: 0.1323 (0.3590) D(x): 0.5177 D(G(z)): 0.4780 / 0.3976 Acc: 31.2500 (26.3439)\n",
      "[4/25][731/782] Loss_D: 0.1668 (0.5024) Loss_G: 0.0414 (0.3589) D(x): 0.5443 D(G(z)): 0.4360 / 0.4665 Acc: 31.2500 (26.3451)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/25][732/782] Loss_D: 0.1012 (0.5023) Loss_G: -0.0649 (0.3588) D(x): 0.6132 D(G(z)): 0.4726 / 0.4663 Acc: 21.8750 (26.3440)\n",
      "[4/25][733/782] Loss_D: 0.2109 (0.5022) Loss_G: 0.2137 (0.3588) D(x): 0.5539 D(G(z)): 0.4262 / 0.3945 Acc: 25.0000 (26.3436)\n",
      "[4/25][734/782] Loss_D: 0.0087 (0.5021) Loss_G: 0.1793 (0.3587) D(x): 0.5797 D(G(z)): 0.4010 / 0.3925 Acc: 32.8125 (26.3453)\n",
      "[4/25][735/782] Loss_D: 0.0485 (0.5020) Loss_G: 0.1003 (0.3587) D(x): 0.5298 D(G(z)): 0.4187 / 0.4085 Acc: 34.3750 (26.3474)\n",
      "[4/25][736/782] Loss_D: 0.0793 (0.5018) Loss_G: 0.1011 (0.3586) D(x): 0.5534 D(G(z)): 0.4376 / 0.4051 Acc: 31.2500 (26.3486)\n",
      "[4/25][737/782] Loss_D: 0.0927 (0.5017) Loss_G: 0.0802 (0.3585) D(x): 0.5687 D(G(z)): 0.4595 / 0.4168 Acc: 31.2500 (26.3499)\n",
      "[4/25][738/782] Loss_D: -0.0012 (0.5016) Loss_G: 0.1073 (0.3585) D(x): 0.5904 D(G(z)): 0.4527 / 0.4141 Acc: 37.5000 (26.3528)\n",
      "[4/25][739/782] Loss_D: -0.0994 (0.5015) Loss_G: 0.1025 (0.3584) D(x): 0.5666 D(G(z)): 0.4117 / 0.3836 Acc: 39.0625 (26.3561)\n",
      "[4/25][740/782] Loss_D: 0.2464 (0.5014) Loss_G: 0.1642 (0.3584) D(x): 0.5545 D(G(z)): 0.4605 / 0.4091 Acc: 21.8750 (26.3549)\n",
      "[4/25][741/782] Loss_D: 0.2895 (0.5013) Loss_G: 0.1278 (0.3583) D(x): 0.5393 D(G(z)): 0.4864 / 0.3963 Acc: 25.0000 (26.3546)\n",
      "[4/25][742/782] Loss_D: 0.2998 (0.5013) Loss_G: -0.0679 (0.3582) D(x): 0.4682 D(G(z)): 0.4568 / 0.4698 Acc: 31.2500 (26.3558)\n",
      "[4/25][743/782] Loss_D: 0.3156 (0.5012) Loss_G: -0.0184 (0.3581) D(x): 0.5662 D(G(z)): 0.5026 / 0.4665 Acc: 20.3125 (26.3543)\n",
      "[4/25][744/782] Loss_D: 0.0643 (0.5011) Loss_G: 0.0760 (0.3580) D(x): 0.5835 D(G(z)): 0.4787 / 0.4093 Acc: 32.8125 (26.3559)\n",
      "[4/25][745/782] Loss_D: 0.2741 (0.5011) Loss_G: 0.0536 (0.3579) D(x): 0.4753 D(G(z)): 0.4731 / 0.4433 Acc: 35.9375 (26.3584)\n",
      "[4/25][746/782] Loss_D: 0.2213 (0.5010) Loss_G: -0.1000 (0.3578) D(x): 0.4979 D(G(z)): 0.4602 / 0.4666 Acc: 28.1250 (26.3589)\n",
      "[4/25][747/782] Loss_D: 0.4006 (0.5010) Loss_G: -0.0045 (0.3577) D(x): 0.5012 D(G(z)): 0.4938 / 0.4625 Acc: 25.0000 (26.3585)\n",
      "[4/25][748/782] Loss_D: 0.4190 (0.5009) Loss_G: -0.0021 (0.3576) D(x): 0.5420 D(G(z)): 0.5847 / 0.4869 Acc: 39.0625 (26.3618)\n",
      "[4/25][749/782] Loss_D: 0.2248 (0.5009) Loss_G: 0.1062 (0.3576) D(x): 0.5293 D(G(z)): 0.4586 / 0.4247 Acc: 28.1250 (26.3623)\n",
      "[4/25][750/782] Loss_D: 0.3456 (0.5008) Loss_G: -0.0115 (0.3575) D(x): 0.4850 D(G(z)): 0.4611 / 0.4650 Acc: 23.4375 (26.3615)\n",
      "[4/25][751/782] Loss_D: 0.1385 (0.5007) Loss_G: -0.1731 (0.3573) D(x): 0.5257 D(G(z)): 0.4962 / 0.5100 Acc: 46.8750 (26.3668)\n",
      "[4/25][752/782] Loss_D: 0.2302 (0.5007) Loss_G: -0.0746 (0.3572) D(x): 0.5472 D(G(z)): 0.4973 / 0.4493 Acc: 26.5625 (26.3668)\n",
      "[4/25][753/782] Loss_D: 0.1823 (0.5006) Loss_G: -0.0215 (0.3571) D(x): 0.5445 D(G(z)): 0.4970 / 0.4306 Acc: 29.6875 (26.3677)\n",
      "[4/25][754/782] Loss_D: 0.1842 (0.5005) Loss_G: 0.0753 (0.3571) D(x): 0.5374 D(G(z)): 0.4555 / 0.4277 Acc: 29.6875 (26.3685)\n",
      "[4/25][755/782] Loss_D: 0.1344 (0.5004) Loss_G: 0.0180 (0.3570) D(x): 0.5090 D(G(z)): 0.4200 / 0.4474 Acc: 28.1250 (26.3690)\n",
      "[4/25][756/782] Loss_D: 0.1201 (0.5003) Loss_G: 0.0538 (0.3569) D(x): 0.5163 D(G(z)): 0.4805 / 0.4279 Acc: 42.1875 (26.3731)\n",
      "[4/25][757/782] Loss_D: 0.1204 (0.5002) Loss_G: -0.0703 (0.3568) D(x): 0.5916 D(G(z)): 0.5301 / 0.4739 Acc: 37.5000 (26.3759)\n",
      "[4/25][758/782] Loss_D: 0.1755 (0.5001) Loss_G: 0.0126 (0.3567) D(x): 0.5663 D(G(z)): 0.5046 / 0.4490 Acc: 32.8125 (26.3776)\n",
      "[4/25][759/782] Loss_D: -0.0071 (0.5000) Loss_G: 0.1976 (0.3567) D(x): 0.4980 D(G(z)): 0.3902 / 0.3731 Acc: 37.5000 (26.3804)\n",
      "[4/25][760/782] Loss_D: 0.3350 (0.5000) Loss_G: 0.0769 (0.3566) D(x): 0.5115 D(G(z)): 0.4631 / 0.4520 Acc: 21.8750 (26.3793)\n",
      "[4/25][761/782] Loss_D: 0.0680 (0.4998) Loss_G: 0.2123 (0.3565) D(x): 0.5729 D(G(z)): 0.4716 / 0.3726 Acc: 37.5000 (26.3821)\n",
      "[4/25][762/782] Loss_D: 0.3099 (0.4998) Loss_G: 0.1915 (0.3565) D(x): 0.5459 D(G(z)): 0.5001 / 0.3965 Acc: 31.2500 (26.3834)\n",
      "[4/25][763/782] Loss_D: 0.1956 (0.4997) Loss_G: 0.0882 (0.3564) D(x): 0.4654 D(G(z)): 0.3862 / 0.4393 Acc: 28.1250 (26.3838)\n",
      "[4/25][764/782] Loss_D: -0.0057 (0.4996) Loss_G: 0.0398 (0.3564) D(x): 0.5063 D(G(z)): 0.4044 / 0.4233 Acc: 40.6250 (26.3875)\n",
      "[4/25][765/782] Loss_D: 0.1826 (0.4995) Loss_G: 0.0658 (0.3563) D(x): 0.5822 D(G(z)): 0.5407 / 0.4424 Acc: 42.1875 (26.3916)\n",
      "[4/25][766/782] Loss_D: 0.1560 (0.4994) Loss_G: 0.0228 (0.3562) D(x): 0.5523 D(G(z)): 0.4854 / 0.4143 Acc: 29.6875 (26.3924)\n",
      "[4/25][767/782] Loss_D: 0.3112 (0.4994) Loss_G: -0.0745 (0.3561) D(x): 0.4699 D(G(z)): 0.4434 / 0.5084 Acc: 35.9375 (26.3949)\n",
      "[4/25][768/782] Loss_D: 0.2084 (0.4993) Loss_G: -0.0974 (0.3560) D(x): 0.5695 D(G(z)): 0.5140 / 0.4854 Acc: 29.6875 (26.3957)\n",
      "[4/25][769/782] Loss_D: 0.1503 (0.4992) Loss_G: -0.0587 (0.3559) D(x): 0.5423 D(G(z)): 0.5084 / 0.4434 Acc: 32.8125 (26.3974)\n",
      "[4/25][770/782] Loss_D: 0.3047 (0.4992) Loss_G: -0.0102 (0.3558) D(x): 0.4863 D(G(z)): 0.4433 / 0.4593 Acc: 29.6875 (26.3982)\n",
      "[4/25][771/782] Loss_D: 0.3399 (0.4991) Loss_G: 0.1196 (0.3557) D(x): 0.5263 D(G(z)): 0.5101 / 0.4185 Acc: 32.8125 (26.3998)\n",
      "[4/25][772/782] Loss_D: 0.2746 (0.4991) Loss_G: 0.0275 (0.3556) D(x): 0.4681 D(G(z)): 0.4819 / 0.4418 Acc: 37.5000 (26.4027)\n",
      "[4/25][773/782] Loss_D: 0.3394 (0.4990) Loss_G: 0.0634 (0.3555) D(x): 0.4454 D(G(z)): 0.4322 / 0.4437 Acc: 35.9375 (26.4051)\n",
      "[4/25][774/782] Loss_D: 0.2623 (0.4990) Loss_G: -0.1672 (0.3554) D(x): 0.4339 D(G(z)): 0.4305 / 0.5285 Acc: 40.6250 (26.4088)\n",
      "[4/25][775/782] Loss_D: 0.5212 (0.4990) Loss_G: -0.1176 (0.3553) D(x): 0.5423 D(G(z)): 0.5925 / 0.5141 Acc: 28.1250 (26.4092)\n",
      "[4/25][776/782] Loss_D: 0.0996 (0.4989) Loss_G: -0.0778 (0.3552) D(x): 0.5744 D(G(z)): 0.5045 / 0.4675 Acc: 35.9375 (26.4117)\n",
      "[4/25][777/782] Loss_D: 0.2215 (0.4988) Loss_G: 0.1361 (0.3551) D(x): 0.4904 D(G(z)): 0.4427 / 0.3859 Acc: 26.5625 (26.4117)\n",
      "[4/25][778/782] Loss_D: 0.2431 (0.4987) Loss_G: 0.1204 (0.3551) D(x): 0.5315 D(G(z)): 0.4758 / 0.4023 Acc: 28.1250 (26.4121)\n",
      "[4/25][779/782] Loss_D: 0.0617 (0.4986) Loss_G: -0.0756 (0.3550) D(x): 0.5079 D(G(z)): 0.4507 / 0.4718 Acc: 40.6250 (26.4158)\n",
      "[4/25][780/782] Loss_D: 0.2809 (0.4986) Loss_G: 0.0295 (0.3549) D(x): 0.5549 D(G(z)): 0.5158 / 0.4691 Acc: 28.1250 (26.4162)\n",
      "[4/25][781/782] Loss_D: 0.1308 (0.4985) Loss_G: 0.0015 (0.3548) D(x): 0.5333 D(G(z)): 0.4737 / 0.4183 Acc: 25.0000 (26.4158)\n",
      "[5/25][0/782] Loss_D: 0.1489 (0.4984) Loss_G: 0.0167 (0.3547) D(x): 0.5409 D(G(z)): 0.4888 / 0.4224 Acc: 40.6250 (26.4195)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[5/25][1/782] Loss_D: 0.0893 (0.4983) Loss_G: 0.0755 (0.3546) D(x): 0.5641 D(G(z)): 0.5265 / 0.3967 Acc: 37.5000 (26.4223)\n",
      "[5/25][2/782] Loss_D: 0.0653 (0.4982) Loss_G: 0.1595 (0.3546) D(x): 0.5038 D(G(z)): 0.4088 / 0.3963 Acc: 37.5000 (26.4251)\n",
      "[5/25][3/782] Loss_D: 0.2662 (0.4981) Loss_G: -0.1663 (0.3544) D(x): 0.4906 D(G(z)): 0.4779 / 0.5137 Acc: 31.2500 (26.4264)\n",
      "[5/25][4/782] Loss_D: 0.2415 (0.4980) Loss_G: -0.0013 (0.3543) D(x): 0.4846 D(G(z)): 0.4767 / 0.4447 Acc: 32.8125 (26.4280)\n",
      "[5/25][5/782] Loss_D: 0.0782 (0.4979) Loss_G: -0.0734 (0.3542) D(x): 0.5648 D(G(z)): 0.5106 / 0.4583 Acc: 35.9375 (26.4304)\n",
      "[5/25][6/782] Loss_D: 0.0806 (0.4978) Loss_G: 0.0098 (0.3541) D(x): 0.5666 D(G(z)): 0.4535 / 0.4222 Acc: 32.8125 (26.4321)\n",
      "[5/25][7/782] Loss_D: 0.0616 (0.4977) Loss_G: 0.0275 (0.3541) D(x): 0.5651 D(G(z)): 0.4494 / 0.4324 Acc: 31.2500 (26.4333)\n",
      "[5/25][8/782] Loss_D: 0.0991 (0.4976) Loss_G: -0.0113 (0.3540) D(x): 0.5282 D(G(z)): 0.5015 / 0.4290 Acc: 40.6250 (26.4369)\n",
      "[5/25][9/782] Loss_D: 0.0979 (0.4975) Loss_G: -0.0120 (0.3539) D(x): 0.4833 D(G(z)): 0.4065 / 0.4524 Acc: 37.5000 (26.4397)\n",
      "[5/25][10/782] Loss_D: 0.1411 (0.4974) Loss_G: -0.1183 (0.3538) D(x): 0.5268 D(G(z)): 0.4553 / 0.4888 Acc: 31.2500 (26.4410)\n",
      "[5/25][11/782] Loss_D: 0.0739 (0.4973) Loss_G: 0.0298 (0.3537) D(x): 0.6170 D(G(z)): 0.4679 / 0.4570 Acc: 31.2500 (26.4422)\n",
      "[5/25][12/782] Loss_D: 0.2545 (0.4972) Loss_G: 0.3046 (0.3537) D(x): 0.6175 D(G(z)): 0.5073 / 0.3444 Acc: 21.8750 (26.4410)\n",
      "[5/25][13/782] Loss_D: -0.1273 (0.4971) Loss_G: 0.4624 (0.3537) D(x): 0.5399 D(G(z)): 0.3349 / 0.3000 Acc: 39.0625 (26.4442)\n",
      "[5/25][14/782] Loss_D: 0.3106 (0.4970) Loss_G: -0.0472 (0.3536) D(x): 0.4525 D(G(z)): 0.4639 / 0.4777 Acc: 34.3750 (26.4463)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/25][15/782] Loss_D: 0.0020 (0.4969) Loss_G: 0.0912 (0.3535) D(x): 0.5432 D(G(z)): 0.4227 / 0.4106 Acc: 32.8125 (26.4479)\n",
      "[5/25][16/782] Loss_D: 0.1564 (0.4968) Loss_G: -0.0422 (0.3534) D(x): 0.5069 D(G(z)): 0.4697 / 0.4304 Acc: 32.8125 (26.4495)\n",
      "[5/25][17/782] Loss_D: 0.2433 (0.4968) Loss_G: -0.0094 (0.3533) D(x): 0.5221 D(G(z)): 0.5150 / 0.4454 Acc: 37.5000 (26.4523)\n",
      "[5/25][18/782] Loss_D: 0.2357 (0.4967) Loss_G: -0.0834 (0.3532) D(x): 0.4766 D(G(z)): 0.4577 / 0.5102 Acc: 37.5000 (26.4551)\n",
      "[5/25][19/782] Loss_D: 0.1787 (0.4966) Loss_G: -0.0058 (0.3531) D(x): 0.5792 D(G(z)): 0.4817 / 0.4525 Acc: 23.4375 (26.4544)\n",
      "[5/25][20/782] Loss_D: 0.2757 (0.4966) Loss_G: -0.0102 (0.3530) D(x): 0.5282 D(G(z)): 0.4765 / 0.4672 Acc: 31.2500 (26.4556)\n",
      "[5/25][21/782] Loss_D: 0.1797 (0.4965) Loss_G: -0.1648 (0.3529) D(x): 0.5214 D(G(z)): 0.4447 / 0.5009 Acc: 26.5625 (26.4556)\n",
      "[5/25][22/782] Loss_D: 0.2378 (0.4964) Loss_G: 0.0322 (0.3528) D(x): 0.5097 D(G(z)): 0.4287 / 0.4627 Acc: 29.6875 (26.4564)\n",
      "[5/25][23/782] Loss_D: 0.1004 (0.4963) Loss_G: -0.1482 (0.3527) D(x): 0.5475 D(G(z)): 0.4801 / 0.4749 Acc: 29.6875 (26.4572)\n",
      "[5/25][24/782] Loss_D: 0.2340 (0.4962) Loss_G: 0.0306 (0.3526) D(x): 0.5321 D(G(z)): 0.4592 / 0.4490 Acc: 25.0000 (26.4569)\n",
      "[5/25][25/782] Loss_D: 0.0959 (0.4961) Loss_G: -0.0577 (0.3525) D(x): 0.5568 D(G(z)): 0.4656 / 0.4698 Acc: 29.6875 (26.4577)\n",
      "[5/25][26/782] Loss_D: 0.1199 (0.4960) Loss_G: -0.0820 (0.3524) D(x): 0.5099 D(G(z)): 0.4499 / 0.4683 Acc: 31.2500 (26.4589)\n",
      "[5/25][27/782] Loss_D: 0.0212 (0.4959) Loss_G: 0.0350 (0.3523) D(x): 0.5466 D(G(z)): 0.4509 / 0.4281 Acc: 37.5000 (26.4617)\n",
      "[5/25][28/782] Loss_D: 0.2072 (0.4959) Loss_G: -0.0052 (0.3522) D(x): 0.5127 D(G(z)): 0.4609 / 0.4422 Acc: 32.8125 (26.4633)\n",
      "[5/25][29/782] Loss_D: 0.1406 (0.4958) Loss_G: 0.0901 (0.3522) D(x): 0.5606 D(G(z)): 0.4648 / 0.4044 Acc: 28.1250 (26.4638)\n",
      "[5/25][30/782] Loss_D: 0.3673 (0.4957) Loss_G: 0.0111 (0.3521) D(x): 0.4489 D(G(z)): 0.4765 / 0.4273 Acc: 28.1250 (26.4642)\n",
      "[5/25][31/782] Loss_D: 0.0658 (0.4956) Loss_G: 0.1160 (0.3520) D(x): 0.5673 D(G(z)): 0.4782 / 0.3980 Acc: 35.9375 (26.4666)\n",
      "[5/25][32/782] Loss_D: 0.0000 (0.4955) Loss_G: 0.0831 (0.3519) D(x): 0.5494 D(G(z)): 0.4190 / 0.4239 Acc: 43.7500 (26.4710)\n",
      "[5/25][33/782] Loss_D: 0.1761 (0.4954) Loss_G: -0.0646 (0.3518) D(x): 0.5174 D(G(z)): 0.4879 / 0.4428 Acc: 35.9375 (26.4734)\n",
      "[5/25][34/782] Loss_D: 0.1877 (0.4953) Loss_G: 0.0390 (0.3518) D(x): 0.5495 D(G(z)): 0.4505 / 0.4494 Acc: 25.0000 (26.4730)\n",
      "[5/25][35/782] Loss_D: 0.2362 (0.4953) Loss_G: 0.1393 (0.3517) D(x): 0.5142 D(G(z)): 0.4789 / 0.3965 Acc: 31.2500 (26.4742)\n",
      "[5/25][36/782] Loss_D: 0.3471 (0.4952) Loss_G: 0.0791 (0.3516) D(x): 0.5099 D(G(z)): 0.4895 / 0.4100 Acc: 21.8750 (26.4730)\n",
      "[5/25][37/782] Loss_D: 0.1278 (0.4951) Loss_G: 0.0059 (0.3515) D(x): 0.4729 D(G(z)): 0.4176 / 0.4338 Acc: 37.5000 (26.4758)\n",
      "[5/25][38/782] Loss_D: 0.2455 (0.4951) Loss_G: 0.1050 (0.3515) D(x): 0.5499 D(G(z)): 0.5177 / 0.4081 Acc: 29.6875 (26.4766)\n",
      "[5/25][39/782] Loss_D: 0.2115 (0.4950) Loss_G: 0.0279 (0.3514) D(x): 0.5352 D(G(z)): 0.4648 / 0.4284 Acc: 25.0000 (26.4763)\n",
      "[5/25][40/782] Loss_D: 0.2140 (0.4949) Loss_G: 0.1943 (0.3514) D(x): 0.5303 D(G(z)): 0.4492 / 0.3706 Acc: 25.0000 (26.4759)\n",
      "[5/25][41/782] Loss_D: 0.0590 (0.4948) Loss_G: 0.0883 (0.3513) D(x): 0.5372 D(G(z)): 0.4375 / 0.4240 Acc: 37.5000 (26.4787)\n",
      "[5/25][42/782] Loss_D: 0.0521 (0.4947) Loss_G: 0.1540 (0.3512) D(x): 0.5644 D(G(z)): 0.4320 / 0.4206 Acc: 39.0625 (26.4819)\n",
      "[5/25][43/782] Loss_D: -0.1513 (0.4945) Loss_G: -0.0228 (0.3512) D(x): 0.5472 D(G(z)): 0.4665 / 0.4379 Acc: 57.8125 (26.4898)\n",
      "[5/25][44/782] Loss_D: 0.1953 (0.4945) Loss_G: 0.0476 (0.3511) D(x): 0.5461 D(G(z)): 0.5028 / 0.4492 Acc: 45.3125 (26.4945)\n",
      "[5/25][45/782] Loss_D: 0.0858 (0.4944) Loss_G: 0.0657 (0.3510) D(x): 0.5768 D(G(z)): 0.4742 / 0.4022 Acc: 31.2500 (26.4958)\n",
      "[5/25][46/782] Loss_D: 0.3702 (0.4943) Loss_G: -0.0586 (0.3509) D(x): 0.4542 D(G(z)): 0.4828 / 0.4721 Acc: 28.1250 (26.4962)\n",
      "[5/25][47/782] Loss_D: 0.0338 (0.4942) Loss_G: -0.2425 (0.3508) D(x): 0.5665 D(G(z)): 0.4912 / 0.5034 Acc: 32.8125 (26.4978)\n",
      "[5/25][48/782] Loss_D: 0.2646 (0.4942) Loss_G: -0.0314 (0.3507) D(x): 0.5655 D(G(z)): 0.5481 / 0.4843 Acc: 34.3750 (26.4997)\n",
      "[5/25][49/782] Loss_D: 0.1327 (0.4941) Loss_G: -0.1462 (0.3505) D(x): 0.4736 D(G(z)): 0.4483 / 0.4793 Acc: 35.9375 (26.5021)\n",
      "[5/25][50/782] Loss_D: 0.2434 (0.4940) Loss_G: -0.1711 (0.3504) D(x): 0.5099 D(G(z)): 0.5171 / 0.4971 Acc: 35.9375 (26.5045)\n",
      "[5/25][51/782] Loss_D: 0.2048 (0.4939) Loss_G: -0.1205 (0.3503) D(x): 0.5340 D(G(z)): 0.5124 / 0.5022 Acc: 39.0625 (26.5077)\n",
      "[5/25][52/782] Loss_D: 0.2542 (0.4939) Loss_G: -0.0338 (0.3502) D(x): 0.5496 D(G(z)): 0.5142 / 0.4624 Acc: 29.6875 (26.5085)\n",
      "[5/25][53/782] Loss_D: 0.2106 (0.4938) Loss_G: 0.0419 (0.3501) D(x): 0.5143 D(G(z)): 0.4827 / 0.4337 Acc: 35.9375 (26.5109)\n",
      "[5/25][54/782] Loss_D: 0.2294 (0.4937) Loss_G: 0.0648 (0.3500) D(x): 0.5129 D(G(z)): 0.5223 / 0.4270 Acc: 46.8750 (26.5160)\n",
      "[5/25][55/782] Loss_D: 0.2057 (0.4937) Loss_G: -0.0426 (0.3499) D(x): 0.4740 D(G(z)): 0.4534 / 0.4606 Acc: 35.9375 (26.5184)\n",
      "[5/25][56/782] Loss_D: 0.1081 (0.4936) Loss_G: -0.0757 (0.3498) D(x): 0.5102 D(G(z)): 0.4345 / 0.4805 Acc: 39.0625 (26.5215)\n",
      "[5/25][57/782] Loss_D: 0.1969 (0.4935) Loss_G: -0.1155 (0.3497) D(x): 0.5804 D(G(z)): 0.4955 / 0.5177 Acc: 32.8125 (26.5231)\n",
      "[5/25][58/782] Loss_D: 0.2402 (0.4934) Loss_G: 0.1083 (0.3496) D(x): 0.5471 D(G(z)): 0.4966 / 0.4006 Acc: 25.0000 (26.5227)\n",
      "[5/25][59/782] Loss_D: 0.2652 (0.4934) Loss_G: 0.0643 (0.3496) D(x): 0.4729 D(G(z)): 0.4536 / 0.4129 Acc: 29.6875 (26.5235)\n",
      "[5/25][60/782] Loss_D: 0.3023 (0.4933) Loss_G: -0.1032 (0.3495) D(x): 0.4773 D(G(z)): 0.4750 / 0.4780 Acc: 29.6875 (26.5243)\n",
      "[5/25][61/782] Loss_D: 0.2817 (0.4933) Loss_G: -0.0700 (0.3494) D(x): 0.5439 D(G(z)): 0.5091 / 0.4823 Acc: 29.6875 (26.5251)\n",
      "[5/25][62/782] Loss_D: 0.3531 (0.4932) Loss_G: -0.1221 (0.3492) D(x): 0.4658 D(G(z)): 0.5218 / 0.4888 Acc: 34.3750 (26.5271)\n",
      "[5/25][63/782] Loss_D: 0.3888 (0.4932) Loss_G: 0.0646 (0.3492) D(x): 0.5315 D(G(z)): 0.4915 / 0.4609 Acc: 21.8750 (26.5259)\n",
      "[5/25][64/782] Loss_D: 0.3021 (0.4932) Loss_G: -0.1763 (0.3490) D(x): 0.5198 D(G(z)): 0.4835 / 0.5085 Acc: 26.5625 (26.5259)\n",
      "[5/25][65/782] Loss_D: 0.3752 (0.4931) Loss_G: 0.0853 (0.3490) D(x): 0.4540 D(G(z)): 0.5094 / 0.4255 Acc: 34.3750 (26.5279)\n",
      "[5/25][66/782] Loss_D: 0.1941 (0.4931) Loss_G: 0.0973 (0.3489) D(x): 0.5485 D(G(z)): 0.5256 / 0.3995 Acc: 35.9375 (26.5303)\n",
      "[5/25][67/782] Loss_D: 0.2506 (0.4930) Loss_G: 0.0212 (0.3488) D(x): 0.5167 D(G(z)): 0.4786 / 0.4226 Acc: 25.0000 (26.5299)\n",
      "[5/25][68/782] Loss_D: 0.3214 (0.4930) Loss_G: 0.1127 (0.3488) D(x): 0.4612 D(G(z)): 0.4250 / 0.4473 Acc: 32.8125 (26.5315)\n",
      "[5/25][69/782] Loss_D: 0.2136 (0.4929) Loss_G: -0.1292 (0.3486) D(x): 0.4716 D(G(z)): 0.4501 / 0.4867 Acc: 31.2500 (26.5327)\n",
      "[5/25][70/782] Loss_D: 0.2626 (0.4928) Loss_G: -0.1741 (0.3485) D(x): 0.5092 D(G(z)): 0.5472 / 0.5145 Acc: 40.6250 (26.5362)\n",
      "[5/25][71/782] Loss_D: 0.1934 (0.4927) Loss_G: -0.1633 (0.3484) D(x): 0.5523 D(G(z)): 0.4808 / 0.5106 Acc: 29.6875 (26.5370)\n",
      "[5/25][72/782] Loss_D: 0.2981 (0.4927) Loss_G: -0.0990 (0.3483) D(x): 0.5076 D(G(z)): 0.5256 / 0.4806 Acc: 29.6875 (26.5378)\n",
      "[5/25][73/782] Loss_D: 0.3058 (0.4927) Loss_G: -0.0142 (0.3482) D(x): 0.5062 D(G(z)): 0.4707 / 0.4772 Acc: 26.5625 (26.5378)\n",
      "[5/25][74/782] Loss_D: 0.1424 (0.4926) Loss_G: -0.0968 (0.3481) D(x): 0.5339 D(G(z)): 0.4822 / 0.4760 Acc: 29.6875 (26.5386)\n",
      "[5/25][75/782] Loss_D: 0.0605 (0.4925) Loss_G: 0.0164 (0.3480) D(x): 0.5552 D(G(z)): 0.4478 / 0.4340 Acc: 34.3750 (26.5405)\n",
      "[5/25][76/782] Loss_D: 0.3352 (0.4924) Loss_G: -0.0606 (0.3479) D(x): 0.4582 D(G(z)): 0.4557 / 0.4718 Acc: 28.1250 (26.5409)\n",
      "[5/25][77/782] Loss_D: 0.1058 (0.4923) Loss_G: -0.0796 (0.3478) D(x): 0.5337 D(G(z)): 0.4327 / 0.4529 Acc: 25.0000 (26.5406)\n",
      "[5/25][78/782] Loss_D: -0.0455 (0.4922) Loss_G: 0.0573 (0.3477) D(x): 0.5617 D(G(z)): 0.4221 / 0.4475 Acc: 45.3125 (26.5453)\n",
      "[5/25][79/782] Loss_D: 0.2339 (0.4921) Loss_G: -0.0282 (0.3476) D(x): 0.5480 D(G(z)): 0.4868 / 0.4722 Acc: 28.1250 (26.5457)\n",
      "[5/25][80/782] Loss_D: 0.2407 (0.4921) Loss_G: 0.0197 (0.3475) D(x): 0.5047 D(G(z)): 0.4546 / 0.4524 Acc: 32.8125 (26.5472)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/25][81/782] Loss_D: -0.0280 (0.4919) Loss_G: -0.1154 (0.3474) D(x): 0.5408 D(G(z)): 0.4648 / 0.4560 Acc: 37.5000 (26.5500)\n",
      "[5/25][82/782] Loss_D: 0.1841 (0.4919) Loss_G: -0.1077 (0.3473) D(x): 0.4719 D(G(z)): 0.4177 / 0.4732 Acc: 26.5625 (26.5500)\n",
      "[5/25][83/782] Loss_D: 0.1567 (0.4918) Loss_G: -0.0560 (0.3472) D(x): 0.5928 D(G(z)): 0.5343 / 0.4610 Acc: 35.9375 (26.5523)\n",
      "[5/25][84/782] Loss_D: 0.2665 (0.4917) Loss_G: -0.0355 (0.3471) D(x): 0.5106 D(G(z)): 0.5332 / 0.4599 Acc: 39.0625 (26.5555)\n",
      "[5/25][85/782] Loss_D: 0.0242 (0.4916) Loss_G: 0.0497 (0.3470) D(x): 0.5120 D(G(z)): 0.3836 / 0.4086 Acc: 26.5625 (26.5555)\n",
      "[5/25][86/782] Loss_D: -0.0063 (0.4915) Loss_G: -0.1152 (0.3469) D(x): 0.5383 D(G(z)): 0.4361 / 0.4595 Acc: 37.5000 (26.5582)\n",
      "[5/25][87/782] Loss_D: -0.0944 (0.4913) Loss_G: -0.0032 (0.3468) D(x): 0.5427 D(G(z)): 0.4362 / 0.4177 Acc: 42.1875 (26.5621)\n",
      "[5/25][88/782] Loss_D: 0.0487 (0.4912) Loss_G: 0.0697 (0.3468) D(x): 0.5498 D(G(z)): 0.4443 / 0.4210 Acc: 35.9375 (26.5645)\n",
      "[5/25][89/782] Loss_D: -0.0715 (0.4911) Loss_G: -0.0172 (0.3467) D(x): 0.5687 D(G(z)): 0.4522 / 0.4361 Acc: 40.6250 (26.5680)\n",
      "[5/25][90/782] Loss_D: 0.2656 (0.4910) Loss_G: -0.0377 (0.3466) D(x): 0.5137 D(G(z)): 0.4683 / 0.4594 Acc: 26.5625 (26.5680)\n",
      "[5/25][91/782] Loss_D: 0.2545 (0.4910) Loss_G: 0.0048 (0.3465) D(x): 0.5180 D(G(z)): 0.4817 / 0.4467 Acc: 29.6875 (26.5687)\n",
      "[5/25][92/782] Loss_D: 0.1177 (0.4909) Loss_G: -0.0950 (0.3464) D(x): 0.5401 D(G(z)): 0.4694 / 0.4753 Acc: 31.2500 (26.5699)\n",
      "[5/25][93/782] Loss_D: 0.1129 (0.4908) Loss_G: 0.0102 (0.3463) D(x): 0.5673 D(G(z)): 0.5191 / 0.4200 Acc: 37.5000 (26.5726)\n",
      "[5/25][94/782] Loss_D: 0.0537 (0.4907) Loss_G: 0.0723 (0.3462) D(x): 0.5233 D(G(z)): 0.4346 / 0.4272 Acc: 39.0625 (26.5758)\n",
      "[5/25][95/782] Loss_D: 0.0544 (0.4906) Loss_G: -0.0443 (0.3461) D(x): 0.5099 D(G(z)): 0.4290 / 0.4550 Acc: 39.0625 (26.5789)\n",
      "[5/25][96/782] Loss_D: 0.0555 (0.4904) Loss_G: 0.0620 (0.3460) D(x): 0.6412 D(G(z)): 0.5212 / 0.4357 Acc: 37.5000 (26.5816)\n",
      "[5/25][97/782] Loss_D: 0.1149 (0.4903) Loss_G: 0.1291 (0.3460) D(x): 0.4980 D(G(z)): 0.3914 / 0.4068 Acc: 39.0625 (26.5847)\n",
      "[5/25][98/782] Loss_D: 0.0515 (0.4902) Loss_G: -0.0949 (0.3459) D(x): 0.5613 D(G(z)): 0.4588 / 0.4629 Acc: 26.5625 (26.5847)\n",
      "[5/25][99/782] Loss_D: 0.1029 (0.4901) Loss_G: 0.0146 (0.3458) D(x): 0.5460 D(G(z)): 0.4662 / 0.4379 Acc: 34.3750 (26.5867)\n",
      "[5/25][100/782] Loss_D: -0.0720 (0.4900) Loss_G: 0.0381 (0.3457) D(x): 0.6069 D(G(z)): 0.4526 / 0.4286 Acc: 40.6250 (26.5902)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[5/25][101/782] Loss_D: 0.0948 (0.4899) Loss_G: 0.0089 (0.3456) D(x): 0.5144 D(G(z)): 0.4333 / 0.4290 Acc: 29.6875 (26.5909)\n",
      "[5/25][102/782] Loss_D: 0.1647 (0.4898) Loss_G: -0.0133 (0.3456) D(x): 0.4943 D(G(z)): 0.4109 / 0.4607 Acc: 28.1250 (26.5913)\n",
      "[5/25][103/782] Loss_D: 0.2568 (0.4898) Loss_G: 0.1178 (0.3455) D(x): 0.5572 D(G(z)): 0.4860 / 0.4145 Acc: 28.1250 (26.5917)\n",
      "[5/25][104/782] Loss_D: 0.3687 (0.4897) Loss_G: 0.0886 (0.3454) D(x): 0.5096 D(G(z)): 0.4988 / 0.4206 Acc: 20.3125 (26.5901)\n",
      "[5/25][105/782] Loss_D: 0.2708 (0.4897) Loss_G: -0.0154 (0.3453) D(x): 0.5003 D(G(z)): 0.4699 / 0.4657 Acc: 32.8125 (26.5917)\n",
      "[5/25][106/782] Loss_D: 0.2649 (0.4896) Loss_G: -0.0162 (0.3453) D(x): 0.4684 D(G(z)): 0.4481 / 0.4611 Acc: 34.3750 (26.5936)\n",
      "[5/25][107/782] Loss_D: 0.2853 (0.4896) Loss_G: 0.0266 (0.3452) D(x): 0.5947 D(G(z)): 0.5164 / 0.4478 Acc: 25.0000 (26.5932)\n",
      "[5/25][108/782] Loss_D: 0.1951 (0.4895) Loss_G: 0.1114 (0.3451) D(x): 0.5262 D(G(z)): 0.4580 / 0.3963 Acc: 20.3125 (26.5917)\n",
      "[5/25][109/782] Loss_D: 0.2878 (0.4894) Loss_G: 0.0563 (0.3450) D(x): 0.4993 D(G(z)): 0.4659 / 0.4337 Acc: 29.6875 (26.5924)\n",
      "[5/25][110/782] Loss_D: 0.2380 (0.4894) Loss_G: 0.1255 (0.3450) D(x): 0.5262 D(G(z)): 0.4808 / 0.4199 Acc: 28.1250 (26.5928)\n",
      "[5/25][111/782] Loss_D: 0.1917 (0.4893) Loss_G: -0.0617 (0.3449) D(x): 0.4634 D(G(z)): 0.4527 / 0.4619 Acc: 37.5000 (26.5955)\n",
      "[5/25][112/782] Loss_D: 0.1346 (0.4892) Loss_G: 0.0984 (0.3448) D(x): 0.5596 D(G(z)): 0.4833 / 0.4199 Acc: 35.9375 (26.5978)\n",
      "[5/25][113/782] Loss_D: 0.1213 (0.4891) Loss_G: 0.0179 (0.3447) D(x): 0.5939 D(G(z)): 0.5025 / 0.4478 Acc: 32.8125 (26.5994)\n",
      "[5/25][114/782] Loss_D: 0.1510 (0.4890) Loss_G: 0.1455 (0.3447) D(x): 0.5922 D(G(z)): 0.5146 / 0.3861 Acc: 35.9375 (26.6017)\n",
      "[5/25][115/782] Loss_D: 0.1447 (0.4890) Loss_G: 0.2454 (0.3447) D(x): 0.5101 D(G(z)): 0.4497 / 0.3662 Acc: 39.0625 (26.6048)\n",
      "[5/25][116/782] Loss_D: 0.1665 (0.4889) Loss_G: 0.0230 (0.3446) D(x): 0.4464 D(G(z)): 0.3781 / 0.4485 Acc: 35.9375 (26.6071)\n",
      "[5/25][117/782] Loss_D: 0.3017 (0.4888) Loss_G: -0.1112 (0.3445) D(x): 0.5083 D(G(z)): 0.4834 / 0.5001 Acc: 31.2500 (26.6083)\n",
      "[5/25][118/782] Loss_D: 0.2931 (0.4888) Loss_G: 0.1464 (0.3444) D(x): 0.5956 D(G(z)): 0.5378 / 0.4097 Acc: 26.5625 (26.6083)\n",
      "[5/25][119/782] Loss_D: -0.0021 (0.4887) Loss_G: 0.1624 (0.3444) D(x): 0.5588 D(G(z)): 0.4508 / 0.3970 Acc: 43.7500 (26.6125)\n",
      "[5/25][120/782] Loss_D: 0.3687 (0.4886) Loss_G: -0.1272 (0.3443) D(x): 0.4513 D(G(z)): 0.4956 / 0.5060 Acc: 32.8125 (26.6141)\n",
      "[5/25][121/782] Loss_D: 0.3473 (0.4886) Loss_G: -0.0182 (0.3442) D(x): 0.5013 D(G(z)): 0.4739 / 0.4493 Acc: 21.8750 (26.6129)\n",
      "[5/25][122/782] Loss_D: 0.2559 (0.4885) Loss_G: -0.0649 (0.3441) D(x): 0.5263 D(G(z)): 0.5145 / 0.4723 Acc: 34.3750 (26.6148)\n",
      "[5/25][123/782] Loss_D: 0.0669 (0.4884) Loss_G: -0.0350 (0.3440) D(x): 0.5185 D(G(z)): 0.4525 / 0.4435 Acc: 40.6250 (26.6183)\n",
      "[5/25][124/782] Loss_D: 0.1256 (0.4883) Loss_G: 0.1508 (0.3439) D(x): 0.6039 D(G(z)): 0.4634 / 0.3903 Acc: 23.4375 (26.6175)\n",
      "[5/25][125/782] Loss_D: 0.2270 (0.4883) Loss_G: -0.0372 (0.3438) D(x): 0.5435 D(G(z)): 0.4968 / 0.4490 Acc: 35.9375 (26.6198)\n",
      "[5/25][126/782] Loss_D: 0.2705 (0.4882) Loss_G: -0.0271 (0.3437) D(x): 0.5361 D(G(z)): 0.5116 / 0.4775 Acc: 37.5000 (26.6225)\n",
      "[5/25][127/782] Loss_D: 0.2275 (0.4882) Loss_G: -0.0660 (0.3436) D(x): 0.4958 D(G(z)): 0.4715 / 0.5030 Acc: 39.0625 (26.6256)\n",
      "[5/25][128/782] Loss_D: 0.2370 (0.4881) Loss_G: -0.0145 (0.3436) D(x): 0.5632 D(G(z)): 0.5225 / 0.4553 Acc: 29.6875 (26.6263)\n",
      "[5/25][129/782] Loss_D: 0.2631 (0.4880) Loss_G: 0.0965 (0.3435) D(x): 0.5192 D(G(z)): 0.4834 / 0.4287 Acc: 37.5000 (26.6290)\n",
      "[5/25][130/782] Loss_D: 0.0092 (0.4879) Loss_G: -0.0055 (0.3434) D(x): 0.5255 D(G(z)): 0.4508 / 0.4469 Acc: 43.7500 (26.6333)\n",
      "[5/25][131/782] Loss_D: 0.2881 (0.4879) Loss_G: 0.0896 (0.3433) D(x): 0.5114 D(G(z)): 0.5068 / 0.4277 Acc: 39.0625 (26.6363)\n",
      "[5/25][132/782] Loss_D: 0.2147 (0.4878) Loss_G: 0.0693 (0.3433) D(x): 0.4896 D(G(z)): 0.4693 / 0.4303 Acc: 40.6250 (26.6398)\n",
      "[5/25][133/782] Loss_D: 0.4199 (0.4878) Loss_G: -0.0792 (0.3432) D(x): 0.4763 D(G(z)): 0.4932 / 0.5142 Acc: 28.1250 (26.6402)\n",
      "[5/25][134/782] Loss_D: 0.1030 (0.4877) Loss_G: -0.0048 (0.3431) D(x): 0.6002 D(G(z)): 0.5543 / 0.4359 Acc: 37.5000 (26.6428)\n",
      "[5/25][135/782] Loss_D: 0.4284 (0.4877) Loss_G: 0.1749 (0.3430) D(x): 0.5012 D(G(z)): 0.5040 / 0.4064 Acc: 23.4375 (26.6421)\n",
      "[5/25][136/782] Loss_D: 0.1003 (0.4876) Loss_G: 0.0393 (0.3430) D(x): 0.5169 D(G(z)): 0.4388 / 0.4387 Acc: 39.0625 (26.6451)\n",
      "[5/25][137/782] Loss_D: 0.1947 (0.4875) Loss_G: 0.0979 (0.3429) D(x): 0.4990 D(G(z)): 0.4129 / 0.4229 Acc: 31.2500 (26.6463)\n",
      "[5/25][138/782] Loss_D: 0.5458 (0.4875) Loss_G: -0.0508 (0.3428) D(x): 0.4313 D(G(z)): 0.4684 / 0.4934 Acc: 28.1250 (26.6466)\n",
      "[5/25][139/782] Loss_D: 0.1395 (0.4874) Loss_G: -0.0119 (0.3427) D(x): 0.5766 D(G(z)): 0.4718 / 0.4509 Acc: 25.0000 (26.6462)\n",
      "[5/25][140/782] Loss_D: 0.1470 (0.4874) Loss_G: 0.1459 (0.3427) D(x): 0.5945 D(G(z)): 0.5165 / 0.3746 Acc: 32.8125 (26.6477)\n",
      "[5/25][141/782] Loss_D: 0.2385 (0.4873) Loss_G: 0.1100 (0.3426) D(x): 0.4750 D(G(z)): 0.4520 / 0.4209 Acc: 34.3750 (26.6496)\n",
      "[5/25][142/782] Loss_D: 0.1469 (0.4872) Loss_G: -0.0877 (0.3425) D(x): 0.5018 D(G(z)): 0.4652 / 0.4571 Acc: 32.8125 (26.6512)\n",
      "[5/25][143/782] Loss_D: 0.1243 (0.4871) Loss_G: 0.0428 (0.3424) D(x): 0.5380 D(G(z)): 0.4662 / 0.4343 Acc: 34.3750 (26.6531)\n",
      "[5/25][144/782] Loss_D: 0.1801 (0.4871) Loss_G: -0.0142 (0.3424) D(x): 0.5285 D(G(z)): 0.4743 / 0.4458 Acc: 34.3750 (26.6550)\n",
      "[5/25][145/782] Loss_D: 0.2418 (0.4870) Loss_G: -0.0415 (0.3423) D(x): 0.4612 D(G(z)): 0.4341 / 0.4586 Acc: 31.2500 (26.6561)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/25][146/782] Loss_D: 0.2765 (0.4869) Loss_G: -0.1859 (0.3421) D(x): 0.4926 D(G(z)): 0.5200 / 0.5078 Acc: 40.6250 (26.6596)\n",
      "[5/25][147/782] Loss_D: 0.1932 (0.4869) Loss_G: -0.0782 (0.3420) D(x): 0.5366 D(G(z)): 0.5415 / 0.4516 Acc: 39.0625 (26.6626)\n",
      "[5/25][148/782] Loss_D: 0.2278 (0.4868) Loss_G: 0.1140 (0.3420) D(x): 0.5489 D(G(z)): 0.5262 / 0.4086 Acc: 35.9375 (26.6649)\n",
      "[5/25][149/782] Loss_D: 0.1302 (0.4867) Loss_G: 0.0018 (0.3419) D(x): 0.4918 D(G(z)): 0.3939 / 0.4208 Acc: 23.4375 (26.6641)\n",
      "[5/25][150/782] Loss_D: 0.1465 (0.4866) Loss_G: -0.0980 (0.3418) D(x): 0.5524 D(G(z)): 0.4925 / 0.4753 Acc: 31.2500 (26.6652)\n",
      "[5/25][151/782] Loss_D: 0.0852 (0.4865) Loss_G: 0.0283 (0.3417) D(x): 0.5591 D(G(z)): 0.4862 / 0.4118 Acc: 35.9375 (26.6675)\n",
      "[5/25][152/782] Loss_D: 0.2947 (0.4865) Loss_G: -0.0004 (0.3416) D(x): 0.4686 D(G(z)): 0.5027 / 0.4280 Acc: 40.6250 (26.6709)\n",
      "[5/25][153/782] Loss_D: 0.3808 (0.4865) Loss_G: 0.1655 (0.3416) D(x): 0.4988 D(G(z)): 0.4812 / 0.4245 Acc: 34.3750 (26.6728)\n",
      "[5/25][154/782] Loss_D: 0.2305 (0.4864) Loss_G: 0.0397 (0.3415) D(x): 0.5349 D(G(z)): 0.4700 / 0.4313 Acc: 29.6875 (26.6736)\n",
      "[5/25][155/782] Loss_D: 0.2149 (0.4863) Loss_G: -0.0116 (0.3414) D(x): 0.4890 D(G(z)): 0.4606 / 0.4485 Acc: 31.2500 (26.6747)\n",
      "[5/25][156/782] Loss_D: 0.3669 (0.4863) Loss_G: -0.0459 (0.3413) D(x): 0.4909 D(G(z)): 0.4950 / 0.4533 Acc: 21.8750 (26.6735)\n",
      "[5/25][157/782] Loss_D: 0.1489 (0.4862) Loss_G: 0.0427 (0.3412) D(x): 0.5429 D(G(z)): 0.4925 / 0.4626 Acc: 46.8750 (26.6785)\n",
      "[5/25][158/782] Loss_D: 0.1545 (0.4861) Loss_G: 0.0454 (0.3412) D(x): 0.5208 D(G(z)): 0.4635 / 0.4208 Acc: 31.2500 (26.6796)\n",
      "[5/25][159/782] Loss_D: 0.1447 (0.4861) Loss_G: -0.0505 (0.3411) D(x): 0.5261 D(G(z)): 0.4823 / 0.4643 Acc: 39.0625 (26.6827)\n",
      "[5/25][160/782] Loss_D: 0.0980 (0.4860) Loss_G: 0.0659 (0.3410) D(x): 0.5378 D(G(z)): 0.4331 / 0.4105 Acc: 31.2500 (26.6838)\n",
      "[5/25][161/782] Loss_D: 0.1643 (0.4859) Loss_G: -0.0089 (0.3409) D(x): 0.5201 D(G(z)): 0.4771 / 0.4531 Acc: 34.3750 (26.6857)\n",
      "[5/25][162/782] Loss_D: 0.2088 (0.4858) Loss_G: -0.1204 (0.3408) D(x): 0.5446 D(G(z)): 0.4846 / 0.4830 Acc: 26.5625 (26.6856)\n",
      "[5/25][163/782] Loss_D: 0.2827 (0.4858) Loss_G: -0.0051 (0.3407) D(x): 0.4864 D(G(z)): 0.4430 / 0.4567 Acc: 29.6875 (26.6864)\n",
      "[5/25][164/782] Loss_D: -0.0548 (0.4856) Loss_G: 0.0944 (0.3407) D(x): 0.6114 D(G(z)): 0.4687 / 0.4092 Acc: 37.5000 (26.6890)\n",
      "[5/25][165/782] Loss_D: 0.2954 (0.4856) Loss_G: 0.1788 (0.3406) D(x): 0.5032 D(G(z)): 0.4949 / 0.3869 Acc: 31.2500 (26.6902)\n",
      "[5/25][166/782] Loss_D: 0.1370 (0.4855) Loss_G: 0.0602 (0.3405) D(x): 0.5371 D(G(z)): 0.4413 / 0.4192 Acc: 23.4375 (26.6894)\n",
      "[5/25][167/782] Loss_D: 0.0271 (0.4854) Loss_G: -0.0783 (0.3404) D(x): 0.5188 D(G(z)): 0.4190 / 0.4641 Acc: 37.5000 (26.6920)\n",
      "[5/25][168/782] Loss_D: 0.0061 (0.4853) Loss_G: 0.0765 (0.3404) D(x): 0.5310 D(G(z)): 0.4256 / 0.3957 Acc: 32.8125 (26.6935)\n",
      "[5/25][169/782] Loss_D: 0.1728 (0.4852) Loss_G: -0.0927 (0.3403) D(x): 0.4928 D(G(z)): 0.4203 / 0.4858 Acc: 25.0000 (26.6931)\n",
      "[5/25][170/782] Loss_D: 0.1424 (0.4851) Loss_G: -0.0484 (0.3402) D(x): 0.5732 D(G(z)): 0.5207 / 0.4662 Acc: 35.9375 (26.6954)\n",
      "[5/25][171/782] Loss_D: 0.1707 (0.4850) Loss_G: -0.1024 (0.3401) D(x): 0.5157 D(G(z)): 0.4666 / 0.4775 Acc: 29.6875 (26.6961)\n",
      "[5/25][172/782] Loss_D: 0.1200 (0.4849) Loss_G: 0.0106 (0.3400) D(x): 0.5402 D(G(z)): 0.4662 / 0.4525 Acc: 32.8125 (26.6976)\n",
      "[5/25][173/782] Loss_D: 0.2081 (0.4849) Loss_G: 0.1007 (0.3399) D(x): 0.5630 D(G(z)): 0.5053 / 0.4151 Acc: 37.5000 (26.7002)\n",
      "[5/25][174/782] Loss_D: 0.3220 (0.4848) Loss_G: 0.1073 (0.3399) D(x): 0.4888 D(G(z)): 0.4808 / 0.4196 Acc: 32.8125 (26.7017)\n",
      "[5/25][175/782] Loss_D: 0.0168 (0.4847) Loss_G: 0.0474 (0.3398) D(x): 0.5049 D(G(z)): 0.4076 / 0.4304 Acc: 40.6250 (26.7051)\n",
      "[5/25][176/782] Loss_D: 0.1613 (0.4846) Loss_G: -0.1436 (0.3397) D(x): 0.5055 D(G(z)): 0.4980 / 0.4803 Acc: 37.5000 (26.7078)\n",
      "[5/25][177/782] Loss_D: 0.2707 (0.4846) Loss_G: -0.0144 (0.3396) D(x): 0.4888 D(G(z)): 0.4604 / 0.4463 Acc: 28.1250 (26.7081)\n",
      "[5/25][178/782] Loss_D: 0.2204 (0.4845) Loss_G: -0.0018 (0.3395) D(x): 0.5407 D(G(z)): 0.5175 / 0.4604 Acc: 37.5000 (26.7108)\n",
      "[5/25][179/782] Loss_D: 0.2198 (0.4845) Loss_G: 0.0444 (0.3394) D(x): 0.5548 D(G(z)): 0.5074 / 0.4286 Acc: 34.3750 (26.7126)\n",
      "[5/25][180/782] Loss_D: 0.0086 (0.4843) Loss_G: 0.0146 (0.3394) D(x): 0.5184 D(G(z)): 0.4240 / 0.4412 Acc: 37.5000 (26.7153)\n",
      "[5/25][181/782] Loss_D: 0.2898 (0.4843) Loss_G: -0.0916 (0.3393) D(x): 0.4680 D(G(z)): 0.4422 / 0.4733 Acc: 25.0000 (26.7149)\n",
      "[5/25][182/782] Loss_D: 0.3054 (0.4842) Loss_G: -0.0530 (0.3392) D(x): 0.5330 D(G(z)): 0.5416 / 0.4605 Acc: 29.6875 (26.7156)\n",
      "[5/25][183/782] Loss_D: 0.0009 (0.4841) Loss_G: 0.0391 (0.3391) D(x): 0.5382 D(G(z)): 0.4929 / 0.4211 Acc: 46.8750 (26.7205)\n",
      "[5/25][184/782] Loss_D: 0.1813 (0.4841) Loss_G: 0.0164 (0.3390) D(x): 0.5298 D(G(z)): 0.4834 / 0.4595 Acc: 35.9375 (26.7228)\n",
      "[5/25][185/782] Loss_D: 0.1363 (0.4840) Loss_G: -0.0138 (0.3389) D(x): 0.5063 D(G(z)): 0.4536 / 0.4327 Acc: 37.5000 (26.7254)\n",
      "[5/25][186/782] Loss_D: 0.1413 (0.4839) Loss_G: -0.0877 (0.3388) D(x): 0.5596 D(G(z)): 0.4380 / 0.4839 Acc: 29.6875 (26.7261)\n",
      "[5/25][187/782] Loss_D: 0.2298 (0.4838) Loss_G: -0.0684 (0.3387) D(x): 0.5553 D(G(z)): 0.4767 / 0.4658 Acc: 20.3125 (26.7245)\n",
      "[5/25][188/782] Loss_D: -0.0117 (0.4837) Loss_G: 0.0588 (0.3387) D(x): 0.5604 D(G(z)): 0.4230 / 0.4052 Acc: 39.0625 (26.7276)\n",
      "[5/25][189/782] Loss_D: 0.2273 (0.4836) Loss_G: -0.1303 (0.3385) D(x): 0.4751 D(G(z)): 0.4610 / 0.4812 Acc: 35.9375 (26.7298)\n",
      "[5/25][190/782] Loss_D: 0.1145 (0.4836) Loss_G: -0.1103 (0.3384) D(x): 0.5506 D(G(z)): 0.4883 / 0.4905 Acc: 35.9375 (26.7320)\n",
      "[5/25][191/782] Loss_D: 0.2164 (0.4835) Loss_G: -0.0687 (0.3383) D(x): 0.4881 D(G(z)): 0.4468 / 0.4770 Acc: 29.6875 (26.7328)\n",
      "[5/25][192/782] Loss_D: 0.2588 (0.4834) Loss_G: -0.0923 (0.3382) D(x): 0.5080 D(G(z)): 0.4996 / 0.4965 Acc: 35.9375 (26.7350)\n",
      "[5/25][193/782] Loss_D: 0.2298 (0.4834) Loss_G: -0.1153 (0.3381) D(x): 0.5792 D(G(z)): 0.5524 / 0.4792 Acc: 34.3750 (26.7369)\n",
      "[5/25][194/782] Loss_D: 0.2915 (0.4833) Loss_G: 0.1096 (0.3381) D(x): 0.5359 D(G(z)): 0.4669 / 0.4287 Acc: 28.1250 (26.7372)\n",
      "[5/25][195/782] Loss_D: 0.0755 (0.4832) Loss_G: 0.1122 (0.3380) D(x): 0.5407 D(G(z)): 0.5011 / 0.3754 Acc: 37.5000 (26.7398)\n",
      "[5/25][196/782] Loss_D: 0.3143 (0.4832) Loss_G: 0.0739 (0.3379) D(x): 0.4583 D(G(z)): 0.4245 / 0.4331 Acc: 23.4375 (26.7390)\n",
      "[5/25][197/782] Loss_D: 0.2337 (0.4831) Loss_G: -0.1911 (0.3378) D(x): 0.4465 D(G(z)): 0.4279 / 0.5280 Acc: 32.8125 (26.7405)\n",
      "[5/25][198/782] Loss_D: 0.0817 (0.4830) Loss_G: -0.1827 (0.3377) D(x): 0.5651 D(G(z)): 0.4796 / 0.5141 Acc: 35.9375 (26.7427)\n",
      "[5/25][199/782] Loss_D: 0.2165 (0.4830) Loss_G: -0.1604 (0.3376) D(x): 0.5892 D(G(z)): 0.5523 / 0.4977 Acc: 26.5625 (26.7427)\n",
      "[5/25][200/782] Loss_D: -0.0397 (0.4828) Loss_G: -0.0047 (0.3375) D(x): 0.5821 D(G(z)): 0.4638 / 0.4261 Acc: 35.9375 (26.7449)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[5/25][201/782] Loss_D: 0.0936 (0.4827) Loss_G: 0.1474 (0.3374) D(x): 0.5167 D(G(z)): 0.4550 / 0.3949 Acc: 42.1875 (26.7487)\n",
      "[5/25][202/782] Loss_D: 0.1076 (0.4826) Loss_G: -0.0454 (0.3373) D(x): 0.4997 D(G(z)): 0.4022 / 0.4401 Acc: 26.5625 (26.7486)\n",
      "[5/25][203/782] Loss_D: 0.2849 (0.4826) Loss_G: -0.1437 (0.3372) D(x): 0.5002 D(G(z)): 0.4941 / 0.4741 Acc: 21.8750 (26.7475)\n",
      "[5/25][204/782] Loss_D: 0.2263 (0.4825) Loss_G: -0.1699 (0.3371) D(x): 0.5349 D(G(z)): 0.4824 / 0.5169 Acc: 25.0000 (26.7470)\n",
      "[5/25][205/782] Loss_D: 0.1596 (0.4825) Loss_G: 0.0383 (0.3370) D(x): 0.5540 D(G(z)): 0.4759 / 0.4343 Acc: 31.2500 (26.7481)\n",
      "[5/25][206/782] Loss_D: 0.2237 (0.4824) Loss_G: -0.0283 (0.3369) D(x): 0.5220 D(G(z)): 0.4701 / 0.4821 Acc: 29.6875 (26.7488)\n",
      "[5/25][207/782] Loss_D: 0.3154 (0.4824) Loss_G: 0.0046 (0.3369) D(x): 0.4303 D(G(z)): 0.4518 / 0.4454 Acc: 42.1875 (26.7526)\n",
      "[5/25][208/782] Loss_D: 0.0748 (0.4823) Loss_G: -0.0759 (0.3368) D(x): 0.5447 D(G(z)): 0.4434 / 0.4716 Acc: 32.8125 (26.7541)\n",
      "[5/25][209/782] Loss_D: -0.0331 (0.4821) Loss_G: -0.0224 (0.3367) D(x): 0.6188 D(G(z)): 0.5083 / 0.4187 Acc: 31.2500 (26.7552)\n",
      "[5/25][210/782] Loss_D: 0.0631 (0.4820) Loss_G: -0.0022 (0.3366) D(x): 0.5229 D(G(z)): 0.4015 / 0.4348 Acc: 29.6875 (26.7559)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/25][211/782] Loss_D: 0.1308 (0.4819) Loss_G: -0.0292 (0.3365) D(x): 0.5432 D(G(z)): 0.4300 / 0.4753 Acc: 31.2500 (26.7570)\n",
      "[5/25][212/782] Loss_D: 0.0393 (0.4818) Loss_G: -0.0775 (0.3364) D(x): 0.6032 D(G(z)): 0.4686 / 0.4755 Acc: 29.6875 (26.7577)\n",
      "[5/25][213/782] Loss_D: 0.1155 (0.4817) Loss_G: 0.0011 (0.3363) D(x): 0.5282 D(G(z)): 0.4644 / 0.4522 Acc: 37.5000 (26.7603)\n",
      "[5/25][214/782] Loss_D: 0.1461 (0.4817) Loss_G: -0.0024 (0.3362) D(x): 0.5269 D(G(z)): 0.4624 / 0.4526 Acc: 34.3750 (26.7621)\n",
      "[5/25][215/782] Loss_D: 0.0012 (0.4816) Loss_G: -0.1120 (0.3361) D(x): 0.5256 D(G(z)): 0.4332 / 0.4689 Acc: 37.5000 (26.7647)\n",
      "[5/25][216/782] Loss_D: -0.0354 (0.4814) Loss_G: -0.0249 (0.3360) D(x): 0.5909 D(G(z)): 0.4910 / 0.4414 Acc: 35.9375 (26.7669)\n",
      "[5/25][217/782] Loss_D: 0.1279 (0.4813) Loss_G: 0.0290 (0.3360) D(x): 0.5405 D(G(z)): 0.4349 / 0.4532 Acc: 28.1250 (26.7673)\n",
      "[5/25][218/782] Loss_D: 0.2280 (0.4813) Loss_G: -0.1224 (0.3359) D(x): 0.4951 D(G(z)): 0.4831 / 0.4892 Acc: 31.2500 (26.7684)\n",
      "[5/25][219/782] Loss_D: 0.0425 (0.4812) Loss_G: -0.0002 (0.3358) D(x): 0.5676 D(G(z)): 0.4472 / 0.4324 Acc: 31.2500 (26.7694)\n",
      "[5/25][220/782] Loss_D: 0.3041 (0.4811) Loss_G: 0.0719 (0.3357) D(x): 0.5319 D(G(z)): 0.5140 / 0.4112 Acc: 25.0000 (26.7690)\n",
      "[5/25][221/782] Loss_D: 0.0518 (0.4810) Loss_G: -0.0361 (0.3356) D(x): 0.5539 D(G(z)): 0.4257 / 0.4537 Acc: 34.3750 (26.7709)\n",
      "[5/25][222/782] Loss_D: 0.1461 (0.4809) Loss_G: -0.0876 (0.3355) D(x): 0.5124 D(G(z)): 0.4545 / 0.4734 Acc: 29.6875 (26.7716)\n",
      "[5/25][223/782] Loss_D: 0.1325 (0.4809) Loss_G: -0.0849 (0.3354) D(x): 0.5379 D(G(z)): 0.4821 / 0.4757 Acc: 37.5000 (26.7742)\n",
      "[5/25][224/782] Loss_D: 0.1164 (0.4808) Loss_G: -0.0127 (0.3353) D(x): 0.5379 D(G(z)): 0.4762 / 0.4525 Acc: 35.9375 (26.7764)\n",
      "[5/25][225/782] Loss_D: 0.0987 (0.4807) Loss_G: 0.2035 (0.3353) D(x): 0.5108 D(G(z)): 0.4248 / 0.3875 Acc: 35.9375 (26.7786)\n",
      "[5/25][226/782] Loss_D: -0.0159 (0.4806) Loss_G: 0.0023 (0.3352) D(x): 0.5583 D(G(z)): 0.4452 / 0.4248 Acc: 32.8125 (26.7800)\n",
      "[5/25][227/782] Loss_D: 0.3183 (0.4805) Loss_G: 0.0175 (0.3351) D(x): 0.5319 D(G(z)): 0.4898 / 0.4562 Acc: 28.1250 (26.7804)\n",
      "[5/25][228/782] Loss_D: -0.0248 (0.4804) Loss_G: 0.1368 (0.3351) D(x): 0.5583 D(G(z)): 0.4183 / 0.4130 Acc: 39.0625 (26.7833)\n",
      "[5/25][229/782] Loss_D: 0.0556 (0.4803) Loss_G: 0.0271 (0.3350) D(x): 0.5247 D(G(z)): 0.4517 / 0.4233 Acc: 37.5000 (26.7859)\n",
      "[5/25][230/782] Loss_D: 0.0441 (0.4802) Loss_G: -0.0630 (0.3349) D(x): 0.5333 D(G(z)): 0.4897 / 0.4540 Acc: 42.1875 (26.7896)\n",
      "[5/25][231/782] Loss_D: 0.2937 (0.4801) Loss_G: -0.0622 (0.3348) D(x): 0.5253 D(G(z)): 0.4921 / 0.4603 Acc: 23.4375 (26.7888)\n",
      "[5/25][232/782] Loss_D: 0.2132 (0.4801) Loss_G: -0.0645 (0.3347) D(x): 0.5219 D(G(z)): 0.4744 / 0.4679 Acc: 32.8125 (26.7903)\n",
      "[5/25][233/782] Loss_D: -0.0717 (0.4799) Loss_G: -0.1129 (0.3346) D(x): 0.5349 D(G(z)): 0.4054 / 0.4825 Acc: 42.1875 (26.7940)\n",
      "[5/25][234/782] Loss_D: 0.1240 (0.4799) Loss_G: -0.1807 (0.3345) D(x): 0.5579 D(G(z)): 0.5084 / 0.5213 Acc: 35.9375 (26.7962)\n",
      "[5/25][235/782] Loss_D: 0.3453 (0.4798) Loss_G: 0.0242 (0.3344) D(x): 0.4957 D(G(z)): 0.5081 / 0.4264 Acc: 29.6875 (26.7969)\n",
      "[5/25][236/782] Loss_D: 0.0567 (0.4797) Loss_G: -0.0448 (0.3343) D(x): 0.5611 D(G(z)): 0.4950 / 0.4608 Acc: 42.1875 (26.8006)\n",
      "[5/25][237/782] Loss_D: 0.1973 (0.4797) Loss_G: 0.0816 (0.3343) D(x): 0.5589 D(G(z)): 0.4818 / 0.4167 Acc: 34.3750 (26.8024)\n",
      "[5/25][238/782] Loss_D: 0.3861 (0.4796) Loss_G: 0.0689 (0.3342) D(x): 0.4392 D(G(z)): 0.4461 / 0.4133 Acc: 25.0000 (26.8020)\n",
      "[5/25][239/782] Loss_D: 0.2200 (0.4796) Loss_G: -0.0724 (0.3341) D(x): 0.5057 D(G(z)): 0.4936 / 0.4653 Acc: 32.8125 (26.8035)\n",
      "[5/25][240/782] Loss_D: 0.2588 (0.4795) Loss_G: -0.0137 (0.3340) D(x): 0.5013 D(G(z)): 0.4491 / 0.4615 Acc: 29.6875 (26.8042)\n",
      "[5/25][241/782] Loss_D: 0.0100 (0.4794) Loss_G: -0.1478 (0.3339) D(x): 0.5466 D(G(z)): 0.4466 / 0.5017 Acc: 34.3750 (26.8060)\n",
      "[5/25][242/782] Loss_D: 0.1757 (0.4793) Loss_G: 0.0346 (0.3338) D(x): 0.5198 D(G(z)): 0.4565 / 0.4556 Acc: 37.5000 (26.8086)\n",
      "[5/25][243/782] Loss_D: 0.1056 (0.4792) Loss_G: -0.1273 (0.3337) D(x): 0.5812 D(G(z)): 0.4848 / 0.4820 Acc: 31.2500 (26.8096)\n",
      "[5/25][244/782] Loss_D: 0.1937 (0.4792) Loss_G: 0.0479 (0.3337) D(x): 0.5846 D(G(z)): 0.5021 / 0.4172 Acc: 23.4375 (26.8088)\n",
      "[5/25][245/782] Loss_D: -0.0333 (0.4791) Loss_G: -0.0320 (0.3336) D(x): 0.5248 D(G(z)): 0.4545 / 0.4342 Acc: 43.7500 (26.8129)\n",
      "[5/25][246/782] Loss_D: 0.1609 (0.4790) Loss_G: 0.1626 (0.3335) D(x): 0.5184 D(G(z)): 0.4528 / 0.3713 Acc: 28.1250 (26.8132)\n",
      "[5/25][247/782] Loss_D: 0.1749 (0.4789) Loss_G: -0.0191 (0.3334) D(x): 0.4803 D(G(z)): 0.4629 / 0.4381 Acc: 37.5000 (26.8158)\n",
      "[5/25][248/782] Loss_D: 0.2004 (0.4788) Loss_G: -0.1756 (0.3333) D(x): 0.4780 D(G(z)): 0.4688 / 0.5062 Acc: 37.5000 (26.8183)\n",
      "[5/25][249/782] Loss_D: 0.1593 (0.4788) Loss_G: 0.0005 (0.3332) D(x): 0.5551 D(G(z)): 0.5116 / 0.4272 Acc: 29.6875 (26.8190)\n",
      "[5/25][250/782] Loss_D: 0.2122 (0.4787) Loss_G: 0.0590 (0.3332) D(x): 0.5317 D(G(z)): 0.5067 / 0.4399 Acc: 37.5000 (26.8216)\n",
      "[5/25][251/782] Loss_D: 0.1045 (0.4786) Loss_G: -0.0927 (0.3331) D(x): 0.5083 D(G(z)): 0.4487 / 0.4671 Acc: 42.1875 (26.8253)\n",
      "[5/25][252/782] Loss_D: 0.0629 (0.4785) Loss_G: 0.0740 (0.3330) D(x): 0.5441 D(G(z)): 0.4276 / 0.4113 Acc: 23.4375 (26.8245)\n",
      "[5/25][253/782] Loss_D: 0.2028 (0.4784) Loss_G: 0.0819 (0.3330) D(x): 0.5143 D(G(z)): 0.4594 / 0.4233 Acc: 34.3750 (26.8263)\n",
      "[5/25][254/782] Loss_D: 0.1248 (0.4784) Loss_G: -0.0157 (0.3329) D(x): 0.5436 D(G(z)): 0.4702 / 0.4444 Acc: 35.9375 (26.8285)\n",
      "[5/25][255/782] Loss_D: 0.1515 (0.4783) Loss_G: -0.0214 (0.3328) D(x): 0.5378 D(G(z)): 0.4766 / 0.4563 Acc: 31.2500 (26.8295)\n",
      "[5/25][256/782] Loss_D: 0.1313 (0.4782) Loss_G: -0.0297 (0.3327) D(x): 0.5377 D(G(z)): 0.4607 / 0.4344 Acc: 29.6875 (26.8302)\n",
      "[5/25][257/782] Loss_D: 0.1346 (0.4781) Loss_G: 0.1115 (0.3326) D(x): 0.5109 D(G(z)): 0.4606 / 0.4283 Acc: 40.6250 (26.8335)\n",
      "[5/25][258/782] Loss_D: 0.0221 (0.4780) Loss_G: -0.1285 (0.3325) D(x): 0.5235 D(G(z)): 0.4317 / 0.4715 Acc: 42.1875 (26.8372)\n",
      "[5/25][259/782] Loss_D: 0.2555 (0.4779) Loss_G: 0.0443 (0.3325) D(x): 0.5713 D(G(z)): 0.5356 / 0.4179 Acc: 28.1250 (26.8375)\n",
      "[5/25][260/782] Loss_D: 0.2172 (0.4779) Loss_G: 0.0133 (0.3324) D(x): 0.4714 D(G(z)): 0.4363 / 0.4370 Acc: 35.9375 (26.8397)\n",
      "[5/25][261/782] Loss_D: 0.1623 (0.4778) Loss_G: -0.0911 (0.3323) D(x): 0.5284 D(G(z)): 0.4737 / 0.4838 Acc: 34.3750 (26.8415)\n",
      "[5/25][262/782] Loss_D: 0.1454 (0.4777) Loss_G: -0.0482 (0.3322) D(x): 0.5819 D(G(z)): 0.5043 / 0.4576 Acc: 26.5625 (26.8415)\n",
      "[5/25][263/782] Loss_D: 0.2351 (0.4777) Loss_G: -0.0331 (0.3321) D(x): 0.5016 D(G(z)): 0.4557 / 0.4598 Acc: 28.1250 (26.8418)\n",
      "[5/25][264/782] Loss_D: 0.2484 (0.4776) Loss_G: 0.0336 (0.3320) D(x): 0.4782 D(G(z)): 0.4465 / 0.4348 Acc: 29.6875 (26.8424)\n",
      "[5/25][265/782] Loss_D: 0.1371 (0.4775) Loss_G: -0.0702 (0.3319) D(x): 0.5617 D(G(z)): 0.4900 / 0.4739 Acc: 34.3750 (26.8442)\n",
      "[5/25][266/782] Loss_D: -0.0707 (0.4774) Loss_G: 0.1028 (0.3319) D(x): 0.6233 D(G(z)): 0.4830 / 0.4242 Acc: 48.4375 (26.8494)\n",
      "[5/25][267/782] Loss_D: 0.1717 (0.4773) Loss_G: 0.0160 (0.3318) D(x): 0.4755 D(G(z)): 0.4481 / 0.4289 Acc: 37.5000 (26.8520)\n",
      "[5/25][268/782] Loss_D: 0.0995 (0.4772) Loss_G: -0.0078 (0.3317) D(x): 0.5189 D(G(z)): 0.4393 / 0.4463 Acc: 35.9375 (26.8541)\n",
      "[5/25][269/782] Loss_D: 0.0633 (0.4771) Loss_G: 0.1780 (0.3317) D(x): 0.5556 D(G(z)): 0.4460 / 0.4001 Acc: 39.0625 (26.8571)\n",
      "[5/25][270/782] Loss_D: 0.1642 (0.4771) Loss_G: 0.0721 (0.3316) D(x): 0.5356 D(G(z)): 0.4505 / 0.4084 Acc: 26.5625 (26.8570)\n",
      "[5/25][271/782] Loss_D: 0.0913 (0.4770) Loss_G: 0.1276 (0.3316) D(x): 0.5785 D(G(z)): 0.5045 / 0.3905 Acc: 34.3750 (26.8588)\n",
      "[5/25][272/782] Loss_D: 0.1493 (0.4769) Loss_G: 0.2084 (0.3315) D(x): 0.5110 D(G(z)): 0.4117 / 0.3789 Acc: 34.3750 (26.8606)\n",
      "[5/25][273/782] Loss_D: 0.0919 (0.4768) Loss_G: 0.0482 (0.3315) D(x): 0.5146 D(G(z)): 0.4012 / 0.4306 Acc: 28.1250 (26.8609)\n",
      "[5/25][274/782] Loss_D: 0.2560 (0.4768) Loss_G: 0.0726 (0.3314) D(x): 0.5329 D(G(z)): 0.5017 / 0.4173 Acc: 31.2500 (26.8619)\n",
      "[5/25][275/782] Loss_D: 0.0503 (0.4766) Loss_G: -0.0618 (0.3313) D(x): 0.5236 D(G(z)): 0.4535 / 0.4683 Acc: 42.1875 (26.8656)\n",
      "[5/25][276/782] Loss_D: 0.2476 (0.4766) Loss_G: -0.0656 (0.3312) D(x): 0.5351 D(G(z)): 0.5090 / 0.5110 Acc: 35.9375 (26.8678)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/25][277/782] Loss_D: 0.1132 (0.4765) Loss_G: -0.0714 (0.3311) D(x): 0.5450 D(G(z)): 0.4460 / 0.4488 Acc: 26.5625 (26.8677)\n",
      "[5/25][278/782] Loss_D: 0.1021 (0.4764) Loss_G: 0.0061 (0.3311) D(x): 0.5391 D(G(z)): 0.4551 / 0.4477 Acc: 39.0625 (26.8706)\n",
      "[5/25][279/782] Loss_D: 0.2708 (0.4764) Loss_G: 0.0729 (0.3310) D(x): 0.5407 D(G(z)): 0.4993 / 0.3958 Acc: 23.4375 (26.8698)\n",
      "[5/25][280/782] Loss_D: 0.1711 (0.4763) Loss_G: 0.0551 (0.3309) D(x): 0.5001 D(G(z)): 0.4312 / 0.4264 Acc: 31.2500 (26.8708)\n",
      "[5/25][281/782] Loss_D: 0.3120 (0.4763) Loss_G: -0.1163 (0.3308) D(x): 0.4955 D(G(z)): 0.4786 / 0.4838 Acc: 28.1250 (26.8711)\n",
      "[5/25][282/782] Loss_D: 0.2108 (0.4762) Loss_G: 0.1305 (0.3308) D(x): 0.6120 D(G(z)): 0.5342 / 0.4160 Acc: 29.6875 (26.8718)\n",
      "[5/25][283/782] Loss_D: 0.2179 (0.4761) Loss_G: 0.1266 (0.3307) D(x): 0.5018 D(G(z)): 0.4080 / 0.4185 Acc: 26.5625 (26.8717)\n",
      "[5/25][284/782] Loss_D: 0.0397 (0.4760) Loss_G: 0.1511 (0.3307) D(x): 0.5966 D(G(z)): 0.4540 / 0.4097 Acc: 32.8125 (26.8731)\n",
      "[5/25][285/782] Loss_D: 0.3441 (0.4760) Loss_G: 0.0563 (0.3306) D(x): 0.4400 D(G(z)): 0.4009 / 0.4456 Acc: 29.6875 (26.8738)\n",
      "[5/25][286/782] Loss_D: 0.0874 (0.4759) Loss_G: -0.2681 (0.3305) D(x): 0.5681 D(G(z)): 0.5369 / 0.5379 Acc: 39.0625 (26.8767)\n",
      "[5/25][287/782] Loss_D: 0.2401 (0.4758) Loss_G: 0.0636 (0.3304) D(x): 0.5264 D(G(z)): 0.4638 / 0.4543 Acc: 37.5000 (26.8792)\n",
      "[5/25][288/782] Loss_D: 0.3490 (0.4758) Loss_G: 0.1013 (0.3304) D(x): 0.5199 D(G(z)): 0.4621 / 0.4367 Acc: 26.5625 (26.8792)\n",
      "[5/25][289/782] Loss_D: 0.2193 (0.4758) Loss_G: -0.0240 (0.3303) D(x): 0.4978 D(G(z)): 0.4605 / 0.4656 Acc: 34.3750 (26.8810)\n",
      "[5/25][290/782] Loss_D: 0.2139 (0.4757) Loss_G: -0.0099 (0.3302) D(x): 0.5120 D(G(z)): 0.4383 / 0.4760 Acc: 28.1250 (26.8812)\n",
      "[5/25][291/782] Loss_D: 0.0484 (0.4756) Loss_G: -0.1141 (0.3301) D(x): 0.5912 D(G(z)): 0.4909 / 0.4907 Acc: 39.0625 (26.8841)\n",
      "[5/25][292/782] Loss_D: -0.0870 (0.4755) Loss_G: 0.0318 (0.3300) D(x): 0.5955 D(G(z)): 0.4740 / 0.4248 Acc: 39.0625 (26.8870)\n",
      "[5/25][293/782] Loss_D: 0.3343 (0.4754) Loss_G: -0.0175 (0.3299) D(x): 0.4532 D(G(z)): 0.4573 / 0.4742 Acc: 28.1250 (26.8873)\n",
      "[5/25][294/782] Loss_D: -0.0172 (0.4753) Loss_G: 0.1063 (0.3299) D(x): 0.5995 D(G(z)): 0.4704 / 0.4021 Acc: 39.0625 (26.8902)\n",
      "[5/25][295/782] Loss_D: 0.2113 (0.4752) Loss_G: 0.0887 (0.3298) D(x): 0.4849 D(G(z)): 0.4466 / 0.4304 Acc: 37.5000 (26.8928)\n",
      "[5/25][296/782] Loss_D: 0.0117 (0.4751) Loss_G: 0.0276 (0.3298) D(x): 0.5816 D(G(z)): 0.4872 / 0.4316 Acc: 42.1875 (26.8964)\n",
      "[5/25][297/782] Loss_D: 0.1219 (0.4751) Loss_G: 0.0902 (0.3297) D(x): 0.4936 D(G(z)): 0.4625 / 0.4028 Acc: 39.0625 (26.8993)\n",
      "[5/25][298/782] Loss_D: 0.1727 (0.4750) Loss_G: 0.0182 (0.3296) D(x): 0.5343 D(G(z)): 0.4669 / 0.4365 Acc: 31.2500 (26.9003)\n",
      "[5/25][299/782] Loss_D: 0.2034 (0.4749) Loss_G: -0.0270 (0.3295) D(x): 0.4757 D(G(z)): 0.4479 / 0.4510 Acc: 37.5000 (26.9028)\n",
      "[5/25][300/782] Loss_D: 0.2909 (0.4749) Loss_G: 0.1188 (0.3295) D(x): 0.5341 D(G(z)): 0.4698 / 0.4317 Acc: 26.5625 (26.9028)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[5/25][301/782] Loss_D: 0.1847 (0.4748) Loss_G: 0.1245 (0.3294) D(x): 0.5761 D(G(z)): 0.4780 / 0.4270 Acc: 31.2500 (26.9038)\n",
      "[5/25][302/782] Loss_D: 0.0203 (0.4747) Loss_G: 0.0825 (0.3294) D(x): 0.5227 D(G(z)): 0.4238 / 0.4110 Acc: 37.5000 (26.9063)\n",
      "[5/25][303/782] Loss_D: 0.0632 (0.4746) Loss_G: 0.0216 (0.3293) D(x): 0.5452 D(G(z)): 0.4258 / 0.4342 Acc: 29.6875 (26.9070)\n",
      "[5/25][304/782] Loss_D: 0.1282 (0.4745) Loss_G: -0.0500 (0.3292) D(x): 0.5721 D(G(z)): 0.4720 / 0.4483 Acc: 29.6875 (26.9076)\n",
      "[5/25][305/782] Loss_D: 0.1925 (0.4744) Loss_G: 0.1009 (0.3292) D(x): 0.5345 D(G(z)): 0.4199 / 0.4527 Acc: 29.6875 (26.9083)\n",
      "[5/25][306/782] Loss_D: 0.0506 (0.4743) Loss_G: -0.1252 (0.3291) D(x): 0.5721 D(G(z)): 0.4437 / 0.4770 Acc: 25.0000 (26.9078)\n",
      "[5/25][307/782] Loss_D: 0.2081 (0.4743) Loss_G: 0.0032 (0.3290) D(x): 0.5641 D(G(z)): 0.4873 / 0.4598 Acc: 31.2500 (26.9089)\n",
      "[5/25][308/782] Loss_D: 0.2215 (0.4742) Loss_G: 0.0717 (0.3289) D(x): 0.5021 D(G(z)): 0.4757 / 0.4194 Acc: 31.2500 (26.9099)\n",
      "[5/25][309/782] Loss_D: 0.2917 (0.4742) Loss_G: 0.1105 (0.3289) D(x): 0.5401 D(G(z)): 0.5086 / 0.4072 Acc: 32.8125 (26.9113)\n",
      "[5/25][310/782] Loss_D: 0.3222 (0.4741) Loss_G: -0.0080 (0.3288) D(x): 0.4697 D(G(z)): 0.4750 / 0.4640 Acc: 35.9375 (26.9134)\n",
      "[5/25][311/782] Loss_D: 0.2938 (0.4741) Loss_G: -0.1213 (0.3287) D(x): 0.5094 D(G(z)): 0.5360 / 0.5002 Acc: 34.3750 (26.9152)\n",
      "[5/25][312/782] Loss_D: 0.1158 (0.4740) Loss_G: 0.1140 (0.3286) D(x): 0.5742 D(G(z)): 0.4739 / 0.4118 Acc: 31.2500 (26.9162)\n",
      "[5/25][313/782] Loss_D: 0.2182 (0.4740) Loss_G: 0.0276 (0.3286) D(x): 0.5014 D(G(z)): 0.4939 / 0.4238 Acc: 34.3750 (26.9180)\n",
      "[5/25][314/782] Loss_D: 0.1346 (0.4739) Loss_G: 0.0914 (0.3285) D(x): 0.5275 D(G(z)): 0.4660 / 0.4243 Acc: 39.0625 (26.9209)\n",
      "[5/25][315/782] Loss_D: 0.3417 (0.4738) Loss_G: -0.0137 (0.3284) D(x): 0.4440 D(G(z)): 0.4574 / 0.4434 Acc: 29.6875 (26.9215)\n",
      "[5/25][316/782] Loss_D: 0.3280 (0.4738) Loss_G: -0.1387 (0.3283) D(x): 0.5338 D(G(z)): 0.5620 / 0.4979 Acc: 34.3750 (26.9233)\n",
      "[5/25][317/782] Loss_D: 0.2567 (0.4738) Loss_G: 0.0645 (0.3282) D(x): 0.5461 D(G(z)): 0.5543 / 0.4263 Acc: 45.3125 (26.9276)\n",
      "[5/25][318/782] Loss_D: 0.2242 (0.4737) Loss_G: 0.1478 (0.3282) D(x): 0.5243 D(G(z)): 0.5032 / 0.3829 Acc: 29.6875 (26.9283)\n",
      "[5/25][319/782] Loss_D: 0.2371 (0.4736) Loss_G: -0.1158 (0.3281) D(x): 0.4279 D(G(z)): 0.4235 / 0.4680 Acc: 35.9375 (26.9304)\n",
      "[5/25][320/782] Loss_D: 0.3535 (0.4736) Loss_G: -0.1780 (0.3280) D(x): 0.4478 D(G(z)): 0.4784 / 0.5261 Acc: 37.5000 (26.9329)\n",
      "[5/25][321/782] Loss_D: 0.2290 (0.4736) Loss_G: -0.1293 (0.3279) D(x): 0.5219 D(G(z)): 0.5265 / 0.5096 Acc: 40.6250 (26.9361)\n",
      "[5/25][322/782] Loss_D: 0.1141 (0.4735) Loss_G: -0.1178 (0.3278) D(x): 0.5346 D(G(z)): 0.4537 / 0.4678 Acc: 29.6875 (26.9368)\n",
      "[5/25][323/782] Loss_D: 0.0547 (0.4734) Loss_G: 0.1028 (0.3277) D(x): 0.6407 D(G(z)): 0.4961 / 0.4537 Acc: 35.9375 (26.9389)\n",
      "[5/25][324/782] Loss_D: 0.1466 (0.4733) Loss_G: 0.1244 (0.3277) D(x): 0.5459 D(G(z)): 0.4796 / 0.4019 Acc: 35.9375 (26.9410)\n",
      "[5/25][325/782] Loss_D: 0.2073 (0.4732) Loss_G: 0.0028 (0.3276) D(x): 0.4995 D(G(z)): 0.4230 / 0.4606 Acc: 28.1250 (26.9413)\n",
      "[5/25][326/782] Loss_D: 0.2649 (0.4732) Loss_G: 0.0858 (0.3275) D(x): 0.5379 D(G(z)): 0.4709 / 0.4339 Acc: 28.1250 (26.9416)\n",
      "[5/25][327/782] Loss_D: 0.2673 (0.4731) Loss_G: 0.1009 (0.3275) D(x): 0.5710 D(G(z)): 0.5206 / 0.4054 Acc: 28.1250 (26.9419)\n",
      "[5/25][328/782] Loss_D: 0.3891 (0.4731) Loss_G: 0.2336 (0.3275) D(x): 0.4844 D(G(z)): 0.5121 / 0.3620 Acc: 32.8125 (26.9433)\n",
      "[5/25][329/782] Loss_D: 0.1364 (0.4730) Loss_G: 0.1731 (0.3274) D(x): 0.4933 D(G(z)): 0.4142 / 0.4060 Acc: 43.7500 (26.9472)\n",
      "[5/25][330/782] Loss_D: 0.1292 (0.4730) Loss_G: 0.0785 (0.3274) D(x): 0.5073 D(G(z)): 0.4158 / 0.4078 Acc: 26.5625 (26.9471)\n",
      "[5/25][331/782] Loss_D: 0.0465 (0.4729) Loss_G: 0.0914 (0.3273) D(x): 0.5277 D(G(z)): 0.4275 / 0.4124 Acc: 37.5000 (26.9496)\n",
      "[5/25][332/782] Loss_D: 0.0514 (0.4728) Loss_G: 0.0161 (0.3272) D(x): 0.5856 D(G(z)): 0.4854 / 0.4200 Acc: 34.3750 (26.9514)\n",
      "[5/25][333/782] Loss_D: 0.2403 (0.4727) Loss_G: 0.0498 (0.3272) D(x): 0.5289 D(G(z)): 0.4711 / 0.4409 Acc: 31.2500 (26.9524)\n",
      "[5/25][334/782] Loss_D: 0.2145 (0.4726) Loss_G: -0.0055 (0.3271) D(x): 0.5169 D(G(z)): 0.4581 / 0.4439 Acc: 28.1250 (26.9527)\n",
      "[5/25][335/782] Loss_D: 0.1752 (0.4726) Loss_G: -0.0374 (0.3270) D(x): 0.5234 D(G(z)): 0.4692 / 0.4468 Acc: 29.6875 (26.9533)\n",
      "[5/25][336/782] Loss_D: 0.0001 (0.4725) Loss_G: -0.1343 (0.3269) D(x): 0.5496 D(G(z)): 0.4249 / 0.4898 Acc: 34.3750 (26.9551)\n",
      "[5/25][337/782] Loss_D: 0.2983 (0.4724) Loss_G: -0.0317 (0.3268) D(x): 0.5639 D(G(z)): 0.4874 / 0.4705 Acc: 23.4375 (26.9542)\n",
      "[5/25][338/782] Loss_D: 0.2016 (0.4724) Loss_G: 0.0905 (0.3268) D(x): 0.5493 D(G(z)): 0.4996 / 0.4102 Acc: 31.2500 (26.9552)\n",
      "[5/25][339/782] Loss_D: 0.1984 (0.4723) Loss_G: -0.1016 (0.3267) D(x): 0.5382 D(G(z)): 0.5031 / 0.4704 Acc: 37.5000 (26.9577)\n",
      "[5/25][340/782] Loss_D: 0.1398 (0.4722) Loss_G: 0.0967 (0.3266) D(x): 0.5100 D(G(z)): 0.4135 / 0.4328 Acc: 31.2500 (26.9587)\n",
      "[5/25][341/782] Loss_D: 0.1842 (0.4721) Loss_G: -0.0629 (0.3265) D(x): 0.5706 D(G(z)): 0.5127 / 0.4549 Acc: 26.5625 (26.9586)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/25][342/782] Loss_D: 0.2073 (0.4721) Loss_G: 0.1238 (0.3265) D(x): 0.5725 D(G(z)): 0.5008 / 0.4245 Acc: 31.2500 (26.9596)\n",
      "[5/25][343/782] Loss_D: 0.1839 (0.4720) Loss_G: 0.0010 (0.3264) D(x): 0.5276 D(G(z)): 0.4685 / 0.4485 Acc: 31.2500 (26.9607)\n",
      "[5/25][344/782] Loss_D: 0.2186 (0.4720) Loss_G: -0.1059 (0.3263) D(x): 0.4511 D(G(z)): 0.4548 / 0.4578 Acc: 35.9375 (26.9628)\n",
      "[5/25][345/782] Loss_D: 0.2221 (0.4719) Loss_G: -0.1123 (0.3262) D(x): 0.5515 D(G(z)): 0.4811 / 0.5164 Acc: 29.6875 (26.9634)\n",
      "[5/25][346/782] Loss_D: 0.0996 (0.4718) Loss_G: -0.0919 (0.3261) D(x): 0.5608 D(G(z)): 0.5123 / 0.4741 Acc: 40.6250 (26.9666)\n",
      "[5/25][347/782] Loss_D: 0.1929 (0.4717) Loss_G: 0.0996 (0.3260) D(x): 0.5145 D(G(z)): 0.4763 / 0.4110 Acc: 37.5000 (26.9691)\n",
      "[5/25][348/782] Loss_D: 0.2232 (0.4717) Loss_G: 0.0523 (0.3260) D(x): 0.5178 D(G(z)): 0.4629 / 0.4249 Acc: 31.2500 (26.9701)\n",
      "[5/25][349/782] Loss_D: 0.2652 (0.4716) Loss_G: -0.0342 (0.3259) D(x): 0.5175 D(G(z)): 0.4997 / 0.4624 Acc: 29.6875 (26.9707)\n",
      "[5/25][350/782] Loss_D: 0.1356 (0.4716) Loss_G: -0.1238 (0.3258) D(x): 0.5017 D(G(z)): 0.4601 / 0.4636 Acc: 31.2500 (26.9717)\n",
      "[5/25][351/782] Loss_D: -0.0098 (0.4714) Loss_G: -0.0954 (0.3257) D(x): 0.5792 D(G(z)): 0.4940 / 0.4515 Acc: 37.5000 (26.9742)\n",
      "[5/25][352/782] Loss_D: -0.0870 (0.4713) Loss_G: 0.0302 (0.3256) D(x): 0.5440 D(G(z)): 0.4211 / 0.4100 Acc: 43.7500 (26.9781)\n",
      "[5/25][353/782] Loss_D: 0.0601 (0.4712) Loss_G: 0.0502 (0.3255) D(x): 0.5698 D(G(z)): 0.4568 / 0.4262 Acc: 31.2500 (26.9791)\n",
      "[5/25][354/782] Loss_D: 0.2164 (0.4712) Loss_G: 0.2321 (0.3255) D(x): 0.4952 D(G(z)): 0.4753 / 0.3517 Acc: 34.3750 (26.9809)\n",
      "[5/25][355/782] Loss_D: 0.0164 (0.4711) Loss_G: 0.1581 (0.3255) D(x): 0.5784 D(G(z)): 0.4297 / 0.3839 Acc: 29.6875 (26.9815)\n",
      "[5/25][356/782] Loss_D: 0.2272 (0.4710) Loss_G: 0.1452 (0.3254) D(x): 0.4659 D(G(z)): 0.4086 / 0.3968 Acc: 32.8125 (26.9829)\n",
      "[5/25][357/782] Loss_D: 0.0218 (0.4709) Loss_G: 0.0499 (0.3254) D(x): 0.5643 D(G(z)): 0.4305 / 0.4293 Acc: 32.8125 (26.9842)\n",
      "[5/25][358/782] Loss_D: 0.0987 (0.4708) Loss_G: 0.2026 (0.3253) D(x): 0.5914 D(G(z)): 0.5110 / 0.3731 Acc: 34.3750 (26.9860)\n",
      "[5/25][359/782] Loss_D: 0.2085 (0.4707) Loss_G: 0.1693 (0.3253) D(x): 0.5342 D(G(z)): 0.4402 / 0.4052 Acc: 26.5625 (26.9859)\n",
      "[5/25][360/782] Loss_D: -0.0550 (0.4706) Loss_G: 0.2251 (0.3253) D(x): 0.5775 D(G(z)): 0.3989 / 0.3682 Acc: 35.9375 (26.9880)\n",
      "[5/25][361/782] Loss_D: 0.1892 (0.4706) Loss_G: -0.1887 (0.3252) D(x): 0.5075 D(G(z)): 0.4279 / 0.5365 Acc: 28.1250 (26.9882)\n",
      "[5/25][362/782] Loss_D: 0.4697 (0.4705) Loss_G: -0.0676 (0.3251) D(x): 0.5433 D(G(z)): 0.5330 / 0.5088 Acc: 28.1250 (26.9885)\n",
      "[5/25][363/782] Loss_D: 0.1891 (0.4705) Loss_G: 0.2422 (0.3250) D(x): 0.5439 D(G(z)): 0.5320 / 0.3581 Acc: 40.6250 (26.9917)\n",
      "[5/25][364/782] Loss_D: 0.1678 (0.4704) Loss_G: -0.0954 (0.3250) D(x): 0.4508 D(G(z)): 0.4245 / 0.4645 Acc: 39.0625 (26.9945)\n",
      "[5/25][365/782] Loss_D: 0.1959 (0.4703) Loss_G: 0.0038 (0.3249) D(x): 0.5315 D(G(z)): 0.4683 / 0.4599 Acc: 29.6875 (26.9951)\n",
      "[5/25][366/782] Loss_D: -0.0867 (0.4702) Loss_G: -0.0750 (0.3248) D(x): 0.5824 D(G(z)): 0.4769 / 0.4464 Acc: 40.6250 (26.9983)\n",
      "[5/25][367/782] Loss_D: 0.1605 (0.4701) Loss_G: 0.1183 (0.3247) D(x): 0.5588 D(G(z)): 0.4866 / 0.3935 Acc: 32.8125 (26.9997)\n",
      "[5/25][368/782] Loss_D: 0.0253 (0.4700) Loss_G: 0.1378 (0.3247) D(x): 0.5076 D(G(z)): 0.3818 / 0.4227 Acc: 39.0625 (27.0025)\n",
      "[5/25][369/782] Loss_D: 0.2376 (0.4700) Loss_G: -0.1013 (0.3246) D(x): 0.4804 D(G(z)): 0.4387 / 0.4784 Acc: 25.0000 (27.0020)\n",
      "[5/25][370/782] Loss_D: 0.2386 (0.4699) Loss_G: -0.0147 (0.3245) D(x): 0.5438 D(G(z)): 0.5213 / 0.4447 Acc: 35.9375 (27.0041)\n",
      "[5/25][371/782] Loss_D: 0.1691 (0.4699) Loss_G: -0.1594 (0.3244) D(x): 0.5347 D(G(z)): 0.5248 / 0.4927 Acc: 32.8125 (27.0055)\n",
      "[5/25][372/782] Loss_D: 0.1261 (0.4698) Loss_G: 0.1193 (0.3244) D(x): 0.5399 D(G(z)): 0.4735 / 0.4066 Acc: 42.1875 (27.0090)\n",
      "[5/25][373/782] Loss_D: 0.4035 (0.4698) Loss_G: -0.1446 (0.3242) D(x): 0.4381 D(G(z)): 0.4724 / 0.4850 Acc: 25.0000 (27.0086)\n",
      "[5/25][374/782] Loss_D: 0.2904 (0.4697) Loss_G: -0.1094 (0.3241) D(x): 0.5401 D(G(z)): 0.5143 / 0.4911 Acc: 23.4375 (27.0077)\n",
      "[5/25][375/782] Loss_D: 0.2546 (0.4697) Loss_G: 0.0483 (0.3241) D(x): 0.5568 D(G(z)): 0.5320 / 0.4399 Acc: 32.8125 (27.0091)\n",
      "[5/25][376/782] Loss_D: 0.4169 (0.4697) Loss_G: 0.0874 (0.3240) D(x): 0.4908 D(G(z)): 0.5140 / 0.4380 Acc: 31.2500 (27.0101)\n",
      "[5/25][377/782] Loss_D: 0.2170 (0.4696) Loss_G: -0.0933 (0.3239) D(x): 0.5418 D(G(z)): 0.4643 / 0.4837 Acc: 28.1250 (27.0103)\n",
      "[5/25][378/782] Loss_D: 0.2078 (0.4695) Loss_G: -0.0346 (0.3238) D(x): 0.4902 D(G(z)): 0.4595 / 0.4468 Acc: 34.3750 (27.0121)\n",
      "[5/25][379/782] Loss_D: 0.2464 (0.4695) Loss_G: 0.0070 (0.3238) D(x): 0.5025 D(G(z)): 0.4956 / 0.4556 Acc: 39.0625 (27.0149)\n",
      "[5/25][380/782] Loss_D: 0.2375 (0.4694) Loss_G: -0.1873 (0.3236) D(x): 0.4945 D(G(z)): 0.5102 / 0.5099 Acc: 39.0625 (27.0177)\n",
      "[5/25][381/782] Loss_D: 0.1401 (0.4694) Loss_G: -0.1047 (0.3235) D(x): 0.5598 D(G(z)): 0.4848 / 0.4650 Acc: 26.5625 (27.0176)\n",
      "[5/25][382/782] Loss_D: 0.4966 (0.4694) Loss_G: -0.1639 (0.3234) D(x): 0.4553 D(G(z)): 0.5482 / 0.5200 Acc: 34.3750 (27.0193)\n",
      "[5/25][383/782] Loss_D: 0.0603 (0.4693) Loss_G: -0.0114 (0.3234) D(x): 0.5225 D(G(z)): 0.4136 / 0.4367 Acc: 31.2500 (27.0203)\n",
      "[5/25][384/782] Loss_D: -0.0423 (0.4692) Loss_G: -0.1260 (0.3233) D(x): 0.5712 D(G(z)): 0.4774 / 0.4792 Acc: 42.1875 (27.0238)\n",
      "[5/25][385/782] Loss_D: 0.1695 (0.4691) Loss_G: 0.0024 (0.3232) D(x): 0.4941 D(G(z)): 0.4994 / 0.4174 Acc: 39.0625 (27.0266)\n",
      "[5/25][386/782] Loss_D: 0.4591 (0.4691) Loss_G: -0.0765 (0.3231) D(x): 0.4577 D(G(z)): 0.5148 / 0.4853 Acc: 32.8125 (27.0279)\n",
      "[5/25][387/782] Loss_D: 0.3665 (0.4691) Loss_G: -0.0291 (0.3230) D(x): 0.4948 D(G(z)): 0.5179 / 0.4780 Acc: 32.8125 (27.0293)\n",
      "[5/25][388/782] Loss_D: 0.2960 (0.4690) Loss_G: 0.0272 (0.3229) D(x): 0.4907 D(G(z)): 0.4634 / 0.4311 Acc: 26.5625 (27.0292)\n",
      "[5/25][389/782] Loss_D: 0.1911 (0.4690) Loss_G: -0.0844 (0.3228) D(x): 0.4877 D(G(z)): 0.4431 / 0.4733 Acc: 34.3750 (27.0309)\n",
      "[5/25][390/782] Loss_D: 0.3418 (0.4689) Loss_G: -0.1199 (0.3227) D(x): 0.5371 D(G(z)): 0.5499 / 0.5002 Acc: 28.1250 (27.0311)\n",
      "[5/25][391/782] Loss_D: 0.0215 (0.4688) Loss_G: -0.1130 (0.3226) D(x): 0.6020 D(G(z)): 0.5139 / 0.4591 Acc: 34.3750 (27.0328)\n",
      "[5/25][392/782] Loss_D: 0.2172 (0.4688) Loss_G: 0.0552 (0.3226) D(x): 0.5146 D(G(z)): 0.4490 / 0.4224 Acc: 26.5625 (27.0327)\n",
      "[5/25][393/782] Loss_D: 0.2701 (0.4687) Loss_G: 0.0645 (0.3225) D(x): 0.4598 D(G(z)): 0.3900 / 0.4425 Acc: 26.5625 (27.0326)\n",
      "[5/25][394/782] Loss_D: 0.1602 (0.4686) Loss_G: -0.1727 (0.3224) D(x): 0.5222 D(G(z)): 0.4640 / 0.4968 Acc: 31.2500 (27.0336)\n",
      "[5/25][395/782] Loss_D: 0.2108 (0.4686) Loss_G: -0.1295 (0.3223) D(x): 0.5319 D(G(z)): 0.4846 / 0.5247 Acc: 39.0625 (27.0364)\n",
      "[5/25][396/782] Loss_D: 0.0357 (0.4685) Loss_G: -0.0412 (0.3222) D(x): 0.5667 D(G(z)): 0.5029 / 0.4601 Acc: 43.7500 (27.0403)\n",
      "[5/25][397/782] Loss_D: 0.0835 (0.4684) Loss_G: 0.0372 (0.3221) D(x): 0.5924 D(G(z)): 0.4676 / 0.4427 Acc: 35.9375 (27.0423)\n",
      "[5/25][398/782] Loss_D: 0.3024 (0.4684) Loss_G: -0.1565 (0.3220) D(x): 0.4453 D(G(z)): 0.4380 / 0.4817 Acc: 26.5625 (27.0422)\n",
      "[5/25][399/782] Loss_D: 0.1220 (0.4683) Loss_G: -0.1691 (0.3219) D(x): 0.5471 D(G(z)): 0.4857 / 0.4896 Acc: 31.2500 (27.0432)\n",
      "[5/25][400/782] Loss_D: 0.3971 (0.4683) Loss_G: 0.0726 (0.3219) D(x): 0.5438 D(G(z)): 0.5499 / 0.4466 Acc: 29.6875 (27.0438)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[5/25][401/782] Loss_D: 0.0186 (0.4682) Loss_G: 0.1140 (0.3218) D(x): 0.5522 D(G(z)): 0.4513 / 0.3870 Acc: 31.2500 (27.0448)\n",
      "[5/25][402/782] Loss_D: 0.0853 (0.4681) Loss_G: 0.0050 (0.3217) D(x): 0.5058 D(G(z)): 0.4273 / 0.4510 Acc: 35.9375 (27.0469)\n",
      "[5/25][403/782] Loss_D: 0.0418 (0.4680) Loss_G: 0.0142 (0.3217) D(x): 0.5476 D(G(z)): 0.4487 / 0.4174 Acc: 29.6875 (27.0475)\n",
      "[5/25][404/782] Loss_D: 0.1058 (0.4679) Loss_G: -0.1713 (0.3215) D(x): 0.5155 D(G(z)): 0.4735 / 0.5042 Acc: 37.5000 (27.0499)\n",
      "[5/25][405/782] Loss_D: 0.0834 (0.4678) Loss_G: -0.0182 (0.3215) D(x): 0.5849 D(G(z)): 0.4665 / 0.4525 Acc: 31.2500 (27.0509)\n",
      "[5/25][406/782] Loss_D: 0.0240 (0.4677) Loss_G: 0.0581 (0.3214) D(x): 0.6121 D(G(z)): 0.4852 / 0.4033 Acc: 25.0000 (27.0504)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/25][407/782] Loss_D: 0.0690 (0.4676) Loss_G: 0.1488 (0.3214) D(x): 0.5161 D(G(z)): 0.4325 / 0.3828 Acc: 34.3750 (27.0521)\n",
      "[5/25][408/782] Loss_D: 0.0345 (0.4675) Loss_G: 0.0031 (0.3213) D(x): 0.5225 D(G(z)): 0.4293 / 0.4270 Acc: 34.3750 (27.0538)\n",
      "[5/25][409/782] Loss_D: 0.3036 (0.4675) Loss_G: -0.1249 (0.3212) D(x): 0.4767 D(G(z)): 0.4500 / 0.5099 Acc: 25.0000 (27.0533)\n",
      "[5/25][410/782] Loss_D: 0.2249 (0.4674) Loss_G: -0.0314 (0.3211) D(x): 0.5585 D(G(z)): 0.4962 / 0.4629 Acc: 26.5625 (27.0532)\n",
      "[5/25][411/782] Loss_D: 0.1838 (0.4673) Loss_G: 0.0879 (0.3211) D(x): 0.5289 D(G(z)): 0.4600 / 0.4076 Acc: 25.0000 (27.0527)\n",
      "[5/25][412/782] Loss_D: 0.2035 (0.4673) Loss_G: 0.0008 (0.3210) D(x): 0.4833 D(G(z)): 0.4181 / 0.4303 Acc: 23.4375 (27.0519)\n",
      "[5/25][413/782] Loss_D: 0.0136 (0.4672) Loss_G: 0.1597 (0.3209) D(x): 0.5804 D(G(z)): 0.4468 / 0.3840 Acc: 32.8125 (27.0532)\n",
      "[5/25][414/782] Loss_D: 0.1806 (0.4671) Loss_G: 0.0976 (0.3209) D(x): 0.5155 D(G(z)): 0.4030 / 0.4054 Acc: 26.5625 (27.0531)\n",
      "[5/25][415/782] Loss_D: 0.1826 (0.4670) Loss_G: -0.0511 (0.3208) D(x): 0.5907 D(G(z)): 0.5224 / 0.4450 Acc: 25.0000 (27.0526)\n",
      "[5/25][416/782] Loss_D: 0.0153 (0.4669) Loss_G: 0.2688 (0.3208) D(x): 0.5916 D(G(z)): 0.4645 / 0.3649 Acc: 32.8125 (27.0540)\n",
      "[5/25][417/782] Loss_D: 0.1740 (0.4669) Loss_G: 0.0437 (0.3207) D(x): 0.4947 D(G(z)): 0.4486 / 0.4075 Acc: 28.1250 (27.0542)\n",
      "[5/25][418/782] Loss_D: 0.2697 (0.4668) Loss_G: 0.1132 (0.3207) D(x): 0.5046 D(G(z)): 0.4537 / 0.3974 Acc: 26.5625 (27.0541)\n",
      "[5/25][419/782] Loss_D: 0.1063 (0.4667) Loss_G: 0.0269 (0.3206) D(x): 0.5638 D(G(z)): 0.4501 / 0.4192 Acc: 28.1250 (27.0543)\n",
      "[5/25][420/782] Loss_D: 0.1840 (0.4667) Loss_G: 0.0031 (0.3205) D(x): 0.5801 D(G(z)): 0.4877 / 0.4652 Acc: 31.2500 (27.0553)\n",
      "[5/25][421/782] Loss_D: 0.0362 (0.4666) Loss_G: -0.1254 (0.3204) D(x): 0.5453 D(G(z)): 0.4439 / 0.4503 Acc: 31.2500 (27.0563)\n",
      "[5/25][422/782] Loss_D: 0.0908 (0.4665) Loss_G: 0.0502 (0.3204) D(x): 0.6046 D(G(z)): 0.4871 / 0.4106 Acc: 29.6875 (27.0569)\n",
      "[5/25][423/782] Loss_D: 0.1437 (0.4664) Loss_G: 0.1270 (0.3203) D(x): 0.4874 D(G(z)): 0.4178 / 0.4200 Acc: 37.5000 (27.0593)\n",
      "[5/25][424/782] Loss_D: 0.0804 (0.4663) Loss_G: 0.0491 (0.3203) D(x): 0.5585 D(G(z)): 0.4515 / 0.4420 Acc: 34.3750 (27.0610)\n",
      "[5/25][425/782] Loss_D: 0.2554 (0.4663) Loss_G: 0.0622 (0.3202) D(x): 0.5213 D(G(z)): 0.5008 / 0.4517 Acc: 42.1875 (27.0645)\n",
      "[5/25][426/782] Loss_D: 0.1755 (0.4662) Loss_G: -0.0083 (0.3201) D(x): 0.5172 D(G(z)): 0.4729 / 0.4336 Acc: 32.8125 (27.0658)\n",
      "[5/25][427/782] Loss_D: 0.1351 (0.4661) Loss_G: 0.0243 (0.3201) D(x): 0.5102 D(G(z)): 0.4925 / 0.4080 Acc: 39.0625 (27.0686)\n",
      "[5/25][428/782] Loss_D: 0.2803 (0.4661) Loss_G: -0.1526 (0.3200) D(x): 0.4515 D(G(z)): 0.4042 / 0.5167 Acc: 31.2500 (27.0695)\n",
      "[5/25][429/782] Loss_D: 0.2385 (0.4660) Loss_G: -0.0815 (0.3199) D(x): 0.5359 D(G(z)): 0.4918 / 0.5003 Acc: 28.1250 (27.0698)\n",
      "[5/25][430/782] Loss_D: 0.1811 (0.4660) Loss_G: -0.1137 (0.3198) D(x): 0.5423 D(G(z)): 0.5102 / 0.4874 Acc: 37.5000 (27.0722)\n",
      "[5/25][431/782] Loss_D: 0.2433 (0.4659) Loss_G: -0.1924 (0.3196) D(x): 0.4881 D(G(z)): 0.4757 / 0.4927 Acc: 28.1250 (27.0724)\n",
      "[5/25][432/782] Loss_D: 0.1672 (0.4659) Loss_G: -0.1823 (0.3195) D(x): 0.5360 D(G(z)): 0.5027 / 0.4988 Acc: 35.9375 (27.0745)\n",
      "[5/25][433/782] Loss_D: 0.1639 (0.4658) Loss_G: -0.0258 (0.3195) D(x): 0.5632 D(G(z)): 0.4730 / 0.4616 Acc: 29.6875 (27.0751)\n",
      "[5/25][434/782] Loss_D: 0.0708 (0.4657) Loss_G: -0.0153 (0.3194) D(x): 0.5487 D(G(z)): 0.4813 / 0.4342 Acc: 37.5000 (27.0775)\n",
      "[5/25][435/782] Loss_D: 0.1119 (0.4656) Loss_G: 0.0058 (0.3193) D(x): 0.4991 D(G(z)): 0.4098 / 0.4450 Acc: 32.8125 (27.0788)\n",
      "[5/25][436/782] Loss_D: 0.1775 (0.4655) Loss_G: -0.1209 (0.3192) D(x): 0.5235 D(G(z)): 0.4691 / 0.4807 Acc: 29.6875 (27.0794)\n",
      "[5/25][437/782] Loss_D: 0.1699 (0.4655) Loss_G: 0.0687 (0.3191) D(x): 0.5732 D(G(z)): 0.4985 / 0.4347 Acc: 31.2500 (27.0803)\n",
      "[5/25][438/782] Loss_D: 0.2917 (0.4654) Loss_G: 0.0377 (0.3191) D(x): 0.4854 D(G(z)): 0.4913 / 0.4311 Acc: 28.1250 (27.0806)\n",
      "[5/25][439/782] Loss_D: 0.2402 (0.4654) Loss_G: 0.0662 (0.3190) D(x): 0.5191 D(G(z)): 0.5072 / 0.4243 Acc: 35.9375 (27.0826)\n",
      "[5/25][440/782] Loss_D: 0.0371 (0.4653) Loss_G: 0.0426 (0.3190) D(x): 0.5688 D(G(z)): 0.4691 / 0.4056 Acc: 31.2500 (27.0836)\n",
      "[5/25][441/782] Loss_D: 0.0890 (0.4652) Loss_G: -0.0357 (0.3189) D(x): 0.5251 D(G(z)): 0.4628 / 0.4324 Acc: 31.2500 (27.0845)\n",
      "[5/25][442/782] Loss_D: 0.1504 (0.4651) Loss_G: 0.0037 (0.3188) D(x): 0.5052 D(G(z)): 0.4365 / 0.4469 Acc: 34.3750 (27.0862)\n",
      "[5/25][443/782] Loss_D: 0.1102 (0.4650) Loss_G: 0.0837 (0.3188) D(x): 0.5424 D(G(z)): 0.4484 / 0.4304 Acc: 32.8125 (27.0875)\n",
      "[5/25][444/782] Loss_D: -0.0384 (0.4649) Loss_G: 0.2711 (0.3187) D(x): 0.5806 D(G(z)): 0.4289 / 0.3855 Acc: 39.0625 (27.0903)\n",
      "[5/25][445/782] Loss_D: 0.1864 (0.4649) Loss_G: 0.0633 (0.3187) D(x): 0.5240 D(G(z)): 0.4553 / 0.4182 Acc: 29.6875 (27.0909)\n",
      "[5/25][446/782] Loss_D: 0.0436 (0.4648) Loss_G: -0.0285 (0.3186) D(x): 0.5404 D(G(z)): 0.4323 / 0.4592 Acc: 29.6875 (27.0915)\n",
      "[5/25][447/782] Loss_D: 0.1063 (0.4647) Loss_G: 0.0656 (0.3185) D(x): 0.5231 D(G(z)): 0.4874 / 0.4175 Acc: 40.6250 (27.0946)\n",
      "[5/25][448/782] Loss_D: 0.0338 (0.4646) Loss_G: 0.1097 (0.3185) D(x): 0.5638 D(G(z)): 0.4525 / 0.4025 Acc: 31.2500 (27.0955)\n",
      "[5/25][449/782] Loss_D: 0.2508 (0.4645) Loss_G: -0.0152 (0.3184) D(x): 0.4942 D(G(z)): 0.4435 / 0.4447 Acc: 23.4375 (27.0947)\n",
      "[5/25][450/782] Loss_D: 0.2990 (0.4645) Loss_G: -0.1854 (0.3183) D(x): 0.5263 D(G(z)): 0.4967 / 0.5042 Acc: 25.0000 (27.0942)\n",
      "[5/25][451/782] Loss_D: 0.0122 (0.4644) Loss_G: 0.0994 (0.3183) D(x): 0.5532 D(G(z)): 0.4295 / 0.3966 Acc: 32.8125 (27.0955)\n",
      "[5/25][452/782] Loss_D: 0.0849 (0.4643) Loss_G: -0.0660 (0.3182) D(x): 0.5361 D(G(z)): 0.4562 / 0.4853 Acc: 35.9375 (27.0975)\n",
      "[5/25][453/782] Loss_D: -0.0401 (0.4642) Loss_G: 0.1522 (0.3181) D(x): 0.6180 D(G(z)): 0.4751 / 0.3976 Acc: 37.5000 (27.0999)\n",
      "[5/25][454/782] Loss_D: 0.0503 (0.4641) Loss_G: 0.1540 (0.3181) D(x): 0.5761 D(G(z)): 0.4564 / 0.3936 Acc: 34.3750 (27.1016)\n",
      "[5/25][455/782] Loss_D: 0.1007 (0.4640) Loss_G: 0.0285 (0.3180) D(x): 0.5173 D(G(z)): 0.4817 / 0.4258 Acc: 39.0625 (27.1043)\n",
      "[5/25][456/782] Loss_D: -0.0509 (0.4639) Loss_G: -0.0197 (0.3179) D(x): 0.4872 D(G(z)): 0.3868 / 0.4301 Acc: 39.0625 (27.1071)\n",
      "[5/25][457/782] Loss_D: 0.2941 (0.4639) Loss_G: 0.0238 (0.3179) D(x): 0.5156 D(G(z)): 0.4823 / 0.4749 Acc: 29.6875 (27.1077)\n",
      "[5/25][458/782] Loss_D: 0.1536 (0.4638) Loss_G: -0.0859 (0.3178) D(x): 0.5603 D(G(z)): 0.4758 / 0.4894 Acc: 29.6875 (27.1082)\n",
      "[5/25][459/782] Loss_D: 0.2108 (0.4637) Loss_G: 0.0190 (0.3177) D(x): 0.5344 D(G(z)): 0.5101 / 0.4426 Acc: 35.9375 (27.1103)\n",
      "[5/25][460/782] Loss_D: 0.3005 (0.4637) Loss_G: -0.0145 (0.3176) D(x): 0.5045 D(G(z)): 0.5042 / 0.4485 Acc: 35.9375 (27.1123)\n",
      "[5/25][461/782] Loss_D: 0.1994 (0.4636) Loss_G: -0.0640 (0.3176) D(x): 0.4736 D(G(z)): 0.4917 / 0.4456 Acc: 42.1875 (27.1157)\n",
      "[5/25][462/782] Loss_D: 0.3314 (0.4636) Loss_G: -0.0900 (0.3175) D(x): 0.4567 D(G(z)): 0.4892 / 0.4727 Acc: 34.3750 (27.1174)\n",
      "[5/25][463/782] Loss_D: 0.3538 (0.4636) Loss_G: -0.0566 (0.3174) D(x): 0.5296 D(G(z)): 0.5383 / 0.4745 Acc: 34.3750 (27.1191)\n",
      "[5/25][464/782] Loss_D: 0.1794 (0.4635) Loss_G: 0.0436 (0.3173) D(x): 0.5241 D(G(z)): 0.4865 / 0.4137 Acc: 29.6875 (27.1196)\n",
      "[5/25][465/782] Loss_D: 0.1198 (0.4634) Loss_G: -0.0528 (0.3172) D(x): 0.5311 D(G(z)): 0.4552 / 0.4611 Acc: 31.2500 (27.1206)\n",
      "[5/25][466/782] Loss_D: 0.1187 (0.4634) Loss_G: 0.0065 (0.3172) D(x): 0.5241 D(G(z)): 0.4606 / 0.4352 Acc: 31.2500 (27.1215)\n",
      "[5/25][467/782] Loss_D: 0.1545 (0.4633) Loss_G: 0.0692 (0.3171) D(x): 0.5006 D(G(z)): 0.4600 / 0.4159 Acc: 39.0625 (27.1243)\n",
      "[5/25][468/782] Loss_D: 0.1872 (0.4632) Loss_G: -0.0586 (0.3170) D(x): 0.5040 D(G(z)): 0.4514 / 0.4828 Acc: 34.3750 (27.1259)\n",
      "[5/25][469/782] Loss_D: 0.2037 (0.4632) Loss_G: -0.0322 (0.3169) D(x): 0.5685 D(G(z)): 0.5156 / 0.4592 Acc: 29.6875 (27.1265)\n",
      "[5/25][470/782] Loss_D: 0.0455 (0.4631) Loss_G: -0.0583 (0.3169) D(x): 0.5348 D(G(z)): 0.4472 / 0.4311 Acc: 31.2500 (27.1274)\n",
      "[5/25][471/782] Loss_D: 0.1531 (0.4630) Loss_G: 0.1897 (0.3168) D(x): 0.5255 D(G(z)): 0.4685 / 0.3890 Acc: 39.0625 (27.1302)\n",
      "[5/25][472/782] Loss_D: 0.0584 (0.4629) Loss_G: 0.1273 (0.3168) D(x): 0.5348 D(G(z)): 0.4128 / 0.3875 Acc: 29.6875 (27.1307)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/25][473/782] Loss_D: 0.1532 (0.4628) Loss_G: -0.0315 (0.3167) D(x): 0.5190 D(G(z)): 0.4650 / 0.4348 Acc: 31.2500 (27.1317)\n",
      "[5/25][474/782] Loss_D: 0.0696 (0.4627) Loss_G: -0.0387 (0.3166) D(x): 0.5661 D(G(z)): 0.4794 / 0.4506 Acc: 34.3750 (27.1333)\n",
      "[5/25][475/782] Loss_D: 0.0788 (0.4627) Loss_G: 0.1084 (0.3166) D(x): 0.5464 D(G(z)): 0.4466 / 0.4157 Acc: 34.3750 (27.1350)\n",
      "[5/25][476/782] Loss_D: 0.1299 (0.4626) Loss_G: 0.1101 (0.3165) D(x): 0.5171 D(G(z)): 0.4361 / 0.4250 Acc: 34.3750 (27.1366)\n",
      "[5/25][477/782] Loss_D: 0.0401 (0.4625) Loss_G: 0.0856 (0.3165) D(x): 0.5415 D(G(z)): 0.4519 / 0.4122 Acc: 37.5000 (27.1390)\n",
      "[5/25][478/782] Loss_D: -0.0932 (0.4624) Loss_G: 0.0578 (0.3164) D(x): 0.5559 D(G(z)): 0.4613 / 0.4094 Acc: 46.8750 (27.1435)\n",
      "[5/25][479/782] Loss_D: 0.1359 (0.4623) Loss_G: 0.0899 (0.3164) D(x): 0.5352 D(G(z)): 0.4887 / 0.3923 Acc: 34.3750 (27.1451)\n",
      "[5/25][480/782] Loss_D: 0.0718 (0.4622) Loss_G: 0.0562 (0.3163) D(x): 0.4916 D(G(z)): 0.4399 / 0.4092 Acc: 45.3125 (27.1493)\n",
      "[5/25][481/782] Loss_D: 0.1347 (0.4621) Loss_G: -0.0161 (0.3162) D(x): 0.5189 D(G(z)): 0.4693 / 0.4386 Acc: 42.1875 (27.1527)\n",
      "[5/25][482/782] Loss_D: 0.2730 (0.4621) Loss_G: 0.1908 (0.3162) D(x): 0.5263 D(G(z)): 0.4966 / 0.3774 Acc: 29.6875 (27.1533)\n",
      "[5/25][483/782] Loss_D: 0.0655 (0.4620) Loss_G: -0.0713 (0.3161) D(x): 0.5082 D(G(z)): 0.4300 / 0.4703 Acc: 35.9375 (27.1553)\n",
      "[5/25][484/782] Loss_D: 0.2647 (0.4619) Loss_G: 0.0222 (0.3160) D(x): 0.5112 D(G(z)): 0.5235 / 0.4365 Acc: 35.9375 (27.1573)\n",
      "[5/25][485/782] Loss_D: 0.2688 (0.4619) Loss_G: 0.0058 (0.3160) D(x): 0.5121 D(G(z)): 0.5018 / 0.4377 Acc: 34.3750 (27.1589)\n",
      "[5/25][486/782] Loss_D: 0.1078 (0.4618) Loss_G: 0.0041 (0.3159) D(x): 0.5349 D(G(z)): 0.4475 / 0.4299 Acc: 34.3750 (27.1606)\n",
      "[5/25][487/782] Loss_D: 0.1926 (0.4618) Loss_G: -0.0380 (0.3158) D(x): 0.5405 D(G(z)): 0.4870 / 0.4794 Acc: 32.8125 (27.1618)\n",
      "[5/25][488/782] Loss_D: 0.0487 (0.4617) Loss_G: -0.0175 (0.3157) D(x): 0.5396 D(G(z)): 0.4685 / 0.4583 Acc: 42.1875 (27.1653)\n",
      "[5/25][489/782] Loss_D: 0.0395 (0.4616) Loss_G: 0.0105 (0.3157) D(x): 0.5678 D(G(z)): 0.5040 / 0.4159 Acc: 43.7500 (27.1690)\n",
      "[5/25][490/782] Loss_D: 0.2520 (0.4615) Loss_G: 0.1653 (0.3156) D(x): 0.4796 D(G(z)): 0.4629 / 0.3749 Acc: 32.8125 (27.1703)\n",
      "[5/25][491/782] Loss_D: 0.2465 (0.4615) Loss_G: 0.0849 (0.3156) D(x): 0.4681 D(G(z)): 0.4514 / 0.4130 Acc: 31.2500 (27.1712)\n",
      "[5/25][492/782] Loss_D: 0.0931 (0.4614) Loss_G: -0.0250 (0.3155) D(x): 0.4992 D(G(z)): 0.3977 / 0.4650 Acc: 39.0625 (27.1739)\n",
      "[5/25][493/782] Loss_D: 0.1612 (0.4613) Loss_G: -0.0867 (0.3154) D(x): 0.5887 D(G(z)): 0.5128 / 0.4796 Acc: 32.8125 (27.1752)\n",
      "[5/25][494/782] Loss_D: 0.1002 (0.4612) Loss_G: 0.1393 (0.3154) D(x): 0.6294 D(G(z)): 0.5143 / 0.4028 Acc: 32.8125 (27.1765)\n",
      "[5/25][495/782] Loss_D: 0.2915 (0.4612) Loss_G: 0.0650 (0.3153) D(x): 0.4867 D(G(z)): 0.4656 / 0.4115 Acc: 26.5625 (27.1764)\n",
      "[5/25][496/782] Loss_D: 0.2400 (0.4611) Loss_G: -0.0763 (0.3152) D(x): 0.4416 D(G(z)): 0.3921 / 0.4728 Acc: 29.6875 (27.1769)\n",
      "[5/25][497/782] Loss_D: 0.0438 (0.4611) Loss_G: -0.1523 (0.3151) D(x): 0.5792 D(G(z)): 0.4716 / 0.5016 Acc: 29.6875 (27.1775)\n",
      "[5/25][498/782] Loss_D: 0.1591 (0.4610) Loss_G: -0.0485 (0.3150) D(x): 0.5727 D(G(z)): 0.5054 / 0.4581 Acc: 32.8125 (27.1788)\n",
      "[5/25][499/782] Loss_D: -0.1351 (0.4608) Loss_G: 0.0837 (0.3150) D(x): 0.5701 D(G(z)): 0.4161 / 0.4046 Acc: 42.1875 (27.1822)\n",
      "[5/25][500/782] Loss_D: 0.1973 (0.4608) Loss_G: 0.0317 (0.3149) D(x): 0.5303 D(G(z)): 0.4824 / 0.4557 Acc: 39.0625 (27.1849)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[5/25][501/782] Loss_D: 0.2631 (0.4607) Loss_G: 0.0255 (0.3149) D(x): 0.4768 D(G(z)): 0.4581 / 0.4221 Acc: 28.1250 (27.1851)\n",
      "[5/25][502/782] Loss_D: 0.1952 (0.4607) Loss_G: -0.0576 (0.3148) D(x): 0.5333 D(G(z)): 0.5079 / 0.4436 Acc: 26.5625 (27.1850)\n",
      "[5/25][503/782] Loss_D: -0.0555 (0.4606) Loss_G: -0.0554 (0.3147) D(x): 0.5151 D(G(z)): 0.4405 / 0.4716 Acc: 50.0000 (27.1901)\n",
      "[5/25][504/782] Loss_D: 0.1492 (0.4605) Loss_G: -0.0402 (0.3146) D(x): 0.5827 D(G(z)): 0.5554 / 0.4519 Acc: 43.7500 (27.1939)\n",
      "[5/25][505/782] Loss_D: 0.1961 (0.4604) Loss_G: 0.0908 (0.3146) D(x): 0.5133 D(G(z)): 0.4748 / 0.3908 Acc: 32.8125 (27.1951)\n",
      "[5/25][506/782] Loss_D: 0.3249 (0.4604) Loss_G: 0.0683 (0.3145) D(x): 0.4593 D(G(z)): 0.4299 / 0.4406 Acc: 29.6875 (27.1957)\n",
      "[5/25][507/782] Loss_D: 0.1469 (0.4603) Loss_G: -0.0309 (0.3144) D(x): 0.5148 D(G(z)): 0.4278 / 0.4392 Acc: 28.1250 (27.1959)\n",
      "[5/25][508/782] Loss_D: 0.3077 (0.4603) Loss_G: 0.1316 (0.3144) D(x): 0.5371 D(G(z)): 0.4863 / 0.4266 Acc: 29.6875 (27.1965)\n",
      "[5/25][509/782] Loss_D: -0.0145 (0.4602) Loss_G: -0.1199 (0.3143) D(x): 0.5327 D(G(z)): 0.4394 / 0.4563 Acc: 35.9375 (27.1985)\n",
      "[5/25][510/782] Loss_D: 0.1886 (0.4601) Loss_G: -0.0883 (0.3142) D(x): 0.5330 D(G(z)): 0.5032 / 0.4724 Acc: 32.8125 (27.1997)\n",
      "[5/25][511/782] Loss_D: 0.0272 (0.4600) Loss_G: 0.0737 (0.3141) D(x): 0.5944 D(G(z)): 0.4853 / 0.4120 Acc: 35.9375 (27.2017)\n",
      "[5/25][512/782] Loss_D: 0.0764 (0.4599) Loss_G: 0.0928 (0.3141) D(x): 0.5353 D(G(z)): 0.4514 / 0.4108 Acc: 34.3750 (27.2033)\n",
      "[5/25][513/782] Loss_D: 0.1436 (0.4599) Loss_G: 0.0097 (0.3140) D(x): 0.5161 D(G(z)): 0.3979 / 0.4461 Acc: 28.1250 (27.2035)\n",
      "[5/25][514/782] Loss_D: 0.0554 (0.4598) Loss_G: -0.0388 (0.3139) D(x): 0.5330 D(G(z)): 0.4696 / 0.4835 Acc: 42.1875 (27.2069)\n",
      "[5/25][515/782] Loss_D: 0.1311 (0.4597) Loss_G: -0.1404 (0.3138) D(x): 0.5626 D(G(z)): 0.4821 / 0.4858 Acc: 28.1250 (27.2071)\n",
      "[5/25][516/782] Loss_D: 0.1382 (0.4596) Loss_G: 0.0490 (0.3138) D(x): 0.5030 D(G(z)): 0.4816 / 0.4288 Acc: 42.1875 (27.2105)\n",
      "[5/25][517/782] Loss_D: 0.1916 (0.4596) Loss_G: 0.0959 (0.3137) D(x): 0.5177 D(G(z)): 0.4547 / 0.4346 Acc: 40.6250 (27.2135)\n",
      "[5/25][518/782] Loss_D: 0.0306 (0.4595) Loss_G: -0.0827 (0.3136) D(x): 0.5315 D(G(z)): 0.4886 / 0.4632 Acc: 40.6250 (27.2166)\n",
      "[5/25][519/782] Loss_D: 0.1063 (0.4594) Loss_G: -0.0217 (0.3136) D(x): 0.5273 D(G(z)): 0.4320 / 0.4528 Acc: 26.5625 (27.2164)\n",
      "[5/25][520/782] Loss_D: 0.3133 (0.4594) Loss_G: -0.1390 (0.3135) D(x): 0.5534 D(G(z)): 0.4994 / 0.4898 Acc: 17.1875 (27.2142)\n",
      "[5/25][521/782] Loss_D: 0.1349 (0.4593) Loss_G: 0.1016 (0.3134) D(x): 0.5409 D(G(z)): 0.4309 / 0.4304 Acc: 29.6875 (27.2147)\n",
      "[5/25][522/782] Loss_D: 0.0873 (0.4592) Loss_G: 0.0789 (0.3134) D(x): 0.5270 D(G(z)): 0.4265 / 0.4248 Acc: 32.8125 (27.2160)\n",
      "[5/25][523/782] Loss_D: 0.1839 (0.4591) Loss_G: -0.0671 (0.3133) D(x): 0.4961 D(G(z)): 0.4501 / 0.4642 Acc: 32.8125 (27.2172)\n",
      "[5/25][524/782] Loss_D: 0.0801 (0.4591) Loss_G: -0.0732 (0.3132) D(x): 0.5886 D(G(z)): 0.4801 / 0.4796 Acc: 32.8125 (27.2185)\n",
      "[5/25][525/782] Loss_D: -0.0489 (0.4589) Loss_G: -0.0098 (0.3131) D(x): 0.6151 D(G(z)): 0.4869 / 0.4422 Acc: 42.1875 (27.2219)\n",
      "[5/25][526/782] Loss_D: 0.1561 (0.4589) Loss_G: 0.1424 (0.3131) D(x): 0.4961 D(G(z)): 0.4474 / 0.3868 Acc: 32.8125 (27.2231)\n",
      "[5/25][527/782] Loss_D: -0.0176 (0.4588) Loss_G: 0.0853 (0.3130) D(x): 0.5011 D(G(z)): 0.3828 / 0.4168 Acc: 40.6250 (27.2262)\n",
      "[5/25][528/782] Loss_D: 0.1326 (0.4587) Loss_G: -0.0212 (0.3130) D(x): 0.5444 D(G(z)): 0.4939 / 0.4446 Acc: 34.3750 (27.2278)\n",
      "[5/25][529/782] Loss_D: 0.0565 (0.4586) Loss_G: -0.0099 (0.3129) D(x): 0.5346 D(G(z)): 0.4818 / 0.4174 Acc: 39.0625 (27.2304)\n",
      "[5/25][530/782] Loss_D: 0.1613 (0.4585) Loss_G: 0.0725 (0.3128) D(x): 0.5299 D(G(z)): 0.4543 / 0.4257 Acc: 29.6875 (27.2310)\n",
      "[5/25][531/782] Loss_D: 0.2250 (0.4585) Loss_G: 0.1395 (0.3128) D(x): 0.5411 D(G(z)): 0.4901 / 0.4390 Acc: 40.6250 (27.2340)\n",
      "[5/25][532/782] Loss_D: 0.1205 (0.4584) Loss_G: -0.0628 (0.3127) D(x): 0.4921 D(G(z)): 0.4170 / 0.4634 Acc: 32.8125 (27.2353)\n",
      "[5/25][533/782] Loss_D: 0.0697 (0.4583) Loss_G: -0.0209 (0.3126) D(x): 0.5975 D(G(z)): 0.5018 / 0.4674 Acc: 32.8125 (27.2365)\n",
      "[5/25][534/782] Loss_D: 0.3257 (0.4583) Loss_G: 0.0522 (0.3126) D(x): 0.4434 D(G(z)): 0.4460 / 0.4428 Acc: 37.5000 (27.2388)\n",
      "[5/25][535/782] Loss_D: 0.0398 (0.4582) Loss_G: -0.0976 (0.3125) D(x): 0.5109 D(G(z)): 0.4151 / 0.4823 Acc: 37.5000 (27.2411)\n",
      "[5/25][536/782] Loss_D: 0.3763 (0.4582) Loss_G: -0.1420 (0.3124) D(x): 0.5194 D(G(z)): 0.5477 / 0.5130 Acc: 35.9375 (27.2431)\n",
      "[5/25][537/782] Loss_D: 0.2176 (0.4581) Loss_G: -0.0979 (0.3123) D(x): 0.5579 D(G(z)): 0.5464 / 0.4796 Acc: 37.5000 (27.2454)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/25][538/782] Loss_D: 0.1543 (0.4581) Loss_G: 0.0239 (0.3122) D(x): 0.5135 D(G(z)): 0.4789 / 0.4203 Acc: 31.2500 (27.2463)\n",
      "[5/25][539/782] Loss_D: -0.0705 (0.4579) Loss_G: -0.0300 (0.3121) D(x): 0.5076 D(G(z)): 0.4129 / 0.4469 Acc: 45.3125 (27.2504)\n",
      "[5/25][540/782] Loss_D: 0.1933 (0.4579) Loss_G: -0.0768 (0.3121) D(x): 0.4999 D(G(z)): 0.4376 / 0.4974 Acc: 32.8125 (27.2516)\n",
      "[5/25][541/782] Loss_D: 0.0298 (0.4578) Loss_G: 0.0127 (0.3120) D(x): 0.5648 D(G(z)): 0.4489 / 0.4322 Acc: 35.9375 (27.2536)\n",
      "[5/25][542/782] Loss_D: 0.2483 (0.4577) Loss_G: -0.0454 (0.3119) D(x): 0.5191 D(G(z)): 0.4702 / 0.4429 Acc: 23.4375 (27.2527)\n",
      "[5/25][543/782] Loss_D: 0.1764 (0.4577) Loss_G: -0.1284 (0.3118) D(x): 0.5242 D(G(z)): 0.5004 / 0.4750 Acc: 31.2500 (27.2536)\n",
      "[5/25][544/782] Loss_D: 0.2510 (0.4576) Loss_G: 0.0027 (0.3117) D(x): 0.4979 D(G(z)): 0.4969 / 0.4272 Acc: 29.6875 (27.2541)\n",
      "[5/25][545/782] Loss_D: 0.2103 (0.4576) Loss_G: 0.0829 (0.3117) D(x): 0.5175 D(G(z)): 0.4511 / 0.4152 Acc: 26.5625 (27.2540)\n",
      "[5/25][546/782] Loss_D: 0.0938 (0.4575) Loss_G: -0.0838 (0.3116) D(x): 0.5029 D(G(z)): 0.4361 / 0.4658 Acc: 35.9375 (27.2559)\n",
      "[5/25][547/782] Loss_D: 0.0787 (0.4574) Loss_G: -0.0239 (0.3115) D(x): 0.5437 D(G(z)): 0.4713 / 0.4401 Acc: 32.8125 (27.2572)\n",
      "[5/25][548/782] Loss_D: 0.0501 (0.4573) Loss_G: -0.1798 (0.3114) D(x): 0.5487 D(G(z)): 0.4993 / 0.4874 Acc: 40.6250 (27.2602)\n",
      "[5/25][549/782] Loss_D: -0.0104 (0.4572) Loss_G: 0.1273 (0.3114) D(x): 0.5719 D(G(z)): 0.4300 / 0.4113 Acc: 37.5000 (27.2625)\n",
      "[5/25][550/782] Loss_D: 0.1875 (0.4571) Loss_G: -0.0247 (0.3113) D(x): 0.5105 D(G(z)): 0.4321 / 0.4579 Acc: 28.1250 (27.2627)\n",
      "[5/25][551/782] Loss_D: 0.2258 (0.4571) Loss_G: 0.0421 (0.3112) D(x): 0.5656 D(G(z)): 0.5037 / 0.4362 Acc: 29.6875 (27.2632)\n",
      "[5/25][552/782] Loss_D: 0.2437 (0.4570) Loss_G: -0.0947 (0.3111) D(x): 0.5198 D(G(z)): 0.5055 / 0.4603 Acc: 29.6875 (27.2638)\n",
      "[5/25][553/782] Loss_D: 0.1584 (0.4570) Loss_G: -0.0015 (0.3111) D(x): 0.5055 D(G(z)): 0.4446 / 0.4343 Acc: 29.6875 (27.2643)\n",
      "[5/25][554/782] Loss_D: -0.0385 (0.4569) Loss_G: -0.1190 (0.3110) D(x): 0.5370 D(G(z)): 0.4523 / 0.4691 Acc: 40.6250 (27.2673)\n",
      "[5/25][555/782] Loss_D: 0.2671 (0.4568) Loss_G: -0.0032 (0.3109) D(x): 0.4737 D(G(z)): 0.4692 / 0.4745 Acc: 35.9375 (27.2692)\n",
      "[5/25][556/782] Loss_D: 0.0802 (0.4567) Loss_G: -0.0956 (0.3108) D(x): 0.5098 D(G(z)): 0.4337 / 0.4798 Acc: 35.9375 (27.2712)\n",
      "[5/25][557/782] Loss_D: 0.2771 (0.4567) Loss_G: -0.0518 (0.3107) D(x): 0.5635 D(G(z)): 0.5286 / 0.4687 Acc: 26.5625 (27.2710)\n",
      "[5/25][558/782] Loss_D: 0.2089 (0.4566) Loss_G: -0.1281 (0.3106) D(x): 0.5191 D(G(z)): 0.4945 / 0.5001 Acc: 35.9375 (27.2729)\n",
      "[5/25][559/782] Loss_D: 0.1989 (0.4566) Loss_G: -0.1624 (0.3105) D(x): 0.5186 D(G(z)): 0.4543 / 0.4969 Acc: 25.0000 (27.2724)\n",
      "[5/25][560/782] Loss_D: 0.1510 (0.4565) Loss_G: 0.0992 (0.3105) D(x): 0.5320 D(G(z)): 0.4285 / 0.4186 Acc: 29.6875 (27.2730)\n",
      "[5/25][561/782] Loss_D: 0.0598 (0.4564) Loss_G: -0.1302 (0.3104) D(x): 0.5004 D(G(z)): 0.4639 / 0.4698 Acc: 40.6250 (27.2760)\n",
      "[5/25][562/782] Loss_D: 0.1070 (0.4564) Loss_G: -0.1358 (0.3103) D(x): 0.5237 D(G(z)): 0.4687 / 0.5031 Acc: 37.5000 (27.2783)\n",
      "[5/25][563/782] Loss_D: 0.2558 (0.4563) Loss_G: 0.0998 (0.3102) D(x): 0.5478 D(G(z)): 0.5140 / 0.4157 Acc: 32.8125 (27.2795)\n",
      "[5/25][564/782] Loss_D: -0.0120 (0.4562) Loss_G: 0.0549 (0.3102) D(x): 0.5429 D(G(z)): 0.4203 / 0.4225 Acc: 39.0625 (27.2821)\n",
      "[5/25][565/782] Loss_D: 0.1306 (0.4561) Loss_G: 0.0739 (0.3101) D(x): 0.5253 D(G(z)): 0.4882 / 0.3932 Acc: 35.9375 (27.2841)\n",
      "[5/25][566/782] Loss_D: 0.0550 (0.4560) Loss_G: 0.0379 (0.3101) D(x): 0.5020 D(G(z)): 0.4502 / 0.4117 Acc: 43.7500 (27.2877)\n",
      "[5/25][567/782] Loss_D: 0.3134 (0.4560) Loss_G: -0.0585 (0.3100) D(x): 0.5114 D(G(z)): 0.4449 / 0.4713 Acc: 18.7500 (27.2858)\n",
      "[5/25][568/782] Loss_D: -0.0229 (0.4559) Loss_G: -0.0602 (0.3099) D(x): 0.5340 D(G(z)): 0.4676 / 0.4666 Acc: 48.4375 (27.2906)\n",
      "[5/25][569/782] Loss_D: 0.1571 (0.4558) Loss_G: -0.1526 (0.3098) D(x): 0.5078 D(G(z)): 0.4798 / 0.4787 Acc: 31.2500 (27.2914)\n",
      "[5/25][570/782] Loss_D: 0.1655 (0.4558) Loss_G: -0.0740 (0.3097) D(x): 0.5761 D(G(z)): 0.4911 / 0.4874 Acc: 29.6875 (27.2920)\n",
      "[5/25][571/782] Loss_D: 0.1374 (0.4557) Loss_G: 0.1939 (0.3097) D(x): 0.5295 D(G(z)): 0.4359 / 0.4031 Acc: 29.6875 (27.2925)\n",
      "[5/25][572/782] Loss_D: 0.1641 (0.4556) Loss_G: 0.0964 (0.3096) D(x): 0.5771 D(G(z)): 0.4636 / 0.4137 Acc: 25.0000 (27.2920)\n",
      "[5/25][573/782] Loss_D: 0.0517 (0.4555) Loss_G: 0.1079 (0.3096) D(x): 0.5148 D(G(z)): 0.4219 / 0.4168 Acc: 42.1875 (27.2953)\n",
      "[5/25][574/782] Loss_D: -0.0079 (0.4554) Loss_G: -0.1000 (0.3095) D(x): 0.5513 D(G(z)): 0.4623 / 0.4722 Acc: 42.1875 (27.2986)\n",
      "[5/25][575/782] Loss_D: 0.0879 (0.4554) Loss_G: -0.1772 (0.3094) D(x): 0.5406 D(G(z)): 0.4456 / 0.4831 Acc: 25.0000 (27.2981)\n",
      "[5/25][576/782] Loss_D: 0.3056 (0.4553) Loss_G: 0.0247 (0.3093) D(x): 0.5151 D(G(z)): 0.5439 / 0.4323 Acc: 32.8125 (27.2994)\n",
      "[5/25][577/782] Loss_D: 0.0938 (0.4552) Loss_G: 0.0284 (0.3093) D(x): 0.5386 D(G(z)): 0.4374 / 0.4206 Acc: 28.1250 (27.2995)\n",
      "[5/25][578/782] Loss_D: 0.2752 (0.4552) Loss_G: 0.0547 (0.3092) D(x): 0.5233 D(G(z)): 0.4895 / 0.4636 Acc: 34.3750 (27.3011)\n",
      "[5/25][579/782] Loss_D: 0.0030 (0.4551) Loss_G: -0.0659 (0.3091) D(x): 0.5492 D(G(z)): 0.4662 / 0.4543 Acc: 37.5000 (27.3034)\n",
      "[5/25][580/782] Loss_D: 0.0175 (0.4550) Loss_G: -0.0005 (0.3091) D(x): 0.5352 D(G(z)): 0.4551 / 0.4325 Acc: 43.7500 (27.3070)\n",
      "[5/25][581/782] Loss_D: 0.0696 (0.4549) Loss_G: -0.0112 (0.3090) D(x): 0.5397 D(G(z)): 0.4802 / 0.4364 Acc: 37.5000 (27.3093)\n",
      "[5/25][582/782] Loss_D: 0.1388 (0.4549) Loss_G: 0.0209 (0.3089) D(x): 0.5367 D(G(z)): 0.4706 / 0.4259 Acc: 29.6875 (27.3098)\n",
      "[5/25][583/782] Loss_D: 0.1428 (0.4548) Loss_G: -0.0542 (0.3088) D(x): 0.4813 D(G(z)): 0.3950 / 0.4553 Acc: 32.8125 (27.3111)\n",
      "[5/25][584/782] Loss_D: 0.1458 (0.4547) Loss_G: 0.2315 (0.3088) D(x): 0.6025 D(G(z)): 0.5039 / 0.3726 Acc: 31.2500 (27.3119)\n",
      "[5/25][585/782] Loss_D: 0.1674 (0.4547) Loss_G: 0.0399 (0.3088) D(x): 0.5469 D(G(z)): 0.5029 / 0.4402 Acc: 37.5000 (27.3142)\n",
      "[5/25][586/782] Loss_D: 0.2497 (0.4546) Loss_G: 0.0657 (0.3087) D(x): 0.5180 D(G(z)): 0.4841 / 0.4118 Acc: 28.1250 (27.3144)\n",
      "[5/25][587/782] Loss_D: 0.1580 (0.4545) Loss_G: 0.1652 (0.3087) D(x): 0.5394 D(G(z)): 0.4979 / 0.3899 Acc: 34.3750 (27.3160)\n",
      "[5/25][588/782] Loss_D: 0.2829 (0.4545) Loss_G: 0.1045 (0.3086) D(x): 0.5127 D(G(z)): 0.4384 / 0.4321 Acc: 28.1250 (27.3161)\n",
      "[5/25][589/782] Loss_D: 0.0552 (0.4544) Loss_G: 0.0446 (0.3086) D(x): 0.5400 D(G(z)): 0.4653 / 0.4107 Acc: 35.9375 (27.3181)\n",
      "[5/25][590/782] Loss_D: 0.2151 (0.4544) Loss_G: 0.0325 (0.3085) D(x): 0.5019 D(G(z)): 0.4668 / 0.4492 Acc: 35.9375 (27.3200)\n",
      "[5/25][591/782] Loss_D: 0.3124 (0.4543) Loss_G: 0.0748 (0.3085) D(x): 0.4944 D(G(z)): 0.4398 / 0.4317 Acc: 26.5625 (27.3198)\n",
      "[5/25][592/782] Loss_D: 0.1820 (0.4543) Loss_G: 0.0703 (0.3084) D(x): 0.5109 D(G(z)): 0.4972 / 0.4073 Acc: 35.9375 (27.3217)\n",
      "[5/25][593/782] Loss_D: 0.2264 (0.4542) Loss_G: 0.1813 (0.3084) D(x): 0.4920 D(G(z)): 0.4682 / 0.4005 Acc: 29.6875 (27.3222)\n",
      "[5/25][594/782] Loss_D: 0.2725 (0.4542) Loss_G: -0.0531 (0.3083) D(x): 0.4998 D(G(z)): 0.4835 / 0.4688 Acc: 37.5000 (27.3245)\n",
      "[5/25][595/782] Loss_D: 0.2205 (0.4541) Loss_G: 0.0251 (0.3082) D(x): 0.4684 D(G(z)): 0.4839 / 0.4207 Acc: 37.5000 (27.3268)\n",
      "[5/25][596/782] Loss_D: 0.1772 (0.4541) Loss_G: 0.0442 (0.3082) D(x): 0.5852 D(G(z)): 0.4606 / 0.4369 Acc: 23.4375 (27.3259)\n",
      "[5/25][597/782] Loss_D: -0.1182 (0.4539) Loss_G: -0.0606 (0.3081) D(x): 0.5622 D(G(z)): 0.3380 / 0.4465 Acc: 31.2500 (27.3268)\n",
      "[5/25][598/782] Loss_D: 0.1273 (0.4539) Loss_G: 0.1098 (0.3081) D(x): 0.6090 D(G(z)): 0.4891 / 0.4149 Acc: 29.6875 (27.3273)\n",
      "[5/25][599/782] Loss_D: -0.0522 (0.4538) Loss_G: 0.0471 (0.3080) D(x): 0.5038 D(G(z)): 0.3949 / 0.4190 Acc: 45.3125 (27.3313)\n",
      "[5/25][600/782] Loss_D: 0.1170 (0.4537) Loss_G: 0.1694 (0.3080) D(x): 0.5613 D(G(z)): 0.4742 / 0.4146 Acc: 37.5000 (27.3335)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[5/25][601/782] Loss_D: 0.1803 (0.4536) Loss_G: 0.0819 (0.3079) D(x): 0.5432 D(G(z)): 0.4812 / 0.4305 Acc: 31.2500 (27.3344)\n",
      "[5/25][602/782] Loss_D: 0.1625 (0.4536) Loss_G: -0.0249 (0.3078) D(x): 0.4873 D(G(z)): 0.4166 / 0.4285 Acc: 28.1250 (27.3346)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/25][603/782] Loss_D: 0.2100 (0.4535) Loss_G: -0.0156 (0.3078) D(x): 0.5529 D(G(z)): 0.4896 / 0.4403 Acc: 23.4375 (27.3337)\n",
      "[5/25][604/782] Loss_D: 0.1484 (0.4534) Loss_G: 0.1603 (0.3077) D(x): 0.6044 D(G(z)): 0.5158 / 0.3824 Acc: 28.1250 (27.3339)\n",
      "[5/25][605/782] Loss_D: 0.2736 (0.4534) Loss_G: 0.0478 (0.3077) D(x): 0.4671 D(G(z)): 0.4224 / 0.4469 Acc: 26.5625 (27.3337)\n",
      "[5/25][606/782] Loss_D: 0.1031 (0.4533) Loss_G: -0.1024 (0.3076) D(x): 0.5139 D(G(z)): 0.4662 / 0.5046 Acc: 40.6250 (27.3367)\n",
      "[5/25][607/782] Loss_D: 0.2184 (0.4533) Loss_G: -0.0314 (0.3075) D(x): 0.5250 D(G(z)): 0.5116 / 0.4518 Acc: 35.9375 (27.3386)\n",
      "[5/25][608/782] Loss_D: 0.0732 (0.4532) Loss_G: -0.0999 (0.3074) D(x): 0.5883 D(G(z)): 0.5064 / 0.4620 Acc: 35.9375 (27.3405)\n",
      "[5/25][609/782] Loss_D: 0.3484 (0.4532) Loss_G: 0.1953 (0.3074) D(x): 0.5133 D(G(z)): 0.5526 / 0.3764 Acc: 32.8125 (27.3417)\n",
      "[5/25][610/782] Loss_D: 0.2933 (0.4531) Loss_G: 0.0760 (0.3074) D(x): 0.4351 D(G(z)): 0.4092 / 0.4319 Acc: 31.2500 (27.3425)\n",
      "[5/25][611/782] Loss_D: 0.2045 (0.4531) Loss_G: -0.2112 (0.3072) D(x): 0.5086 D(G(z)): 0.4318 / 0.5339 Acc: 26.5625 (27.3424)\n",
      "[5/25][612/782] Loss_D: 0.2894 (0.4530) Loss_G: -0.0209 (0.3072) D(x): 0.5620 D(G(z)): 0.5442 / 0.4608 Acc: 28.1250 (27.3425)\n",
      "[5/25][613/782] Loss_D: 0.2791 (0.4530) Loss_G: -0.1200 (0.3071) D(x): 0.5199 D(G(z)): 0.5257 / 0.4781 Acc: 32.8125 (27.3438)\n",
      "[5/25][614/782] Loss_D: 0.2173 (0.4529) Loss_G: 0.0332 (0.3070) D(x): 0.5574 D(G(z)): 0.4916 / 0.4445 Acc: 28.1250 (27.3439)\n",
      "[5/25][615/782] Loss_D: 0.2523 (0.4529) Loss_G: 0.1099 (0.3070) D(x): 0.5137 D(G(z)): 0.4439 / 0.4310 Acc: 29.6875 (27.3444)\n",
      "[5/25][616/782] Loss_D: 0.1126 (0.4528) Loss_G: 0.1003 (0.3069) D(x): 0.5479 D(G(z)): 0.4351 / 0.4128 Acc: 28.1250 (27.3446)\n",
      "[5/25][617/782] Loss_D: -0.0599 (0.4527) Loss_G: -0.1090 (0.3068) D(x): 0.4952 D(G(z)): 0.4093 / 0.4628 Acc: 45.3125 (27.3486)\n",
      "[5/25][618/782] Loss_D: 0.0468 (0.4526) Loss_G: -0.0257 (0.3068) D(x): 0.5789 D(G(z)): 0.4783 / 0.4704 Acc: 40.6250 (27.3515)\n",
      "[5/25][619/782] Loss_D: 0.2418 (0.4526) Loss_G: 0.2262 (0.3067) D(x): 0.5447 D(G(z)): 0.5029 / 0.4023 Acc: 39.0625 (27.3541)\n",
      "[5/25][620/782] Loss_D: 0.0914 (0.4525) Loss_G: 0.0767 (0.3067) D(x): 0.5417 D(G(z)): 0.4491 / 0.4111 Acc: 32.8125 (27.3553)\n",
      "[5/25][621/782] Loss_D: 0.0702 (0.4524) Loss_G: -0.1243 (0.3066) D(x): 0.5135 D(G(z)): 0.4458 / 0.4789 Acc: 39.0625 (27.3579)\n",
      "[5/25][622/782] Loss_D: -0.0242 (0.4523) Loss_G: 0.0562 (0.3065) D(x): 0.6062 D(G(z)): 0.4889 / 0.4177 Acc: 37.5000 (27.3601)\n",
      "[5/25][623/782] Loss_D: 0.0287 (0.4522) Loss_G: 0.1447 (0.3065) D(x): 0.5593 D(G(z)): 0.4435 / 0.3683 Acc: 32.8125 (27.3613)\n",
      "[5/25][624/782] Loss_D: 0.1762 (0.4521) Loss_G: 0.2563 (0.3065) D(x): 0.5066 D(G(z)): 0.4411 / 0.3501 Acc: 25.0000 (27.3608)\n",
      "[5/25][625/782] Loss_D: 0.3158 (0.4521) Loss_G: 0.0340 (0.3064) D(x): 0.4735 D(G(z)): 0.5087 / 0.4478 Acc: 40.6250 (27.3637)\n",
      "[5/25][626/782] Loss_D: 0.1890 (0.4521) Loss_G: 0.0133 (0.3064) D(x): 0.5412 D(G(z)): 0.4850 / 0.4140 Acc: 31.2500 (27.3646)\n",
      "[5/25][627/782] Loss_D: 0.1859 (0.4520) Loss_G: -0.0448 (0.3063) D(x): 0.4885 D(G(z)): 0.4428 / 0.4716 Acc: 34.3750 (27.3661)\n",
      "[5/25][628/782] Loss_D: 0.2149 (0.4519) Loss_G: -0.0440 (0.3062) D(x): 0.5631 D(G(z)): 0.5013 / 0.4742 Acc: 32.8125 (27.3673)\n",
      "[5/25][629/782] Loss_D: 0.2166 (0.4519) Loss_G: 0.0521 (0.3062) D(x): 0.5072 D(G(z)): 0.4985 / 0.4236 Acc: 35.9375 (27.3692)\n",
      "[5/25][630/782] Loss_D: -0.0572 (0.4518) Loss_G: 0.0775 (0.3061) D(x): 0.5350 D(G(z)): 0.4540 / 0.4312 Acc: 50.0000 (27.3742)\n",
      "[5/25][631/782] Loss_D: 0.1330 (0.4517) Loss_G: 0.0648 (0.3060) D(x): 0.4792 D(G(z)): 0.4582 / 0.4454 Acc: 45.3125 (27.3782)\n",
      "[5/25][632/782] Loss_D: 0.2705 (0.4517) Loss_G: -0.0057 (0.3060) D(x): 0.4959 D(G(z)): 0.4426 / 0.4266 Acc: 20.3125 (27.3766)\n",
      "[5/25][633/782] Loss_D: 0.3314 (0.4516) Loss_G: -0.0488 (0.3059) D(x): 0.4926 D(G(z)): 0.4929 / 0.4642 Acc: 29.6875 (27.3771)\n",
      "[5/25][634/782] Loss_D: 0.0172 (0.4516) Loss_G: -0.0807 (0.3058) D(x): 0.5233 D(G(z)): 0.4624 / 0.4814 Acc: 48.4375 (27.3817)\n",
      "[5/25][635/782] Loss_D: 0.1675 (0.4515) Loss_G: -0.0596 (0.3057) D(x): 0.5675 D(G(z)): 0.5092 / 0.4540 Acc: 34.3750 (27.3833)\n",
      "[5/25][636/782] Loss_D: 0.0297 (0.4514) Loss_G: 0.1459 (0.3057) D(x): 0.5315 D(G(z)): 0.4462 / 0.4016 Acc: 42.1875 (27.3865)\n",
      "[5/25][637/782] Loss_D: 0.3597 (0.4514) Loss_G: 0.1948 (0.3057) D(x): 0.4759 D(G(z)): 0.4662 / 0.4077 Acc: 37.5000 (27.3888)\n",
      "[5/25][638/782] Loss_D: 0.2282 (0.4513) Loss_G: -0.0134 (0.3056) D(x): 0.5084 D(G(z)): 0.4664 / 0.4362 Acc: 35.9375 (27.3906)\n",
      "[5/25][639/782] Loss_D: 0.2723 (0.4513) Loss_G: -0.0354 (0.3055) D(x): 0.5300 D(G(z)): 0.5235 / 0.4561 Acc: 34.3750 (27.3922)\n",
      "[5/25][640/782] Loss_D: 0.1910 (0.4512) Loss_G: -0.0262 (0.3055) D(x): 0.5322 D(G(z)): 0.5121 / 0.4499 Acc: 39.0625 (27.3947)\n",
      "[5/25][641/782] Loss_D: 0.0296 (0.4511) Loss_G: 0.2017 (0.3054) D(x): 0.5390 D(G(z)): 0.4093 / 0.3684 Acc: 31.2500 (27.3956)\n",
      "[5/25][642/782] Loss_D: 0.1029 (0.4511) Loss_G: 0.1132 (0.3054) D(x): 0.5597 D(G(z)): 0.4387 / 0.4129 Acc: 32.8125 (27.3968)\n",
      "[5/25][643/782] Loss_D: 0.2928 (0.4510) Loss_G: 0.1879 (0.3054) D(x): 0.5646 D(G(z)): 0.5084 / 0.3923 Acc: 28.1250 (27.3969)\n",
      "[5/25][644/782] Loss_D: 0.3335 (0.4510) Loss_G: -0.0014 (0.3053) D(x): 0.4833 D(G(z)): 0.4689 / 0.4564 Acc: 35.9375 (27.3988)\n",
      "[5/25][645/782] Loss_D: 0.3198 (0.4510) Loss_G: -0.0257 (0.3052) D(x): 0.5246 D(G(z)): 0.5075 / 0.4701 Acc: 29.6875 (27.3993)\n",
      "[5/25][646/782] Loss_D: 0.3616 (0.4510) Loss_G: 0.0775 (0.3052) D(x): 0.4915 D(G(z)): 0.4880 / 0.4383 Acc: 35.9375 (27.4012)\n",
      "[5/25][647/782] Loss_D: 0.1191 (0.4509) Loss_G: -0.0123 (0.3051) D(x): 0.5571 D(G(z)): 0.5218 / 0.4725 Acc: 45.3125 (27.4051)\n",
      "[5/25][648/782] Loss_D: 0.2374 (0.4508) Loss_G: 0.0576 (0.3051) D(x): 0.5118 D(G(z)): 0.4713 / 0.4118 Acc: 31.2500 (27.4060)\n",
      "[5/25][649/782] Loss_D: 0.2664 (0.4508) Loss_G: -0.0648 (0.3050) D(x): 0.4840 D(G(z)): 0.4587 / 0.4721 Acc: 31.2500 (27.4068)\n",
      "[5/25][650/782] Loss_D: 0.0897 (0.4507) Loss_G: -0.0732 (0.3049) D(x): 0.5181 D(G(z)): 0.4843 / 0.4493 Acc: 42.1875 (27.4100)\n",
      "[5/25][651/782] Loss_D: 0.2068 (0.4507) Loss_G: 0.0073 (0.3048) D(x): 0.5644 D(G(z)): 0.5258 / 0.4449 Acc: 35.9375 (27.4119)\n",
      "[5/25][652/782] Loss_D: 0.2122 (0.4506) Loss_G: 0.1383 (0.3048) D(x): 0.4744 D(G(z)): 0.4550 / 0.3939 Acc: 37.5000 (27.4141)\n",
      "[5/25][653/782] Loss_D: 0.1782 (0.4505) Loss_G: 0.0526 (0.3047) D(x): 0.5325 D(G(z)): 0.4766 / 0.4389 Acc: 32.8125 (27.4153)\n",
      "[5/25][654/782] Loss_D: 0.0139 (0.4505) Loss_G: 0.0291 (0.3047) D(x): 0.5054 D(G(z)): 0.4162 / 0.4265 Acc: 42.1875 (27.4185)\n",
      "[5/25][655/782] Loss_D: 0.1449 (0.4504) Loss_G: -0.0468 (0.3046) D(x): 0.4953 D(G(z)): 0.4329 / 0.4686 Acc: 32.8125 (27.4197)\n",
      "[5/25][656/782] Loss_D: 0.2840 (0.4503) Loss_G: -0.0779 (0.3045) D(x): 0.5498 D(G(z)): 0.5605 / 0.4608 Acc: 34.3750 (27.4212)\n",
      "[5/25][657/782] Loss_D: 0.1932 (0.4503) Loss_G: 0.0313 (0.3045) D(x): 0.5189 D(G(z)): 0.4742 / 0.4037 Acc: 25.0000 (27.4207)\n",
      "[5/25][658/782] Loss_D: 0.3236 (0.4503) Loss_G: 0.0717 (0.3044) D(x): 0.5297 D(G(z)): 0.4728 / 0.4500 Acc: 26.5625 (27.4205)\n",
      "[5/25][659/782] Loss_D: 0.2305 (0.4502) Loss_G: -0.1653 (0.3043) D(x): 0.4880 D(G(z)): 0.4792 / 0.4881 Acc: 34.3750 (27.4220)\n",
      "[5/25][660/782] Loss_D: 0.3817 (0.4502) Loss_G: -0.0950 (0.3042) D(x): 0.5076 D(G(z)): 0.5650 / 0.4836 Acc: 32.8125 (27.4232)\n",
      "[5/25][661/782] Loss_D: 0.3088 (0.4502) Loss_G: 0.0401 (0.3042) D(x): 0.5368 D(G(z)): 0.5178 / 0.4180 Acc: 29.6875 (27.4237)\n",
      "[5/25][662/782] Loss_D: 0.5267 (0.4502) Loss_G: -0.0498 (0.3041) D(x): 0.4303 D(G(z)): 0.4827 / 0.4911 Acc: 25.0000 (27.4232)\n",
      "[5/25][663/782] Loss_D: 0.2293 (0.4501) Loss_G: -0.0740 (0.3040) D(x): 0.5140 D(G(z)): 0.4922 / 0.4885 Acc: 34.3750 (27.4247)\n",
      "[5/25][664/782] Loss_D: 0.2145 (0.4501) Loss_G: -0.1164 (0.3039) D(x): 0.5501 D(G(z)): 0.5168 / 0.4912 Acc: 31.2500 (27.4255)\n",
      "[5/25][665/782] Loss_D: 0.2729 (0.4500) Loss_G: -0.1869 (0.3038) D(x): 0.5167 D(G(z)): 0.5305 / 0.5214 Acc: 31.2500 (27.4264)\n",
      "[5/25][666/782] Loss_D: 0.2655 (0.4500) Loss_G: 0.0298 (0.3037) D(x): 0.5586 D(G(z)): 0.4984 / 0.4482 Acc: 28.1250 (27.4265)\n",
      "[5/25][667/782] Loss_D: 0.5100 (0.4500) Loss_G: 0.0921 (0.3037) D(x): 0.4524 D(G(z)): 0.4797 / 0.3975 Acc: 21.8750 (27.4253)\n",
      "[5/25][668/782] Loss_D: 0.3221 (0.4500) Loss_G: -0.0825 (0.3036) D(x): 0.4856 D(G(z)): 0.4877 / 0.4782 Acc: 26.5625 (27.4251)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/25][669/782] Loss_D: 0.1685 (0.4499) Loss_G: -0.1168 (0.3035) D(x): 0.5570 D(G(z)): 0.5377 / 0.4793 Acc: 32.8125 (27.4263)\n",
      "[5/25][670/782] Loss_D: 0.0549 (0.4498) Loss_G: -0.0504 (0.3034) D(x): 0.5297 D(G(z)): 0.4414 / 0.4371 Acc: 32.8125 (27.4275)\n",
      "[5/25][671/782] Loss_D: -0.0007 (0.4497) Loss_G: -0.0708 (0.3034) D(x): 0.5386 D(G(z)): 0.4443 / 0.4496 Acc: 35.9375 (27.4293)\n",
      "[5/25][672/782] Loss_D: 0.0367 (0.4497) Loss_G: -0.0254 (0.3033) D(x): 0.5429 D(G(z)): 0.4497 / 0.4824 Acc: 42.1875 (27.4326)\n",
      "[5/25][673/782] Loss_D: 0.1501 (0.4496) Loss_G: -0.1861 (0.3032) D(x): 0.5137 D(G(z)): 0.4659 / 0.5102 Acc: 29.6875 (27.4331)\n",
      "[5/25][674/782] Loss_D: 0.1014 (0.4495) Loss_G: -0.1491 (0.3031) D(x): 0.5669 D(G(z)): 0.5000 / 0.4914 Acc: 32.8125 (27.4342)\n",
      "[5/25][675/782] Loss_D: 0.0103 (0.4494) Loss_G: -0.0348 (0.3030) D(x): 0.5500 D(G(z)): 0.4689 / 0.4394 Acc: 39.0625 (27.4368)\n",
      "[5/25][676/782] Loss_D: 0.1788 (0.4494) Loss_G: -0.0125 (0.3029) D(x): 0.4897 D(G(z)): 0.4512 / 0.4651 Acc: 39.0625 (27.4393)\n",
      "[5/25][677/782] Loss_D: 0.1535 (0.4493) Loss_G: -0.0363 (0.3029) D(x): 0.5369 D(G(z)): 0.4502 / 0.4425 Acc: 29.6875 (27.4398)\n",
      "[5/25][678/782] Loss_D: 0.1807 (0.4492) Loss_G: -0.0097 (0.3028) D(x): 0.5381 D(G(z)): 0.4907 / 0.4530 Acc: 32.8125 (27.4410)\n",
      "[5/25][679/782] Loss_D: 0.2161 (0.4492) Loss_G: -0.0254 (0.3027) D(x): 0.5193 D(G(z)): 0.4373 / 0.4544 Acc: 23.4375 (27.4401)\n",
      "[5/25][680/782] Loss_D: 0.0636 (0.4491) Loss_G: -0.0024 (0.3027) D(x): 0.5816 D(G(z)): 0.4940 / 0.4256 Acc: 34.3750 (27.4416)\n",
      "[5/25][681/782] Loss_D: 0.2310 (0.4491) Loss_G: -0.0674 (0.3026) D(x): 0.4989 D(G(z)): 0.4906 / 0.4633 Acc: 32.8125 (27.4428)\n",
      "[5/25][682/782] Loss_D: 0.1457 (0.4490) Loss_G: -0.0146 (0.3025) D(x): 0.5704 D(G(z)): 0.4940 / 0.4279 Acc: 26.5625 (27.4426)\n",
      "[5/25][683/782] Loss_D: 0.0421 (0.4489) Loss_G: 0.1529 (0.3025) D(x): 0.5186 D(G(z)): 0.4715 / 0.3628 Acc: 43.7500 (27.4461)\n",
      "[5/25][684/782] Loss_D: 0.1350 (0.4488) Loss_G: 0.0248 (0.3024) D(x): 0.5377 D(G(z)): 0.4748 / 0.3962 Acc: 26.5625 (27.4459)\n",
      "[5/25][685/782] Loss_D: 0.0067 (0.4487) Loss_G: 0.0937 (0.3024) D(x): 0.4861 D(G(z)): 0.4008 / 0.3648 Acc: 34.3750 (27.4474)\n",
      "[5/25][686/782] Loss_D: 0.0748 (0.4487) Loss_G: -0.1002 (0.3023) D(x): 0.5048 D(G(z)): 0.4329 / 0.4845 Acc: 35.9375 (27.4493)\n",
      "[5/25][687/782] Loss_D: 0.1423 (0.4486) Loss_G: -0.1474 (0.3022) D(x): 0.5346 D(G(z)): 0.5022 / 0.4903 Acc: 32.8125 (27.4505)\n",
      "[5/25][688/782] Loss_D: -0.0428 (0.4485) Loss_G: 0.0235 (0.3021) D(x): 0.5766 D(G(z)): 0.4716 / 0.4058 Acc: 39.0625 (27.4530)\n",
      "[5/25][689/782] Loss_D: 0.1233 (0.4484) Loss_G: 0.0428 (0.3021) D(x): 0.5094 D(G(z)): 0.4878 / 0.4382 Acc: 40.6250 (27.4558)\n",
      "[5/25][690/782] Loss_D: 0.0290 (0.4483) Loss_G: 0.0298 (0.3020) D(x): 0.5191 D(G(z)): 0.4475 / 0.4334 Acc: 40.6250 (27.4587)\n",
      "[5/25][691/782] Loss_D: -0.0330 (0.4482) Loss_G: -0.0576 (0.3019) D(x): 0.5294 D(G(z)): 0.4495 / 0.4332 Acc: 39.0625 (27.4612)\n",
      "[5/25][692/782] Loss_D: 0.1203 (0.4481) Loss_G: -0.0286 (0.3019) D(x): 0.5101 D(G(z)): 0.4533 / 0.4494 Acc: 31.2500 (27.4620)\n",
      "[5/25][693/782] Loss_D: 0.2730 (0.4481) Loss_G: -0.0292 (0.3018) D(x): 0.4925 D(G(z)): 0.4743 / 0.4474 Acc: 28.1250 (27.4622)\n",
      "[5/25][694/782] Loss_D: 0.2077 (0.4481) Loss_G: -0.0432 (0.3017) D(x): 0.5355 D(G(z)): 0.5090 / 0.4648 Acc: 39.0625 (27.4647)\n",
      "[5/25][695/782] Loss_D: 0.2075 (0.4480) Loss_G: -0.0047 (0.3016) D(x): 0.5594 D(G(z)): 0.4808 / 0.4230 Acc: 17.1875 (27.4625)\n",
      "[5/25][696/782] Loss_D: 0.1326 (0.4479) Loss_G: -0.0370 (0.3016) D(x): 0.5170 D(G(z)): 0.4490 / 0.4523 Acc: 32.8125 (27.4636)\n",
      "[5/25][697/782] Loss_D: 0.1221 (0.4479) Loss_G: 0.0092 (0.3015) D(x): 0.5403 D(G(z)): 0.4388 / 0.4552 Acc: 29.6875 (27.4641)\n",
      "[5/25][698/782] Loss_D: 0.2649 (0.4478) Loss_G: -0.0933 (0.3014) D(x): 0.5106 D(G(z)): 0.4659 / 0.4759 Acc: 23.4375 (27.4633)\n",
      "[5/25][699/782] Loss_D: -0.0190 (0.4477) Loss_G: -0.1256 (0.3013) D(x): 0.5489 D(G(z)): 0.4404 / 0.4780 Acc: 39.0625 (27.4658)\n",
      "[5/25][700/782] Loss_D: 0.2570 (0.4477) Loss_G: -0.0656 (0.3012) D(x): 0.5416 D(G(z)): 0.4950 / 0.4986 Acc: 28.1250 (27.4659)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[5/25][701/782] Loss_D: 0.1931 (0.4476) Loss_G: -0.0331 (0.3012) D(x): 0.5210 D(G(z)): 0.4867 / 0.4531 Acc: 35.9375 (27.4677)\n",
      "[5/25][702/782] Loss_D: 0.0030 (0.4475) Loss_G: -0.0527 (0.3011) D(x): 0.5274 D(G(z)): 0.4360 / 0.4431 Acc: 39.0625 (27.4703)\n",
      "[5/25][703/782] Loss_D: 0.3295 (0.4475) Loss_G: -0.1103 (0.3010) D(x): 0.4842 D(G(z)): 0.4868 / 0.4871 Acc: 28.1250 (27.4704)\n",
      "[5/25][704/782] Loss_D: -0.0435 (0.4474) Loss_G: 0.0220 (0.3009) D(x): 0.5430 D(G(z)): 0.4741 / 0.4086 Acc: 45.3125 (27.4743)\n",
      "[5/25][705/782] Loss_D: 0.0843 (0.4473) Loss_G: -0.0567 (0.3009) D(x): 0.4949 D(G(z)): 0.4351 / 0.4540 Acc: 37.5000 (27.4764)\n",
      "[5/25][706/782] Loss_D: 0.2008 (0.4473) Loss_G: -0.1728 (0.3008) D(x): 0.5439 D(G(z)): 0.4999 / 0.5065 Acc: 26.5625 (27.4762)\n",
      "[5/25][707/782] Loss_D: 0.1689 (0.4472) Loss_G: -0.0640 (0.3007) D(x): 0.5748 D(G(z)): 0.4926 / 0.4562 Acc: 25.0000 (27.4757)\n",
      "[5/25][708/782] Loss_D: 0.1902 (0.4471) Loss_G: -0.1160 (0.3006) D(x): 0.5163 D(G(z)): 0.4980 / 0.4582 Acc: 35.9375 (27.4775)\n",
      "[5/25][709/782] Loss_D: 0.1046 (0.4471) Loss_G: -0.0492 (0.3005) D(x): 0.5246 D(G(z)): 0.4628 / 0.4741 Acc: 43.7500 (27.4811)\n",
      "[5/25][710/782] Loss_D: 0.1981 (0.4470) Loss_G: -0.0465 (0.3004) D(x): 0.4843 D(G(z)): 0.4586 / 0.4584 Acc: 32.8125 (27.4822)\n",
      "[5/25][711/782] Loss_D: 0.2736 (0.4470) Loss_G: -0.0258 (0.3004) D(x): 0.5686 D(G(z)): 0.5200 / 0.4449 Acc: 25.0000 (27.4817)\n",
      "[5/25][712/782] Loss_D: 0.3670 (0.4470) Loss_G: -0.1155 (0.3003) D(x): 0.4728 D(G(z)): 0.5190 / 0.5044 Acc: 35.9375 (27.4835)\n",
      "[5/25][713/782] Loss_D: 0.2091 (0.4469) Loss_G: -0.0494 (0.3002) D(x): 0.5099 D(G(z)): 0.4806 / 0.4606 Acc: 29.6875 (27.4840)\n",
      "[5/25][714/782] Loss_D: 0.1856 (0.4469) Loss_G: -0.1142 (0.3001) D(x): 0.5248 D(G(z)): 0.4847 / 0.4853 Acc: 31.2500 (27.4848)\n",
      "[5/25][715/782] Loss_D: 0.3580 (0.4468) Loss_G: -0.0966 (0.3000) D(x): 0.4685 D(G(z)): 0.5066 / 0.4737 Acc: 34.3750 (27.4863)\n",
      "[5/25][716/782] Loss_D: 0.2027 (0.4468) Loss_G: 0.0198 (0.3000) D(x): 0.5364 D(G(z)): 0.4996 / 0.4443 Acc: 32.8125 (27.4874)\n",
      "[5/25][717/782] Loss_D: 0.2760 (0.4467) Loss_G: 0.0421 (0.2999) D(x): 0.4872 D(G(z)): 0.4663 / 0.4426 Acc: 32.8125 (27.4886)\n",
      "[5/25][718/782] Loss_D: 0.1290 (0.4467) Loss_G: -0.0571 (0.2998) D(x): 0.5558 D(G(z)): 0.4861 / 0.4647 Acc: 34.3750 (27.4901)\n",
      "[5/25][719/782] Loss_D: 0.2785 (0.4466) Loss_G: 0.0750 (0.2998) D(x): 0.5256 D(G(z)): 0.4792 / 0.4382 Acc: 29.6875 (27.4906)\n",
      "[5/25][720/782] Loss_D: 0.1237 (0.4466) Loss_G: 0.0057 (0.2997) D(x): 0.4938 D(G(z)): 0.4242 / 0.4370 Acc: 34.3750 (27.4920)\n",
      "[5/25][721/782] Loss_D: 0.2331 (0.4465) Loss_G: 0.0247 (0.2997) D(x): 0.5871 D(G(z)): 0.5021 / 0.4455 Acc: 25.0000 (27.4915)\n",
      "[5/25][722/782] Loss_D: 0.1796 (0.4465) Loss_G: 0.0203 (0.2996) D(x): 0.5012 D(G(z)): 0.4477 / 0.4329 Acc: 29.6875 (27.4920)\n",
      "[5/25][723/782] Loss_D: 0.1854 (0.4464) Loss_G: 0.0261 (0.2996) D(x): 0.5523 D(G(z)): 0.4648 / 0.4581 Acc: 26.5625 (27.4918)\n",
      "[5/25][724/782] Loss_D: 0.0459 (0.4463) Loss_G: -0.0964 (0.2995) D(x): 0.5665 D(G(z)): 0.4616 / 0.4810 Acc: 32.8125 (27.4929)\n",
      "[5/25][725/782] Loss_D: 0.1016 (0.4463) Loss_G: 0.0522 (0.2994) D(x): 0.5628 D(G(z)): 0.4584 / 0.4457 Acc: 34.3750 (27.4944)\n",
      "[5/25][726/782] Loss_D: 0.0995 (0.4462) Loss_G: 0.0479 (0.2994) D(x): 0.5945 D(G(z)): 0.4789 / 0.4313 Acc: 32.8125 (27.4956)\n",
      "[5/25][727/782] Loss_D: 0.0149 (0.4461) Loss_G: 0.0474 (0.2993) D(x): 0.5625 D(G(z)): 0.4486 / 0.4156 Acc: 31.2500 (27.4964)\n",
      "[5/25][728/782] Loss_D: 0.1699 (0.4460) Loss_G: -0.0056 (0.2992) D(x): 0.5183 D(G(z)): 0.4126 / 0.4337 Acc: 25.0000 (27.4958)\n",
      "[5/25][729/782] Loss_D: -0.0310 (0.4459) Loss_G: -0.0110 (0.2992) D(x): 0.5716 D(G(z)): 0.4434 / 0.4398 Acc: 42.1875 (27.4990)\n",
      "[5/25][730/782] Loss_D: 0.0706 (0.4458) Loss_G: 0.0298 (0.2991) D(x): 0.5979 D(G(z)): 0.5150 / 0.4179 Acc: 37.5000 (27.5011)\n",
      "[5/25][731/782] Loss_D: 0.0726 (0.4458) Loss_G: 0.0949 (0.2991) D(x): 0.5126 D(G(z)): 0.4525 / 0.4309 Acc: 50.0000 (27.5060)\n",
      "[5/25][732/782] Loss_D: 0.3032 (0.4457) Loss_G: -0.0364 (0.2990) D(x): 0.4789 D(G(z)): 0.4602 / 0.4852 Acc: 32.8125 (27.5071)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/25][733/782] Loss_D: 0.0970 (0.4457) Loss_G: -0.1865 (0.2989) D(x): 0.5018 D(G(z)): 0.4605 / 0.5102 Acc: 39.0625 (27.5096)\n",
      "[5/25][734/782] Loss_D: 0.2021 (0.4456) Loss_G: -0.0483 (0.2988) D(x): 0.5959 D(G(z)): 0.5476 / 0.4886 Acc: 35.9375 (27.5114)\n",
      "[5/25][735/782] Loss_D: 0.1600 (0.4455) Loss_G: 0.0145 (0.2988) D(x): 0.5183 D(G(z)): 0.4769 / 0.4417 Acc: 39.0625 (27.5139)\n",
      "[5/25][736/782] Loss_D: 0.2407 (0.4455) Loss_G: -0.0393 (0.2987) D(x): 0.5290 D(G(z)): 0.5223 / 0.4492 Acc: 34.3750 (27.5154)\n",
      "[5/25][737/782] Loss_D: 0.2552 (0.4455) Loss_G: 0.0082 (0.2986) D(x): 0.4575 D(G(z)): 0.3927 / 0.4437 Acc: 28.1250 (27.5155)\n",
      "[5/25][738/782] Loss_D: 0.0673 (0.4454) Loss_G: -0.1669 (0.2985) D(x): 0.5256 D(G(z)): 0.4806 / 0.4843 Acc: 35.9375 (27.5173)\n",
      "[5/25][739/782] Loss_D: 0.0665 (0.4453) Loss_G: -0.0668 (0.2984) D(x): 0.5738 D(G(z)): 0.4775 / 0.4651 Acc: 34.3750 (27.5188)\n",
      "[5/25][740/782] Loss_D: 0.1148 (0.4452) Loss_G: -0.0235 (0.2984) D(x): 0.5554 D(G(z)): 0.4907 / 0.4398 Acc: 37.5000 (27.5210)\n",
      "[5/25][741/782] Loss_D: 0.1365 (0.4452) Loss_G: -0.0696 (0.2983) D(x): 0.5038 D(G(z)): 0.4684 / 0.4664 Acc: 35.9375 (27.5228)\n",
      "[5/25][742/782] Loss_D: 0.0444 (0.4451) Loss_G: -0.0363 (0.2982) D(x): 0.5229 D(G(z)): 0.4592 / 0.4504 Acc: 39.0625 (27.5253)\n",
      "[5/25][743/782] Loss_D: 0.1862 (0.4450) Loss_G: -0.0908 (0.2981) D(x): 0.5084 D(G(z)): 0.4411 / 0.4944 Acc: 35.9375 (27.5271)\n",
      "[5/25][744/782] Loss_D: 0.1225 (0.4449) Loss_G: -0.1260 (0.2980) D(x): 0.5446 D(G(z)): 0.4651 / 0.4650 Acc: 23.4375 (27.5262)\n",
      "[5/25][745/782] Loss_D: 0.1887 (0.4449) Loss_G: 0.0401 (0.2980) D(x): 0.5623 D(G(z)): 0.5222 / 0.4128 Acc: 34.3750 (27.5277)\n",
      "[5/25][746/782] Loss_D: 0.1682 (0.4448) Loss_G: 0.0336 (0.2979) D(x): 0.4898 D(G(z)): 0.4213 / 0.4280 Acc: 34.3750 (27.5291)\n",
      "[5/25][747/782] Loss_D: 0.1493 (0.4448) Loss_G: -0.1246 (0.2978) D(x): 0.4994 D(G(z)): 0.4612 / 0.4732 Acc: 35.9375 (27.5309)\n",
      "[5/25][748/782] Loss_D: 0.0556 (0.4447) Loss_G: 0.0502 (0.2978) D(x): 0.5692 D(G(z)): 0.4479 / 0.4330 Acc: 29.6875 (27.5314)\n",
      "[5/25][749/782] Loss_D: -0.0444 (0.4446) Loss_G: 0.0424 (0.2977) D(x): 0.5793 D(G(z)): 0.4430 / 0.4321 Acc: 37.5000 (27.5335)\n",
      "[5/25][750/782] Loss_D: 0.0494 (0.4445) Loss_G: -0.0072 (0.2977) D(x): 0.5417 D(G(z)): 0.4219 / 0.4548 Acc: 31.2500 (27.5343)\n",
      "[5/25][751/782] Loss_D: 0.0469 (0.4444) Loss_G: -0.0678 (0.2976) D(x): 0.5765 D(G(z)): 0.4742 / 0.4647 Acc: 34.3750 (27.5358)\n",
      "[5/25][752/782] Loss_D: 0.0741 (0.4443) Loss_G: -0.1191 (0.2975) D(x): 0.5542 D(G(z)): 0.5161 / 0.4682 Acc: 39.0625 (27.5383)\n",
      "[5/25][753/782] Loss_D: -0.0962 (0.4442) Loss_G: -0.0355 (0.2974) D(x): 0.5300 D(G(z)): 0.4167 / 0.4263 Acc: 39.0625 (27.5407)\n",
      "[5/25][754/782] Loss_D: 0.2521 (0.4442) Loss_G: -0.1509 (0.2973) D(x): 0.4944 D(G(z)): 0.5157 / 0.4900 Acc: 40.6250 (27.5435)\n",
      "[5/25][755/782] Loss_D: 0.1413 (0.4441) Loss_G: -0.0792 (0.2973) D(x): 0.5009 D(G(z)): 0.4537 / 0.5036 Acc: 46.8750 (27.5477)\n",
      "[5/25][756/782] Loss_D: 0.4403 (0.4441) Loss_G: -0.0010 (0.2972) D(x): 0.4760 D(G(z)): 0.4923 / 0.4443 Acc: 32.8125 (27.5488)\n",
      "[5/25][757/782] Loss_D: 0.0331 (0.4440) Loss_G: -0.0276 (0.2971) D(x): 0.5563 D(G(z)): 0.4903 / 0.4163 Acc: 37.5000 (27.5509)\n",
      "[5/25][758/782] Loss_D: 0.1174 (0.4439) Loss_G: -0.1572 (0.2970) D(x): 0.5232 D(G(z)): 0.4666 / 0.4728 Acc: 34.3750 (27.5524)\n",
      "[5/25][759/782] Loss_D: 0.1357 (0.4439) Loss_G: -0.1644 (0.2969) D(x): 0.4771 D(G(z)): 0.4476 / 0.5084 Acc: 37.5000 (27.5545)\n",
      "[5/25][760/782] Loss_D: 0.3118 (0.4439) Loss_G: -0.1864 (0.2968) D(x): 0.4943 D(G(z)): 0.5322 / 0.5074 Acc: 34.3750 (27.5560)\n",
      "[5/25][761/782] Loss_D: 0.2152 (0.4438) Loss_G: 0.0655 (0.2968) D(x): 0.5431 D(G(z)): 0.5105 / 0.4300 Acc: 35.9375 (27.5578)\n",
      "[5/25][762/782] Loss_D: 0.2139 (0.4438) Loss_G: 0.1050 (0.2967) D(x): 0.5337 D(G(z)): 0.4650 / 0.4230 Acc: 34.3750 (27.5592)\n",
      "[5/25][763/782] Loss_D: 0.0694 (0.4437) Loss_G: -0.0315 (0.2967) D(x): 0.4953 D(G(z)): 0.3983 / 0.4616 Acc: 34.3750 (27.5607)\n",
      "[5/25][764/782] Loss_D: 0.1992 (0.4436) Loss_G: -0.0945 (0.2966) D(x): 0.5649 D(G(z)): 0.4933 / 0.4659 Acc: 25.0000 (27.5602)\n",
      "[5/25][765/782] Loss_D: 0.1918 (0.4436) Loss_G: -0.0199 (0.2965) D(x): 0.5211 D(G(z)): 0.4577 / 0.4691 Acc: 31.2500 (27.5609)\n",
      "[5/25][766/782] Loss_D: 0.1690 (0.4435) Loss_G: 0.0275 (0.2965) D(x): 0.5245 D(G(z)): 0.4828 / 0.4362 Acc: 31.2500 (27.5617)\n",
      "[5/25][767/782] Loss_D: 0.2138 (0.4435) Loss_G: -0.0023 (0.2964) D(x): 0.5260 D(G(z)): 0.5244 / 0.4592 Acc: 39.0625 (27.5642)\n",
      "[5/25][768/782] Loss_D: 0.3218 (0.4434) Loss_G: 0.0656 (0.2963) D(x): 0.5005 D(G(z)): 0.4812 / 0.4489 Acc: 32.8125 (27.5653)\n",
      "[5/25][769/782] Loss_D: 0.0969 (0.4434) Loss_G: -0.0786 (0.2963) D(x): 0.5101 D(G(z)): 0.4478 / 0.4434 Acc: 34.3750 (27.5668)\n",
      "[5/25][770/782] Loss_D: 0.1243 (0.4433) Loss_G: 0.0204 (0.2962) D(x): 0.5345 D(G(z)): 0.4596 / 0.4377 Acc: 28.1250 (27.5669)\n",
      "[5/25][771/782] Loss_D: -0.0738 (0.4432) Loss_G: 0.0911 (0.2962) D(x): 0.5920 D(G(z)): 0.4195 / 0.4168 Acc: 35.9375 (27.5687)\n",
      "[5/25][772/782] Loss_D: 0.1512 (0.4431) Loss_G: 0.0109 (0.2961) D(x): 0.5029 D(G(z)): 0.4469 / 0.4465 Acc: 34.3750 (27.5701)\n",
      "[5/25][773/782] Loss_D: -0.0306 (0.4430) Loss_G: -0.0822 (0.2960) D(x): 0.5387 D(G(z)): 0.4491 / 0.4950 Acc: 48.4375 (27.5746)\n",
      "[5/25][774/782] Loss_D: 0.2476 (0.4430) Loss_G: -0.1606 (0.2959) D(x): 0.5340 D(G(z)): 0.5617 / 0.4805 Acc: 37.5000 (27.5767)\n",
      "[5/25][775/782] Loss_D: 0.0664 (0.4429) Loss_G: 0.0075 (0.2959) D(x): 0.5468 D(G(z)): 0.4566 / 0.4490 Acc: 37.5000 (27.5788)\n",
      "[5/25][776/782] Loss_D: 0.3354 (0.4429) Loss_G: -0.0337 (0.2958) D(x): 0.4746 D(G(z)): 0.4761 / 0.4670 Acc: 31.2500 (27.5796)\n",
      "[5/25][777/782] Loss_D: 0.2729 (0.4428) Loss_G: -0.1522 (0.2957) D(x): 0.5241 D(G(z)): 0.5098 / 0.4733 Acc: 26.5625 (27.5794)\n",
      "[5/25][778/782] Loss_D: 0.0641 (0.4428) Loss_G: -0.0710 (0.2956) D(x): 0.5751 D(G(z)): 0.4963 / 0.4602 Acc: 37.5000 (27.5815)\n",
      "[5/25][779/782] Loss_D: 0.0439 (0.4427) Loss_G: 0.0427 (0.2956) D(x): 0.5689 D(G(z)): 0.4485 / 0.4480 Acc: 35.9375 (27.5833)\n",
      "[5/25][780/782] Loss_D: 0.2252 (0.4426) Loss_G: -0.0016 (0.2955) D(x): 0.4894 D(G(z)): 0.4573 / 0.4382 Acc: 28.1250 (27.5834)\n",
      "[5/25][781/782] Loss_D: 0.4031 (0.4426) Loss_G: -0.0052 (0.2954) D(x): 0.4750 D(G(z)): 0.5021 / 0.4556 Acc: 31.2500 (27.5842)\n",
      "[6/25][0/782] Loss_D: 0.1408 (0.4426) Loss_G: 0.0435 (0.2954) D(x): 0.5652 D(G(z)): 0.5070 / 0.4509 Acc: 39.0625 (27.5866)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[6/25][1/782] Loss_D: 0.2976 (0.4425) Loss_G: 0.0645 (0.2953) D(x): 0.5082 D(G(z)): 0.4758 / 0.4452 Acc: 28.1250 (27.5867)\n",
      "[6/25][2/782] Loss_D: 0.2248 (0.4425) Loss_G: -0.0546 (0.2953) D(x): 0.4906 D(G(z)): 0.4786 / 0.4656 Acc: 37.5000 (27.5889)\n",
      "[6/25][3/782] Loss_D: 0.2587 (0.4424) Loss_G: 0.0510 (0.2952) D(x): 0.5560 D(G(z)): 0.5143 / 0.4320 Acc: 29.6875 (27.5893)\n",
      "[6/25][4/782] Loss_D: 0.3206 (0.4424) Loss_G: 0.0639 (0.2952) D(x): 0.5424 D(G(z)): 0.5158 / 0.4426 Acc: 31.2500 (27.5901)\n",
      "[6/25][5/782] Loss_D: 0.3092 (0.4424) Loss_G: -0.0176 (0.2951) D(x): 0.4888 D(G(z)): 0.4936 / 0.4709 Acc: 32.8125 (27.5912)\n",
      "[6/25][6/782] Loss_D: 0.2086 (0.4423) Loss_G: -0.0109 (0.2950) D(x): 0.4813 D(G(z)): 0.4666 / 0.4515 Acc: 40.6250 (27.5940)\n",
      "[6/25][7/782] Loss_D: 0.1813 (0.4423) Loss_G: -0.0341 (0.2950) D(x): 0.4838 D(G(z)): 0.4785 / 0.4721 Acc: 39.0625 (27.5964)\n",
      "[6/25][8/782] Loss_D: 0.1914 (0.4422) Loss_G: -0.1570 (0.2949) D(x): 0.5115 D(G(z)): 0.5086 / 0.4926 Acc: 34.3750 (27.5979)\n",
      "[6/25][9/782] Loss_D: 0.1905 (0.4422) Loss_G: 0.0166 (0.2948) D(x): 0.5306 D(G(z)): 0.5056 / 0.4282 Acc: 35.9375 (27.5996)\n",
      "[6/25][10/782] Loss_D: 0.0858 (0.4421) Loss_G: 0.0036 (0.2947) D(x): 0.5321 D(G(z)): 0.4648 / 0.4511 Acc: 37.5000 (27.6017)\n",
      "[6/25][11/782] Loss_D: 0.0091 (0.4420) Loss_G: -0.0440 (0.2947) D(x): 0.4945 D(G(z)): 0.4737 / 0.4490 Acc: 51.5625 (27.6068)\n",
      "[6/25][12/782] Loss_D: 0.0370 (0.4419) Loss_G: -0.2021 (0.2946) D(x): 0.4880 D(G(z)): 0.4137 / 0.5017 Acc: 40.6250 (27.6096)\n",
      "[6/25][13/782] Loss_D: 0.1243 (0.4418) Loss_G: -0.1588 (0.2945) D(x): 0.5209 D(G(z)): 0.4977 / 0.4837 Acc: 37.5000 (27.6117)\n",
      "[6/25][14/782] Loss_D: 0.1785 (0.4418) Loss_G: -0.0698 (0.2944) D(x): 0.5864 D(G(z)): 0.5377 / 0.4580 Acc: 29.6875 (27.6121)\n",
      "[6/25][15/782] Loss_D: -0.0449 (0.4417) Loss_G: -0.1120 (0.2943) D(x): 0.5101 D(G(z)): 0.4211 / 0.4762 Acc: 42.1875 (27.6152)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/25][16/782] Loss_D: 0.1060 (0.4416) Loss_G: -0.0443 (0.2942) D(x): 0.5136 D(G(z)): 0.4423 / 0.4644 Acc: 34.3750 (27.6167)\n",
      "[6/25][17/782] Loss_D: 0.2422 (0.4416) Loss_G: -0.0607 (0.2941) D(x): 0.5396 D(G(z)): 0.4742 / 0.4635 Acc: 26.5625 (27.6164)\n",
      "[6/25][18/782] Loss_D: 0.1112 (0.4415) Loss_G: -0.1180 (0.2941) D(x): 0.5308 D(G(z)): 0.4487 / 0.4769 Acc: 23.4375 (27.6156)\n",
      "[6/25][19/782] Loss_D: 0.1248 (0.4414) Loss_G: 0.0456 (0.2940) D(x): 0.5628 D(G(z)): 0.5151 / 0.4263 Acc: 39.0625 (27.6180)\n",
      "[6/25][20/782] Loss_D: 0.1244 (0.4414) Loss_G: 0.2143 (0.2940) D(x): 0.5598 D(G(z)): 0.4918 / 0.3412 Acc: 29.6875 (27.6184)\n",
      "[6/25][21/782] Loss_D: 0.1863 (0.4413) Loss_G: 0.0622 (0.2939) D(x): 0.4239 D(G(z)): 0.3901 / 0.4366 Acc: 42.1875 (27.6215)\n",
      "[6/25][22/782] Loss_D: 0.0463 (0.4412) Loss_G: -0.2192 (0.2938) D(x): 0.5095 D(G(z)): 0.4160 / 0.5174 Acc: 28.1250 (27.6216)\n",
      "[6/25][23/782] Loss_D: 0.0378 (0.4411) Loss_G: -0.0293 (0.2938) D(x): 0.5660 D(G(z)): 0.5084 / 0.4388 Acc: 43.7500 (27.6250)\n",
      "[6/25][24/782] Loss_D: 0.0593 (0.4411) Loss_G: -0.0945 (0.2937) D(x): 0.5919 D(G(z)): 0.5149 / 0.4582 Acc: 34.3750 (27.6265)\n",
      "[6/25][25/782] Loss_D: 0.0009 (0.4410) Loss_G: -0.0874 (0.2936) D(x): 0.5098 D(G(z)): 0.4474 / 0.4637 Acc: 45.3125 (27.6302)\n",
      "[6/25][26/782] Loss_D: 0.1520 (0.4409) Loss_G: -0.0046 (0.2935) D(x): 0.5164 D(G(z)): 0.4631 / 0.4419 Acc: 32.8125 (27.6313)\n",
      "[6/25][27/782] Loss_D: 0.2089 (0.4409) Loss_G: -0.0516 (0.2935) D(x): 0.4803 D(G(z)): 0.4388 / 0.4668 Acc: 29.6875 (27.6318)\n",
      "[6/25][28/782] Loss_D: 0.2376 (0.4408) Loss_G: -0.1691 (0.2934) D(x): 0.5145 D(G(z)): 0.4846 / 0.4974 Acc: 28.1250 (27.6319)\n",
      "[6/25][29/782] Loss_D: 0.3131 (0.4408) Loss_G: -0.1074 (0.2933) D(x): 0.5940 D(G(z)): 0.5348 / 0.4781 Acc: 14.0625 (27.6290)\n",
      "[6/25][30/782] Loss_D: 0.1990 (0.4407) Loss_G: -0.1004 (0.2932) D(x): 0.5426 D(G(z)): 0.4970 / 0.4692 Acc: 29.6875 (27.6294)\n",
      "[6/25][31/782] Loss_D: 0.0244 (0.4407) Loss_G: 0.0345 (0.2931) D(x): 0.5150 D(G(z)): 0.4688 / 0.4186 Acc: 40.6250 (27.6322)\n",
      "[6/25][32/782] Loss_D: 0.2022 (0.4406) Loss_G: -0.0127 (0.2931) D(x): 0.5057 D(G(z)): 0.4378 / 0.4721 Acc: 31.2500 (27.6329)\n",
      "[6/25][33/782] Loss_D: 0.0279 (0.4405) Loss_G: -0.0628 (0.2930) D(x): 0.5383 D(G(z)): 0.4368 / 0.4454 Acc: 34.3750 (27.6344)\n",
      "[6/25][34/782] Loss_D: 0.0422 (0.4404) Loss_G: -0.0374 (0.2929) D(x): 0.5469 D(G(z)): 0.4825 / 0.4631 Acc: 43.7500 (27.6378)\n",
      "[6/25][35/782] Loss_D: -0.0293 (0.4403) Loss_G: 0.0472 (0.2929) D(x): 0.5701 D(G(z)): 0.4727 / 0.4249 Acc: 45.3125 (27.6415)\n",
      "[6/25][36/782] Loss_D: 0.2335 (0.4403) Loss_G: 0.1296 (0.2928) D(x): 0.4968 D(G(z)): 0.4442 / 0.4368 Acc: 34.3750 (27.6429)\n",
      "[6/25][37/782] Loss_D: 0.3061 (0.4403) Loss_G: 0.1133 (0.2928) D(x): 0.5104 D(G(z)): 0.4741 / 0.4337 Acc: 28.1250 (27.6430)\n",
      "[6/25][38/782] Loss_D: 0.3623 (0.4402) Loss_G: 0.0018 (0.2927) D(x): 0.4844 D(G(z)): 0.4947 / 0.4560 Acc: 28.1250 (27.6431)\n",
      "[6/25][39/782] Loss_D: 0.2480 (0.4402) Loss_G: -0.0829 (0.2927) D(x): 0.5188 D(G(z)): 0.5195 / 0.4673 Acc: 31.2500 (27.6439)\n",
      "[6/25][40/782] Loss_D: 0.1772 (0.4401) Loss_G: 0.0355 (0.2926) D(x): 0.5160 D(G(z)): 0.4874 / 0.4365 Acc: 37.5000 (27.6460)\n",
      "[6/25][41/782] Loss_D: 0.1882 (0.4401) Loss_G: -0.0290 (0.2925) D(x): 0.5182 D(G(z)): 0.4731 / 0.4409 Acc: 29.6875 (27.6464)\n",
      "[6/25][42/782] Loss_D: 0.1560 (0.4400) Loss_G: -0.1298 (0.2925) D(x): 0.4926 D(G(z)): 0.4490 / 0.4844 Acc: 32.8125 (27.6475)\n",
      "[6/25][43/782] Loss_D: 0.2320 (0.4400) Loss_G: -0.1063 (0.2924) D(x): 0.5195 D(G(z)): 0.4591 / 0.4963 Acc: 32.8125 (27.6486)\n",
      "[6/25][44/782] Loss_D: 0.2067 (0.4399) Loss_G: -0.1315 (0.2923) D(x): 0.5351 D(G(z)): 0.4960 / 0.4976 Acc: 28.1250 (27.6487)\n",
      "[6/25][45/782] Loss_D: 0.1016 (0.4399) Loss_G: -0.1786 (0.2922) D(x): 0.5228 D(G(z)): 0.4726 / 0.5140 Acc: 35.9375 (27.6504)\n",
      "[6/25][46/782] Loss_D: 0.1253 (0.4398) Loss_G: -0.0594 (0.2921) D(x): 0.5381 D(G(z)): 0.4877 / 0.4487 Acc: 32.8125 (27.6515)\n",
      "[6/25][47/782] Loss_D: 0.1692 (0.4397) Loss_G: -0.0392 (0.2920) D(x): 0.4806 D(G(z)): 0.4682 / 0.4516 Acc: 37.5000 (27.6536)\n",
      "[6/25][48/782] Loss_D: -0.0684 (0.4396) Loss_G: -0.2138 (0.2919) D(x): 0.5332 D(G(z)): 0.4532 / 0.5038 Acc: 43.7500 (27.6570)\n",
      "[6/25][49/782] Loss_D: 0.3131 (0.4396) Loss_G: 0.1233 (0.2919) D(x): 0.5372 D(G(z)): 0.4906 / 0.4288 Acc: 28.1250 (27.6571)\n",
      "[6/25][50/782] Loss_D: 0.0317 (0.4395) Loss_G: -0.0716 (0.2918) D(x): 0.5385 D(G(z)): 0.4400 / 0.4702 Acc: 35.9375 (27.6589)\n",
      "[6/25][51/782] Loss_D: 0.2156 (0.4395) Loss_G: -0.0412 (0.2918) D(x): 0.5123 D(G(z)): 0.4497 / 0.4781 Acc: 28.1250 (27.6590)\n",
      "[6/25][52/782] Loss_D: 0.1116 (0.4394) Loss_G: -0.0382 (0.2917) D(x): 0.5919 D(G(z)): 0.4930 / 0.4315 Acc: 26.5625 (27.6587)\n",
      "[6/25][53/782] Loss_D: 0.2089 (0.4394) Loss_G: 0.0417 (0.2916) D(x): 0.5527 D(G(z)): 0.4953 / 0.4280 Acc: 26.5625 (27.6585)\n",
      "[6/25][54/782] Loss_D: -0.0321 (0.4393) Loss_G: -0.1140 (0.2915) D(x): 0.5029 D(G(z)): 0.4305 / 0.4696 Acc: 46.8750 (27.6625)\n",
      "[6/25][55/782] Loss_D: 0.1005 (0.4392) Loss_G: -0.0093 (0.2915) D(x): 0.5433 D(G(z)): 0.4734 / 0.4214 Acc: 29.6875 (27.6630)\n",
      "[6/25][56/782] Loss_D: 0.3562 (0.4392) Loss_G: 0.0012 (0.2914) D(x): 0.4823 D(G(z)): 0.4761 / 0.4478 Acc: 23.4375 (27.6621)\n",
      "[6/25][57/782] Loss_D: 0.1755 (0.4391) Loss_G: 0.0213 (0.2914) D(x): 0.5419 D(G(z)): 0.4359 / 0.4746 Acc: 28.1250 (27.6622)\n",
      "[6/25][58/782] Loss_D: 0.2526 (0.4391) Loss_G: -0.0804 (0.2913) D(x): 0.5665 D(G(z)): 0.5465 / 0.4731 Acc: 37.5000 (27.6642)\n",
      "[6/25][59/782] Loss_D: 0.3580 (0.4391) Loss_G: 0.0666 (0.2912) D(x): 0.4628 D(G(z)): 0.4871 / 0.4181 Acc: 31.2500 (27.6650)\n",
      "[6/25][60/782] Loss_D: 0.2832 (0.4390) Loss_G: -0.0575 (0.2912) D(x): 0.4287 D(G(z)): 0.4211 / 0.4568 Acc: 29.6875 (27.6654)\n",
      "[6/25][61/782] Loss_D: 0.3547 (0.4390) Loss_G: -0.0097 (0.2911) D(x): 0.5559 D(G(z)): 0.5320 / 0.4806 Acc: 34.3750 (27.6668)\n",
      "[6/25][62/782] Loss_D: 0.2571 (0.4390) Loss_G: -0.0160 (0.2910) D(x): 0.5770 D(G(z)): 0.5605 / 0.4595 Acc: 34.3750 (27.6682)\n",
      "[6/25][63/782] Loss_D: 0.2820 (0.4389) Loss_G: 0.0127 (0.2910) D(x): 0.4763 D(G(z)): 0.4565 / 0.4474 Acc: 29.6875 (27.6687)\n",
      "[6/25][64/782] Loss_D: 0.1430 (0.4389) Loss_G: 0.0134 (0.2909) D(x): 0.4975 D(G(z)): 0.4640 / 0.4281 Acc: 35.9375 (27.6704)\n",
      "[6/25][65/782] Loss_D: 0.2523 (0.4388) Loss_G: -0.0218 (0.2909) D(x): 0.4758 D(G(z)): 0.4928 / 0.4570 Acc: 39.0625 (27.6728)\n",
      "[6/25][66/782] Loss_D: 0.2480 (0.4388) Loss_G: 0.0401 (0.2908) D(x): 0.5204 D(G(z)): 0.4716 / 0.4429 Acc: 34.3750 (27.6742)\n",
      "[6/25][67/782] Loss_D: 0.1651 (0.4387) Loss_G: 0.0125 (0.2907) D(x): 0.5278 D(G(z)): 0.4872 / 0.4353 Acc: 34.3750 (27.6756)\n",
      "[6/25][68/782] Loss_D: 0.2431 (0.4387) Loss_G: -0.1049 (0.2907) D(x): 0.4957 D(G(z)): 0.4720 / 0.4913 Acc: 26.5625 (27.6754)\n",
      "[6/25][69/782] Loss_D: 0.2128 (0.4387) Loss_G: -0.0341 (0.2906) D(x): 0.4799 D(G(z)): 0.4638 / 0.4657 Acc: 34.3750 (27.6768)\n",
      "[6/25][70/782] Loss_D: 0.0806 (0.4386) Loss_G: -0.0540 (0.2905) D(x): 0.5437 D(G(z)): 0.4497 / 0.4774 Acc: 32.8125 (27.6779)\n",
      "[6/25][71/782] Loss_D: 0.0391 (0.4385) Loss_G: -0.0504 (0.2904) D(x): 0.5684 D(G(z)): 0.4601 / 0.4584 Acc: 40.6250 (27.6806)\n",
      "[6/25][72/782] Loss_D: 0.2377 (0.4385) Loss_G: -0.1250 (0.2904) D(x): 0.4948 D(G(z)): 0.4944 / 0.4711 Acc: 37.5000 (27.6826)\n",
      "[6/25][73/782] Loss_D: 0.1221 (0.4384) Loss_G: 0.0496 (0.2903) D(x): 0.5432 D(G(z)): 0.4255 / 0.4306 Acc: 28.1250 (27.6827)\n",
      "[6/25][74/782] Loss_D: 0.1050 (0.4383) Loss_G: -0.1261 (0.2902) D(x): 0.5878 D(G(z)): 0.5396 / 0.4679 Acc: 31.2500 (27.6835)\n",
      "[6/25][75/782] Loss_D: -0.0159 (0.4382) Loss_G: -0.0127 (0.2902) D(x): 0.5005 D(G(z)): 0.4022 / 0.4041 Acc: 29.6875 (27.6839)\n",
      "[6/25][76/782] Loss_D: 0.2220 (0.4382) Loss_G: -0.0640 (0.2901) D(x): 0.4795 D(G(z)): 0.4461 / 0.4631 Acc: 32.8125 (27.6850)\n",
      "[6/25][77/782] Loss_D: 0.0758 (0.4381) Loss_G: -0.1374 (0.2900) D(x): 0.5243 D(G(z)): 0.4839 / 0.4603 Acc: 34.3750 (27.6864)\n",
      "[6/25][78/782] Loss_D: 0.3137 (0.4381) Loss_G: -0.0908 (0.2899) D(x): 0.5200 D(G(z)): 0.5323 / 0.4865 Acc: 34.3750 (27.6878)\n",
      "[6/25][79/782] Loss_D: 0.1887 (0.4380) Loss_G: 0.0037 (0.2899) D(x): 0.5594 D(G(z)): 0.5170 / 0.4218 Acc: 29.6875 (27.6882)\n",
      "[6/25][80/782] Loss_D: 0.1915 (0.4380) Loss_G: 0.0230 (0.2898) D(x): 0.5138 D(G(z)): 0.4293 / 0.4564 Acc: 26.5625 (27.6880)\n",
      "[6/25][81/782] Loss_D: 0.2721 (0.4379) Loss_G: 0.0007 (0.2897) D(x): 0.5104 D(G(z)): 0.4592 / 0.4594 Acc: 26.5625 (27.6877)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/25][82/782] Loss_D: 0.0356 (0.4379) Loss_G: -0.1303 (0.2897) D(x): 0.5190 D(G(z)): 0.4531 / 0.4763 Acc: 39.0625 (27.6901)\n",
      "[6/25][83/782] Loss_D: 0.1371 (0.4378) Loss_G: -0.0631 (0.2896) D(x): 0.5496 D(G(z)): 0.4829 / 0.4656 Acc: 35.9375 (27.6918)\n",
      "[6/25][84/782] Loss_D: -0.0016 (0.4377) Loss_G: -0.1393 (0.2895) D(x): 0.5537 D(G(z)): 0.4401 / 0.4852 Acc: 37.5000 (27.6939)\n",
      "[6/25][85/782] Loss_D: 0.2239 (0.4377) Loss_G: -0.0727 (0.2894) D(x): 0.5050 D(G(z)): 0.4637 / 0.4594 Acc: 29.6875 (27.6943)\n",
      "[6/25][86/782] Loss_D: 0.0881 (0.4376) Loss_G: -0.0545 (0.2893) D(x): 0.5373 D(G(z)): 0.4963 / 0.4503 Acc: 37.5000 (27.6964)\n",
      "[6/25][87/782] Loss_D: 0.2954 (0.4375) Loss_G: 0.0549 (0.2893) D(x): 0.5312 D(G(z)): 0.4827 / 0.4355 Acc: 26.5625 (27.6961)\n",
      "[6/25][88/782] Loss_D: 0.1058 (0.4375) Loss_G: 0.0876 (0.2892) D(x): 0.5562 D(G(z)): 0.4847 / 0.4371 Acc: 40.6250 (27.6988)\n",
      "[6/25][89/782] Loss_D: 0.0643 (0.4374) Loss_G: -0.1583 (0.2892) D(x): 0.5133 D(G(z)): 0.4630 / 0.4935 Acc: 35.9375 (27.7006)\n",
      "[6/25][90/782] Loss_D: 0.1168 (0.4373) Loss_G: -0.0096 (0.2891) D(x): 0.5597 D(G(z)): 0.4571 / 0.4476 Acc: 26.5625 (27.7003)\n",
      "[6/25][91/782] Loss_D: 0.2523 (0.4373) Loss_G: 0.0710 (0.2890) D(x): 0.5387 D(G(z)): 0.5090 / 0.4028 Acc: 26.5625 (27.7001)\n",
      "[6/25][92/782] Loss_D: 0.1526 (0.4372) Loss_G: 0.0674 (0.2890) D(x): 0.4925 D(G(z)): 0.4704 / 0.4073 Acc: 40.6250 (27.7028)\n",
      "[6/25][93/782] Loss_D: 0.1378 (0.4372) Loss_G: 0.0153 (0.2889) D(x): 0.4922 D(G(z)): 0.4260 / 0.4387 Acc: 32.8125 (27.7038)\n",
      "[6/25][94/782] Loss_D: 0.0349 (0.4371) Loss_G: -0.0899 (0.2889) D(x): 0.5767 D(G(z)): 0.4745 / 0.4594 Acc: 32.8125 (27.7049)\n",
      "[6/25][95/782] Loss_D: 0.2583 (0.4371) Loss_G: 0.1663 (0.2888) D(x): 0.5947 D(G(z)): 0.5148 / 0.4048 Acc: 29.6875 (27.7053)\n",
      "[6/25][96/782] Loss_D: 0.0049 (0.4370) Loss_G: 0.1019 (0.2888) D(x): 0.5106 D(G(z)): 0.4072 / 0.4175 Acc: 35.9375 (27.7071)\n",
      "[6/25][97/782] Loss_D: -0.0041 (0.4369) Loss_G: -0.1401 (0.2887) D(x): 0.4725 D(G(z)): 0.3902 / 0.4748 Acc: 34.3750 (27.7084)\n",
      "[6/25][98/782] Loss_D: 0.0285 (0.4368) Loss_G: -0.0971 (0.2886) D(x): 0.5561 D(G(z)): 0.4736 / 0.4707 Acc: 39.0625 (27.7108)\n",
      "[6/25][99/782] Loss_D: 0.0625 (0.4367) Loss_G: 0.0123 (0.2886) D(x): 0.5483 D(G(z)): 0.4875 / 0.4441 Acc: 45.3125 (27.7145)\n",
      "[6/25][100/782] Loss_D: 0.0485 (0.4366) Loss_G: -0.1128 (0.2885) D(x): 0.5213 D(G(z)): 0.4540 / 0.4723 Acc: 37.5000 (27.7165)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[6/25][101/782] Loss_D: 0.0189 (0.4365) Loss_G: -0.1013 (0.2884) D(x): 0.5941 D(G(z)): 0.4922 / 0.4734 Acc: 34.3750 (27.7179)\n",
      "[6/25][102/782] Loss_D: 0.1606 (0.4365) Loss_G: 0.0419 (0.2884) D(x): 0.5188 D(G(z)): 0.4874 / 0.4235 Acc: 35.9375 (27.7196)\n",
      "[6/25][103/782] Loss_D: 0.1356 (0.4364) Loss_G: -0.0400 (0.2883) D(x): 0.4777 D(G(z)): 0.4524 / 0.4671 Acc: 40.6250 (27.7223)\n",
      "[6/25][104/782] Loss_D: 0.0465 (0.4363) Loss_G: -0.0236 (0.2882) D(x): 0.5508 D(G(z)): 0.4632 / 0.4309 Acc: 29.6875 (27.7227)\n",
      "[6/25][105/782] Loss_D: 0.1468 (0.4363) Loss_G: 0.0226 (0.2882) D(x): 0.5218 D(G(z)): 0.4452 / 0.4433 Acc: 29.6875 (27.7231)\n",
      "[6/25][106/782] Loss_D: -0.0113 (0.4362) Loss_G: 0.0329 (0.2881) D(x): 0.5734 D(G(z)): 0.4648 / 0.4386 Acc: 39.0625 (27.7255)\n",
      "[6/25][107/782] Loss_D: 0.0650 (0.4361) Loss_G: 0.0656 (0.2881) D(x): 0.5384 D(G(z)): 0.4466 / 0.4106 Acc: 32.8125 (27.7266)\n",
      "[6/25][108/782] Loss_D: 0.0636 (0.4360) Loss_G: 0.0273 (0.2880) D(x): 0.5463 D(G(z)): 0.4473 / 0.4283 Acc: 32.8125 (27.7276)\n",
      "[6/25][109/782] Loss_D: 0.0571 (0.4359) Loss_G: -0.0670 (0.2879) D(x): 0.5040 D(G(z)): 0.4633 / 0.4509 Acc: 42.1875 (27.7306)\n",
      "[6/25][110/782] Loss_D: 0.3178 (0.4359) Loss_G: -0.0975 (0.2879) D(x): 0.5000 D(G(z)): 0.4944 / 0.4986 Acc: 29.6875 (27.7310)\n",
      "[6/25][111/782] Loss_D: 0.3481 (0.4359) Loss_G: 0.0779 (0.2878) D(x): 0.5166 D(G(z)): 0.5073 / 0.4484 Acc: 31.2500 (27.7318)\n",
      "[6/25][112/782] Loss_D: 0.1297 (0.4358) Loss_G: 0.0187 (0.2878) D(x): 0.5361 D(G(z)): 0.4726 / 0.4323 Acc: 43.7500 (27.7351)\n",
      "[6/25][113/782] Loss_D: 0.4043 (0.4358) Loss_G: -0.0646 (0.2877) D(x): 0.4285 D(G(z)): 0.4914 / 0.4799 Acc: 35.9375 (27.7368)\n",
      "[6/25][114/782] Loss_D: 0.1923 (0.4358) Loss_G: -0.1462 (0.2876) D(x): 0.5105 D(G(z)): 0.5064 / 0.4918 Acc: 40.6250 (27.7395)\n",
      "[6/25][115/782] Loss_D: 0.1969 (0.4357) Loss_G: 0.0211 (0.2875) D(x): 0.5215 D(G(z)): 0.4724 / 0.4340 Acc: 31.2500 (27.7402)\n",
      "[6/25][116/782] Loss_D: 0.2276 (0.4357) Loss_G: -0.0635 (0.2875) D(x): 0.5278 D(G(z)): 0.5001 / 0.4747 Acc: 26.5625 (27.7400)\n",
      "[6/25][117/782] Loss_D: 0.2752 (0.4357) Loss_G: 0.0436 (0.2874) D(x): 0.4991 D(G(z)): 0.4920 / 0.4245 Acc: 31.2500 (27.7407)\n",
      "[6/25][118/782] Loss_D: 0.1758 (0.4356) Loss_G: -0.0240 (0.2874) D(x): 0.5085 D(G(z)): 0.4682 / 0.4433 Acc: 29.6875 (27.7411)\n",
      "[6/25][119/782] Loss_D: 0.2759 (0.4356) Loss_G: 0.0142 (0.2873) D(x): 0.4932 D(G(z)): 0.4596 / 0.4439 Acc: 31.2500 (27.7418)\n",
      "[6/25][120/782] Loss_D: 0.1834 (0.4355) Loss_G: -0.0841 (0.2872) D(x): 0.5075 D(G(z)): 0.4954 / 0.4673 Acc: 39.0625 (27.7442)\n",
      "[6/25][121/782] Loss_D: 0.2434 (0.4355) Loss_G: -0.0597 (0.2871) D(x): 0.5298 D(G(z)): 0.5166 / 0.4667 Acc: 32.8125 (27.7452)\n",
      "[6/25][122/782] Loss_D: 0.2136 (0.4354) Loss_G: -0.0224 (0.2871) D(x): 0.5257 D(G(z)): 0.5018 / 0.4453 Acc: 32.8125 (27.7463)\n",
      "[6/25][123/782] Loss_D: 0.1908 (0.4354) Loss_G: -0.0862 (0.2870) D(x): 0.5000 D(G(z)): 0.4471 / 0.4695 Acc: 26.5625 (27.7461)\n",
      "[6/25][124/782] Loss_D: 0.2276 (0.4353) Loss_G: -0.1730 (0.2869) D(x): 0.4772 D(G(z)): 0.4797 / 0.5229 Acc: 39.0625 (27.7484)\n",
      "[6/25][125/782] Loss_D: 0.1151 (0.4353) Loss_G: -0.0366 (0.2868) D(x): 0.5562 D(G(z)): 0.4992 / 0.4433 Acc: 34.3750 (27.7498)\n",
      "[6/25][126/782] Loss_D: 0.1501 (0.4352) Loss_G: -0.1121 (0.2868) D(x): 0.5251 D(G(z)): 0.4956 / 0.4555 Acc: 35.9375 (27.7515)\n",
      "[6/25][127/782] Loss_D: 0.1714 (0.4352) Loss_G: 0.0452 (0.2867) D(x): 0.5554 D(G(z)): 0.4724 / 0.4212 Acc: 25.0000 (27.7509)\n",
      "[6/25][128/782] Loss_D: 0.1249 (0.4351) Loss_G: -0.0964 (0.2866) D(x): 0.4860 D(G(z)): 0.4825 / 0.4457 Acc: 37.5000 (27.7529)\n",
      "[6/25][129/782] Loss_D: 0.2753 (0.4351) Loss_G: -0.1905 (0.2865) D(x): 0.4852 D(G(z)): 0.4725 / 0.5153 Acc: 23.4375 (27.7520)\n",
      "[6/25][130/782] Loss_D: 0.1113 (0.4350) Loss_G: -0.2340 (0.2864) D(x): 0.5202 D(G(z)): 0.4933 / 0.5281 Acc: 37.5000 (27.7541)\n",
      "[6/25][131/782] Loss_D: 0.0908 (0.4349) Loss_G: -0.0094 (0.2864) D(x): 0.5771 D(G(z)): 0.5070 / 0.4291 Acc: 34.3750 (27.7554)\n",
      "[6/25][132/782] Loss_D: 0.2549 (0.4349) Loss_G: 0.0514 (0.2863) D(x): 0.4968 D(G(z)): 0.5049 / 0.4183 Acc: 34.3750 (27.7568)\n",
      "[6/25][133/782] Loss_D: 0.1877 (0.4348) Loss_G: 0.0128 (0.2863) D(x): 0.4605 D(G(z)): 0.3942 / 0.4316 Acc: 32.8125 (27.7578)\n",
      "[6/25][134/782] Loss_D: 0.2197 (0.4348) Loss_G: -0.0828 (0.2862) D(x): 0.5057 D(G(z)): 0.4991 / 0.4682 Acc: 34.3750 (27.7592)\n",
      "[6/25][135/782] Loss_D: 0.1828 (0.4347) Loss_G: -0.0423 (0.2861) D(x): 0.5529 D(G(z)): 0.4937 / 0.4537 Acc: 26.5625 (27.7590)\n",
      "[6/25][136/782] Loss_D: 0.1906 (0.4347) Loss_G: 0.0182 (0.2861) D(x): 0.5201 D(G(z)): 0.4847 / 0.4555 Acc: 37.5000 (27.7610)\n",
      "[6/25][137/782] Loss_D: 0.1328 (0.4346) Loss_G: -0.0190 (0.2860) D(x): 0.4758 D(G(z)): 0.4379 / 0.4354 Acc: 37.5000 (27.7630)\n",
      "[6/25][138/782] Loss_D: 0.2431 (0.4346) Loss_G: 0.0941 (0.2860) D(x): 0.6015 D(G(z)): 0.4751 / 0.4597 Acc: 26.5625 (27.7628)\n",
      "[6/25][139/782] Loss_D: 0.0798 (0.4345) Loss_G: 0.0549 (0.2859) D(x): 0.5952 D(G(z)): 0.5284 / 0.4270 Acc: 37.5000 (27.7648)\n",
      "[6/25][140/782] Loss_D: 0.1164 (0.4344) Loss_G: 0.0241 (0.2858) D(x): 0.4890 D(G(z)): 0.4196 / 0.4192 Acc: 31.2500 (27.7655)\n",
      "[6/25][141/782] Loss_D: 0.0913 (0.4344) Loss_G: 0.0227 (0.2858) D(x): 0.5096 D(G(z)): 0.4342 / 0.4348 Acc: 37.5000 (27.7675)\n",
      "[6/25][142/782] Loss_D: 0.1557 (0.4343) Loss_G: -0.1131 (0.2857) D(x): 0.5356 D(G(z)): 0.5004 / 0.4869 Acc: 37.5000 (27.7695)\n",
      "[6/25][143/782] Loss_D: 0.1572 (0.4343) Loss_G: -0.0050 (0.2857) D(x): 0.5697 D(G(z)): 0.5178 / 0.4451 Acc: 34.3750 (27.7709)\n",
      "[6/25][144/782] Loss_D: 0.0989 (0.4342) Loss_G: 0.0937 (0.2856) D(x): 0.5181 D(G(z)): 0.4579 / 0.3991 Acc: 42.1875 (27.7739)\n",
      "[6/25][145/782] Loss_D: 0.0362 (0.4341) Loss_G: -0.0885 (0.2855) D(x): 0.5144 D(G(z)): 0.4281 / 0.4778 Acc: 35.9375 (27.7756)\n",
      "[6/25][146/782] Loss_D: 0.0642 (0.4340) Loss_G: -0.1350 (0.2854) D(x): 0.5549 D(G(z)): 0.4664 / 0.5159 Acc: 35.9375 (27.7772)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/25][147/782] Loss_D: 0.0960 (0.4340) Loss_G: -0.1310 (0.2854) D(x): 0.5549 D(G(z)): 0.4673 / 0.5120 Acc: 37.5000 (27.7792)\n",
      "[6/25][148/782] Loss_D: 0.1058 (0.4339) Loss_G: 0.0610 (0.2853) D(x): 0.5545 D(G(z)): 0.4977 / 0.4172 Acc: 37.5000 (27.7813)\n",
      "[6/25][149/782] Loss_D: 0.2753 (0.4339) Loss_G: 0.0862 (0.2853) D(x): 0.5060 D(G(z)): 0.4775 / 0.4182 Acc: 28.1250 (27.7813)\n",
      "[6/25][150/782] Loss_D: 0.0618 (0.4338) Loss_G: 0.1445 (0.2852) D(x): 0.5492 D(G(z)): 0.4429 / 0.4114 Acc: 34.3750 (27.7827)\n",
      "[6/25][151/782] Loss_D: 0.1251 (0.4337) Loss_G: 0.0237 (0.2852) D(x): 0.5280 D(G(z)): 0.4844 / 0.4377 Acc: 39.0625 (27.7850)\n",
      "[6/25][152/782] Loss_D: 0.1963 (0.4337) Loss_G: -0.0332 (0.2851) D(x): 0.5028 D(G(z)): 0.4732 / 0.4412 Acc: 34.3750 (27.7864)\n",
      "[6/25][153/782] Loss_D: 0.2251 (0.4336) Loss_G: -0.1280 (0.2850) D(x): 0.5093 D(G(z)): 0.4892 / 0.4702 Acc: 28.1250 (27.7864)\n",
      "[6/25][154/782] Loss_D: 0.2250 (0.4336) Loss_G: -0.0356 (0.2850) D(x): 0.5419 D(G(z)): 0.5166 / 0.4577 Acc: 31.2500 (27.7872)\n",
      "[6/25][155/782] Loss_D: 0.1812 (0.4335) Loss_G: -0.1618 (0.2849) D(x): 0.4832 D(G(z)): 0.4960 / 0.4872 Acc: 39.0625 (27.7895)\n",
      "[6/25][156/782] Loss_D: 0.1056 (0.4335) Loss_G: -0.0692 (0.2848) D(x): 0.5208 D(G(z)): 0.5012 / 0.4605 Acc: 42.1875 (27.7925)\n",
      "[6/25][157/782] Loss_D: -0.0542 (0.4334) Loss_G: -0.0323 (0.2847) D(x): 0.5637 D(G(z)): 0.4455 / 0.4269 Acc: 31.2500 (27.7932)\n",
      "[6/25][158/782] Loss_D: 0.1366 (0.4333) Loss_G: -0.0185 (0.2847) D(x): 0.4861 D(G(z)): 0.4430 / 0.4485 Acc: 40.6250 (27.7958)\n",
      "[6/25][159/782] Loss_D: 0.2182 (0.4333) Loss_G: 0.0045 (0.2846) D(x): 0.5160 D(G(z)): 0.4855 / 0.4413 Acc: 32.8125 (27.7968)\n",
      "[6/25][160/782] Loss_D: 0.1159 (0.4332) Loss_G: -0.1184 (0.2845) D(x): 0.5260 D(G(z)): 0.5197 / 0.4499 Acc: 37.5000 (27.7988)\n",
      "[6/25][161/782] Loss_D: 0.1634 (0.4331) Loss_G: -0.0648 (0.2845) D(x): 0.5355 D(G(z)): 0.4915 / 0.4515 Acc: 31.2500 (27.7996)\n",
      "[6/25][162/782] Loss_D: 0.2284 (0.4331) Loss_G: -0.0866 (0.2844) D(x): 0.5240 D(G(z)): 0.4654 / 0.4743 Acc: 23.4375 (27.7987)\n",
      "[6/25][163/782] Loss_D: -0.0898 (0.4330) Loss_G: 0.1240 (0.2844) D(x): 0.5672 D(G(z)): 0.4470 / 0.4037 Acc: 46.8750 (27.8026)\n",
      "[6/25][164/782] Loss_D: 0.0576 (0.4329) Loss_G: -0.0365 (0.2843) D(x): 0.5385 D(G(z)): 0.4720 / 0.4365 Acc: 39.0625 (27.8049)\n",
      "[6/25][165/782] Loss_D: 0.1132 (0.4328) Loss_G: -0.0704 (0.2842) D(x): 0.5240 D(G(z)): 0.4663 / 0.4536 Acc: 40.6250 (27.8075)\n",
      "[6/25][166/782] Loss_D: 0.2195 (0.4328) Loss_G: 0.0083 (0.2842) D(x): 0.5082 D(G(z)): 0.4506 / 0.4257 Acc: 28.1250 (27.8076)\n",
      "[6/25][167/782] Loss_D: 0.2931 (0.4328) Loss_G: -0.0505 (0.2841) D(x): 0.5127 D(G(z)): 0.4543 / 0.4641 Acc: 23.4375 (27.8067)\n",
      "[6/25][168/782] Loss_D: 0.1416 (0.4327) Loss_G: 0.0429 (0.2840) D(x): 0.5460 D(G(z)): 0.4814 / 0.4279 Acc: 35.9375 (27.8084)\n",
      "[6/25][169/782] Loss_D: 0.0545 (0.4326) Loss_G: -0.1859 (0.2839) D(x): 0.5083 D(G(z)): 0.4713 / 0.4812 Acc: 37.5000 (27.8104)\n",
      "[6/25][170/782] Loss_D: 0.2417 (0.4326) Loss_G: -0.0862 (0.2839) D(x): 0.5571 D(G(z)): 0.5425 / 0.4684 Acc: 28.1250 (27.8104)\n",
      "[6/25][171/782] Loss_D: -0.0116 (0.4325) Loss_G: -0.0776 (0.2838) D(x): 0.5359 D(G(z)): 0.4845 / 0.4612 Acc: 50.0000 (27.8150)\n",
      "[6/25][172/782] Loss_D: 0.2785 (0.4325) Loss_G: -0.0059 (0.2837) D(x): 0.4991 D(G(z)): 0.4861 / 0.4497 Acc: 32.8125 (27.8160)\n",
      "[6/25][173/782] Loss_D: 0.2279 (0.4324) Loss_G: -0.1958 (0.2836) D(x): 0.4739 D(G(z)): 0.4833 / 0.4866 Acc: 34.3750 (27.8174)\n",
      "[6/25][174/782] Loss_D: 0.2663 (0.4324) Loss_G: -0.1146 (0.2836) D(x): 0.5285 D(G(z)): 0.5213 / 0.4904 Acc: 31.2500 (27.8181)\n",
      "[6/25][175/782] Loss_D: 0.0936 (0.4323) Loss_G: -0.0103 (0.2835) D(x): 0.5308 D(G(z)): 0.4849 / 0.4394 Acc: 39.0625 (27.8204)\n",
      "[6/25][176/782] Loss_D: 0.1189 (0.4323) Loss_G: -0.0280 (0.2834) D(x): 0.5153 D(G(z)): 0.4647 / 0.4440 Acc: 34.3750 (27.8217)\n",
      "[6/25][177/782] Loss_D: 0.1285 (0.4322) Loss_G: -0.0745 (0.2834) D(x): 0.4915 D(G(z)): 0.4577 / 0.4546 Acc: 35.9375 (27.8234)\n",
      "[6/25][178/782] Loss_D: 0.0712 (0.4321) Loss_G: -0.1500 (0.2833) D(x): 0.5621 D(G(z)): 0.5037 / 0.4643 Acc: 32.8125 (27.8244)\n",
      "[6/25][179/782] Loss_D: 0.0334 (0.4320) Loss_G: -0.0340 (0.2832) D(x): 0.5091 D(G(z)): 0.4486 / 0.4413 Acc: 42.1875 (27.8274)\n",
      "[6/25][180/782] Loss_D: 0.0271 (0.4320) Loss_G: -0.0628 (0.2831) D(x): 0.5772 D(G(z)): 0.4698 / 0.4586 Acc: 35.9375 (27.8290)\n",
      "[6/25][181/782] Loss_D: 0.1680 (0.4319) Loss_G: 0.0739 (0.2831) D(x): 0.5527 D(G(z)): 0.5059 / 0.4223 Acc: 37.5000 (27.8310)\n",
      "[6/25][182/782] Loss_D: 0.2578 (0.4319) Loss_G: -0.0847 (0.2830) D(x): 0.4902 D(G(z)): 0.4492 / 0.5013 Acc: 32.8125 (27.8321)\n",
      "[6/25][183/782] Loss_D: 0.1317 (0.4318) Loss_G: -0.0802 (0.2829) D(x): 0.5317 D(G(z)): 0.4652 / 0.4768 Acc: 29.6875 (27.8324)\n",
      "[6/25][184/782] Loss_D: 0.0344 (0.4317) Loss_G: -0.0917 (0.2829) D(x): 0.5352 D(G(z)): 0.4659 / 0.4803 Acc: 37.5000 (27.8344)\n",
      "[6/25][185/782] Loss_D: -0.0451 (0.4316) Loss_G: -0.0010 (0.2828) D(x): 0.6097 D(G(z)): 0.4630 / 0.4366 Acc: 35.9375 (27.8361)\n",
      "[6/25][186/782] Loss_D: 0.1232 (0.4316) Loss_G: 0.0283 (0.2828) D(x): 0.5292 D(G(z)): 0.4651 / 0.4293 Acc: 37.5000 (27.8381)\n",
      "[6/25][187/782] Loss_D: 0.2009 (0.4315) Loss_G: -0.1145 (0.2827) D(x): 0.5254 D(G(z)): 0.5141 / 0.4783 Acc: 35.9375 (27.8397)\n",
      "[6/25][188/782] Loss_D: 0.2118 (0.4315) Loss_G: -0.0711 (0.2826) D(x): 0.4907 D(G(z)): 0.4724 / 0.4456 Acc: 34.3750 (27.8411)\n",
      "[6/25][189/782] Loss_D: 0.5110 (0.4315) Loss_G: -0.0785 (0.2825) D(x): 0.4796 D(G(z)): 0.5277 / 0.5025 Acc: 23.4375 (27.8402)\n",
      "[6/25][190/782] Loss_D: 0.2202 (0.4314) Loss_G: 0.0944 (0.2825) D(x): 0.5412 D(G(z)): 0.5191 / 0.3934 Acc: 31.2500 (27.8409)\n",
      "[6/25][191/782] Loss_D: 0.2545 (0.4314) Loss_G: -0.0251 (0.2824) D(x): 0.4858 D(G(z)): 0.4728 / 0.4617 Acc: 39.0625 (27.8431)\n",
      "[6/25][192/782] Loss_D: 0.2712 (0.4314) Loss_G: -0.0369 (0.2824) D(x): 0.5251 D(G(z)): 0.4859 / 0.4476 Acc: 23.4375 (27.8422)\n",
      "[6/25][193/782] Loss_D: -0.0268 (0.4313) Loss_G: 0.0115 (0.2823) D(x): 0.5319 D(G(z)): 0.4100 / 0.4198 Acc: 32.8125 (27.8433)\n",
      "[6/25][194/782] Loss_D: 0.0988 (0.4312) Loss_G: -0.1009 (0.2822) D(x): 0.4806 D(G(z)): 0.4836 / 0.4773 Acc: 46.8750 (27.8472)\n",
      "[6/25][195/782] Loss_D: 0.3018 (0.4312) Loss_G: -0.1465 (0.2821) D(x): 0.5327 D(G(z)): 0.4946 / 0.4828 Acc: 21.8750 (27.8459)\n",
      "[6/25][196/782] Loss_D: 0.1232 (0.4311) Loss_G: -0.0663 (0.2821) D(x): 0.5159 D(G(z)): 0.4686 / 0.4581 Acc: 37.5000 (27.8479)\n",
      "[6/25][197/782] Loss_D: 0.4126 (0.4311) Loss_G: 0.1146 (0.2820) D(x): 0.5321 D(G(z)): 0.4883 / 0.4334 Acc: 20.3125 (27.8464)\n",
      "[6/25][198/782] Loss_D: 0.0720 (0.4311) Loss_G: -0.0230 (0.2820) D(x): 0.5549 D(G(z)): 0.5156 / 0.4245 Acc: 40.6250 (27.8490)\n",
      "[6/25][199/782] Loss_D: 0.1728 (0.4310) Loss_G: 0.1162 (0.2819) D(x): 0.5151 D(G(z)): 0.4632 / 0.3978 Acc: 37.5000 (27.8510)\n",
      "[6/25][200/782] Loss_D: 0.2214 (0.4310) Loss_G: -0.0347 (0.2819) D(x): 0.4693 D(G(z)): 0.4310 / 0.4573 Acc: 28.1250 (27.8510)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[6/25][201/782] Loss_D: 0.3161 (0.4309) Loss_G: 0.0726 (0.2818) D(x): 0.4854 D(G(z)): 0.4464 / 0.4294 Acc: 28.1250 (27.8511)\n",
      "[6/25][202/782] Loss_D: -0.0131 (0.4308) Loss_G: 0.0111 (0.2818) D(x): 0.6107 D(G(z)): 0.4556 / 0.4558 Acc: 35.9375 (27.8527)\n",
      "[6/25][203/782] Loss_D: 0.2548 (0.4308) Loss_G: 0.0550 (0.2817) D(x): 0.4928 D(G(z)): 0.4630 / 0.4228 Acc: 32.8125 (27.8537)\n",
      "[6/25][204/782] Loss_D: 0.2769 (0.4308) Loss_G: 0.0442 (0.2817) D(x): 0.5551 D(G(z)): 0.4915 / 0.4480 Acc: 25.0000 (27.8531)\n",
      "[6/25][205/782] Loss_D: 0.1235 (0.4307) Loss_G: 0.1113 (0.2816) D(x): 0.5680 D(G(z)): 0.4480 / 0.4176 Acc: 25.0000 (27.8526)\n",
      "[6/25][206/782] Loss_D: 0.1616 (0.4307) Loss_G: 0.1838 (0.2816) D(x): 0.5376 D(G(z)): 0.4800 / 0.4025 Acc: 39.0625 (27.8549)\n",
      "[6/25][207/782] Loss_D: 0.3733 (0.4306) Loss_G: 0.0883 (0.2816) D(x): 0.5420 D(G(z)): 0.5240 / 0.4305 Acc: 35.9375 (27.8565)\n",
      "[6/25][208/782] Loss_D: 0.3206 (0.4306) Loss_G: 0.0459 (0.2815) D(x): 0.5301 D(G(z)): 0.5318 / 0.4445 Acc: 39.0625 (27.8588)\n",
      "[6/25][209/782] Loss_D: 0.1951 (0.4306) Loss_G: 0.0662 (0.2815) D(x): 0.5142 D(G(z)): 0.4393 / 0.4303 Acc: 23.4375 (27.8579)\n",
      "[6/25][210/782] Loss_D: 0.2058 (0.4305) Loss_G: 0.0359 (0.2814) D(x): 0.4645 D(G(z)): 0.3928 / 0.4566 Acc: 31.2500 (27.8586)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/25][211/782] Loss_D: 0.0560 (0.4305) Loss_G: -0.0411 (0.2814) D(x): 0.5608 D(G(z)): 0.4719 / 0.4539 Acc: 35.9375 (27.8602)\n",
      "[6/25][212/782] Loss_D: 0.0444 (0.4304) Loss_G: -0.0128 (0.2813) D(x): 0.5565 D(G(z)): 0.4675 / 0.4427 Acc: 34.3750 (27.8616)\n",
      "[6/25][213/782] Loss_D: 0.1325 (0.4303) Loss_G: -0.0042 (0.2813) D(x): 0.5741 D(G(z)): 0.5253 / 0.4476 Acc: 40.6250 (27.8642)\n",
      "[6/25][214/782] Loss_D: 0.2174 (0.4303) Loss_G: 0.0050 (0.2812) D(x): 0.4836 D(G(z)): 0.4724 / 0.4267 Acc: 37.5000 (27.8661)\n",
      "[6/25][215/782] Loss_D: 0.2358 (0.4302) Loss_G: 0.0116 (0.2811) D(x): 0.5439 D(G(z)): 0.4899 / 0.4466 Acc: 29.6875 (27.8665)\n",
      "[6/25][216/782] Loss_D: 0.0585 (0.4302) Loss_G: -0.1151 (0.2811) D(x): 0.4805 D(G(z)): 0.4526 / 0.4634 Acc: 51.5625 (27.8713)\n",
      "[6/25][217/782] Loss_D: 0.1811 (0.4301) Loss_G: 0.0435 (0.2810) D(x): 0.5170 D(G(z)): 0.4898 / 0.4391 Acc: 39.0625 (27.8736)\n",
      "[6/25][218/782] Loss_D: 0.0250 (0.4300) Loss_G: -0.0653 (0.2809) D(x): 0.5850 D(G(z)): 0.4815 / 0.4577 Acc: 31.2500 (27.8743)\n",
      "[6/25][219/782] Loss_D: -0.0525 (0.4299) Loss_G: 0.1494 (0.2809) D(x): 0.5785 D(G(z)): 0.4567 / 0.3924 Acc: 42.1875 (27.8772)\n",
      "[6/25][220/782] Loss_D: 0.0874 (0.4299) Loss_G: 0.0346 (0.2809) D(x): 0.4905 D(G(z)): 0.3960 / 0.4412 Acc: 32.8125 (27.8782)\n",
      "[6/25][221/782] Loss_D: 0.1980 (0.4298) Loss_G: 0.0029 (0.2808) D(x): 0.5566 D(G(z)): 0.4994 / 0.4603 Acc: 28.1250 (27.8783)\n",
      "[6/25][222/782] Loss_D: 0.1966 (0.4298) Loss_G: 0.0860 (0.2808) D(x): 0.5492 D(G(z)): 0.4820 / 0.4317 Acc: 32.8125 (27.8793)\n",
      "[6/25][223/782] Loss_D: 0.0526 (0.4297) Loss_G: -0.0349 (0.2807) D(x): 0.5064 D(G(z)): 0.4238 / 0.4484 Acc: 37.5000 (27.8812)\n",
      "[6/25][224/782] Loss_D: 0.1461 (0.4296) Loss_G: 0.0256 (0.2807) D(x): 0.5547 D(G(z)): 0.4932 / 0.4118 Acc: 28.1250 (27.8813)\n",
      "[6/25][225/782] Loss_D: 0.1698 (0.4296) Loss_G: 0.0496 (0.2806) D(x): 0.5287 D(G(z)): 0.4459 / 0.4219 Acc: 25.0000 (27.8807)\n",
      "[6/25][226/782] Loss_D: 0.0549 (0.4295) Loss_G: 0.0687 (0.2806) D(x): 0.5595 D(G(z)): 0.4512 / 0.3917 Acc: 31.2500 (27.8814)\n",
      "[6/25][227/782] Loss_D: 0.2460 (0.4295) Loss_G: -0.0498 (0.2805) D(x): 0.4932 D(G(z)): 0.4616 / 0.4514 Acc: 23.4375 (27.8805)\n",
      "[6/25][228/782] Loss_D: 0.0981 (0.4294) Loss_G: -0.0319 (0.2804) D(x): 0.5499 D(G(z)): 0.4673 / 0.4479 Acc: 32.8125 (27.8815)\n",
      "[6/25][229/782] Loss_D: -0.0852 (0.4293) Loss_G: 0.0186 (0.2804) D(x): 0.5725 D(G(z)): 0.4421 / 0.4404 Acc: 42.1875 (27.8844)\n",
      "[6/25][230/782] Loss_D: 0.1716 (0.4292) Loss_G: 0.0309 (0.2803) D(x): 0.5422 D(G(z)): 0.4828 / 0.4537 Acc: 37.5000 (27.8863)\n",
      "[6/25][231/782] Loss_D: 0.1071 (0.4292) Loss_G: -0.0310 (0.2803) D(x): 0.5470 D(G(z)): 0.4805 / 0.4523 Acc: 34.3750 (27.8876)\n",
      "[6/25][232/782] Loss_D: -0.0477 (0.4291) Loss_G: 0.0127 (0.2802) D(x): 0.5623 D(G(z)): 0.4846 / 0.4182 Acc: 43.7500 (27.8909)\n",
      "[6/25][233/782] Loss_D: 0.1619 (0.4290) Loss_G: -0.0244 (0.2802) D(x): 0.4682 D(G(z)): 0.4366 / 0.4482 Acc: 40.6250 (27.8934)\n",
      "[6/25][234/782] Loss_D: 0.1353 (0.4290) Loss_G: -0.0521 (0.2801) D(x): 0.5130 D(G(z)): 0.5101 / 0.4500 Acc: 46.8750 (27.8973)\n",
      "[6/25][235/782] Loss_D: 0.2464 (0.4289) Loss_G: 0.0013 (0.2800) D(x): 0.5111 D(G(z)): 0.5132 / 0.4546 Acc: 39.0625 (27.8996)\n",
      "[6/25][236/782] Loss_D: 0.1221 (0.4289) Loss_G: -0.0703 (0.2800) D(x): 0.5246 D(G(z)): 0.4931 / 0.4292 Acc: 29.6875 (27.8999)\n",
      "[6/25][237/782] Loss_D: 0.1864 (0.4288) Loss_G: 0.0751 (0.2799) D(x): 0.5256 D(G(z)): 0.4731 / 0.4199 Acc: 31.2500 (27.9006)\n",
      "[6/25][238/782] Loss_D: 0.2058 (0.4288) Loss_G: 0.0769 (0.2799) D(x): 0.5248 D(G(z)): 0.4922 / 0.4172 Acc: 34.3750 (27.9019)\n",
      "[6/25][239/782] Loss_D: 0.1938 (0.4287) Loss_G: -0.0900 (0.2798) D(x): 0.4539 D(G(z)): 0.4311 / 0.4529 Acc: 32.8125 (27.9029)\n",
      "[6/25][240/782] Loss_D: 0.1817 (0.4287) Loss_G: -0.1068 (0.2797) D(x): 0.5124 D(G(z)): 0.4852 / 0.4762 Acc: 32.8125 (27.9039)\n",
      "[6/25][241/782] Loss_D: 0.2019 (0.4286) Loss_G: -0.1286 (0.2796) D(x): 0.5643 D(G(z)): 0.5385 / 0.4817 Acc: 32.8125 (27.9049)\n",
      "[6/25][242/782] Loss_D: 0.1343 (0.4286) Loss_G: -0.0924 (0.2796) D(x): 0.4900 D(G(z)): 0.4381 / 0.4659 Acc: 35.9375 (27.9065)\n",
      "[6/25][243/782] Loss_D: 0.2024 (0.4285) Loss_G: 0.0400 (0.2795) D(x): 0.5513 D(G(z)): 0.5085 / 0.4302 Acc: 31.2500 (27.9072)\n",
      "[6/25][244/782] Loss_D: 0.2094 (0.4285) Loss_G: 0.0135 (0.2795) D(x): 0.4904 D(G(z)): 0.4475 / 0.4580 Acc: 35.9375 (27.9088)\n",
      "[6/25][245/782] Loss_D: 0.2322 (0.4284) Loss_G: -0.0005 (0.2794) D(x): 0.5221 D(G(z)): 0.4671 / 0.4398 Acc: 28.1250 (27.9089)\n",
      "[6/25][246/782] Loss_D: 0.0956 (0.4284) Loss_G: -0.0731 (0.2793) D(x): 0.5442 D(G(z)): 0.4495 / 0.4570 Acc: 26.5625 (27.9086)\n",
      "[6/25][247/782] Loss_D: 0.1756 (0.4283) Loss_G: 0.1184 (0.2793) D(x): 0.5200 D(G(z)): 0.4510 / 0.4166 Acc: 34.3750 (27.9099)\n",
      "[6/25][248/782] Loss_D: 0.0450 (0.4282) Loss_G: 0.0169 (0.2793) D(x): 0.5663 D(G(z)): 0.4870 / 0.4334 Acc: 35.9375 (27.9115)\n",
      "[6/25][249/782] Loss_D: 0.2375 (0.4282) Loss_G: 0.0312 (0.2792) D(x): 0.4970 D(G(z)): 0.4977 / 0.4150 Acc: 35.9375 (27.9132)\n",
      "[6/25][250/782] Loss_D: 0.2180 (0.4282) Loss_G: -0.0279 (0.2791) D(x): 0.5104 D(G(z)): 0.4678 / 0.4550 Acc: 25.0000 (27.9126)\n",
      "[6/25][251/782] Loss_D: 0.1955 (0.4281) Loss_G: 0.0194 (0.2791) D(x): 0.5463 D(G(z)): 0.5039 / 0.4058 Acc: 31.2500 (27.9133)\n",
      "[6/25][252/782] Loss_D: 0.2391 (0.4281) Loss_G: 0.0047 (0.2790) D(x): 0.5288 D(G(z)): 0.5232 / 0.4383 Acc: 32.8125 (27.9142)\n",
      "[6/25][253/782] Loss_D: 0.0586 (0.4280) Loss_G: -0.0707 (0.2790) D(x): 0.4944 D(G(z)): 0.4015 / 0.4549 Acc: 31.2500 (27.9149)\n",
      "[6/25][254/782] Loss_D: 0.2190 (0.4280) Loss_G: -0.0894 (0.2789) D(x): 0.4732 D(G(z)): 0.4626 / 0.4931 Acc: 37.5000 (27.9169)\n",
      "[6/25][255/782] Loss_D: 0.1647 (0.4279) Loss_G: -0.0420 (0.2788) D(x): 0.5697 D(G(z)): 0.5234 / 0.4591 Acc: 34.3750 (27.9182)\n",
      "[6/25][256/782] Loss_D: -0.0190 (0.4278) Loss_G: -0.1079 (0.2787) D(x): 0.5964 D(G(z)): 0.4739 / 0.4896 Acc: 34.3750 (27.9195)\n",
      "[6/25][257/782] Loss_D: 0.1826 (0.4278) Loss_G: 0.0195 (0.2787) D(x): 0.5178 D(G(z)): 0.4556 / 0.4659 Acc: 42.1875 (27.9223)\n",
      "[6/25][258/782] Loss_D: 0.1222 (0.4277) Loss_G: -0.2289 (0.2786) D(x): 0.4722 D(G(z)): 0.4609 / 0.5319 Acc: 46.8750 (27.9262)\n",
      "[6/25][259/782] Loss_D: 0.1060 (0.4276) Loss_G: -0.0306 (0.2785) D(x): 0.5616 D(G(z)): 0.4960 / 0.4445 Acc: 37.5000 (27.9281)\n",
      "[6/25][260/782] Loss_D: -0.0326 (0.4275) Loss_G: -0.0995 (0.2784) D(x): 0.5349 D(G(z)): 0.4466 / 0.4710 Acc: 42.1875 (27.9310)\n",
      "[6/25][261/782] Loss_D: 0.2754 (0.4275) Loss_G: 0.0870 (0.2784) D(x): 0.5205 D(G(z)): 0.4956 / 0.4183 Acc: 31.2500 (27.9317)\n",
      "[6/25][262/782] Loss_D: 0.2411 (0.4275) Loss_G: 0.1110 (0.2784) D(x): 0.5179 D(G(z)): 0.5076 / 0.4167 Acc: 34.3750 (27.9330)\n",
      "[6/25][263/782] Loss_D: 0.1884 (0.4274) Loss_G: -0.1120 (0.2783) D(x): 0.5316 D(G(z)): 0.5067 / 0.4613 Acc: 31.2500 (27.9336)\n",
      "[6/25][264/782] Loss_D: 0.2227 (0.4274) Loss_G: 0.0320 (0.2782) D(x): 0.5272 D(G(z)): 0.4751 / 0.4776 Acc: 39.0625 (27.9359)\n",
      "[6/25][265/782] Loss_D: 0.0316 (0.4273) Loss_G: -0.0942 (0.2782) D(x): 0.4950 D(G(z)): 0.4660 / 0.4504 Acc: 45.3125 (27.9394)\n",
      "[6/25][266/782] Loss_D: 0.1500 (0.4272) Loss_G: -0.0447 (0.2781) D(x): 0.5268 D(G(z)): 0.4872 / 0.4682 Acc: 35.9375 (27.9410)\n",
      "[6/25][267/782] Loss_D: 0.1535 (0.4272) Loss_G: -0.0158 (0.2780) D(x): 0.5053 D(G(z)): 0.4650 / 0.4442 Acc: 34.3750 (27.9423)\n",
      "[6/25][268/782] Loss_D: 0.0365 (0.4271) Loss_G: -0.0788 (0.2780) D(x): 0.5239 D(G(z)): 0.5088 / 0.4579 Acc: 50.0000 (27.9467)\n",
      "[6/25][269/782] Loss_D: 0.2988 (0.4271) Loss_G: -0.1089 (0.2779) D(x): 0.4701 D(G(z)): 0.4733 / 0.4677 Acc: 31.2500 (27.9474)\n",
      "[6/25][270/782] Loss_D: 0.1884 (0.4270) Loss_G: -0.1138 (0.2778) D(x): 0.5720 D(G(z)): 0.5361 / 0.4642 Acc: 26.5625 (27.9471)\n",
      "[6/25][271/782] Loss_D: 0.1680 (0.4270) Loss_G: 0.1855 (0.2778) D(x): 0.5592 D(G(z)): 0.4482 / 0.3846 Acc: 29.6875 (27.9475)\n",
      "[6/25][272/782] Loss_D: 0.1162 (0.4269) Loss_G: 0.0777 (0.2778) D(x): 0.5528 D(G(z)): 0.4605 / 0.4084 Acc: 29.6875 (27.9478)\n",
      "[6/25][273/782] Loss_D: 0.3292 (0.4269) Loss_G: -0.0621 (0.2777) D(x): 0.4532 D(G(z)): 0.4183 / 0.4551 Acc: 23.4375 (27.9469)\n",
      "[6/25][274/782] Loss_D: -0.0271 (0.4268) Loss_G: -0.1407 (0.2776) D(x): 0.5804 D(G(z)): 0.4451 / 0.4837 Acc: 28.1250 (27.9469)\n",
      "[6/25][275/782] Loss_D: 0.2176 (0.4268) Loss_G: -0.0840 (0.2775) D(x): 0.5699 D(G(z)): 0.5395 / 0.4830 Acc: 32.8125 (27.9479)\n",
      "[6/25][276/782] Loss_D: 0.0324 (0.4267) Loss_G: -0.1544 (0.2774) D(x): 0.4921 D(G(z)): 0.4309 / 0.4736 Acc: 35.9375 (27.9495)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/25][277/782] Loss_D: 0.2737 (0.4267) Loss_G: -0.1271 (0.2774) D(x): 0.4706 D(G(z)): 0.4671 / 0.5010 Acc: 34.3750 (27.9508)\n",
      "[6/25][278/782] Loss_D: 0.2659 (0.4266) Loss_G: -0.0197 (0.2773) D(x): 0.5208 D(G(z)): 0.5371 / 0.4707 Acc: 43.7500 (27.9540)\n",
      "[6/25][279/782] Loss_D: 0.2018 (0.4266) Loss_G: -0.0918 (0.2772) D(x): 0.4950 D(G(z)): 0.4746 / 0.4800 Acc: 32.8125 (27.9550)\n",
      "[6/25][280/782] Loss_D: 0.0533 (0.4265) Loss_G: -0.0468 (0.2772) D(x): 0.5138 D(G(z)): 0.4361 / 0.4709 Acc: 35.9375 (27.9566)\n",
      "[6/25][281/782] Loss_D: 0.2513 (0.4265) Loss_G: 0.0215 (0.2771) D(x): 0.5649 D(G(z)): 0.5061 / 0.4375 Acc: 26.5625 (27.9563)\n",
      "[6/25][282/782] Loss_D: 0.4104 (0.4265) Loss_G: -0.0322 (0.2771) D(x): 0.4582 D(G(z)): 0.4646 / 0.4811 Acc: 29.6875 (27.9567)\n",
      "[6/25][283/782] Loss_D: 0.1422 (0.4264) Loss_G: -0.0814 (0.2770) D(x): 0.5489 D(G(z)): 0.4912 / 0.4574 Acc: 28.1250 (27.9567)\n",
      "[6/25][284/782] Loss_D: 0.0867 (0.4263) Loss_G: -0.0269 (0.2769) D(x): 0.5076 D(G(z)): 0.4198 / 0.4367 Acc: 29.6875 (27.9570)\n",
      "[6/25][285/782] Loss_D: 0.1661 (0.4263) Loss_G: -0.0114 (0.2769) D(x): 0.5041 D(G(z)): 0.4998 / 0.4491 Acc: 43.7500 (27.9602)\n",
      "[6/25][286/782] Loss_D: 0.2388 (0.4263) Loss_G: -0.0784 (0.2768) D(x): 0.4883 D(G(z)): 0.4710 / 0.4818 Acc: 37.5000 (27.9621)\n",
      "[6/25][287/782] Loss_D: 0.1990 (0.4262) Loss_G: -0.1186 (0.2767) D(x): 0.4936 D(G(z)): 0.5062 / 0.4711 Acc: 40.6250 (27.9647)\n",
      "[6/25][288/782] Loss_D: 0.2693 (0.4262) Loss_G: -0.1267 (0.2766) D(x): 0.5378 D(G(z)): 0.5439 / 0.4796 Acc: 32.8125 (27.9656)\n",
      "[6/25][289/782] Loss_D: 0.1942 (0.4261) Loss_G: 0.0106 (0.2766) D(x): 0.5193 D(G(z)): 0.5009 / 0.4519 Acc: 39.0625 (27.9679)\n",
      "[6/25][290/782] Loss_D: 0.1700 (0.4261) Loss_G: -0.0289 (0.2765) D(x): 0.5003 D(G(z)): 0.4779 / 0.4512 Acc: 40.6250 (27.9704)\n",
      "[6/25][291/782] Loss_D: 0.0680 (0.4260) Loss_G: -0.1710 (0.2764) D(x): 0.5048 D(G(z)): 0.4514 / 0.4760 Acc: 31.2500 (27.9711)\n",
      "[6/25][292/782] Loss_D: 0.1511 (0.4259) Loss_G: 0.0544 (0.2764) D(x): 0.5142 D(G(z)): 0.5064 / 0.4181 Acc: 40.6250 (27.9736)\n",
      "[6/25][293/782] Loss_D: 0.2895 (0.4259) Loss_G: -0.0499 (0.2763) D(x): 0.4800 D(G(z)): 0.4724 / 0.4753 Acc: 31.2500 (27.9743)\n",
      "[6/25][294/782] Loss_D: 0.1456 (0.4259) Loss_G: -0.0693 (0.2762) D(x): 0.4831 D(G(z)): 0.4822 / 0.4528 Acc: 40.6250 (27.9768)\n",
      "[6/25][295/782] Loss_D: 0.0013 (0.4258) Loss_G: -0.1633 (0.2762) D(x): 0.5256 D(G(z)): 0.4846 / 0.4868 Acc: 45.3125 (27.9803)\n",
      "[6/25][296/782] Loss_D: 0.3068 (0.4258) Loss_G: -0.1173 (0.2761) D(x): 0.4925 D(G(z)): 0.5057 / 0.4964 Acc: 32.8125 (27.9812)\n",
      "[6/25][297/782] Loss_D: 0.0624 (0.4257) Loss_G: -0.0024 (0.2760) D(x): 0.5010 D(G(z)): 0.4796 / 0.4695 Acc: 53.1250 (27.9863)\n",
      "[6/25][298/782] Loss_D: 0.1843 (0.4256) Loss_G: -0.0827 (0.2760) D(x): 0.5232 D(G(z)): 0.5007 / 0.4670 Acc: 35.9375 (27.9879)\n",
      "[6/25][299/782] Loss_D: 0.1096 (0.4256) Loss_G: -0.1949 (0.2759) D(x): 0.5619 D(G(z)): 0.4632 / 0.5065 Acc: 25.0000 (27.9873)\n",
      "[6/25][300/782] Loss_D: 0.2160 (0.4255) Loss_G: -0.0601 (0.2758) D(x): 0.5132 D(G(z)): 0.4935 / 0.4500 Acc: 31.2500 (27.9879)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[6/25][301/782] Loss_D: 0.0010 (0.4254) Loss_G: -0.0402 (0.2757) D(x): 0.5549 D(G(z)): 0.4610 / 0.4428 Acc: 37.5000 (27.9898)\n",
      "[6/25][302/782] Loss_D: 0.0880 (0.4254) Loss_G: -0.0761 (0.2757) D(x): 0.4878 D(G(z)): 0.4440 / 0.4401 Acc: 40.6250 (27.9924)\n",
      "[6/25][303/782] Loss_D: 0.0527 (0.4253) Loss_G: -0.1342 (0.2756) D(x): 0.5695 D(G(z)): 0.4830 / 0.5140 Acc: 37.5000 (27.9943)\n",
      "[6/25][304/782] Loss_D: -0.0819 (0.4252) Loss_G: -0.0729 (0.2755) D(x): 0.5672 D(G(z)): 0.4771 / 0.4408 Acc: 48.4375 (27.9984)\n",
      "[6/25][305/782] Loss_D: 0.3333 (0.4252) Loss_G: -0.0078 (0.2754) D(x): 0.5014 D(G(z)): 0.5048 / 0.4561 Acc: 29.6875 (27.9987)\n",
      "[6/25][306/782] Loss_D: 0.1088 (0.4251) Loss_G: -0.0636 (0.2754) D(x): 0.5187 D(G(z)): 0.4629 / 0.4499 Acc: 35.9375 (28.0003)\n",
      "[6/25][307/782] Loss_D: 0.1757 (0.4251) Loss_G: -0.0951 (0.2753) D(x): 0.4736 D(G(z)): 0.4992 / 0.4682 Acc: 46.8750 (28.0041)\n",
      "[6/25][308/782] Loss_D: 0.0987 (0.4250) Loss_G: -0.0387 (0.2752) D(x): 0.5167 D(G(z)): 0.4662 / 0.4348 Acc: 35.9375 (28.0056)\n",
      "[6/25][309/782] Loss_D: 0.1761 (0.4250) Loss_G: 0.0437 (0.2752) D(x): 0.5508 D(G(z)): 0.4597 / 0.4389 Acc: 26.5625 (28.0054)\n",
      "[6/25][310/782] Loss_D: -0.0123 (0.4249) Loss_G: -0.0141 (0.2751) D(x): 0.5411 D(G(z)): 0.4857 / 0.4335 Acc: 43.7500 (28.0085)\n",
      "[6/25][311/782] Loss_D: 0.0707 (0.4248) Loss_G: 0.0104 (0.2751) D(x): 0.4919 D(G(z)): 0.4470 / 0.4417 Acc: 45.3125 (28.0120)\n",
      "[6/25][312/782] Loss_D: 0.0843 (0.4247) Loss_G: 0.0144 (0.2750) D(x): 0.5694 D(G(z)): 0.4784 / 0.4345 Acc: 29.6875 (28.0123)\n",
      "[6/25][313/782] Loss_D: 0.0088 (0.4246) Loss_G: -0.0492 (0.2750) D(x): 0.5273 D(G(z)): 0.4369 / 0.4399 Acc: 35.9375 (28.0139)\n",
      "[6/25][314/782] Loss_D: 0.0226 (0.4246) Loss_G: -0.0875 (0.2749) D(x): 0.5406 D(G(z)): 0.4065 / 0.4463 Acc: 25.0000 (28.0133)\n",
      "[6/25][315/782] Loss_D: 0.1288 (0.4245) Loss_G: -0.1036 (0.2748) D(x): 0.5679 D(G(z)): 0.5143 / 0.4388 Acc: 34.3750 (28.0146)\n",
      "[6/25][316/782] Loss_D: -0.1374 (0.4244) Loss_G: -0.0173 (0.2748) D(x): 0.5554 D(G(z)): 0.4857 / 0.4213 Acc: 50.0000 (28.0189)\n",
      "[6/25][317/782] Loss_D: 0.2712 (0.4244) Loss_G: -0.1030 (0.2747) D(x): 0.4696 D(G(z)): 0.4630 / 0.4440 Acc: 31.2500 (28.0196)\n",
      "[6/25][318/782] Loss_D: 0.0004 (0.4243) Loss_G: -0.1479 (0.2746) D(x): 0.5255 D(G(z)): 0.4705 / 0.4566 Acc: 39.0625 (28.0218)\n",
      "[6/25][319/782] Loss_D: 0.0721 (0.4242) Loss_G: -0.0330 (0.2745) D(x): 0.5418 D(G(z)): 0.4477 / 0.4493 Acc: 28.1250 (28.0218)\n",
      "[6/25][320/782] Loss_D: 0.3587 (0.4242) Loss_G: -0.1500 (0.2745) D(x): 0.4888 D(G(z)): 0.5044 / 0.4743 Acc: 25.0000 (28.0212)\n",
      "[6/25][321/782] Loss_D: -0.1142 (0.4241) Loss_G: 0.0204 (0.2744) D(x): 0.6826 D(G(z)): 0.4994 / 0.3898 Acc: 31.2500 (28.0219)\n",
      "[6/25][322/782] Loss_D: 0.0430 (0.4240) Loss_G: -0.0614 (0.2743) D(x): 0.4480 D(G(z)): 0.3935 / 0.4643 Acc: 48.4375 (28.0259)\n",
      "[6/25][323/782] Loss_D: 0.0528 (0.4239) Loss_G: -0.0015 (0.2743) D(x): 0.5394 D(G(z)): 0.4684 / 0.4342 Acc: 39.0625 (28.0281)\n",
      "[6/25][324/782] Loss_D: 0.2717 (0.4239) Loss_G: -0.0603 (0.2742) D(x): 0.5063 D(G(z)): 0.4898 / 0.4669 Acc: 23.4375 (28.0272)\n",
      "[6/25][325/782] Loss_D: 0.2477 (0.4239) Loss_G: -0.0826 (0.2741) D(x): 0.5230 D(G(z)): 0.5133 / 0.4655 Acc: 31.2500 (28.0278)\n",
      "[6/25][326/782] Loss_D: 0.1424 (0.4238) Loss_G: -0.0030 (0.2741) D(x): 0.5354 D(G(z)): 0.4623 / 0.4399 Acc: 29.6875 (28.0282)\n",
      "[6/25][327/782] Loss_D: 0.1680 (0.4238) Loss_G: -0.0417 (0.2740) D(x): 0.4796 D(G(z)): 0.4577 / 0.4423 Acc: 31.2500 (28.0288)\n",
      "[6/25][328/782] Loss_D: 0.1840 (0.4237) Loss_G: -0.2591 (0.2739) D(x): 0.5214 D(G(z)): 0.5164 / 0.5224 Acc: 34.3750 (28.0301)\n",
      "[6/25][329/782] Loss_D: 0.1311 (0.4237) Loss_G: -0.1777 (0.2738) D(x): 0.5591 D(G(z)): 0.5563 / 0.4791 Acc: 40.6250 (28.0326)\n",
      "[6/25][330/782] Loss_D: 0.2110 (0.4236) Loss_G: -0.1560 (0.2737) D(x): 0.5115 D(G(z)): 0.4921 / 0.4806 Acc: 32.8125 (28.0335)\n",
      "[6/25][331/782] Loss_D: 0.2242 (0.4236) Loss_G: -0.1170 (0.2737) D(x): 0.5244 D(G(z)): 0.5132 / 0.4668 Acc: 32.8125 (28.0345)\n",
      "[6/25][332/782] Loss_D: 0.2205 (0.4235) Loss_G: -0.0698 (0.2736) D(x): 0.5059 D(G(z)): 0.4973 / 0.4658 Acc: 31.2500 (28.0351)\n",
      "[6/25][333/782] Loss_D: 0.0382 (0.4235) Loss_G: -0.0984 (0.2735) D(x): 0.5086 D(G(z)): 0.4299 / 0.4469 Acc: 34.3750 (28.0364)\n",
      "[6/25][334/782] Loss_D: 0.0746 (0.4234) Loss_G: -0.1077 (0.2735) D(x): 0.5231 D(G(z)): 0.4921 / 0.4820 Acc: 39.0625 (28.0386)\n",
      "[6/25][335/782] Loss_D: 0.3111 (0.4234) Loss_G: -0.1509 (0.2734) D(x): 0.4920 D(G(z)): 0.5118 / 0.4978 Acc: 32.8125 (28.0395)\n",
      "[6/25][336/782] Loss_D: -0.0105 (0.4233) Loss_G: -0.0757 (0.2733) D(x): 0.5608 D(G(z)): 0.4729 / 0.4535 Acc: 35.9375 (28.0411)\n",
      "[6/25][337/782] Loss_D: 0.1616 (0.4232) Loss_G: 0.0247 (0.2732) D(x): 0.5124 D(G(z)): 0.4739 / 0.4105 Acc: 29.6875 (28.0414)\n",
      "[6/25][338/782] Loss_D: 0.0106 (0.4231) Loss_G: 0.0748 (0.2732) D(x): 0.5227 D(G(z)): 0.4545 / 0.4093 Acc: 35.9375 (28.0430)\n",
      "[6/25][339/782] Loss_D: 0.2076 (0.4231) Loss_G: 0.0963 (0.2732) D(x): 0.4953 D(G(z)): 0.4786 / 0.3829 Acc: 35.9375 (28.0446)\n",
      "[6/25][340/782] Loss_D: 0.0217 (0.4230) Loss_G: -0.0674 (0.2731) D(x): 0.5506 D(G(z)): 0.4523 / 0.4426 Acc: 35.9375 (28.0461)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/25][341/782] Loss_D: -0.1321 (0.4229) Loss_G: 0.0309 (0.2731) D(x): 0.5376 D(G(z)): 0.4022 / 0.4046 Acc: 39.0625 (28.0483)\n",
      "[6/25][342/782] Loss_D: -0.0812 (0.4228) Loss_G: -0.0678 (0.2730) D(x): 0.5604 D(G(z)): 0.4455 / 0.4387 Acc: 39.0625 (28.0505)\n",
      "[6/25][343/782] Loss_D: -0.0726 (0.4227) Loss_G: -0.1533 (0.2729) D(x): 0.5442 D(G(z)): 0.3797 / 0.4765 Acc: 31.2500 (28.0512)\n",
      "[6/25][344/782] Loss_D: 0.1460 (0.4227) Loss_G: -0.0100 (0.2728) D(x): 0.5840 D(G(z)): 0.5107 / 0.4129 Acc: 29.6875 (28.0515)\n",
      "[6/25][345/782] Loss_D: 0.1463 (0.4226) Loss_G: -0.1783 (0.2728) D(x): 0.5213 D(G(z)): 0.5010 / 0.4769 Acc: 35.9375 (28.0530)\n",
      "[6/25][346/782] Loss_D: 0.3098 (0.4226) Loss_G: -0.1055 (0.2727) D(x): 0.4739 D(G(z)): 0.5057 / 0.4580 Acc: 32.8125 (28.0540)\n",
      "[6/25][347/782] Loss_D: 0.2302 (0.4225) Loss_G: -0.0761 (0.2726) D(x): 0.4925 D(G(z)): 0.4853 / 0.4477 Acc: 29.6875 (28.0543)\n",
      "[6/25][348/782] Loss_D: 0.1361 (0.4225) Loss_G: -0.0445 (0.2726) D(x): 0.5675 D(G(z)): 0.4705 / 0.4359 Acc: 20.3125 (28.0528)\n",
      "[6/25][349/782] Loss_D: 0.2527 (0.4225) Loss_G: -0.2020 (0.2725) D(x): 0.4905 D(G(z)): 0.4955 / 0.5176 Acc: 35.9375 (28.0543)\n",
      "[6/25][350/782] Loss_D: 0.2056 (0.4224) Loss_G: -0.0295 (0.2724) D(x): 0.4995 D(G(z)): 0.5189 / 0.4211 Acc: 37.5000 (28.0562)\n",
      "[6/25][351/782] Loss_D: 0.2266 (0.4224) Loss_G: -0.0175 (0.2723) D(x): 0.5132 D(G(z)): 0.4862 / 0.4296 Acc: 31.2500 (28.0568)\n",
      "[6/25][352/782] Loss_D: 0.1864 (0.4223) Loss_G: -0.1730 (0.2723) D(x): 0.4978 D(G(z)): 0.5103 / 0.4744 Acc: 32.8125 (28.0578)\n",
      "[6/25][353/782] Loss_D: 0.3611 (0.4223) Loss_G: -0.1408 (0.2722) D(x): 0.4924 D(G(z)): 0.5204 / 0.4760 Acc: 28.1250 (28.0578)\n",
      "[6/25][354/782] Loss_D: 0.2290 (0.4223) Loss_G: -0.1367 (0.2721) D(x): 0.5145 D(G(z)): 0.4952 / 0.4789 Acc: 26.5625 (28.0575)\n",
      "[6/25][355/782] Loss_D: 0.2737 (0.4222) Loss_G: -0.1265 (0.2720) D(x): 0.4802 D(G(z)): 0.5047 / 0.4813 Acc: 39.0625 (28.0597)\n",
      "[6/25][356/782] Loss_D: 0.1342 (0.4222) Loss_G: 0.0310 (0.2720) D(x): 0.5992 D(G(z)): 0.4869 / 0.4352 Acc: 28.1250 (28.0597)\n",
      "[6/25][357/782] Loss_D: 0.1277 (0.4221) Loss_G: -0.0738 (0.2719) D(x): 0.4892 D(G(z)): 0.4439 / 0.4352 Acc: 31.2500 (28.0603)\n",
      "[6/25][358/782] Loss_D: 0.0974 (0.4221) Loss_G: -0.0334 (0.2718) D(x): 0.5075 D(G(z)): 0.4283 / 0.4213 Acc: 28.1250 (28.0603)\n",
      "[6/25][359/782] Loss_D: -0.1112 (0.4220) Loss_G: -0.0718 (0.2718) D(x): 0.5713 D(G(z)): 0.4455 / 0.4260 Acc: 35.9375 (28.0619)\n",
      "[6/25][360/782] Loss_D: 0.1847 (0.4219) Loss_G: -0.1044 (0.2717) D(x): 0.5483 D(G(z)): 0.4776 / 0.4390 Acc: 21.8750 (28.0607)\n",
      "[6/25][361/782] Loss_D: 0.0755 (0.4218) Loss_G: -0.0267 (0.2716) D(x): 0.5161 D(G(z)): 0.4346 / 0.4346 Acc: 28.1250 (28.0607)\n",
      "[6/25][362/782] Loss_D: 0.0168 (0.4218) Loss_G: -0.0946 (0.2716) D(x): 0.5684 D(G(z)): 0.4320 / 0.4607 Acc: 31.2500 (28.0613)\n",
      "[6/25][363/782] Loss_D: -0.0513 (0.4217) Loss_G: -0.0974 (0.2715) D(x): 0.5680 D(G(z)): 0.4593 / 0.4488 Acc: 34.3750 (28.0626)\n",
      "[6/25][364/782] Loss_D: 0.0606 (0.4216) Loss_G: -0.0713 (0.2714) D(x): 0.5332 D(G(z)): 0.4689 / 0.4309 Acc: 37.5000 (28.0644)\n",
      "[6/25][365/782] Loss_D: -0.0060 (0.4215) Loss_G: -0.0231 (0.2714) D(x): 0.5872 D(G(z)): 0.4804 / 0.4232 Acc: 35.9375 (28.0660)\n",
      "[6/25][366/782] Loss_D: 0.1806 (0.4215) Loss_G: -0.0719 (0.2713) D(x): 0.5208 D(G(z)): 0.4635 / 0.4239 Acc: 20.3125 (28.0645)\n",
      "[6/25][367/782] Loss_D: -0.0809 (0.4214) Loss_G: -0.0138 (0.2712) D(x): 0.6040 D(G(z)): 0.4793 / 0.4001 Acc: 29.6875 (28.0648)\n",
      "[6/25][368/782] Loss_D: -0.0973 (0.4213) Loss_G: -0.0198 (0.2712) D(x): 0.5636 D(G(z)): 0.4028 / 0.4128 Acc: 32.8125 (28.0657)\n",
      "[6/25][369/782] Loss_D: -0.0527 (0.4212) Loss_G: 0.1151 (0.2711) D(x): 0.6168 D(G(z)): 0.4930 / 0.3724 Acc: 35.9375 (28.0673)\n",
      "[6/25][370/782] Loss_D: -0.1268 (0.4211) Loss_G: 0.2023 (0.2711) D(x): 0.4744 D(G(z)): 0.3698 / 0.3429 Acc: 45.3125 (28.0707)\n",
      "[6/25][371/782] Loss_D: -0.1381 (0.4210) Loss_G: 0.0943 (0.2711) D(x): 0.5820 D(G(z)): 0.4378 / 0.3771 Acc: 35.9375 (28.0722)\n",
      "[6/25][372/782] Loss_D: -0.0810 (0.4209) Loss_G: -0.0301 (0.2710) D(x): 0.5720 D(G(z)): 0.4590 / 0.4237 Acc: 39.0625 (28.0744)\n",
      "[6/25][373/782] Loss_D: 0.3271 (0.4208) Loss_G: -0.1499 (0.2710) D(x): 0.5203 D(G(z)): 0.5744 / 0.4622 Acc: 32.8125 (28.0753)\n",
      "[6/25][374/782] Loss_D: 0.2502 (0.4208) Loss_G: -0.0309 (0.2709) D(x): 0.5161 D(G(z)): 0.5248 / 0.4292 Acc: 31.2500 (28.0760)\n",
      "[6/25][375/782] Loss_D: 0.2712 (0.4208) Loss_G: -0.0383 (0.2708) D(x): 0.6069 D(G(z)): 0.5508 / 0.4585 Acc: 29.6875 (28.0763)\n",
      "[6/25][376/782] Loss_D: 0.4793 (0.4208) Loss_G: -0.1511 (0.2708) D(x): 0.4098 D(G(z)): 0.5340 / 0.4707 Acc: 35.9375 (28.0778)\n",
      "[6/25][377/782] Loss_D: 0.0389 (0.4207) Loss_G: -0.2130 (0.2707) D(x): 0.4622 D(G(z)): 0.4306 / 0.5047 Acc: 45.3125 (28.0812)\n",
      "[6/25][378/782] Loss_D: 0.1354 (0.4207) Loss_G: -0.2201 (0.2706) D(x): 0.5318 D(G(z)): 0.5266 / 0.5084 Acc: 35.9375 (28.0828)\n",
      "[6/25][379/782] Loss_D: 0.1839 (0.4206) Loss_G: -0.1454 (0.2705) D(x): 0.4842 D(G(z)): 0.4817 / 0.4743 Acc: 32.8125 (28.0837)\n",
      "[6/25][380/782] Loss_D: 0.0414 (0.4205) Loss_G: -0.0343 (0.2704) D(x): 0.5825 D(G(z)): 0.5002 / 0.4416 Acc: 31.2500 (28.0843)\n",
      "[6/25][381/782] Loss_D: 0.3393 (0.4205) Loss_G: -0.1151 (0.2703) D(x): 0.4654 D(G(z)): 0.5170 / 0.4507 Acc: 32.8125 (28.0853)\n",
      "[6/25][382/782] Loss_D: 0.0445 (0.4204) Loss_G: -0.0666 (0.2703) D(x): 0.5545 D(G(z)): 0.4725 / 0.4402 Acc: 40.6250 (28.0877)\n",
      "[6/25][383/782] Loss_D: -0.0734 (0.4203) Loss_G: 0.0612 (0.2702) D(x): 0.5522 D(G(z)): 0.4462 / 0.4096 Acc: 39.0625 (28.0899)\n",
      "[6/25][384/782] Loss_D: -0.0573 (0.4203) Loss_G: 0.0792 (0.2702) D(x): 0.5884 D(G(z)): 0.4535 / 0.4058 Acc: 35.9375 (28.0915)\n",
      "[6/25][385/782] Loss_D: 0.0995 (0.4202) Loss_G: 0.0676 (0.2702) D(x): 0.5745 D(G(z)): 0.4706 / 0.4143 Acc: 25.0000 (28.0908)\n",
      "[6/25][386/782] Loss_D: 0.0791 (0.4201) Loss_G: 0.1382 (0.2701) D(x): 0.5671 D(G(z)): 0.4551 / 0.3937 Acc: 32.8125 (28.0918)\n",
      "[6/25][387/782] Loss_D: 0.0906 (0.4201) Loss_G: 0.0304 (0.2701) D(x): 0.4979 D(G(z)): 0.4406 / 0.3989 Acc: 28.1250 (28.0918)\n",
      "[6/25][388/782] Loss_D: 0.0778 (0.4200) Loss_G: -0.0839 (0.2700) D(x): 0.5105 D(G(z)): 0.4613 / 0.4521 Acc: 39.0625 (28.0939)\n",
      "[6/25][389/782] Loss_D: 0.2925 (0.4200) Loss_G: -0.2455 (0.2699) D(x): 0.4701 D(G(z)): 0.4890 / 0.5206 Acc: 25.0000 (28.0933)\n",
      "[6/25][390/782] Loss_D: -0.0245 (0.4199) Loss_G: 0.1390 (0.2699) D(x): 0.5763 D(G(z)): 0.4843 / 0.3709 Acc: 39.0625 (28.0955)\n",
      "[6/25][391/782] Loss_D: -0.0845 (0.4198) Loss_G: 0.1235 (0.2699) D(x): 0.5582 D(G(z)): 0.4545 / 0.3672 Acc: 35.9375 (28.0970)\n",
      "[6/25][392/782] Loss_D: 0.1760 (0.4197) Loss_G: 0.0847 (0.2698) D(x): 0.4722 D(G(z)): 0.4254 / 0.3948 Acc: 29.6875 (28.0973)\n",
      "[6/25][393/782] Loss_D: 0.2272 (0.4197) Loss_G: -0.0395 (0.2698) D(x): 0.5256 D(G(z)): 0.5192 / 0.4350 Acc: 29.6875 (28.0977)\n",
      "[6/25][394/782] Loss_D: 0.0609 (0.4196) Loss_G: 0.0123 (0.2697) D(x): 0.5467 D(G(z)): 0.4751 / 0.4226 Acc: 29.6875 (28.0980)\n",
      "[6/25][395/782] Loss_D: 0.0519 (0.4195) Loss_G: -0.0601 (0.2696) D(x): 0.5050 D(G(z)): 0.4474 / 0.4396 Acc: 35.9375 (28.0995)\n",
      "[6/25][396/782] Loss_D: 0.1004 (0.4195) Loss_G: 0.0114 (0.2696) D(x): 0.5589 D(G(z)): 0.4980 / 0.4030 Acc: 32.8125 (28.1004)\n",
      "[6/25][397/782] Loss_D: 0.1401 (0.4194) Loss_G: -0.0524 (0.2695) D(x): 0.4914 D(G(z)): 0.4711 / 0.4220 Acc: 31.2500 (28.1011)\n",
      "[6/25][398/782] Loss_D: 0.0497 (0.4194) Loss_G: -0.0880 (0.2695) D(x): 0.5031 D(G(z)): 0.4687 / 0.4460 Acc: 37.5000 (28.1029)\n",
      "[6/25][399/782] Loss_D: 0.1911 (0.4193) Loss_G: -0.0516 (0.2694) D(x): 0.4717 D(G(z)): 0.4422 / 0.4524 Acc: 28.1250 (28.1029)\n",
      "[6/25][400/782] Loss_D: 0.0649 (0.4192) Loss_G: -0.1278 (0.2693) D(x): 0.5118 D(G(z)): 0.5031 / 0.4796 Acc: 45.3125 (28.1063)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[6/25][401/782] Loss_D: 0.0461 (0.4192) Loss_G: -0.0993 (0.2692) D(x): 0.5767 D(G(z)): 0.4944 / 0.4611 Acc: 32.8125 (28.1072)\n",
      "[6/25][402/782] Loss_D: 0.2339 (0.4191) Loss_G: -0.1198 (0.2692) D(x): 0.5092 D(G(z)): 0.4852 / 0.4777 Acc: 28.1250 (28.1072)\n",
      "[6/25][403/782] Loss_D: -0.0028 (0.4191) Loss_G: -0.1898 (0.2691) D(x): 0.5521 D(G(z)): 0.5056 / 0.4813 Acc: 43.7500 (28.1103)\n",
      "[6/25][404/782] Loss_D: 0.1938 (0.4190) Loss_G: -0.1302 (0.2690) D(x): 0.4797 D(G(z)): 0.4322 / 0.4567 Acc: 23.4375 (28.1094)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/25][405/782] Loss_D: 0.1220 (0.4189) Loss_G: -0.0143 (0.2689) D(x): 0.5418 D(G(z)): 0.5151 / 0.4153 Acc: 31.2500 (28.1100)\n",
      "[6/25][406/782] Loss_D: -0.0779 (0.4189) Loss_G: -0.0265 (0.2689) D(x): 0.5555 D(G(z)): 0.4226 / 0.4360 Acc: 37.5000 (28.1118)\n",
      "[6/25][407/782] Loss_D: 0.0405 (0.4188) Loss_G: -0.0437 (0.2688) D(x): 0.5352 D(G(z)): 0.4604 / 0.4365 Acc: 37.5000 (28.1137)\n",
      "[6/25][408/782] Loss_D: 0.1114 (0.4187) Loss_G: -0.0508 (0.2688) D(x): 0.5648 D(G(z)): 0.4719 / 0.4326 Acc: 21.8750 (28.1124)\n",
      "[6/25][409/782] Loss_D: -0.0484 (0.4186) Loss_G: -0.0526 (0.2687) D(x): 0.5599 D(G(z)): 0.4530 / 0.4268 Acc: 35.9375 (28.1140)\n",
      "[6/25][410/782] Loss_D: -0.0803 (0.4185) Loss_G: -0.0495 (0.2686) D(x): 0.5284 D(G(z)): 0.4346 / 0.4300 Acc: 37.5000 (28.1158)\n",
      "[6/25][411/782] Loss_D: 0.1586 (0.4185) Loss_G: -0.0746 (0.2686) D(x): 0.5137 D(G(z)): 0.4404 / 0.4505 Acc: 23.4375 (28.1149)\n",
      "[6/25][412/782] Loss_D: 0.0782 (0.4184) Loss_G: -0.0862 (0.2685) D(x): 0.5312 D(G(z)): 0.4683 / 0.4592 Acc: 34.3750 (28.1161)\n",
      "[6/25][413/782] Loss_D: 0.0429 (0.4183) Loss_G: -0.0402 (0.2684) D(x): 0.6015 D(G(z)): 0.5315 / 0.4373 Acc: 39.0625 (28.1183)\n",
      "[6/25][414/782] Loss_D: 0.1266 (0.4183) Loss_G: -0.1584 (0.2684) D(x): 0.4988 D(G(z)): 0.4862 / 0.4593 Acc: 34.3750 (28.1195)\n",
      "[6/25][415/782] Loss_D: 0.0423 (0.4182) Loss_G: 0.0051 (0.2683) D(x): 0.5047 D(G(z)): 0.3836 / 0.4036 Acc: 26.5625 (28.1192)\n",
      "[6/25][416/782] Loss_D: 0.2643 (0.4182) Loss_G: -0.1775 (0.2682) D(x): 0.5350 D(G(z)): 0.5133 / 0.4974 Acc: 23.4375 (28.1183)\n",
      "[6/25][417/782] Loss_D: 0.0144 (0.4181) Loss_G: 0.0772 (0.2682) D(x): 0.4812 D(G(z)): 0.3847 / 0.3972 Acc: 39.0625 (28.1204)\n",
      "[6/25][418/782] Loss_D: 0.3401 (0.4181) Loss_G: -0.1755 (0.2681) D(x): 0.4568 D(G(z)): 0.4950 / 0.4927 Acc: 29.6875 (28.1207)\n",
      "[6/25][419/782] Loss_D: -0.0911 (0.4180) Loss_G: -0.1134 (0.2680) D(x): 0.5857 D(G(z)): 0.4594 / 0.4436 Acc: 39.0625 (28.1229)\n",
      "[6/25][420/782] Loss_D: 0.0941 (0.4179) Loss_G: -0.0543 (0.2680) D(x): 0.5505 D(G(z)): 0.5057 / 0.4186 Acc: 32.8125 (28.1238)\n",
      "[6/25][421/782] Loss_D: 0.2212 (0.4179) Loss_G: 0.0243 (0.2679) D(x): 0.5044 D(G(z)): 0.4343 / 0.4102 Acc: 21.8750 (28.1226)\n",
      "[6/25][422/782] Loss_D: 0.4072 (0.4179) Loss_G: -0.0960 (0.2678) D(x): 0.4985 D(G(z)): 0.5387 / 0.4741 Acc: 23.4375 (28.1216)\n",
      "[6/25][423/782] Loss_D: 0.0148 (0.4178) Loss_G: -0.0967 (0.2678) D(x): 0.5667 D(G(z)): 0.4974 / 0.4490 Acc: 37.5000 (28.1235)\n",
      "[6/25][424/782] Loss_D: -0.0185 (0.4177) Loss_G: 0.0014 (0.2677) D(x): 0.5647 D(G(z)): 0.4634 / 0.3951 Acc: 32.8125 (28.1244)\n",
      "[6/25][425/782] Loss_D: 0.1941 (0.4177) Loss_G: -0.0439 (0.2677) D(x): 0.4671 D(G(z)): 0.4259 / 0.4302 Acc: 23.4375 (28.1235)\n",
      "[6/25][426/782] Loss_D: -0.0249 (0.4176) Loss_G: 0.0625 (0.2676) D(x): 0.5413 D(G(z)): 0.4535 / 0.3771 Acc: 35.9375 (28.1250)\n",
      "[6/25][427/782] Loss_D: 0.0666 (0.4175) Loss_G: -0.0678 (0.2676) D(x): 0.5301 D(G(z)): 0.4741 / 0.4582 Acc: 35.9375 (28.1265)\n",
      "[6/25][428/782] Loss_D: 0.0405 (0.4174) Loss_G: -0.1531 (0.2675) D(x): 0.5895 D(G(z)): 0.5083 / 0.4791 Acc: 34.3750 (28.1277)\n",
      "[6/25][429/782] Loss_D: 0.3215 (0.4174) Loss_G: -0.0841 (0.2674) D(x): 0.5303 D(G(z)): 0.5222 / 0.4515 Acc: 25.0000 (28.1271)\n",
      "[6/25][430/782] Loss_D: -0.1458 (0.4173) Loss_G: 0.0114 (0.2674) D(x): 0.5945 D(G(z)): 0.4443 / 0.4116 Acc: 37.5000 (28.1290)\n",
      "[6/25][431/782] Loss_D: 0.0802 (0.4172) Loss_G: -0.0007 (0.2673) D(x): 0.5438 D(G(z)): 0.4959 / 0.4334 Acc: 35.9375 (28.1305)\n",
      "[6/25][432/782] Loss_D: -0.0715 (0.4172) Loss_G: -0.1266 (0.2672) D(x): 0.5664 D(G(z)): 0.4262 / 0.4472 Acc: 26.5625 (28.1302)\n",
      "[6/25][433/782] Loss_D: 0.1288 (0.4171) Loss_G: -0.1585 (0.2671) D(x): 0.5045 D(G(z)): 0.4420 / 0.4735 Acc: 25.0000 (28.1296)\n",
      "[6/25][434/782] Loss_D: 0.1155 (0.4170) Loss_G: -0.2593 (0.2670) D(x): 0.5973 D(G(z)): 0.5590 / 0.5153 Acc: 34.3750 (28.1308)\n",
      "[6/25][435/782] Loss_D: 0.0728 (0.4170) Loss_G: -0.0999 (0.2670) D(x): 0.5554 D(G(z)): 0.4623 / 0.4450 Acc: 28.1250 (28.1308)\n",
      "[6/25][436/782] Loss_D: 0.0977 (0.4169) Loss_G: -0.0140 (0.2669) D(x): 0.5333 D(G(z)): 0.4836 / 0.4353 Acc: 35.9375 (28.1323)\n",
      "[6/25][437/782] Loss_D: 0.0515 (0.4168) Loss_G: -0.1613 (0.2668) D(x): 0.4860 D(G(z)): 0.4421 / 0.4668 Acc: 34.3750 (28.1335)\n",
      "[6/25][438/782] Loss_D: 0.0803 (0.4168) Loss_G: -0.0806 (0.2668) D(x): 0.5294 D(G(z)): 0.4940 / 0.4441 Acc: 42.1875 (28.1363)\n",
      "[6/25][439/782] Loss_D: 0.0499 (0.4167) Loss_G: -0.0404 (0.2667) D(x): 0.5442 D(G(z)): 0.4792 / 0.4137 Acc: 29.6875 (28.1366)\n",
      "[6/25][440/782] Loss_D: 0.3735 (0.4167) Loss_G: -0.0877 (0.2666) D(x): 0.5024 D(G(z)): 0.5401 / 0.4347 Acc: 23.4375 (28.1357)\n",
      "[6/25][441/782] Loss_D: 0.1576 (0.4166) Loss_G: -0.0122 (0.2666) D(x): 0.4763 D(G(z)): 0.4463 / 0.4226 Acc: 32.8125 (28.1366)\n",
      "[6/25][442/782] Loss_D: 0.0371 (0.4166) Loss_G: -0.0629 (0.2665) D(x): 0.5542 D(G(z)): 0.4535 / 0.4251 Acc: 25.0000 (28.1360)\n",
      "[6/25][443/782] Loss_D: -0.0644 (0.4165) Loss_G: -0.0521 (0.2664) D(x): 0.5320 D(G(z)): 0.4342 / 0.4352 Acc: 37.5000 (28.1378)\n",
      "[6/25][444/782] Loss_D: 0.1319 (0.4164) Loss_G: -0.0711 (0.2664) D(x): 0.5286 D(G(z)): 0.4914 / 0.4304 Acc: 29.6875 (28.1381)\n",
      "[6/25][445/782] Loss_D: 0.0492 (0.4163) Loss_G: -0.0455 (0.2663) D(x): 0.5256 D(G(z)): 0.4313 / 0.4266 Acc: 29.6875 (28.1384)\n",
      "[6/25][446/782] Loss_D: 0.0741 (0.4163) Loss_G: -0.1287 (0.2662) D(x): 0.4928 D(G(z)): 0.4782 / 0.4463 Acc: 39.0625 (28.1405)\n",
      "[6/25][447/782] Loss_D: 0.0719 (0.4162) Loss_G: -0.0057 (0.2662) D(x): 0.5298 D(G(z)): 0.4860 / 0.4405 Acc: 43.7500 (28.1435)\n",
      "[6/25][448/782] Loss_D: 0.0879 (0.4161) Loss_G: -0.1319 (0.2661) D(x): 0.5794 D(G(z)): 0.5366 / 0.4497 Acc: 37.5000 (28.1454)\n",
      "[6/25][449/782] Loss_D: -0.0055 (0.4161) Loss_G: -0.0325 (0.2661) D(x): 0.5021 D(G(z)): 0.4235 / 0.4182 Acc: 40.6250 (28.1478)\n",
      "[6/25][450/782] Loss_D: -0.0540 (0.4160) Loss_G: -0.0436 (0.2660) D(x): 0.5060 D(G(z)): 0.4131 / 0.4241 Acc: 40.6250 (28.1502)\n",
      "[6/25][451/782] Loss_D: -0.0139 (0.4159) Loss_G: -0.0488 (0.2659) D(x): 0.5732 D(G(z)): 0.4389 / 0.4258 Acc: 31.2500 (28.1508)\n",
      "[6/25][452/782] Loss_D: 0.1273 (0.4158) Loss_G: -0.0350 (0.2659) D(x): 0.5187 D(G(z)): 0.4768 / 0.4174 Acc: 32.8125 (28.1517)\n",
      "[6/25][453/782] Loss_D: -0.0920 (0.4157) Loss_G: -0.1386 (0.2658) D(x): 0.5164 D(G(z)): 0.4165 / 0.4668 Acc: 37.5000 (28.1535)\n",
      "[6/25][454/782] Loss_D: 0.1372 (0.4157) Loss_G: -0.1302 (0.2657) D(x): 0.5391 D(G(z)): 0.4684 / 0.4769 Acc: 26.5625 (28.1532)\n",
      "[6/25][455/782] Loss_D: -0.0719 (0.4156) Loss_G: -0.1022 (0.2657) D(x): 0.5667 D(G(z)): 0.5013 / 0.4331 Acc: 43.7500 (28.1563)\n",
      "[6/25][456/782] Loss_D: 0.1809 (0.4155) Loss_G: -0.0553 (0.2656) D(x): 0.5222 D(G(z)): 0.5088 / 0.4338 Acc: 31.2500 (28.1569)\n",
      "[6/25][457/782] Loss_D: 0.2742 (0.4155) Loss_G: -0.0271 (0.2655) D(x): 0.4725 D(G(z)): 0.5051 / 0.4078 Acc: 29.6875 (28.1572)\n",
      "[6/25][458/782] Loss_D: 0.2557 (0.4155) Loss_G: -0.1605 (0.2654) D(x): 0.4540 D(G(z)): 0.4545 / 0.4855 Acc: 31.2500 (28.1578)\n",
      "[6/25][459/782] Loss_D: 0.0421 (0.4154) Loss_G: -0.2236 (0.2654) D(x): 0.5699 D(G(z)): 0.4704 / 0.5012 Acc: 25.0000 (28.1571)\n",
      "[6/25][460/782] Loss_D: 0.1634 (0.4154) Loss_G: -0.3131 (0.2652) D(x): 0.5498 D(G(z)): 0.5321 / 0.5356 Acc: 32.8125 (28.1581)\n",
      "[6/25][461/782] Loss_D: 0.4297 (0.4154) Loss_G: -0.0359 (0.2652) D(x): 0.4865 D(G(z)): 0.5323 / 0.4315 Acc: 23.4375 (28.1571)\n",
      "[6/25][462/782] Loss_D: 0.2405 (0.4153) Loss_G: -0.1905 (0.2651) D(x): 0.4790 D(G(z)): 0.4797 / 0.4871 Acc: 25.0000 (28.1565)\n",
      "[6/25][463/782] Loss_D: 0.3409 (0.4153) Loss_G: -0.1136 (0.2650) D(x): 0.4706 D(G(z)): 0.4961 / 0.4682 Acc: 28.1250 (28.1565)\n",
      "[6/25][464/782] Loss_D: -0.0251 (0.4152) Loss_G: -0.1110 (0.2649) D(x): 0.5223 D(G(z)): 0.4319 / 0.4413 Acc: 39.0625 (28.1586)\n",
      "[6/25][465/782] Loss_D: 0.1709 (0.4152) Loss_G: -0.2472 (0.2648) D(x): 0.4954 D(G(z)): 0.4991 / 0.4949 Acc: 32.8125 (28.1595)\n",
      "[6/25][466/782] Loss_D: -0.0263 (0.4151) Loss_G: -0.2336 (0.2648) D(x): 0.5329 D(G(z)): 0.4361 / 0.4956 Acc: 35.9375 (28.1610)\n",
      "[6/25][467/782] Loss_D: 0.0496 (0.4150) Loss_G: -0.1133 (0.2647) D(x): 0.5149 D(G(z)): 0.4916 / 0.4423 Acc: 40.6250 (28.1635)\n",
      "[6/25][468/782] Loss_D: 0.0468 (0.4150) Loss_G: -0.1218 (0.2646) D(x): 0.5364 D(G(z)): 0.4949 / 0.4602 Acc: 39.0625 (28.1656)\n",
      "[6/25][469/782] Loss_D: 0.1197 (0.4149) Loss_G: -0.1337 (0.2645) D(x): 0.5108 D(G(z)): 0.5057 / 0.4527 Acc: 35.9375 (28.1671)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/25][470/782] Loss_D: 0.2158 (0.4149) Loss_G: -0.0619 (0.2645) D(x): 0.4830 D(G(z)): 0.4677 / 0.4528 Acc: 26.5625 (28.1668)\n",
      "[6/25][471/782] Loss_D: 0.0915 (0.4148) Loss_G: -0.2744 (0.2644) D(x): 0.5235 D(G(z)): 0.4543 / 0.5122 Acc: 28.1250 (28.1668)\n",
      "[6/25][472/782] Loss_D: -0.0090 (0.4147) Loss_G: -0.1177 (0.2643) D(x): 0.5977 D(G(z)): 0.4854 / 0.4578 Acc: 32.8125 (28.1677)\n",
      "[6/25][473/782] Loss_D: 0.0308 (0.4146) Loss_G: -0.1271 (0.2642) D(x): 0.5360 D(G(z)): 0.4479 / 0.4523 Acc: 28.1250 (28.1676)\n",
      "[6/25][474/782] Loss_D: 0.0007 (0.4146) Loss_G: -0.2002 (0.2641) D(x): 0.4994 D(G(z)): 0.4215 / 0.4805 Acc: 35.9375 (28.1692)\n",
      "[6/25][475/782] Loss_D: -0.1510 (0.4145) Loss_G: -0.3017 (0.2640) D(x): 0.5967 D(G(z)): 0.4712 / 0.5201 Acc: 40.6250 (28.1716)\n",
      "[6/25][476/782] Loss_D: 0.0405 (0.4144) Loss_G: -0.1135 (0.2639) D(x): 0.5773 D(G(z)): 0.5160 / 0.4372 Acc: 32.8125 (28.1725)\n",
      "[6/25][477/782] Loss_D: 0.1881 (0.4143) Loss_G: -0.0256 (0.2639) D(x): 0.4861 D(G(z)): 0.5071 / 0.4056 Acc: 34.3750 (28.1737)\n",
      "[6/25][478/782] Loss_D: 0.1531 (0.4143) Loss_G: -0.2315 (0.2638) D(x): 0.5040 D(G(z)): 0.5006 / 0.4850 Acc: 31.2500 (28.1743)\n",
      "[6/25][479/782] Loss_D: 0.1594 (0.4142) Loss_G: 0.0127 (0.2637) D(x): 0.5007 D(G(z)): 0.4646 / 0.4095 Acc: 32.8125 (28.1751)\n",
      "[6/25][480/782] Loss_D: 0.1185 (0.4142) Loss_G: -0.1831 (0.2637) D(x): 0.5375 D(G(z)): 0.5195 / 0.4997 Acc: 34.3750 (28.1763)\n",
      "[6/25][481/782] Loss_D: 0.2236 (0.4141) Loss_G: -0.2172 (0.2636) D(x): 0.4306 D(G(z)): 0.4762 / 0.4999 Acc: 43.7500 (28.1794)\n",
      "[6/25][482/782] Loss_D: -0.0203 (0.4141) Loss_G: -0.2179 (0.2635) D(x): 0.5337 D(G(z)): 0.4931 / 0.4847 Acc: 43.7500 (28.1824)\n",
      "[6/25][483/782] Loss_D: 0.1399 (0.4140) Loss_G: -0.1515 (0.2634) D(x): 0.5115 D(G(z)): 0.4663 / 0.4758 Acc: 31.2500 (28.1830)\n",
      "[6/25][484/782] Loss_D: 0.1250 (0.4140) Loss_G: -0.2008 (0.2633) D(x): 0.5689 D(G(z)): 0.5500 / 0.4740 Acc: 32.8125 (28.1839)\n",
      "[6/25][485/782] Loss_D: 0.1652 (0.4139) Loss_G: -0.0605 (0.2632) D(x): 0.5092 D(G(z)): 0.4528 / 0.4359 Acc: 29.6875 (28.1841)\n",
      "[6/25][486/782] Loss_D: 0.1988 (0.4139) Loss_G: -0.0629 (0.2632) D(x): 0.4958 D(G(z)): 0.4663 / 0.4446 Acc: 23.4375 (28.1832)\n",
      "[6/25][487/782] Loss_D: 0.3813 (0.4139) Loss_G: -0.2741 (0.2631) D(x): 0.4813 D(G(z)): 0.5312 / 0.5184 Acc: 20.3125 (28.1817)\n",
      "[6/25][488/782] Loss_D: 0.1940 (0.4138) Loss_G: -0.2330 (0.2630) D(x): 0.4953 D(G(z)): 0.5048 / 0.4973 Acc: 34.3750 (28.1829)\n",
      "[6/25][489/782] Loss_D: 0.1361 (0.4138) Loss_G: -0.1175 (0.2629) D(x): 0.4682 D(G(z)): 0.4322 / 0.4696 Acc: 28.1250 (28.1829)\n",
      "[6/25][490/782] Loss_D: 0.2876 (0.4137) Loss_G: -0.2292 (0.2628) D(x): 0.5194 D(G(z)): 0.5220 / 0.5064 Acc: 26.5625 (28.1826)\n",
      "[6/25][491/782] Loss_D: 0.0598 (0.4137) Loss_G: -0.1570 (0.2627) D(x): 0.5593 D(G(z)): 0.4964 / 0.4523 Acc: 31.2500 (28.1832)\n",
      "[6/25][492/782] Loss_D: 0.0019 (0.4136) Loss_G: -0.0134 (0.2627) D(x): 0.5388 D(G(z)): 0.4570 / 0.4060 Acc: 40.6250 (28.1856)\n",
      "[6/25][493/782] Loss_D: 0.0722 (0.4135) Loss_G: 0.0082 (0.2626) D(x): 0.4785 D(G(z)): 0.4540 / 0.4098 Acc: 39.0625 (28.1877)\n",
      "[6/25][494/782] Loss_D: 0.2191 (0.4135) Loss_G: -0.0785 (0.2626) D(x): 0.5014 D(G(z)): 0.4862 / 0.4218 Acc: 25.0000 (28.1871)\n",
      "[6/25][495/782] Loss_D: 0.0822 (0.4134) Loss_G: -0.0699 (0.2625) D(x): 0.5313 D(G(z)): 0.4488 / 0.4301 Acc: 26.5625 (28.1867)\n",
      "[6/25][496/782] Loss_D: 0.1736 (0.4134) Loss_G: -0.1164 (0.2624) D(x): 0.5262 D(G(z)): 0.5325 / 0.4515 Acc: 35.9375 (28.1882)\n",
      "[6/25][497/782] Loss_D: 0.1085 (0.4133) Loss_G: -0.0156 (0.2624) D(x): 0.5034 D(G(z)): 0.4727 / 0.4111 Acc: 29.6875 (28.1885)\n",
      "[6/25][498/782] Loss_D: -0.0341 (0.4132) Loss_G: -0.1280 (0.2623) D(x): 0.5473 D(G(z)): 0.4655 / 0.4499 Acc: 37.5000 (28.1903)\n",
      "[6/25][499/782] Loss_D: 0.0943 (0.4132) Loss_G: -0.1600 (0.2622) D(x): 0.5140 D(G(z)): 0.4563 / 0.4720 Acc: 31.2500 (28.1909)\n",
      "[6/25][500/782] Loss_D: -0.0948 (0.4131) Loss_G: -0.1122 (0.2621) D(x): 0.5944 D(G(z)): 0.4826 / 0.4498 Acc: 35.9375 (28.1924)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[6/25][501/782] Loss_D: 0.0797 (0.4130) Loss_G: -0.0283 (0.2621) D(x): 0.5365 D(G(z)): 0.4631 / 0.4330 Acc: 37.5000 (28.1942)\n",
      "[6/25][502/782] Loss_D: 0.1357 (0.4130) Loss_G: -0.0127 (0.2620) D(x): 0.4927 D(G(z)): 0.4474 / 0.4234 Acc: 32.8125 (28.1951)\n",
      "[6/25][503/782] Loss_D: 0.0245 (0.4129) Loss_G: -0.1517 (0.2619) D(x): 0.5471 D(G(z)): 0.4622 / 0.4703 Acc: 32.8125 (28.1960)\n",
      "[6/25][504/782] Loss_D: 0.0929 (0.4128) Loss_G: -0.1310 (0.2619) D(x): 0.5182 D(G(z)): 0.4641 / 0.4510 Acc: 26.5625 (28.1957)\n",
      "[6/25][505/782] Loss_D: -0.1344 (0.4127) Loss_G: -0.0397 (0.2618) D(x): 0.5608 D(G(z)): 0.4345 / 0.4240 Acc: 42.1875 (28.1983)\n",
      "[6/25][506/782] Loss_D: -0.2345 (0.4126) Loss_G: -0.0258 (0.2618) D(x): 0.5807 D(G(z)): 0.4418 / 0.4211 Acc: 43.7500 (28.2013)\n",
      "[6/25][507/782] Loss_D: 0.0374 (0.4125) Loss_G: -0.1196 (0.2617) D(x): 0.5310 D(G(z)): 0.4716 / 0.4577 Acc: 32.8125 (28.2022)\n",
      "[6/25][508/782] Loss_D: 0.0121 (0.4124) Loss_G: -0.0906 (0.2616) D(x): 0.4998 D(G(z)): 0.4260 / 0.4473 Acc: 37.5000 (28.2040)\n",
      "[6/25][509/782] Loss_D: -0.0327 (0.4124) Loss_G: -0.0815 (0.2615) D(x): 0.5979 D(G(z)): 0.4526 / 0.4452 Acc: 28.1250 (28.2040)\n",
      "[6/25][510/782] Loss_D: -0.1787 (0.4122) Loss_G: 0.1347 (0.2615) D(x): 0.5439 D(G(z)): 0.4191 / 0.3533 Acc: 45.3125 (28.2073)\n",
      "[6/25][511/782] Loss_D: -0.2564 (0.4121) Loss_G: -0.0115 (0.2615) D(x): 0.5748 D(G(z)): 0.3836 / 0.3978 Acc: 37.5000 (28.2091)\n",
      "[6/25][512/782] Loss_D: 0.0183 (0.4120) Loss_G: -0.1973 (0.2614) D(x): 0.5346 D(G(z)): 0.4837 / 0.4803 Acc: 35.9375 (28.2106)\n",
      "[6/25][513/782] Loss_D: 0.0397 (0.4120) Loss_G: -0.0993 (0.2613) D(x): 0.4916 D(G(z)): 0.4433 / 0.4320 Acc: 35.9375 (28.2120)\n",
      "[6/25][514/782] Loss_D: 0.0903 (0.4119) Loss_G: -0.1243 (0.2612) D(x): 0.5254 D(G(z)): 0.5538 / 0.4523 Acc: 50.0000 (28.2162)\n",
      "[6/25][515/782] Loss_D: 0.0212 (0.4118) Loss_G: -0.1184 (0.2612) D(x): 0.5866 D(G(z)): 0.5080 / 0.4674 Acc: 31.2500 (28.2168)\n",
      "[6/25][516/782] Loss_D: 0.0766 (0.4118) Loss_G: 0.0609 (0.2611) D(x): 0.5187 D(G(z)): 0.4553 / 0.3897 Acc: 29.6875 (28.2171)\n",
      "[6/25][517/782] Loss_D: 0.1255 (0.4117) Loss_G: -0.1185 (0.2611) D(x): 0.5036 D(G(z)): 0.4117 / 0.4500 Acc: 21.8750 (28.2159)\n",
      "[6/25][518/782] Loss_D: -0.0177 (0.4116) Loss_G: -0.1952 (0.2610) D(x): 0.5117 D(G(z)): 0.4579 / 0.4743 Acc: 39.0625 (28.2180)\n",
      "[6/25][519/782] Loss_D: 0.2798 (0.4116) Loss_G: -0.2032 (0.2609) D(x): 0.5215 D(G(z)): 0.5202 / 0.4879 Acc: 21.8750 (28.2167)\n",
      "[6/25][520/782] Loss_D: 0.1204 (0.4115) Loss_G: -0.0226 (0.2608) D(x): 0.5581 D(G(z)): 0.4826 / 0.4400 Acc: 25.0000 (28.2161)\n",
      "[6/25][521/782] Loss_D: 0.3978 (0.4115) Loss_G: -0.1720 (0.2607) D(x): 0.4740 D(G(z)): 0.5397 / 0.5004 Acc: 31.2500 (28.2167)\n",
      "[6/25][522/782] Loss_D: 0.1978 (0.4115) Loss_G: -0.0956 (0.2607) D(x): 0.5428 D(G(z)): 0.4977 / 0.4400 Acc: 23.4375 (28.2158)\n",
      "[6/25][523/782] Loss_D: 0.2841 (0.4115) Loss_G: -0.0799 (0.2606) D(x): 0.4649 D(G(z)): 0.5173 / 0.4495 Acc: 34.3750 (28.2170)\n",
      "[6/25][524/782] Loss_D: 0.1067 (0.4114) Loss_G: -0.1332 (0.2605) D(x): 0.4920 D(G(z)): 0.4767 / 0.4589 Acc: 39.0625 (28.2190)\n",
      "[6/25][525/782] Loss_D: 0.1422 (0.4114) Loss_G: -0.2077 (0.2604) D(x): 0.4970 D(G(z)): 0.4815 / 0.5092 Acc: 37.5000 (28.2208)\n",
      "[6/25][526/782] Loss_D: 0.1534 (0.4113) Loss_G: -0.0703 (0.2604) D(x): 0.5663 D(G(z)): 0.4839 / 0.4401 Acc: 21.8750 (28.2196)\n",
      "[6/25][527/782] Loss_D: 0.0606 (0.4112) Loss_G: -0.0617 (0.2603) D(x): 0.4985 D(G(z)): 0.4496 / 0.4407 Acc: 37.5000 (28.2214)\n",
      "[6/25][528/782] Loss_D: 0.0960 (0.4112) Loss_G: -0.0249 (0.2603) D(x): 0.5330 D(G(z)): 0.4240 / 0.4415 Acc: 21.8750 (28.2202)\n",
      "[6/25][529/782] Loss_D: 0.0942 (0.4111) Loss_G: -0.0258 (0.2602) D(x): 0.5561 D(G(z)): 0.4905 / 0.4183 Acc: 31.2500 (28.2207)\n",
      "[6/25][530/782] Loss_D: 0.0068 (0.4110) Loss_G: -0.0644 (0.2601) D(x): 0.6352 D(G(z)): 0.5025 / 0.4286 Acc: 23.4375 (28.2198)\n",
      "[6/25][531/782] Loss_D: -0.0388 (0.4110) Loss_G: 0.1208 (0.2601) D(x): 0.5390 D(G(z)): 0.4349 / 0.3797 Acc: 39.0625 (28.2219)\n",
      "[6/25][532/782] Loss_D: -0.0156 (0.4109) Loss_G: -0.0190 (0.2601) D(x): 0.5143 D(G(z)): 0.4161 / 0.4122 Acc: 31.2500 (28.2225)\n",
      "[6/25][533/782] Loss_D: 0.1435 (0.4108) Loss_G: -0.0041 (0.2600) D(x): 0.5179 D(G(z)): 0.4406 / 0.4310 Acc: 28.1250 (28.2225)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/25][534/782] Loss_D: 0.0158 (0.4108) Loss_G: -0.0568 (0.2600) D(x): 0.5872 D(G(z)): 0.4921 / 0.4203 Acc: 34.3750 (28.2236)\n",
      "[6/25][535/782] Loss_D: 0.1086 (0.4107) Loss_G: 0.0658 (0.2599) D(x): 0.5180 D(G(z)): 0.4799 / 0.4026 Acc: 31.2500 (28.2242)\n",
      "[6/25][536/782] Loss_D: 0.0434 (0.4106) Loss_G: -0.1005 (0.2599) D(x): 0.4767 D(G(z)): 0.4229 / 0.4369 Acc: 35.9375 (28.2257)\n",
      "[6/25][537/782] Loss_D: 0.0110 (0.4105) Loss_G: -0.0886 (0.2598) D(x): 0.5645 D(G(z)): 0.4755 / 0.4510 Acc: 35.9375 (28.2272)\n",
      "[6/25][538/782] Loss_D: 0.3301 (0.4105) Loss_G: -0.1942 (0.2597) D(x): 0.4704 D(G(z)): 0.4995 / 0.4895 Acc: 25.0000 (28.2266)\n",
      "[6/25][539/782] Loss_D: 0.1745 (0.4105) Loss_G: -0.2590 (0.2596) D(x): 0.5519 D(G(z)): 0.5267 / 0.5380 Acc: 32.8125 (28.2274)\n",
      "[6/25][540/782] Loss_D: 0.1326 (0.4104) Loss_G: -0.2283 (0.2595) D(x): 0.5394 D(G(z)): 0.5363 / 0.5087 Acc: 45.3125 (28.2307)\n",
      "[6/25][541/782] Loss_D: 0.0850 (0.4104) Loss_G: -0.1082 (0.2594) D(x): 0.5401 D(G(z)): 0.5058 / 0.4610 Acc: 34.3750 (28.2319)\n",
      "[6/25][542/782] Loss_D: 0.1335 (0.4103) Loss_G: -0.1051 (0.2594) D(x): 0.4898 D(G(z)): 0.4818 / 0.4542 Acc: 42.1875 (28.2345)\n",
      "[6/25][543/782] Loss_D: 0.0786 (0.4103) Loss_G: -0.2615 (0.2593) D(x): 0.5187 D(G(z)): 0.4792 / 0.5044 Acc: 35.9375 (28.2360)\n",
      "[6/25][544/782] Loss_D: -0.0175 (0.4102) Loss_G: -0.1476 (0.2592) D(x): 0.5110 D(G(z)): 0.4774 / 0.4813 Acc: 50.0000 (28.2402)\n",
      "[6/25][545/782] Loss_D: 0.2603 (0.4101) Loss_G: -0.1735 (0.2591) D(x): 0.5531 D(G(z)): 0.5363 / 0.4688 Acc: 25.0000 (28.2395)\n",
      "[6/25][546/782] Loss_D: 0.2115 (0.4101) Loss_G: 0.0484 (0.2591) D(x): 0.5246 D(G(z)): 0.5038 / 0.4041 Acc: 26.5625 (28.2392)\n",
      "[6/25][547/782] Loss_D: 0.2281 (0.4101) Loss_G: -0.0318 (0.2590) D(x): 0.4823 D(G(z)): 0.4709 / 0.4145 Acc: 25.0000 (28.2386)\n",
      "[6/25][548/782] Loss_D: 0.1256 (0.4100) Loss_G: -0.0906 (0.2589) D(x): 0.4748 D(G(z)): 0.4463 / 0.4465 Acc: 34.3750 (28.2398)\n",
      "[6/25][549/782] Loss_D: -0.0068 (0.4099) Loss_G: -0.2570 (0.2588) D(x): 0.5522 D(G(z)): 0.4754 / 0.5086 Acc: 35.9375 (28.2412)\n",
      "[6/25][550/782] Loss_D: -0.0010 (0.4099) Loss_G: -0.2248 (0.2588) D(x): 0.5455 D(G(z)): 0.4850 / 0.5097 Acc: 46.8750 (28.2448)\n",
      "[6/25][551/782] Loss_D: 0.1387 (0.4098) Loss_G: -0.1160 (0.2587) D(x): 0.5110 D(G(z)): 0.4924 / 0.4478 Acc: 37.5000 (28.2466)\n",
      "[6/25][552/782] Loss_D: 0.0164 (0.4097) Loss_G: 0.0105 (0.2586) D(x): 0.5457 D(G(z)): 0.4809 / 0.4174 Acc: 39.0625 (28.2486)\n",
      "[6/25][553/782] Loss_D: -0.0451 (0.4096) Loss_G: 0.0265 (0.2586) D(x): 0.5318 D(G(z)): 0.4153 / 0.4031 Acc: 32.8125 (28.2495)\n",
      "[6/25][554/782] Loss_D: 0.0756 (0.4096) Loss_G: -0.0355 (0.2585) D(x): 0.5399 D(G(z)): 0.4796 / 0.4200 Acc: 32.8125 (28.2504)\n",
      "[6/25][555/782] Loss_D: 0.0640 (0.4095) Loss_G: -0.1650 (0.2585) D(x): 0.5378 D(G(z)): 0.4997 / 0.4748 Acc: 40.6250 (28.2527)\n",
      "[6/25][556/782] Loss_D: 0.0901 (0.4095) Loss_G: -0.1442 (0.2584) D(x): 0.4847 D(G(z)): 0.4143 / 0.4553 Acc: 25.0000 (28.2521)\n",
      "[6/25][557/782] Loss_D: 0.0273 (0.4094) Loss_G: -0.0794 (0.2583) D(x): 0.5453 D(G(z)): 0.4462 / 0.4463 Acc: 26.5625 (28.2518)\n",
      "[6/25][558/782] Loss_D: 0.1987 (0.4093) Loss_G: -0.1600 (0.2582) D(x): 0.5323 D(G(z)): 0.5394 / 0.4902 Acc: 32.8125 (28.2527)\n",
      "[6/25][559/782] Loss_D: 0.0352 (0.4093) Loss_G: 0.0128 (0.2582) D(x): 0.5500 D(G(z)): 0.4877 / 0.4100 Acc: 37.5000 (28.2544)\n",
      "[6/25][560/782] Loss_D: 0.0138 (0.4092) Loss_G: 0.0907 (0.2582) D(x): 0.5285 D(G(z)): 0.4533 / 0.3783 Acc: 29.6875 (28.2547)\n",
      "[6/25][561/782] Loss_D: 0.1628 (0.4092) Loss_G: -0.1495 (0.2581) D(x): 0.4800 D(G(z)): 0.4468 / 0.4506 Acc: 29.6875 (28.2550)\n",
      "[6/25][562/782] Loss_D: 0.0349 (0.4091) Loss_G: -0.0947 (0.2580) D(x): 0.5351 D(G(z)): 0.4609 / 0.4427 Acc: 32.8125 (28.2558)\n",
      "[6/25][563/782] Loss_D: -0.1124 (0.4090) Loss_G: -0.1827 (0.2579) D(x): 0.5326 D(G(z)): 0.4634 / 0.4657 Acc: 43.7500 (28.2588)\n",
      "[6/25][564/782] Loss_D: -0.0706 (0.4089) Loss_G: -0.1839 (0.2578) D(x): 0.5142 D(G(z)): 0.4430 / 0.4702 Acc: 43.7500 (28.2617)\n",
      "[6/25][565/782] Loss_D: 0.0606 (0.4088) Loss_G: -0.1141 (0.2578) D(x): 0.5526 D(G(z)): 0.5053 / 0.4713 Acc: 40.6250 (28.2641)\n",
      "[6/25][566/782] Loss_D: 0.0281 (0.4088) Loss_G: -0.0766 (0.2577) D(x): 0.5321 D(G(z)): 0.4719 / 0.4331 Acc: 32.8125 (28.2649)\n",
      "[6/25][567/782] Loss_D: 0.0628 (0.4087) Loss_G: -0.0529 (0.2576) D(x): 0.5598 D(G(z)): 0.5110 / 0.4286 Acc: 34.3750 (28.2661)\n",
      "[6/25][568/782] Loss_D: -0.0200 (0.4086) Loss_G: -0.1037 (0.2576) D(x): 0.4859 D(G(z)): 0.4534 / 0.4295 Acc: 45.3125 (28.2693)\n",
      "[6/25][569/782] Loss_D: 0.1443 (0.4086) Loss_G: -0.1230 (0.2575) D(x): 0.5100 D(G(z)): 0.4731 / 0.4541 Acc: 25.0000 (28.2687)\n",
      "[6/25][570/782] Loss_D: 0.0427 (0.4085) Loss_G: -0.0509 (0.2574) D(x): 0.5357 D(G(z)): 0.4487 / 0.4181 Acc: 28.1250 (28.2687)\n",
      "[6/25][571/782] Loss_D: 0.2000 (0.4084) Loss_G: -0.1235 (0.2574) D(x): 0.4996 D(G(z)): 0.4873 / 0.4453 Acc: 32.8125 (28.2696)\n",
      "[6/25][572/782] Loss_D: 0.0198 (0.4084) Loss_G: -0.1408 (0.2573) D(x): 0.5824 D(G(z)): 0.4897 / 0.4461 Acc: 28.1250 (28.2695)\n",
      "[6/25][573/782] Loss_D: -0.0812 (0.4083) Loss_G: 0.0348 (0.2573) D(x): 0.5209 D(G(z)): 0.4574 / 0.3962 Acc: 45.3125 (28.2728)\n",
      "[6/25][574/782] Loss_D: 0.1719 (0.4082) Loss_G: -0.1416 (0.2572) D(x): 0.4690 D(G(z)): 0.4340 / 0.4657 Acc: 26.5625 (28.2724)\n",
      "[6/25][575/782] Loss_D: 0.1127 (0.4082) Loss_G: -0.1310 (0.2571) D(x): 0.4702 D(G(z)): 0.4634 / 0.4654 Acc: 42.1875 (28.2751)\n",
      "[6/25][576/782] Loss_D: 0.0202 (0.4081) Loss_G: -0.0146 (0.2571) D(x): 0.6154 D(G(z)): 0.5237 / 0.4204 Acc: 35.9375 (28.2765)\n",
      "[6/25][577/782] Loss_D: 0.0055 (0.4080) Loss_G: 0.0289 (0.2570) D(x): 0.5374 D(G(z)): 0.4279 / 0.3856 Acc: 28.1250 (28.2765)\n",
      "[6/25][578/782] Loss_D: 0.0213 (0.4080) Loss_G: -0.1592 (0.2569) D(x): 0.4924 D(G(z)): 0.4575 / 0.4604 Acc: 43.7500 (28.2794)\n",
      "[6/25][579/782] Loss_D: 0.2161 (0.4079) Loss_G: -0.1552 (0.2569) D(x): 0.5238 D(G(z)): 0.5242 / 0.4686 Acc: 32.8125 (28.2803)\n",
      "[6/25][580/782] Loss_D: 0.3417 (0.4079) Loss_G: -0.1294 (0.2568) D(x): 0.4568 D(G(z)): 0.5059 / 0.4665 Acc: 32.8125 (28.2812)\n",
      "[6/25][581/782] Loss_D: 0.1724 (0.4079) Loss_G: -0.1316 (0.2567) D(x): 0.5103 D(G(z)): 0.5022 / 0.4729 Acc: 39.0625 (28.2832)\n",
      "[6/25][582/782] Loss_D: 0.1219 (0.4078) Loss_G: -0.2086 (0.2566) D(x): 0.5005 D(G(z)): 0.4972 / 0.4842 Acc: 35.9375 (28.2847)\n",
      "[6/25][583/782] Loss_D: 0.1610 (0.4078) Loss_G: -0.1458 (0.2565) D(x): 0.4967 D(G(z)): 0.4938 / 0.4669 Acc: 32.8125 (28.2855)\n",
      "[6/25][584/782] Loss_D: 0.0365 (0.4077) Loss_G: -0.1723 (0.2565) D(x): 0.5256 D(G(z)): 0.4861 / 0.4663 Acc: 35.9375 (28.2870)\n",
      "[6/25][585/782] Loss_D: 0.1750 (0.4076) Loss_G: -0.1271 (0.2564) D(x): 0.5224 D(G(z)): 0.5419 / 0.4581 Acc: 34.3750 (28.2881)\n",
      "[6/25][586/782] Loss_D: 0.1393 (0.4076) Loss_G: -0.1229 (0.2563) D(x): 0.4714 D(G(z)): 0.4647 / 0.4619 Acc: 34.3750 (28.2893)\n",
      "[6/25][587/782] Loss_D: 0.0361 (0.4075) Loss_G: -0.1282 (0.2562) D(x): 0.5050 D(G(z)): 0.4945 / 0.4379 Acc: 43.7500 (28.2922)\n",
      "[6/25][588/782] Loss_D: 0.0892 (0.4075) Loss_G: -0.1382 (0.2562) D(x): 0.5431 D(G(z)): 0.5010 / 0.4398 Acc: 31.2500 (28.2928)\n",
      "[6/25][589/782] Loss_D: 0.0294 (0.4074) Loss_G: -0.1565 (0.2561) D(x): 0.4650 D(G(z)): 0.4424 / 0.4599 Acc: 40.6250 (28.2951)\n",
      "[6/25][590/782] Loss_D: 0.0380 (0.4073) Loss_G: -0.1340 (0.2560) D(x): 0.5305 D(G(z)): 0.4658 / 0.4684 Acc: 31.2500 (28.2957)\n",
      "[6/25][591/782] Loss_D: 0.0417 (0.4073) Loss_G: -0.1673 (0.2559) D(x): 0.5582 D(G(z)): 0.4721 / 0.4612 Acc: 26.5625 (28.2953)\n",
      "[6/25][592/782] Loss_D: 0.1577 (0.4072) Loss_G: -0.2499 (0.2558) D(x): 0.5219 D(G(z)): 0.4898 / 0.5056 Acc: 28.1250 (28.2953)\n",
      "[6/25][593/782] Loss_D: 0.0987 (0.4071) Loss_G: -0.0442 (0.2558) D(x): 0.5249 D(G(z)): 0.4842 / 0.4188 Acc: 31.2500 (28.2959)\n",
      "[6/25][594/782] Loss_D: 0.0939 (0.4071) Loss_G: 0.0438 (0.2557) D(x): 0.5353 D(G(z)): 0.4921 / 0.4092 Acc: 34.3750 (28.2970)\n",
      "[6/25][595/782] Loss_D: 0.0229 (0.4070) Loss_G: -0.0705 (0.2557) D(x): 0.5386 D(G(z)): 0.4531 / 0.4255 Acc: 31.2500 (28.2976)\n",
      "[6/25][596/782] Loss_D: 0.2034 (0.4070) Loss_G: -0.0108 (0.2556) D(x): 0.5140 D(G(z)): 0.4994 / 0.4140 Acc: 26.5625 (28.2972)\n",
      "[6/25][597/782] Loss_D: 0.1266 (0.4069) Loss_G: -0.1142 (0.2556) D(x): 0.4694 D(G(z)): 0.4363 / 0.4340 Acc: 35.9375 (28.2987)\n",
      "[6/25][598/782] Loss_D: -0.0496 (0.4068) Loss_G: -0.1741 (0.2555) D(x): 0.5545 D(G(z)): 0.4934 / 0.4699 Acc: 40.6250 (28.3010)\n",
      "[6/25][599/782] Loss_D: -0.0600 (0.4067) Loss_G: -0.2721 (0.2554) D(x): 0.5468 D(G(z)): 0.4510 / 0.5108 Acc: 34.3750 (28.3022)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/25][600/782] Loss_D: 0.2343 (0.4067) Loss_G: -0.1975 (0.2553) D(x): 0.4857 D(G(z)): 0.5191 / 0.4737 Acc: 34.3750 (28.3033)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[6/25][601/782] Loss_D: -0.0157 (0.4066) Loss_G: -0.1964 (0.2552) D(x): 0.5205 D(G(z)): 0.4980 / 0.4774 Acc: 40.6250 (28.3056)\n",
      "[6/25][602/782] Loss_D: 0.1244 (0.4066) Loss_G: -0.1798 (0.2551) D(x): 0.5149 D(G(z)): 0.4928 / 0.4690 Acc: 32.8125 (28.3065)\n",
      "[6/25][603/782] Loss_D: -0.0146 (0.4065) Loss_G: -0.1033 (0.2551) D(x): 0.5652 D(G(z)): 0.4907 / 0.4515 Acc: 37.5000 (28.3082)\n",
      "[6/25][604/782] Loss_D: 0.1677 (0.4065) Loss_G: -0.1370 (0.2550) D(x): 0.4308 D(G(z)): 0.4104 / 0.4617 Acc: 32.8125 (28.3091)\n",
      "[6/25][605/782] Loss_D: 0.2914 (0.4064) Loss_G: -0.2383 (0.2549) D(x): 0.4729 D(G(z)): 0.5450 / 0.4940 Acc: 35.9375 (28.3105)\n",
      "[6/25][606/782] Loss_D: 0.0829 (0.4064) Loss_G: -0.1721 (0.2548) D(x): 0.5273 D(G(z)): 0.5297 / 0.4676 Acc: 40.6250 (28.3128)\n",
      "[6/25][607/782] Loss_D: 0.0068 (0.4063) Loss_G: -0.2030 (0.2547) D(x): 0.5156 D(G(z)): 0.4731 / 0.4796 Acc: 39.0625 (28.3149)\n",
      "[6/25][608/782] Loss_D: 0.1382 (0.4063) Loss_G: -0.0435 (0.2547) D(x): 0.5382 D(G(z)): 0.5110 / 0.4191 Acc: 39.0625 (28.3169)\n",
      "[6/25][609/782] Loss_D: 0.0024 (0.4062) Loss_G: -0.0643 (0.2546) D(x): 0.5340 D(G(z)): 0.4563 / 0.4230 Acc: 37.5000 (28.3186)\n",
      "[6/25][610/782] Loss_D: -0.0345 (0.4061) Loss_G: -0.0032 (0.2546) D(x): 0.5345 D(G(z)): 0.4145 / 0.4049 Acc: 29.6875 (28.3189)\n",
      "[6/25][611/782] Loss_D: -0.0657 (0.4060) Loss_G: -0.0591 (0.2545) D(x): 0.5718 D(G(z)): 0.4567 / 0.4299 Acc: 31.2500 (28.3194)\n",
      "[6/25][612/782] Loss_D: -0.0767 (0.4059) Loss_G: -0.0907 (0.2544) D(x): 0.5381 D(G(z)): 0.4497 / 0.4406 Acc: 37.5000 (28.3212)\n",
      "[6/25][613/782] Loss_D: 0.1514 (0.4059) Loss_G: -0.0812 (0.2544) D(x): 0.4894 D(G(z)): 0.4549 / 0.4368 Acc: 28.1250 (28.3211)\n",
      "[6/25][614/782] Loss_D: -0.0756 (0.4058) Loss_G: -0.0931 (0.2543) D(x): 0.5845 D(G(z)): 0.4930 / 0.4313 Acc: 35.9375 (28.3226)\n",
      "[6/25][615/782] Loss_D: -0.0145 (0.4057) Loss_G: -0.0330 (0.2543) D(x): 0.5481 D(G(z)): 0.4600 / 0.4173 Acc: 34.3750 (28.3237)\n",
      "[6/25][616/782] Loss_D: -0.0889 (0.4056) Loss_G: 0.0143 (0.2542) D(x): 0.5663 D(G(z)): 0.4577 / 0.3950 Acc: 37.5000 (28.3254)\n",
      "[6/25][617/782] Loss_D: -0.0482 (0.4055) Loss_G: -0.1471 (0.2541) D(x): 0.5369 D(G(z)): 0.4413 / 0.4489 Acc: 32.8125 (28.3263)\n",
      "[6/25][618/782] Loss_D: 0.1068 (0.4055) Loss_G: -0.1615 (0.2541) D(x): 0.5052 D(G(z)): 0.4744 / 0.4769 Acc: 32.8125 (28.3271)\n",
      "[6/25][619/782] Loss_D: 0.3075 (0.4054) Loss_G: -0.1034 (0.2540) D(x): 0.5117 D(G(z)): 0.5285 / 0.4667 Acc: 28.1250 (28.3271)\n",
      "[6/25][620/782] Loss_D: 0.1727 (0.4054) Loss_G: -0.0882 (0.2539) D(x): 0.5418 D(G(z)): 0.5122 / 0.4226 Acc: 25.0000 (28.3265)\n",
      "[6/25][621/782] Loss_D: 0.2061 (0.4054) Loss_G: -0.1411 (0.2539) D(x): 0.4176 D(G(z)): 0.4711 / 0.4599 Acc: 43.7500 (28.3294)\n",
      "[6/25][622/782] Loss_D: 0.2909 (0.4053) Loss_G: -0.2324 (0.2538) D(x): 0.5157 D(G(z)): 0.5161 / 0.4980 Acc: 20.3125 (28.3278)\n",
      "[6/25][623/782] Loss_D: 0.1509 (0.4053) Loss_G: -0.1314 (0.2537) D(x): 0.5178 D(G(z)): 0.4850 / 0.4498 Acc: 25.0000 (28.3272)\n",
      "[6/25][624/782] Loss_D: 0.1332 (0.4052) Loss_G: -0.2433 (0.2536) D(x): 0.5034 D(G(z)): 0.4899 / 0.4962 Acc: 35.9375 (28.3287)\n",
      "[6/25][625/782] Loss_D: 0.0172 (0.4052) Loss_G: -0.2135 (0.2535) D(x): 0.5250 D(G(z)): 0.4516 / 0.5045 Acc: 34.3750 (28.3298)\n",
      "[6/25][626/782] Loss_D: 0.1924 (0.4051) Loss_G: -0.1520 (0.2534) D(x): 0.5314 D(G(z)): 0.5119 / 0.4810 Acc: 26.5625 (28.3295)\n",
      "[6/25][627/782] Loss_D: 0.0751 (0.4051) Loss_G: -0.2267 (0.2533) D(x): 0.4983 D(G(z)): 0.4668 / 0.4996 Acc: 32.8125 (28.3303)\n",
      "[6/25][628/782] Loss_D: 0.2503 (0.4050) Loss_G: -0.1688 (0.2533) D(x): 0.5137 D(G(z)): 0.5195 / 0.4818 Acc: 31.2500 (28.3308)\n",
      "[6/25][629/782] Loss_D: 0.1075 (0.4050) Loss_G: -0.1115 (0.2532) D(x): 0.5038 D(G(z)): 0.4856 / 0.4489 Acc: 34.3750 (28.3320)\n",
      "[6/25][630/782] Loss_D: 0.0801 (0.4049) Loss_G: -0.1555 (0.2531) D(x): 0.5096 D(G(z)): 0.4583 / 0.4603 Acc: 26.5625 (28.3317)\n",
      "[6/25][631/782] Loss_D: 0.0081 (0.4048) Loss_G: -0.1586 (0.2530) D(x): 0.5435 D(G(z)): 0.4685 / 0.4541 Acc: 37.5000 (28.3334)\n",
      "[6/25][632/782] Loss_D: 0.0105 (0.4048) Loss_G: -0.0543 (0.2530) D(x): 0.5241 D(G(z)): 0.4795 / 0.4295 Acc: 35.9375 (28.3348)\n",
      "[6/25][633/782] Loss_D: 0.2094 (0.4047) Loss_G: -0.3093 (0.2529) D(x): 0.5199 D(G(z)): 0.5208 / 0.5241 Acc: 28.1250 (28.3348)\n",
      "[6/25][634/782] Loss_D: 0.0800 (0.4047) Loss_G: -0.1761 (0.2528) D(x): 0.5140 D(G(z)): 0.4623 / 0.4723 Acc: 29.6875 (28.3350)\n",
      "[6/25][635/782] Loss_D: 0.0638 (0.4046) Loss_G: -0.0721 (0.2527) D(x): 0.5025 D(G(z)): 0.4325 / 0.4452 Acc: 28.1250 (28.3350)\n",
      "[6/25][636/782] Loss_D: -0.0002 (0.4045) Loss_G: -0.0817 (0.2527) D(x): 0.5616 D(G(z)): 0.4583 / 0.4303 Acc: 29.6875 (28.3352)\n",
      "[6/25][637/782] Loss_D: 0.0006 (0.4045) Loss_G: -0.1516 (0.2526) D(x): 0.5399 D(G(z)): 0.4346 / 0.4745 Acc: 32.8125 (28.3361)\n",
      "[6/25][638/782] Loss_D: -0.0165 (0.4044) Loss_G: -0.2071 (0.2525) D(x): 0.5392 D(G(z)): 0.4681 / 0.4843 Acc: 39.0625 (28.3381)\n",
      "[6/25][639/782] Loss_D: -0.1539 (0.4043) Loss_G: -0.0693 (0.2524) D(x): 0.5716 D(G(z)): 0.4684 / 0.4191 Acc: 42.1875 (28.3407)\n",
      "[6/25][640/782] Loss_D: 0.1184 (0.4042) Loss_G: 0.0242 (0.2524) D(x): 0.5590 D(G(z)): 0.4896 / 0.4030 Acc: 21.8750 (28.3395)\n",
      "[6/25][641/782] Loss_D: 0.0046 (0.4041) Loss_G: -0.1335 (0.2523) D(x): 0.5052 D(G(z)): 0.4619 / 0.4556 Acc: 40.6250 (28.3418)\n",
      "[6/25][642/782] Loss_D: -0.0444 (0.4041) Loss_G: -0.0567 (0.2523) D(x): 0.4957 D(G(z)): 0.4337 / 0.4334 Acc: 43.7500 (28.3447)\n",
      "[6/25][643/782] Loss_D: 0.0683 (0.4040) Loss_G: -0.1637 (0.2522) D(x): 0.5391 D(G(z)): 0.4931 / 0.4693 Acc: 32.8125 (28.3455)\n",
      "[6/25][644/782] Loss_D: -0.0057 (0.4039) Loss_G: -0.1262 (0.2521) D(x): 0.5553 D(G(z)): 0.5030 / 0.4432 Acc: 39.0625 (28.3475)\n",
      "[6/25][645/782] Loss_D: 0.0696 (0.4039) Loss_G: -0.0391 (0.2521) D(x): 0.5172 D(G(z)): 0.4798 / 0.4223 Acc: 34.3750 (28.3486)\n",
      "[6/25][646/782] Loss_D: -0.0238 (0.4038) Loss_G: -0.0080 (0.2520) D(x): 0.5178 D(G(z)): 0.4890 / 0.4099 Acc: 43.7500 (28.3515)\n",
      "[6/25][647/782] Loss_D: 0.0019 (0.4037) Loss_G: -0.0965 (0.2520) D(x): 0.5107 D(G(z)): 0.4319 / 0.4356 Acc: 32.8125 (28.3524)\n",
      "[6/25][648/782] Loss_D: 0.1143 (0.4036) Loss_G: -0.1202 (0.2519) D(x): 0.5060 D(G(z)): 0.4649 / 0.4673 Acc: 29.6875 (28.3526)\n",
      "[6/25][649/782] Loss_D: 0.0531 (0.4036) Loss_G: -0.1890 (0.2518) D(x): 0.5257 D(G(z)): 0.4738 / 0.4830 Acc: 31.2500 (28.3531)\n",
      "[6/25][650/782] Loss_D: 0.0600 (0.4035) Loss_G: -0.1255 (0.2517) D(x): 0.5313 D(G(z)): 0.4647 / 0.4516 Acc: 29.6875 (28.3534)\n",
      "[6/25][651/782] Loss_D: -0.1314 (0.4034) Loss_G: -0.0989 (0.2517) D(x): 0.6197 D(G(z)): 0.5046 / 0.4427 Acc: 40.6250 (28.3557)\n",
      "[6/25][652/782] Loss_D: -0.0027 (0.4033) Loss_G: -0.0647 (0.2516) D(x): 0.5180 D(G(z)): 0.4289 / 0.4145 Acc: 32.8125 (28.3565)\n",
      "[6/25][653/782] Loss_D: -0.0490 (0.4033) Loss_G: -0.0863 (0.2515) D(x): 0.4982 D(G(z)): 0.4060 / 0.4355 Acc: 34.3750 (28.3577)\n",
      "[6/25][654/782] Loss_D: 0.1488 (0.4032) Loss_G: -0.1868 (0.2515) D(x): 0.5217 D(G(z)): 0.5043 / 0.4701 Acc: 34.3750 (28.3588)\n",
      "[6/25][655/782] Loss_D: -0.0414 (0.4031) Loss_G: -0.1667 (0.2514) D(x): 0.5660 D(G(z)): 0.4968 / 0.4678 Acc: 42.1875 (28.3614)\n",
      "[6/25][656/782] Loss_D: 0.1954 (0.4031) Loss_G: -0.2584 (0.2513) D(x): 0.4892 D(G(z)): 0.4758 / 0.5068 Acc: 26.5625 (28.3610)\n",
      "[6/25][657/782] Loss_D: 0.0871 (0.4030) Loss_G: -0.2061 (0.2512) D(x): 0.5307 D(G(z)): 0.4818 / 0.4959 Acc: 29.6875 (28.3613)\n",
      "[6/25][658/782] Loss_D: 0.3181 (0.4030) Loss_G: -0.2256 (0.2511) D(x): 0.5253 D(G(z)): 0.5602 / 0.4908 Acc: 28.1250 (28.3612)\n",
      "[6/25][659/782] Loss_D: 0.2184 (0.4030) Loss_G: -0.0972 (0.2511) D(x): 0.4947 D(G(z)): 0.4773 / 0.4476 Acc: 26.5625 (28.3609)\n",
      "[6/25][660/782] Loss_D: 0.0715 (0.4029) Loss_G: -0.0772 (0.2510) D(x): 0.4983 D(G(z)): 0.4465 / 0.4357 Acc: 34.3750 (28.3620)\n",
      "[6/25][661/782] Loss_D: -0.0549 (0.4028) Loss_G: -0.2333 (0.2509) D(x): 0.5030 D(G(z)): 0.4572 / 0.4929 Acc: 42.1875 (28.3646)\n",
      "[6/25][662/782] Loss_D: 0.1599 (0.4028) Loss_G: -0.0811 (0.2508) D(x): 0.5403 D(G(z)): 0.5326 / 0.4376 Acc: 32.8125 (28.3654)\n",
      "[6/25][663/782] Loss_D: 0.0393 (0.4027) Loss_G: -0.1998 (0.2508) D(x): 0.4925 D(G(z)): 0.4724 / 0.4670 Acc: 42.1875 (28.3680)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/25][664/782] Loss_D: 0.0095 (0.4026) Loss_G: -0.2537 (0.2507) D(x): 0.5202 D(G(z)): 0.4573 / 0.5151 Acc: 37.5000 (28.3697)\n",
      "[6/25][665/782] Loss_D: 0.2546 (0.4026) Loss_G: -0.1933 (0.2506) D(x): 0.5293 D(G(z)): 0.5074 / 0.4779 Acc: 23.4375 (28.3688)\n",
      "[6/25][666/782] Loss_D: 0.0540 (0.4026) Loss_G: -0.0001 (0.2505) D(x): 0.5748 D(G(z)): 0.5043 / 0.3998 Acc: 31.2500 (28.3693)\n",
      "[6/25][667/782] Loss_D: 0.1687 (0.4025) Loss_G: 0.0033 (0.2505) D(x): 0.4903 D(G(z)): 0.4580 / 0.4066 Acc: 34.3750 (28.3705)\n",
      "[6/25][668/782] Loss_D: -0.0314 (0.4024) Loss_G: -0.1772 (0.2504) D(x): 0.5015 D(G(z)): 0.4267 / 0.4610 Acc: 37.5000 (28.3722)\n",
      "[6/25][669/782] Loss_D: 0.0809 (0.4024) Loss_G: -0.2409 (0.2503) D(x): 0.5075 D(G(z)): 0.4703 / 0.4948 Acc: 32.8125 (28.3730)\n",
      "[6/25][670/782] Loss_D: 0.0187 (0.4023) Loss_G: -0.0810 (0.2502) D(x): 0.5264 D(G(z)): 0.4539 / 0.4347 Acc: 37.5000 (28.3747)\n",
      "[6/25][671/782] Loss_D: 0.0527 (0.4022) Loss_G: -0.1774 (0.2502) D(x): 0.5494 D(G(z)): 0.4957 / 0.4739 Acc: 34.3750 (28.3758)\n",
      "[6/25][672/782] Loss_D: 0.0863 (0.4022) Loss_G: -0.1274 (0.2501) D(x): 0.5321 D(G(z)): 0.4790 / 0.4493 Acc: 34.3750 (28.3769)\n",
      "[6/25][673/782] Loss_D: -0.0915 (0.4021) Loss_G: -0.1959 (0.2500) D(x): 0.5747 D(G(z)): 0.4666 / 0.4738 Acc: 39.0625 (28.3789)\n",
      "[6/25][674/782] Loss_D: 0.1568 (0.4020) Loss_G: -0.0986 (0.2500) D(x): 0.5525 D(G(z)): 0.5082 / 0.4406 Acc: 25.0000 (28.3783)\n",
      "[6/25][675/782] Loss_D: 0.1267 (0.4020) Loss_G: 0.0069 (0.2499) D(x): 0.5050 D(G(z)): 0.5063 / 0.4074 Acc: 39.0625 (28.3803)\n",
      "[6/25][676/782] Loss_D: -0.0050 (0.4019) Loss_G: -0.1164 (0.2498) D(x): 0.5099 D(G(z)): 0.4671 / 0.4409 Acc: 40.6250 (28.3826)\n",
      "[6/25][677/782] Loss_D: -0.0165 (0.4018) Loss_G: -0.1924 (0.2498) D(x): 0.5067 D(G(z)): 0.4660 / 0.4685 Acc: 43.7500 (28.3854)\n",
      "[6/25][678/782] Loss_D: 0.0650 (0.4018) Loss_G: -0.2300 (0.2497) D(x): 0.5569 D(G(z)): 0.5201 / 0.4935 Acc: 39.0625 (28.3874)\n",
      "[6/25][679/782] Loss_D: 0.3067 (0.4017) Loss_G: -0.2401 (0.2496) D(x): 0.4368 D(G(z)): 0.4980 / 0.4958 Acc: 29.6875 (28.3876)\n",
      "[6/25][680/782] Loss_D: 0.1355 (0.4017) Loss_G: -0.2067 (0.2495) D(x): 0.4920 D(G(z)): 0.4997 / 0.4682 Acc: 39.0625 (28.3896)\n",
      "[6/25][681/782] Loss_D: 0.0819 (0.4016) Loss_G: -0.0667 (0.2494) D(x): 0.5259 D(G(z)): 0.4689 / 0.4624 Acc: 34.3750 (28.3907)\n",
      "[6/25][682/782] Loss_D: 0.1040 (0.4016) Loss_G: -0.1554 (0.2494) D(x): 0.5311 D(G(z)): 0.5120 / 0.4743 Acc: 35.9375 (28.3922)\n",
      "[6/25][683/782] Loss_D: 0.2706 (0.4016) Loss_G: -0.2002 (0.2493) D(x): 0.5176 D(G(z)): 0.5201 / 0.4849 Acc: 25.0000 (28.3915)\n",
      "[6/25][684/782] Loss_D: 0.1161 (0.4015) Loss_G: -0.1948 (0.2492) D(x): 0.5188 D(G(z)): 0.5053 / 0.4880 Acc: 34.3750 (28.3926)\n",
      "[6/25][685/782] Loss_D: 0.0538 (0.4014) Loss_G: -0.1118 (0.2491) D(x): 0.5091 D(G(z)): 0.4667 / 0.4520 Acc: 37.5000 (28.3943)\n",
      "[6/25][686/782] Loss_D: 0.0400 (0.4014) Loss_G: -0.1462 (0.2490) D(x): 0.5286 D(G(z)): 0.4540 / 0.4726 Acc: 34.3750 (28.3954)\n",
      "[6/25][687/782] Loss_D: 0.0405 (0.4013) Loss_G: -0.2087 (0.2490) D(x): 0.5067 D(G(z)): 0.5104 / 0.4758 Acc: 45.3125 (28.3986)\n",
      "[6/25][688/782] Loss_D: 0.1572 (0.4013) Loss_G: -0.2189 (0.2489) D(x): 0.4961 D(G(z)): 0.5344 / 0.4774 Acc: 40.6250 (28.4009)\n",
      "[6/25][689/782] Loss_D: 0.0880 (0.4012) Loss_G: -0.0553 (0.2488) D(x): 0.5043 D(G(z)): 0.4584 / 0.4257 Acc: 32.8125 (28.4017)\n",
      "[6/25][690/782] Loss_D: 0.0079 (0.4011) Loss_G: -0.1519 (0.2487) D(x): 0.5241 D(G(z)): 0.4367 / 0.4482 Acc: 28.1250 (28.4016)\n",
      "[6/25][691/782] Loss_D: -0.0065 (0.4011) Loss_G: -0.1776 (0.2487) D(x): 0.5391 D(G(z)): 0.5079 / 0.4675 Acc: 43.7500 (28.4045)\n",
      "[6/25][692/782] Loss_D: 0.0923 (0.4010) Loss_G: -0.0777 (0.2486) D(x): 0.5079 D(G(z)): 0.4754 / 0.4428 Acc: 39.0625 (28.4065)\n",
      "[6/25][693/782] Loss_D: -0.1254 (0.4009) Loss_G: -0.1682 (0.2485) D(x): 0.5091 D(G(z)): 0.4485 / 0.4682 Acc: 50.0000 (28.4105)\n",
      "[6/25][694/782] Loss_D: 0.0671 (0.4008) Loss_G: -0.1800 (0.2484) D(x): 0.5080 D(G(z)): 0.4599 / 0.4774 Acc: 35.9375 (28.4119)\n",
      "[6/25][695/782] Loss_D: 0.0771 (0.4008) Loss_G: -0.1091 (0.2484) D(x): 0.5687 D(G(z)): 0.4746 / 0.4372 Acc: 23.4375 (28.4109)\n",
      "[6/25][696/782] Loss_D: 0.0607 (0.4007) Loss_G: -0.1220 (0.2483) D(x): 0.5161 D(G(z)): 0.4845 / 0.4391 Acc: 32.8125 (28.4118)\n",
      "[6/25][697/782] Loss_D: -0.1626 (0.4006) Loss_G: -0.1640 (0.2482) D(x): 0.5680 D(G(z)): 0.4334 / 0.4718 Acc: 37.5000 (28.4134)\n",
      "[6/25][698/782] Loss_D: -0.1289 (0.4005) Loss_G: -0.1400 (0.2482) D(x): 0.5647 D(G(z)): 0.4560 / 0.4537 Acc: 43.7500 (28.4163)\n",
      "[6/25][699/782] Loss_D: 0.0947 (0.4005) Loss_G: -0.1487 (0.2481) D(x): 0.5670 D(G(z)): 0.4617 / 0.4607 Acc: 23.4375 (28.4154)\n",
      "[6/25][700/782] Loss_D: -0.0214 (0.4004) Loss_G: -0.1673 (0.2480) D(x): 0.5247 D(G(z)): 0.4327 / 0.4771 Acc: 35.9375 (28.4168)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[6/25][701/782] Loss_D: 0.1830 (0.4003) Loss_G: -0.1015 (0.2480) D(x): 0.5000 D(G(z)): 0.5098 / 0.4548 Acc: 31.2500 (28.4173)\n",
      "[6/25][702/782] Loss_D: 0.0448 (0.4003) Loss_G: -0.1683 (0.2479) D(x): 0.5129 D(G(z)): 0.4720 / 0.4656 Acc: 31.2500 (28.4178)\n",
      "[6/25][703/782] Loss_D: 0.0412 (0.4002) Loss_G: -0.2042 (0.2478) D(x): 0.4888 D(G(z)): 0.4741 / 0.4888 Acc: 40.6250 (28.4201)\n",
      "[6/25][704/782] Loss_D: 0.0851 (0.4001) Loss_G: -0.1906 (0.2477) D(x): 0.5605 D(G(z)): 0.5288 / 0.4777 Acc: 42.1875 (28.4226)\n",
      "[6/25][705/782] Loss_D: 0.1379 (0.4001) Loss_G: -0.0760 (0.2476) D(x): 0.4986 D(G(z)): 0.4775 / 0.4375 Acc: 34.3750 (28.4237)\n",
      "[6/25][706/782] Loss_D: 0.0896 (0.4000) Loss_G: -0.2001 (0.2476) D(x): 0.4789 D(G(z)): 0.4717 / 0.4802 Acc: 39.0625 (28.4257)\n",
      "[6/25][707/782] Loss_D: -0.0507 (0.4000) Loss_G: -0.0631 (0.2475) D(x): 0.5455 D(G(z)): 0.4547 / 0.4360 Acc: 35.9375 (28.4271)\n",
      "[6/25][708/782] Loss_D: -0.1096 (0.3999) Loss_G: -0.1018 (0.2474) D(x): 0.5165 D(G(z)): 0.4348 / 0.4514 Acc: 46.8750 (28.4305)\n",
      "[6/25][709/782] Loss_D: 0.1439 (0.3998) Loss_G: -0.1549 (0.2474) D(x): 0.5073 D(G(z)): 0.5007 / 0.4609 Acc: 34.3750 (28.4316)\n",
      "[6/25][710/782] Loss_D: 0.3185 (0.3998) Loss_G: -0.1743 (0.2473) D(x): 0.4655 D(G(z)): 0.4923 / 0.4847 Acc: 23.4375 (28.4307)\n",
      "[6/25][711/782] Loss_D: 0.1472 (0.3998) Loss_G: -0.2290 (0.2472) D(x): 0.5018 D(G(z)): 0.5103 / 0.4873 Acc: 35.9375 (28.4321)\n",
      "[6/25][712/782] Loss_D: 0.1394 (0.3997) Loss_G: -0.1861 (0.2471) D(x): 0.5221 D(G(z)): 0.5031 / 0.4700 Acc: 31.2500 (28.4326)\n",
      "[6/25][713/782] Loss_D: -0.0760 (0.3996) Loss_G: -0.2457 (0.2470) D(x): 0.5449 D(G(z)): 0.4670 / 0.4903 Acc: 40.6250 (28.4348)\n",
      "[6/25][714/782] Loss_D: 0.1182 (0.3996) Loss_G: -0.0942 (0.2470) D(x): 0.5353 D(G(z)): 0.4836 / 0.4404 Acc: 28.1250 (28.4348)\n",
      "[6/25][715/782] Loss_D: -0.0642 (0.3995) Loss_G: -0.1727 (0.2469) D(x): 0.5437 D(G(z)): 0.4348 / 0.4559 Acc: 35.9375 (28.4362)\n",
      "[6/25][716/782] Loss_D: -0.0100 (0.3994) Loss_G: -0.1581 (0.2468) D(x): 0.5422 D(G(z)): 0.4410 / 0.4706 Acc: 31.2500 (28.4367)\n",
      "[6/25][717/782] Loss_D: 0.1020 (0.3993) Loss_G: -0.1685 (0.2467) D(x): 0.5283 D(G(z)): 0.5060 / 0.4674 Acc: 35.9375 (28.4381)\n",
      "[6/25][718/782] Loss_D: -0.1296 (0.3992) Loss_G: -0.0906 (0.2467) D(x): 0.5291 D(G(z)): 0.4270 / 0.4457 Acc: 40.6250 (28.4403)\n",
      "[6/25][719/782] Loss_D: 0.0248 (0.3992) Loss_G: -0.1626 (0.2466) D(x): 0.4863 D(G(z)): 0.4535 / 0.4626 Acc: 37.5000 (28.4420)\n",
      "[6/25][720/782] Loss_D: 0.0372 (0.3991) Loss_G: -0.1040 (0.2465) D(x): 0.5474 D(G(z)): 0.4518 / 0.4545 Acc: 23.4375 (28.4411)\n",
      "[6/25][721/782] Loss_D: 0.0041 (0.3990) Loss_G: -0.1515 (0.2465) D(x): 0.5597 D(G(z)): 0.4655 / 0.4631 Acc: 29.6875 (28.4413)\n",
      "[6/25][722/782] Loss_D: 0.0319 (0.3990) Loss_G: -0.0948 (0.2464) D(x): 0.5537 D(G(z)): 0.4895 / 0.4281 Acc: 31.2500 (28.4418)\n",
      "[6/25][723/782] Loss_D: -0.1524 (0.3989) Loss_G: -0.1207 (0.2463) D(x): 0.5428 D(G(z)): 0.4299 / 0.4376 Acc: 42.1875 (28.4444)\n",
      "[6/25][724/782] Loss_D: -0.1635 (0.3988) Loss_G: -0.0941 (0.2463) D(x): 0.5605 D(G(z)): 0.4714 / 0.4386 Acc: 48.4375 (28.4481)\n",
      "[6/25][725/782] Loss_D: 0.0807 (0.3987) Loss_G: -0.1726 (0.2462) D(x): 0.5075 D(G(z)): 0.4665 / 0.4637 Acc: 37.5000 (28.4497)\n",
      "[6/25][726/782] Loss_D: 0.0036 (0.3986) Loss_G: -0.0976 (0.2461) D(x): 0.5514 D(G(z)): 0.4659 / 0.4453 Acc: 25.0000 (28.4491)\n",
      "[6/25][727/782] Loss_D: 0.1329 (0.3986) Loss_G: -0.1626 (0.2461) D(x): 0.5239 D(G(z)): 0.4861 / 0.4629 Acc: 31.2500 (28.4496)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/25][728/782] Loss_D: 0.0395 (0.3985) Loss_G: -0.2543 (0.2460) D(x): 0.4882 D(G(z)): 0.4546 / 0.5133 Acc: 40.6250 (28.4519)\n",
      "[6/25][729/782] Loss_D: 0.0418 (0.3985) Loss_G: -0.0690 (0.2459) D(x): 0.5570 D(G(z)): 0.4934 / 0.4280 Acc: 32.8125 (28.4527)\n",
      "[6/25][730/782] Loss_D: -0.0962 (0.3984) Loss_G: 0.1290 (0.2459) D(x): 0.5785 D(G(z)): 0.4521 / 0.3682 Acc: 31.2500 (28.4532)\n",
      "[6/25][731/782] Loss_D: 0.0119 (0.3983) Loss_G: -0.0592 (0.2458) D(x): 0.4725 D(G(z)): 0.4197 / 0.4332 Acc: 45.3125 (28.4563)\n",
      "[6/25][732/782] Loss_D: -0.0459 (0.3982) Loss_G: -0.1705 (0.2457) D(x): 0.5437 D(G(z)): 0.4775 / 0.4709 Acc: 39.0625 (28.4582)\n",
      "[6/25][733/782] Loss_D: 0.0476 (0.3981) Loss_G: -0.2351 (0.2457) D(x): 0.5314 D(G(z)): 0.5005 / 0.5122 Acc: 43.7500 (28.4611)\n",
      "[6/25][734/782] Loss_D: -0.0904 (0.3981) Loss_G: -0.1781 (0.2456) D(x): 0.5046 D(G(z)): 0.4086 / 0.4832 Acc: 40.6250 (28.4633)\n",
      "[6/25][735/782] Loss_D: 0.0218 (0.3980) Loss_G: -0.1605 (0.2455) D(x): 0.5542 D(G(z)): 0.4838 / 0.4778 Acc: 34.3750 (28.4644)\n",
      "[6/25][736/782] Loss_D: 0.0597 (0.3979) Loss_G: -0.2245 (0.2454) D(x): 0.5265 D(G(z)): 0.4994 / 0.5148 Acc: 39.0625 (28.4663)\n",
      "[6/25][737/782] Loss_D: 0.1569 (0.3979) Loss_G: -0.2252 (0.2453) D(x): 0.5125 D(G(z)): 0.4931 / 0.4872 Acc: 29.6875 (28.4666)\n",
      "[6/25][738/782] Loss_D: 0.2170 (0.3978) Loss_G: -0.1391 (0.2453) D(x): 0.4858 D(G(z)): 0.5388 / 0.4410 Acc: 39.0625 (28.4685)\n",
      "[6/25][739/782] Loss_D: -0.0671 (0.3978) Loss_G: -0.0356 (0.2452) D(x): 0.5312 D(G(z)): 0.4749 / 0.4189 Acc: 43.7500 (28.4713)\n",
      "[6/25][740/782] Loss_D: 0.0804 (0.3977) Loss_G: -0.1207 (0.2451) D(x): 0.4797 D(G(z)): 0.4397 / 0.4592 Acc: 40.6250 (28.4736)\n",
      "[6/25][741/782] Loss_D: 0.0836 (0.3976) Loss_G: -0.2073 (0.2451) D(x): 0.4744 D(G(z)): 0.5080 / 0.4853 Acc: 45.3125 (28.4767)\n",
      "[6/25][742/782] Loss_D: 0.0849 (0.3976) Loss_G: -0.1973 (0.2450) D(x): 0.5414 D(G(z)): 0.4931 / 0.4781 Acc: 32.8125 (28.4775)\n",
      "[6/25][743/782] Loss_D: -0.0376 (0.3975) Loss_G: 0.0099 (0.2449) D(x): 0.5145 D(G(z)): 0.4190 / 0.4113 Acc: 32.8125 (28.4783)\n",
      "[6/25][744/782] Loss_D: -0.0475 (0.3974) Loss_G: -0.2164 (0.2449) D(x): 0.5328 D(G(z)): 0.4544 / 0.4953 Acc: 37.5000 (28.4799)\n",
      "[6/25][745/782] Loss_D: -0.0733 (0.3973) Loss_G: -0.1240 (0.2448) D(x): 0.5926 D(G(z)): 0.5034 / 0.4570 Acc: 40.6250 (28.4822)\n",
      "[6/25][746/782] Loss_D: 0.2313 (0.3973) Loss_G: -0.0989 (0.2447) D(x): 0.4877 D(G(z)): 0.4832 / 0.4421 Acc: 29.6875 (28.4824)\n",
      "[6/25][747/782] Loss_D: -0.0161 (0.3972) Loss_G: -0.0927 (0.2447) D(x): 0.5119 D(G(z)): 0.4455 / 0.4358 Acc: 39.0625 (28.4843)\n",
      "[6/25][748/782] Loss_D: 0.0468 (0.3972) Loss_G: -0.1225 (0.2446) D(x): 0.5229 D(G(z)): 0.4945 / 0.4423 Acc: 35.9375 (28.4857)\n",
      "[6/25][749/782] Loss_D: 0.1219 (0.3971) Loss_G: -0.2157 (0.2445) D(x): 0.5254 D(G(z)): 0.4817 / 0.4798 Acc: 28.1250 (28.4856)\n",
      "[6/25][750/782] Loss_D: 0.0792 (0.3971) Loss_G: -0.1793 (0.2444) D(x): 0.5219 D(G(z)): 0.4680 / 0.4780 Acc: 35.9375 (28.4870)\n",
      "[6/25][751/782] Loss_D: 0.2508 (0.3970) Loss_G: -0.0781 (0.2444) D(x): 0.4942 D(G(z)): 0.4792 / 0.4318 Acc: 28.1250 (28.4869)\n",
      "[6/25][752/782] Loss_D: 0.1270 (0.3970) Loss_G: -0.1170 (0.2443) D(x): 0.5175 D(G(z)): 0.4943 / 0.4611 Acc: 35.9375 (28.4883)\n",
      "[6/25][753/782] Loss_D: 0.0911 (0.3969) Loss_G: -0.2110 (0.2442) D(x): 0.4963 D(G(z)): 0.5039 / 0.4786 Acc: 37.5000 (28.4899)\n",
      "[6/25][754/782] Loss_D: 0.0704 (0.3969) Loss_G: -0.2297 (0.2441) D(x): 0.5224 D(G(z)): 0.4887 / 0.4834 Acc: 34.3750 (28.4910)\n",
      "[6/25][755/782] Loss_D: -0.0492 (0.3968) Loss_G: -0.0421 (0.2441) D(x): 0.5453 D(G(z)): 0.4638 / 0.4208 Acc: 37.5000 (28.4927)\n",
      "[6/25][756/782] Loss_D: 0.0781 (0.3967) Loss_G: -0.0798 (0.2440) D(x): 0.5265 D(G(z)): 0.4689 / 0.4201 Acc: 29.6875 (28.4929)\n",
      "[6/25][757/782] Loss_D: 0.1595 (0.3967) Loss_G: -0.1318 (0.2440) D(x): 0.4587 D(G(z)): 0.4574 / 0.4417 Acc: 31.2500 (28.4934)\n",
      "[6/25][758/782] Loss_D: 0.0196 (0.3966) Loss_G: -0.2847 (0.2439) D(x): 0.5199 D(G(z)): 0.4708 / 0.5190 Acc: 39.0625 (28.4953)\n",
      "[6/25][759/782] Loss_D: 0.0805 (0.3966) Loss_G: -0.1828 (0.2438) D(x): 0.4931 D(G(z)): 0.5043 / 0.4891 Acc: 42.1875 (28.4979)\n",
      "[6/25][760/782] Loss_D: -0.0480 (0.3965) Loss_G: -0.2405 (0.2437) D(x): 0.5686 D(G(z)): 0.5244 / 0.4822 Acc: 42.1875 (28.5004)\n",
      "[6/25][761/782] Loss_D: 0.0906 (0.3964) Loss_G: -0.1577 (0.2436) D(x): 0.5695 D(G(z)): 0.5053 / 0.4627 Acc: 28.1250 (28.5003)\n",
      "[6/25][762/782] Loss_D: 0.1201 (0.3964) Loss_G: -0.0917 (0.2436) D(x): 0.4775 D(G(z)): 0.4788 / 0.4361 Acc: 35.9375 (28.5017)\n",
      "[6/25][763/782] Loss_D: 0.0454 (0.3963) Loss_G: -0.1826 (0.2435) D(x): 0.5271 D(G(z)): 0.4503 / 0.4759 Acc: 32.8125 (28.5025)\n",
      "[6/25][764/782] Loss_D: 0.0426 (0.3962) Loss_G: -0.0947 (0.2434) D(x): 0.5539 D(G(z)): 0.4688 / 0.4395 Acc: 28.1250 (28.5024)\n",
      "[6/25][765/782] Loss_D: 0.1647 (0.3962) Loss_G: -0.1375 (0.2433) D(x): 0.4723 D(G(z)): 0.4663 / 0.4521 Acc: 31.2500 (28.5029)\n",
      "[6/25][766/782] Loss_D: 0.0213 (0.3961) Loss_G: -0.2240 (0.2433) D(x): 0.5528 D(G(z)): 0.4667 / 0.4787 Acc: 26.5625 (28.5025)\n",
      "[6/25][767/782] Loss_D: 0.0584 (0.3961) Loss_G: -0.1528 (0.2432) D(x): 0.5080 D(G(z)): 0.4473 / 0.4614 Acc: 29.6875 (28.5027)\n",
      "[6/25][768/782] Loss_D: 0.1691 (0.3960) Loss_G: -0.1119 (0.2431) D(x): 0.5288 D(G(z)): 0.4964 / 0.4639 Acc: 29.6875 (28.5030)\n",
      "[6/25][769/782] Loss_D: 0.0445 (0.3960) Loss_G: -0.0511 (0.2431) D(x): 0.5352 D(G(z)): 0.4767 / 0.4142 Acc: 34.3750 (28.5040)\n",
      "[6/25][770/782] Loss_D: -0.0316 (0.3959) Loss_G: -0.1126 (0.2430) D(x): 0.5182 D(G(z)): 0.4674 / 0.4435 Acc: 42.1875 (28.5065)\n",
      "[6/25][771/782] Loss_D: -0.0443 (0.3958) Loss_G: -0.0653 (0.2429) D(x): 0.5236 D(G(z)): 0.4597 / 0.4133 Acc: 40.6250 (28.5088)\n",
      "[6/25][772/782] Loss_D: 0.0510 (0.3957) Loss_G: -0.1745 (0.2429) D(x): 0.5401 D(G(z)): 0.4908 / 0.4718 Acc: 34.3750 (28.5098)\n",
      "[6/25][773/782] Loss_D: 0.0581 (0.3957) Loss_G: -0.0763 (0.2428) D(x): 0.5210 D(G(z)): 0.4660 / 0.4361 Acc: 32.8125 (28.5106)\n",
      "[6/25][774/782] Loss_D: -0.0888 (0.3956) Loss_G: -0.1616 (0.2427) D(x): 0.5316 D(G(z)): 0.4615 / 0.4624 Acc: 45.3125 (28.5137)\n",
      "[6/25][775/782] Loss_D: 0.2541 (0.3956) Loss_G: -0.1169 (0.2427) D(x): 0.4837 D(G(z)): 0.4911 / 0.4671 Acc: 25.0000 (28.5131)\n",
      "[6/25][776/782] Loss_D: -0.1002 (0.3955) Loss_G: -0.1044 (0.2426) D(x): 0.5486 D(G(z)): 0.4464 / 0.4475 Acc: 37.5000 (28.5147)\n",
      "[6/25][777/782] Loss_D: -0.0461 (0.3954) Loss_G: -0.1800 (0.2425) D(x): 0.5478 D(G(z)): 0.4622 / 0.4604 Acc: 35.9375 (28.5161)\n",
      "[6/25][778/782] Loss_D: 0.0467 (0.3953) Loss_G: -0.1030 (0.2425) D(x): 0.5655 D(G(z)): 0.5272 / 0.4328 Acc: 35.9375 (28.5174)\n",
      "[6/25][779/782] Loss_D: 0.0252 (0.3953) Loss_G: -0.1613 (0.2424) D(x): 0.5340 D(G(z)): 0.4574 / 0.4652 Acc: 29.6875 (28.5176)\n",
      "[6/25][780/782] Loss_D: 0.0130 (0.3952) Loss_G: -0.2516 (0.2423) D(x): 0.5419 D(G(z)): 0.4741 / 0.4962 Acc: 37.5000 (28.5193)\n",
      "[6/25][781/782] Loss_D: 0.1533 (0.3951) Loss_G: -0.0896 (0.2422) D(x): 0.4849 D(G(z)): 0.4476 / 0.4382 Acc: 25.0000 (28.5186)\n",
      "[7/25][0/782] Loss_D: -0.0381 (0.3951) Loss_G: -0.2150 (0.2422) D(x): 0.5589 D(G(z)): 0.4788 / 0.4899 Acc: 35.9375 (28.5200)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[7/25][1/782] Loss_D: -0.0643 (0.3950) Loss_G: -0.1509 (0.2421) D(x): 0.6262 D(G(z)): 0.4708 / 0.4598 Acc: 25.0000 (28.5193)\n",
      "[7/25][2/782] Loss_D: -0.0733 (0.3949) Loss_G: -0.1124 (0.2420) D(x): 0.5265 D(G(z)): 0.4446 / 0.4375 Acc: 37.5000 (28.5210)\n",
      "[7/25][3/782] Loss_D: 0.0842 (0.3948) Loss_G: -0.2862 (0.2419) D(x): 0.5017 D(G(z)): 0.4781 / 0.5058 Acc: 32.8125 (28.5218)\n",
      "[7/25][4/782] Loss_D: -0.0528 (0.3948) Loss_G: -0.1204 (0.2419) D(x): 0.5196 D(G(z)): 0.4321 / 0.4734 Acc: 37.5000 (28.5234)\n",
      "[7/25][5/782] Loss_D: 0.0388 (0.3947) Loss_G: -0.0872 (0.2418) D(x): 0.5383 D(G(z)): 0.4875 / 0.4334 Acc: 32.8125 (28.5242)\n",
      "[7/25][6/782] Loss_D: 0.0134 (0.3946) Loss_G: -0.1645 (0.2417) D(x): 0.5585 D(G(z)): 0.4870 / 0.4744 Acc: 37.5000 (28.5258)\n",
      "[7/25][7/782] Loss_D: 0.1333 (0.3946) Loss_G: -0.1679 (0.2416) D(x): 0.4899 D(G(z)): 0.4700 / 0.4720 Acc: 35.9375 (28.5272)\n",
      "[7/25][8/782] Loss_D: 0.0560 (0.3945) Loss_G: -0.1215 (0.2416) D(x): 0.5524 D(G(z)): 0.5116 / 0.4385 Acc: 37.5000 (28.5288)\n",
      "[7/25][9/782] Loss_D: 0.1965 (0.3945) Loss_G: -0.1693 (0.2415) D(x): 0.4801 D(G(z)): 0.5007 / 0.4744 Acc: 32.8125 (28.5296)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/25][10/782] Loss_D: 0.0833 (0.3944) Loss_G: -0.1880 (0.2414) D(x): 0.4688 D(G(z)): 0.4507 / 0.4719 Acc: 42.1875 (28.5321)\n",
      "[7/25][11/782] Loss_D: 0.3020 (0.3944) Loss_G: -0.1175 (0.2414) D(x): 0.5285 D(G(z)): 0.5295 / 0.4487 Acc: 21.8750 (28.5309)\n",
      "[7/25][12/782] Loss_D: 0.0392 (0.3943) Loss_G: -0.1050 (0.2413) D(x): 0.5660 D(G(z)): 0.5289 / 0.4432 Acc: 35.9375 (28.5322)\n",
      "[7/25][13/782] Loss_D: 0.3085 (0.3943) Loss_G: 0.0178 (0.2413) D(x): 0.4488 D(G(z)): 0.4975 / 0.4122 Acc: 31.2500 (28.5327)\n",
      "[7/25][14/782] Loss_D: 0.0405 (0.3943) Loss_G: -0.1297 (0.2412) D(x): 0.4611 D(G(z)): 0.4228 / 0.4585 Acc: 40.6250 (28.5349)\n",
      "[7/25][15/782] Loss_D: 0.2077 (0.3942) Loss_G: -0.1792 (0.2411) D(x): 0.4998 D(G(z)): 0.5337 / 0.4820 Acc: 35.9375 (28.5363)\n",
      "[7/25][16/782] Loss_D: 0.0863 (0.3942) Loss_G: -0.1442 (0.2410) D(x): 0.5120 D(G(z)): 0.4881 / 0.4633 Acc: 39.0625 (28.5382)\n",
      "[7/25][17/782] Loss_D: 0.0855 (0.3941) Loss_G: -0.1434 (0.2410) D(x): 0.5075 D(G(z)): 0.5019 / 0.4701 Acc: 43.7500 (28.5409)\n",
      "[7/25][18/782] Loss_D: -0.1030 (0.3940) Loss_G: -0.1943 (0.2409) D(x): 0.5558 D(G(z)): 0.4329 / 0.4960 Acc: 39.0625 (28.5429)\n",
      "[7/25][19/782] Loss_D: 0.1452 (0.3940) Loss_G: -0.2357 (0.2408) D(x): 0.5259 D(G(z)): 0.5106 / 0.5024 Acc: 34.3750 (28.5439)\n",
      "[7/25][20/782] Loss_D: 0.1411 (0.3939) Loss_G: -0.1582 (0.2407) D(x): 0.5085 D(G(z)): 0.5104 / 0.4589 Acc: 42.1875 (28.5464)\n",
      "[7/25][21/782] Loss_D: 0.2279 (0.3939) Loss_G: -0.0117 (0.2407) D(x): 0.5089 D(G(z)): 0.4926 / 0.4118 Acc: 26.5625 (28.5460)\n",
      "[7/25][22/782] Loss_D: 0.3228 (0.3939) Loss_G: -0.1642 (0.2406) D(x): 0.4138 D(G(z)): 0.4843 / 0.4648 Acc: 40.6250 (28.5482)\n",
      "[7/25][23/782] Loss_D: 0.1358 (0.3938) Loss_G: -0.1138 (0.2406) D(x): 0.5379 D(G(z)): 0.4829 / 0.4459 Acc: 26.5625 (28.5479)\n",
      "[7/25][24/782] Loss_D: 0.2524 (0.3938) Loss_G: -0.2604 (0.2405) D(x): 0.4968 D(G(z)): 0.5119 / 0.5110 Acc: 26.5625 (28.5475)\n",
      "[7/25][25/782] Loss_D: 0.0257 (0.3937) Loss_G: -0.1666 (0.2404) D(x): 0.5309 D(G(z)): 0.4936 / 0.4882 Acc: 42.1875 (28.5500)\n",
      "[7/25][26/782] Loss_D: 0.1496 (0.3937) Loss_G: -0.1714 (0.2403) D(x): 0.4824 D(G(z)): 0.4801 / 0.4815 Acc: 39.0625 (28.5519)\n",
      "[7/25][27/782] Loss_D: 0.0549 (0.3936) Loss_G: -0.1555 (0.2402) D(x): 0.4942 D(G(z)): 0.4964 / 0.4748 Acc: 45.3125 (28.5550)\n",
      "[7/25][28/782] Loss_D: 0.2907 (0.3936) Loss_G: -0.2491 (0.2402) D(x): 0.4676 D(G(z)): 0.4952 / 0.4988 Acc: 29.6875 (28.5552)\n",
      "[7/25][29/782] Loss_D: -0.0168 (0.3935) Loss_G: -0.2010 (0.2401) D(x): 0.5177 D(G(z)): 0.4661 / 0.4772 Acc: 35.9375 (28.5565)\n",
      "[7/25][30/782] Loss_D: 0.1951 (0.3935) Loss_G: -0.1742 (0.2400) D(x): 0.5470 D(G(z)): 0.5392 / 0.4742 Acc: 32.8125 (28.5573)\n",
      "[7/25][31/782] Loss_D: -0.0107 (0.3934) Loss_G: -0.1380 (0.2399) D(x): 0.5242 D(G(z)): 0.4515 / 0.4487 Acc: 39.0625 (28.5592)\n",
      "[7/25][32/782] Loss_D: 0.1912 (0.3934) Loss_G: -0.1395 (0.2399) D(x): 0.5174 D(G(z)): 0.4797 / 0.4725 Acc: 21.8750 (28.5580)\n",
      "[7/25][33/782] Loss_D: -0.0854 (0.3933) Loss_G: -0.1107 (0.2398) D(x): 0.5500 D(G(z)): 0.4296 / 0.4370 Acc: 31.2500 (28.5585)\n",
      "[7/25][34/782] Loss_D: 0.1324 (0.3933) Loss_G: -0.1366 (0.2397) D(x): 0.5231 D(G(z)): 0.4811 / 0.4527 Acc: 28.1250 (28.5584)\n",
      "[7/25][35/782] Loss_D: 0.0818 (0.3932) Loss_G: -0.1045 (0.2397) D(x): 0.5705 D(G(z)): 0.4469 / 0.4537 Acc: 20.3125 (28.5569)\n",
      "[7/25][36/782] Loss_D: 0.0508 (0.3931) Loss_G: -0.1153 (0.2396) D(x): 0.5162 D(G(z)): 0.4317 / 0.4452 Acc: 26.5625 (28.5565)\n",
      "[7/25][37/782] Loss_D: -0.1726 (0.3930) Loss_G: -0.1307 (0.2395) D(x): 0.5733 D(G(z)): 0.4695 / 0.4422 Acc: 43.7500 (28.5593)\n",
      "[7/25][38/782] Loss_D: 0.0444 (0.3930) Loss_G: -0.1016 (0.2395) D(x): 0.5332 D(G(z)): 0.4856 / 0.4417 Acc: 37.5000 (28.5609)\n",
      "[7/25][39/782] Loss_D: 0.0704 (0.3929) Loss_G: -0.0908 (0.2394) D(x): 0.4981 D(G(z)): 0.4256 / 0.4430 Acc: 31.2500 (28.5614)\n",
      "[7/25][40/782] Loss_D: 0.1696 (0.3929) Loss_G: -0.1011 (0.2393) D(x): 0.5599 D(G(z)): 0.5121 / 0.4328 Acc: 26.5625 (28.5610)\n",
      "[7/25][41/782] Loss_D: -0.0362 (0.3928) Loss_G: -0.1690 (0.2393) D(x): 0.5487 D(G(z)): 0.4729 / 0.4583 Acc: 39.0625 (28.5629)\n",
      "[7/25][42/782] Loss_D: 0.0425 (0.3927) Loss_G: -0.1579 (0.2392) D(x): 0.5017 D(G(z)): 0.4427 / 0.4570 Acc: 34.3750 (28.5640)\n",
      "[7/25][43/782] Loss_D: -0.0281 (0.3927) Loss_G: -0.1184 (0.2391) D(x): 0.5199 D(G(z)): 0.4644 / 0.4361 Acc: 42.1875 (28.5665)\n",
      "[7/25][44/782] Loss_D: -0.0098 (0.3926) Loss_G: -0.1618 (0.2391) D(x): 0.5152 D(G(z)): 0.4632 / 0.4541 Acc: 35.9375 (28.5678)\n",
      "[7/25][45/782] Loss_D: 0.2933 (0.3926) Loss_G: -0.0837 (0.2390) D(x): 0.5023 D(G(z)): 0.5279 / 0.4475 Acc: 26.5625 (28.5674)\n",
      "[7/25][46/782] Loss_D: -0.0063 (0.3925) Loss_G: -0.1594 (0.2389) D(x): 0.5317 D(G(z)): 0.4780 / 0.4504 Acc: 35.9375 (28.5688)\n",
      "[7/25][47/782] Loss_D: 0.0547 (0.3924) Loss_G: -0.1201 (0.2389) D(x): 0.5802 D(G(z)): 0.4878 / 0.4478 Acc: 23.4375 (28.5678)\n",
      "[7/25][48/782] Loss_D: 0.0052 (0.3924) Loss_G: -0.1280 (0.2388) D(x): 0.5257 D(G(z)): 0.4546 / 0.4400 Acc: 40.6250 (28.5700)\n",
      "[7/25][49/782] Loss_D: 0.0974 (0.3923) Loss_G: -0.1587 (0.2387) D(x): 0.5021 D(G(z)): 0.4828 / 0.4618 Acc: 34.3750 (28.5711)\n",
      "[7/25][50/782] Loss_D: -0.0786 (0.3922) Loss_G: -0.2239 (0.2386) D(x): 0.5751 D(G(z)): 0.4926 / 0.4744 Acc: 37.5000 (28.5727)\n",
      "[7/25][51/782] Loss_D: 0.0933 (0.3922) Loss_G: -0.2364 (0.2386) D(x): 0.4911 D(G(z)): 0.4606 / 0.4994 Acc: 34.3750 (28.5737)\n",
      "[7/25][52/782] Loss_D: -0.0559 (0.3921) Loss_G: -0.1858 (0.2385) D(x): 0.5390 D(G(z)): 0.4670 / 0.4775 Acc: 39.0625 (28.5756)\n",
      "[7/25][53/782] Loss_D: -0.0003 (0.3920) Loss_G: -0.2544 (0.2384) D(x): 0.5906 D(G(z)): 0.4916 / 0.4999 Acc: 28.1250 (28.5755)\n",
      "[7/25][54/782] Loss_D: 0.1437 (0.3920) Loss_G: -0.1699 (0.2383) D(x): 0.5546 D(G(z)): 0.4943 / 0.4553 Acc: 21.8750 (28.5743)\n",
      "[7/25][55/782] Loss_D: 0.0799 (0.3919) Loss_G: -0.0674 (0.2383) D(x): 0.4777 D(G(z)): 0.4346 / 0.4234 Acc: 29.6875 (28.5745)\n",
      "[7/25][56/782] Loss_D: 0.1355 (0.3919) Loss_G: -0.2168 (0.2382) D(x): 0.4810 D(G(z)): 0.4915 / 0.4899 Acc: 35.9375 (28.5759)\n",
      "[7/25][57/782] Loss_D: 0.0257 (0.3918) Loss_G: -0.1652 (0.2381) D(x): 0.5204 D(G(z)): 0.4445 / 0.4669 Acc: 29.6875 (28.5761)\n",
      "[7/25][58/782] Loss_D: 0.0535 (0.3918) Loss_G: -0.2694 (0.2380) D(x): 0.5362 D(G(z)): 0.5228 / 0.5146 Acc: 40.6250 (28.5782)\n",
      "[7/25][59/782] Loss_D: -0.0052 (0.3917) Loss_G: -0.2314 (0.2379) D(x): 0.5573 D(G(z)): 0.5068 / 0.4900 Acc: 35.9375 (28.5796)\n",
      "[7/25][60/782] Loss_D: 0.0960 (0.3916) Loss_G: -0.2252 (0.2379) D(x): 0.5353 D(G(z)): 0.5128 / 0.4858 Acc: 32.8125 (28.5803)\n",
      "[7/25][61/782] Loss_D: 0.1506 (0.3916) Loss_G: -0.2055 (0.2378) D(x): 0.4999 D(G(z)): 0.4764 / 0.4762 Acc: 26.5625 (28.5800)\n",
      "[7/25][62/782] Loss_D: 0.0443 (0.3915) Loss_G: -0.2037 (0.2377) D(x): 0.5172 D(G(z)): 0.4799 / 0.4706 Acc: 31.2500 (28.5805)\n",
      "[7/25][63/782] Loss_D: 0.0072 (0.3915) Loss_G: -0.0999 (0.2376) D(x): 0.5243 D(G(z)): 0.4593 / 0.4277 Acc: 35.9375 (28.5818)\n",
      "[7/25][64/782] Loss_D: 0.0488 (0.3914) Loss_G: -0.1417 (0.2376) D(x): 0.5016 D(G(z)): 0.4407 / 0.4579 Acc: 31.2500 (28.5823)\n",
      "[7/25][65/782] Loss_D: -0.0079 (0.3913) Loss_G: -0.1246 (0.2375) D(x): 0.5297 D(G(z)): 0.4533 / 0.4570 Acc: 32.8125 (28.5830)\n",
      "[7/25][66/782] Loss_D: 0.0916 (0.3913) Loss_G: -0.1484 (0.2374) D(x): 0.5494 D(G(z)): 0.4803 / 0.4819 Acc: 32.8125 (28.5838)\n",
      "[7/25][67/782] Loss_D: -0.0152 (0.3912) Loss_G: -0.0853 (0.2374) D(x): 0.5738 D(G(z)): 0.4719 / 0.4577 Acc: 39.0625 (28.5857)\n",
      "[7/25][68/782] Loss_D: 0.2238 (0.3912) Loss_G: -0.1681 (0.2373) D(x): 0.5049 D(G(z)): 0.5253 / 0.4662 Acc: 34.3750 (28.5867)\n",
      "[7/25][69/782] Loss_D: -0.0523 (0.3911) Loss_G: -0.1437 (0.2372) D(x): 0.5376 D(G(z)): 0.4454 / 0.4543 Acc: 35.9375 (28.5881)\n",
      "[7/25][70/782] Loss_D: 0.0255 (0.3910) Loss_G: -0.0850 (0.2372) D(x): 0.5235 D(G(z)): 0.4728 / 0.4514 Acc: 42.1875 (28.5905)\n",
      "[7/25][71/782] Loss_D: 0.0348 (0.3909) Loss_G: -0.2021 (0.2371) D(x): 0.5151 D(G(z)): 0.5005 / 0.4781 Acc: 46.8750 (28.5938)\n",
      "[7/25][72/782] Loss_D: 0.0517 (0.3909) Loss_G: -0.1250 (0.2370) D(x): 0.5610 D(G(z)): 0.4806 / 0.4460 Acc: 25.0000 (28.5932)\n",
      "[7/25][73/782] Loss_D: -0.0022 (0.3908) Loss_G: -0.1927 (0.2369) D(x): 0.5090 D(G(z)): 0.4372 / 0.4721 Acc: 34.3750 (28.5942)\n",
      "[7/25][74/782] Loss_D: 0.0623 (0.3908) Loss_G: -0.1513 (0.2369) D(x): 0.5337 D(G(z)): 0.4814 / 0.4589 Acc: 31.2500 (28.5947)\n",
      "[7/25][75/782] Loss_D: -0.1139 (0.3907) Loss_G: -0.1591 (0.2368) D(x): 0.5942 D(G(z)): 0.4922 / 0.4494 Acc: 37.5000 (28.5963)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/25][76/782] Loss_D: -0.0854 (0.3906) Loss_G: -0.1174 (0.2367) D(x): 0.5277 D(G(z)): 0.4567 / 0.4360 Acc: 42.1875 (28.5987)\n",
      "[7/25][77/782] Loss_D: -0.1225 (0.3905) Loss_G: -0.0752 (0.2367) D(x): 0.5120 D(G(z)): 0.4448 / 0.4301 Acc: 45.3125 (28.6017)\n",
      "[7/25][78/782] Loss_D: 0.0270 (0.3904) Loss_G: -0.1355 (0.2366) D(x): 0.5171 D(G(z)): 0.4508 / 0.4626 Acc: 32.8125 (28.6025)\n",
      "[7/25][79/782] Loss_D: -0.0334 (0.3903) Loss_G: -0.0502 (0.2366) D(x): 0.5387 D(G(z)): 0.4780 / 0.4271 Acc: 37.5000 (28.6041)\n",
      "[7/25][80/782] Loss_D: -0.0303 (0.3903) Loss_G: -0.2219 (0.2365) D(x): 0.4867 D(G(z)): 0.4625 / 0.4867 Acc: 46.8750 (28.6074)\n",
      "[7/25][81/782] Loss_D: 0.0987 (0.3902) Loss_G: -0.2616 (0.2364) D(x): 0.5363 D(G(z)): 0.4926 / 0.4944 Acc: 28.1250 (28.6073)\n",
      "[7/25][82/782] Loss_D: 0.1138 (0.3902) Loss_G: -0.1638 (0.2363) D(x): 0.5470 D(G(z)): 0.4865 / 0.4568 Acc: 26.5625 (28.6069)\n",
      "[7/25][83/782] Loss_D: 0.0490 (0.3901) Loss_G: -0.1420 (0.2363) D(x): 0.5137 D(G(z)): 0.4617 / 0.4830 Acc: 39.0625 (28.6088)\n",
      "[7/25][84/782] Loss_D: 0.0618 (0.3900) Loss_G: -0.1363 (0.2362) D(x): 0.5202 D(G(z)): 0.4779 / 0.4493 Acc: 34.3750 (28.6099)\n",
      "[7/25][85/782] Loss_D: 0.0064 (0.3900) Loss_G: -0.0339 (0.2361) D(x): 0.5346 D(G(z)): 0.4498 / 0.4045 Acc: 29.6875 (28.6100)\n",
      "[7/25][86/782] Loss_D: 0.0080 (0.3899) Loss_G: -0.1276 (0.2361) D(x): 0.5208 D(G(z)): 0.4652 / 0.4533 Acc: 32.8125 (28.6108)\n",
      "[7/25][87/782] Loss_D: 0.0485 (0.3899) Loss_G: 0.0221 (0.2360) D(x): 0.5764 D(G(z)): 0.5021 / 0.3982 Acc: 31.2500 (28.6113)\n",
      "[7/25][88/782] Loss_D: -0.0162 (0.3898) Loss_G: -0.0287 (0.2360) D(x): 0.4816 D(G(z)): 0.4476 / 0.4224 Acc: 42.1875 (28.6137)\n",
      "[7/25][89/782] Loss_D: -0.1358 (0.3897) Loss_G: -0.1317 (0.2359) D(x): 0.5272 D(G(z)): 0.4105 / 0.4559 Acc: 37.5000 (28.6153)\n",
      "[7/25][90/782] Loss_D: -0.0759 (0.3896) Loss_G: -0.1118 (0.2359) D(x): 0.5407 D(G(z)): 0.4675 / 0.4450 Acc: 40.6250 (28.6175)\n",
      "[7/25][91/782] Loss_D: 0.1186 (0.3896) Loss_G: -0.0824 (0.2358) D(x): 0.5103 D(G(z)): 0.4867 / 0.4346 Acc: 34.3750 (28.6185)\n",
      "[7/25][92/782] Loss_D: -0.0431 (0.3895) Loss_G: -0.0836 (0.2357) D(x): 0.5877 D(G(z)): 0.4721 / 0.4244 Acc: 28.1250 (28.6184)\n",
      "[7/25][93/782] Loss_D: -0.0747 (0.3894) Loss_G: -0.0379 (0.2357) D(x): 0.5415 D(G(z)): 0.4540 / 0.4042 Acc: 40.6250 (28.6206)\n",
      "[7/25][94/782] Loss_D: 0.1097 (0.3893) Loss_G: -0.1487 (0.2356) D(x): 0.5061 D(G(z)): 0.4520 / 0.4667 Acc: 26.5625 (28.6202)\n",
      "[7/25][95/782] Loss_D: 0.0542 (0.3893) Loss_G: -0.1407 (0.2356) D(x): 0.4886 D(G(z)): 0.4363 / 0.4563 Acc: 34.3750 (28.6212)\n",
      "[7/25][96/782] Loss_D: -0.0335 (0.3892) Loss_G: -0.2498 (0.2355) D(x): 0.5325 D(G(z)): 0.4689 / 0.5028 Acc: 37.5000 (28.6228)\n",
      "[7/25][97/782] Loss_D: 0.2003 (0.3892) Loss_G: -0.1852 (0.2354) D(x): 0.5163 D(G(z)): 0.5446 / 0.4748 Acc: 32.8125 (28.6236)\n",
      "[7/25][98/782] Loss_D: 0.0190 (0.3891) Loss_G: -0.1132 (0.2353) D(x): 0.5553 D(G(z)): 0.4537 / 0.4483 Acc: 28.1250 (28.6235)\n",
      "[7/25][99/782] Loss_D: 0.0343 (0.3890) Loss_G: -0.1576 (0.2353) D(x): 0.4940 D(G(z)): 0.4880 / 0.4598 Acc: 46.8750 (28.6268)\n",
      "[7/25][100/782] Loss_D: 0.0923 (0.3890) Loss_G: -0.1679 (0.2352) D(x): 0.5231 D(G(z)): 0.4608 / 0.4712 Acc: 28.1250 (28.6267)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[7/25][101/782] Loss_D: 0.0808 (0.3889) Loss_G: -0.1359 (0.2351) D(x): 0.5663 D(G(z)): 0.5068 / 0.4442 Acc: 29.6875 (28.6269)\n",
      "[7/25][102/782] Loss_D: 0.0726 (0.3889) Loss_G: -0.1778 (0.2351) D(x): 0.5294 D(G(z)): 0.4835 / 0.4782 Acc: 35.9375 (28.6282)\n",
      "[7/25][103/782] Loss_D: -0.1011 (0.3888) Loss_G: -0.1338 (0.2350) D(x): 0.5187 D(G(z)): 0.4201 / 0.4549 Acc: 35.9375 (28.6295)\n",
      "[7/25][104/782] Loss_D: 0.0293 (0.3887) Loss_G: -0.1226 (0.2349) D(x): 0.5401 D(G(z)): 0.4820 / 0.4476 Acc: 34.3750 (28.6305)\n",
      "[7/25][105/782] Loss_D: 0.0693 (0.3887) Loss_G: -0.1271 (0.2349) D(x): 0.5033 D(G(z)): 0.4640 / 0.4528 Acc: 37.5000 (28.6321)\n",
      "[7/25][106/782] Loss_D: 0.0939 (0.3886) Loss_G: 0.0066 (0.2348) D(x): 0.5315 D(G(z)): 0.5181 / 0.3988 Acc: 35.9375 (28.6334)\n",
      "[7/25][107/782] Loss_D: 0.0134 (0.3885) Loss_G: -0.1043 (0.2348) D(x): 0.4883 D(G(z)): 0.4381 / 0.4409 Acc: 39.0625 (28.6353)\n",
      "[7/25][108/782] Loss_D: -0.0036 (0.3885) Loss_G: -0.1706 (0.2347) D(x): 0.5232 D(G(z)): 0.4686 / 0.4611 Acc: 39.0625 (28.6372)\n",
      "[7/25][109/782] Loss_D: 0.0661 (0.3884) Loss_G: -0.2339 (0.2346) D(x): 0.5101 D(G(z)): 0.5068 / 0.5007 Acc: 45.3125 (28.6401)\n",
      "[7/25][110/782] Loss_D: 0.0439 (0.3884) Loss_G: -0.0820 (0.2345) D(x): 0.5123 D(G(z)): 0.5007 / 0.4293 Acc: 42.1875 (28.6426)\n",
      "[7/25][111/782] Loss_D: 0.2659 (0.3883) Loss_G: -0.1838 (0.2345) D(x): 0.4942 D(G(z)): 0.4908 / 0.4782 Acc: 21.8750 (28.6414)\n",
      "[7/25][112/782] Loss_D: 0.1109 (0.3883) Loss_G: -0.2394 (0.2344) D(x): 0.5016 D(G(z)): 0.4836 / 0.4925 Acc: 35.9375 (28.6427)\n",
      "[7/25][113/782] Loss_D: 0.3065 (0.3883) Loss_G: -0.1420 (0.2343) D(x): 0.5015 D(G(z)): 0.5107 / 0.4779 Acc: 23.4375 (28.6417)\n",
      "[7/25][114/782] Loss_D: 0.2148 (0.3882) Loss_G: -0.2364 (0.2342) D(x): 0.4890 D(G(z)): 0.4908 / 0.4918 Acc: 31.2500 (28.6422)\n",
      "[7/25][115/782] Loss_D: -0.0326 (0.3882) Loss_G: -0.0703 (0.2342) D(x): 0.5291 D(G(z)): 0.4955 / 0.4219 Acc: 42.1875 (28.6446)\n",
      "[7/25][116/782] Loss_D: 0.1082 (0.3881) Loss_G: -0.2087 (0.2341) D(x): 0.5144 D(G(z)): 0.4925 / 0.5036 Acc: 39.0625 (28.6465)\n",
      "[7/25][117/782] Loss_D: 0.1091 (0.3881) Loss_G: -0.1534 (0.2340) D(x): 0.5091 D(G(z)): 0.5159 / 0.4690 Acc: 39.0625 (28.6483)\n",
      "[7/25][118/782] Loss_D: 0.2847 (0.3880) Loss_G: -0.2697 (0.2339) D(x): 0.4827 D(G(z)): 0.5220 / 0.5027 Acc: 29.6875 (28.6485)\n",
      "[7/25][119/782] Loss_D: -0.0238 (0.3880) Loss_G: -0.1428 (0.2339) D(x): 0.5499 D(G(z)): 0.4814 / 0.4492 Acc: 35.9375 (28.6498)\n",
      "[7/25][120/782] Loss_D: 0.0834 (0.3879) Loss_G: -0.2086 (0.2338) D(x): 0.4985 D(G(z)): 0.4602 / 0.4839 Acc: 29.6875 (28.6500)\n",
      "[7/25][121/782] Loss_D: 0.0101 (0.3878) Loss_G: 0.0011 (0.2337) D(x): 0.5582 D(G(z)): 0.5044 / 0.4089 Acc: 39.0625 (28.6519)\n",
      "[7/25][122/782] Loss_D: 0.0184 (0.3878) Loss_G: -0.0884 (0.2337) D(x): 0.5012 D(G(z)): 0.4473 / 0.4386 Acc: 35.9375 (28.6532)\n",
      "[7/25][123/782] Loss_D: 0.1562 (0.3877) Loss_G: -0.1259 (0.2336) D(x): 0.5061 D(G(z)): 0.4678 / 0.4567 Acc: 25.0000 (28.6525)\n",
      "[7/25][124/782] Loss_D: 0.0923 (0.3877) Loss_G: -0.1877 (0.2336) D(x): 0.4906 D(G(z)): 0.4688 / 0.4828 Acc: 34.3750 (28.6536)\n",
      "[7/25][125/782] Loss_D: -0.0262 (0.3876) Loss_G: -0.2335 (0.2335) D(x): 0.5393 D(G(z)): 0.5048 / 0.4955 Acc: 42.1875 (28.6560)\n",
      "[7/25][126/782] Loss_D: 0.0752 (0.3876) Loss_G: -0.1719 (0.2334) D(x): 0.5586 D(G(z)): 0.5025 / 0.4688 Acc: 32.8125 (28.6567)\n",
      "[7/25][127/782] Loss_D: -0.0771 (0.3875) Loss_G: -0.0627 (0.2333) D(x): 0.5241 D(G(z)): 0.4401 / 0.4262 Acc: 46.8750 (28.6600)\n",
      "[7/25][128/782] Loss_D: 0.0039 (0.3874) Loss_G: -0.1648 (0.2333) D(x): 0.5011 D(G(z)): 0.4281 / 0.4615 Acc: 32.8125 (28.6607)\n",
      "[7/25][129/782] Loss_D: 0.0191 (0.3873) Loss_G: -0.1356 (0.2332) D(x): 0.5399 D(G(z)): 0.4502 / 0.4372 Acc: 28.1250 (28.6606)\n",
      "[7/25][130/782] Loss_D: -0.0392 (0.3873) Loss_G: -0.1972 (0.2331) D(x): 0.5739 D(G(z)): 0.4631 / 0.4726 Acc: 31.2500 (28.6611)\n",
      "[7/25][131/782] Loss_D: -0.0042 (0.3872) Loss_G: -0.0297 (0.2331) D(x): 0.5623 D(G(z)): 0.5002 / 0.4197 Acc: 37.5000 (28.6626)\n",
      "[7/25][132/782] Loss_D: 0.0604 (0.3871) Loss_G: -0.1022 (0.2330) D(x): 0.4617 D(G(z)): 0.4336 / 0.4403 Acc: 34.3750 (28.6637)\n",
      "[7/25][133/782] Loss_D: -0.0041 (0.3871) Loss_G: -0.2655 (0.2329) D(x): 0.5296 D(G(z)): 0.4665 / 0.4990 Acc: 31.2500 (28.6641)\n",
      "[7/25][134/782] Loss_D: -0.0686 (0.3870) Loss_G: -0.0578 (0.2329) D(x): 0.5429 D(G(z)): 0.4778 / 0.4104 Acc: 40.6250 (28.6663)\n",
      "[7/25][135/782] Loss_D: 0.0163 (0.3869) Loss_G: -0.0300 (0.2328) D(x): 0.5763 D(G(z)): 0.4933 / 0.4159 Acc: 31.2500 (28.6667)\n",
      "[7/25][136/782] Loss_D: -0.0053 (0.3868) Loss_G: -0.0989 (0.2328) D(x): 0.5120 D(G(z)): 0.4587 / 0.4429 Acc: 39.0625 (28.6686)\n",
      "[7/25][137/782] Loss_D: 0.0895 (0.3868) Loss_G: -0.1733 (0.2327) D(x): 0.5258 D(G(z)): 0.4652 / 0.4814 Acc: 25.0000 (28.6679)\n",
      "[7/25][138/782] Loss_D: 0.1245 (0.3867) Loss_G: -0.1775 (0.2326) D(x): 0.5403 D(G(z)): 0.4957 / 0.4927 Acc: 32.8125 (28.6687)\n",
      "[7/25][139/782] Loss_D: 0.0528 (0.3867) Loss_G: -0.1913 (0.2326) D(x): 0.4961 D(G(z)): 0.4854 / 0.4849 Acc: 39.0625 (28.6705)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/25][140/782] Loss_D: 0.0077 (0.3866) Loss_G: -0.1884 (0.2325) D(x): 0.5305 D(G(z)): 0.4707 / 0.4716 Acc: 34.3750 (28.6715)\n",
      "[7/25][141/782] Loss_D: 0.1693 (0.3866) Loss_G: -0.0590 (0.2324) D(x): 0.5433 D(G(z)): 0.5210 / 0.4441 Acc: 29.6875 (28.6717)\n",
      "[7/25][142/782] Loss_D: -0.0403 (0.3865) Loss_G: -0.1058 (0.2324) D(x): 0.5194 D(G(z)): 0.4720 / 0.4395 Acc: 42.1875 (28.6741)\n",
      "[7/25][143/782] Loss_D: -0.0404 (0.3864) Loss_G: -0.1134 (0.2323) D(x): 0.5415 D(G(z)): 0.4739 / 0.4513 Acc: 39.0625 (28.6760)\n",
      "[7/25][144/782] Loss_D: 0.0830 (0.3864) Loss_G: -0.1894 (0.2322) D(x): 0.4652 D(G(z)): 0.4223 / 0.4835 Acc: 32.8125 (28.6767)\n",
      "[7/25][145/782] Loss_D: 0.0600 (0.3863) Loss_G: -0.1292 (0.2322) D(x): 0.5711 D(G(z)): 0.5204 / 0.4558 Acc: 34.3750 (28.6777)\n",
      "[7/25][146/782] Loss_D: 0.0952 (0.3863) Loss_G: -0.2101 (0.2321) D(x): 0.5245 D(G(z)): 0.4804 / 0.4872 Acc: 29.6875 (28.6779)\n",
      "[7/25][147/782] Loss_D: 0.1628 (0.3862) Loss_G: -0.1377 (0.2320) D(x): 0.5502 D(G(z)): 0.5244 / 0.4487 Acc: 28.1250 (28.6778)\n",
      "[7/25][148/782] Loss_D: 0.0706 (0.3862) Loss_G: -0.1340 (0.2320) D(x): 0.5181 D(G(z)): 0.4309 / 0.4620 Acc: 28.1250 (28.6777)\n",
      "[7/25][149/782] Loss_D: 0.1436 (0.3861) Loss_G: -0.1716 (0.2319) D(x): 0.5061 D(G(z)): 0.4695 / 0.4688 Acc: 23.4375 (28.6768)\n",
      "[7/25][150/782] Loss_D: 0.1109 (0.3861) Loss_G: -0.2185 (0.2318) D(x): 0.5249 D(G(z)): 0.4579 / 0.4870 Acc: 25.0000 (28.6761)\n",
      "[7/25][151/782] Loss_D: -0.0204 (0.3860) Loss_G: -0.0037 (0.2318) D(x): 0.5634 D(G(z)): 0.4737 / 0.4170 Acc: 35.9375 (28.6774)\n",
      "[7/25][152/782] Loss_D: 0.0255 (0.3859) Loss_G: -0.0977 (0.2317) D(x): 0.5128 D(G(z)): 0.4662 / 0.4409 Acc: 39.0625 (28.6792)\n",
      "[7/25][153/782] Loss_D: 0.0515 (0.3859) Loss_G: -0.1818 (0.2316) D(x): 0.5219 D(G(z)): 0.4806 / 0.4599 Acc: 39.0625 (28.6811)\n",
      "[7/25][154/782] Loss_D: 0.1642 (0.3858) Loss_G: -0.0764 (0.2316) D(x): 0.5075 D(G(z)): 0.4619 / 0.4302 Acc: 26.5625 (28.6807)\n",
      "[7/25][155/782] Loss_D: -0.0405 (0.3858) Loss_G: -0.1404 (0.2315) D(x): 0.5286 D(G(z)): 0.4470 / 0.4597 Acc: 32.8125 (28.6814)\n",
      "[7/25][156/782] Loss_D: 0.0474 (0.3857) Loss_G: -0.1247 (0.2314) D(x): 0.5546 D(G(z)): 0.5051 / 0.4608 Acc: 34.3750 (28.6825)\n",
      "[7/25][157/782] Loss_D: 0.1440 (0.3857) Loss_G: -0.1418 (0.2314) D(x): 0.4457 D(G(z)): 0.4604 / 0.4500 Acc: 39.0625 (28.6843)\n",
      "[7/25][158/782] Loss_D: 0.0136 (0.3856) Loss_G: -0.0784 (0.2313) D(x): 0.5225 D(G(z)): 0.4765 / 0.4242 Acc: 34.3750 (28.6853)\n",
      "[7/25][159/782] Loss_D: 0.0324 (0.3855) Loss_G: -0.0482 (0.2313) D(x): 0.4920 D(G(z)): 0.4345 / 0.4321 Acc: 37.5000 (28.6869)\n",
      "[7/25][160/782] Loss_D: 0.0688 (0.3855) Loss_G: -0.2012 (0.2312) D(x): 0.5261 D(G(z)): 0.4770 / 0.4640 Acc: 31.2500 (28.6873)\n",
      "[7/25][161/782] Loss_D: 0.1148 (0.3854) Loss_G: -0.1792 (0.2311) D(x): 0.5237 D(G(z)): 0.4897 / 0.4606 Acc: 34.3750 (28.6883)\n",
      "[7/25][162/782] Loss_D: -0.0229 (0.3854) Loss_G: -0.0947 (0.2311) D(x): 0.5224 D(G(z)): 0.4939 / 0.4274 Acc: 42.1875 (28.6907)\n",
      "[7/25][163/782] Loss_D: -0.0585 (0.3853) Loss_G: -0.0851 (0.2310) D(x): 0.5285 D(G(z)): 0.4399 / 0.4201 Acc: 34.3750 (28.6917)\n",
      "[7/25][164/782] Loss_D: 0.0842 (0.3852) Loss_G: -0.1364 (0.2309) D(x): 0.5092 D(G(z)): 0.4803 / 0.4404 Acc: 35.9375 (28.6930)\n",
      "[7/25][165/782] Loss_D: 0.0131 (0.3852) Loss_G: -0.2085 (0.2309) D(x): 0.5218 D(G(z)): 0.4677 / 0.4786 Acc: 40.6250 (28.6951)\n",
      "[7/25][166/782] Loss_D: -0.0252 (0.3851) Loss_G: -0.1541 (0.2308) D(x): 0.4993 D(G(z)): 0.4566 / 0.4553 Acc: 43.7500 (28.6978)\n",
      "[7/25][167/782] Loss_D: -0.1260 (0.3850) Loss_G: -0.2336 (0.2307) D(x): 0.4928 D(G(z)): 0.4038 / 0.4822 Acc: 40.6250 (28.6999)\n",
      "[7/25][168/782] Loss_D: 0.1117 (0.3850) Loss_G: -0.2412 (0.2306) D(x): 0.5074 D(G(z)): 0.5088 / 0.4970 Acc: 39.0625 (28.7018)\n",
      "[7/25][169/782] Loss_D: 0.0135 (0.3849) Loss_G: -0.1658 (0.2306) D(x): 0.5699 D(G(z)): 0.4990 / 0.4787 Acc: 34.3750 (28.7028)\n",
      "[7/25][170/782] Loss_D: 0.1293 (0.3848) Loss_G: -0.1762 (0.2305) D(x): 0.5252 D(G(z)): 0.4930 / 0.4708 Acc: 31.2500 (28.7032)\n",
      "[7/25][171/782] Loss_D: 0.1701 (0.3848) Loss_G: -0.0176 (0.2304) D(x): 0.5138 D(G(z)): 0.5104 / 0.3996 Acc: 29.6875 (28.7034)\n",
      "[7/25][172/782] Loss_D: 0.0052 (0.3847) Loss_G: -0.1845 (0.2304) D(x): 0.4802 D(G(z)): 0.4236 / 0.4663 Acc: 32.8125 (28.7041)\n",
      "[7/25][173/782] Loss_D: 0.0490 (0.3847) Loss_G: -0.1559 (0.2303) D(x): 0.5141 D(G(z)): 0.4966 / 0.4554 Acc: 37.5000 (28.7057)\n",
      "[7/25][174/782] Loss_D: 0.0412 (0.3846) Loss_G: -0.1491 (0.2302) D(x): 0.5194 D(G(z)): 0.4494 / 0.4704 Acc: 29.6875 (28.7059)\n",
      "[7/25][175/782] Loss_D: 0.0188 (0.3845) Loss_G: -0.1869 (0.2302) D(x): 0.5309 D(G(z)): 0.4864 / 0.4714 Acc: 34.3750 (28.7069)\n",
      "[7/25][176/782] Loss_D: -0.1135 (0.3845) Loss_G: 0.0139 (0.2301) D(x): 0.5438 D(G(z)): 0.4699 / 0.3929 Acc: 43.7500 (28.7095)\n",
      "[7/25][177/782] Loss_D: -0.0719 (0.3844) Loss_G: -0.1058 (0.2301) D(x): 0.5308 D(G(z)): 0.4261 / 0.4318 Acc: 34.3750 (28.7105)\n",
      "[7/25][178/782] Loss_D: -0.1010 (0.3843) Loss_G: -0.1180 (0.2300) D(x): 0.5000 D(G(z)): 0.4523 / 0.4365 Acc: 46.8750 (28.7137)\n",
      "[7/25][179/782] Loss_D: 0.2105 (0.3843) Loss_G: -0.1464 (0.2299) D(x): 0.5334 D(G(z)): 0.5502 / 0.4693 Acc: 31.2500 (28.7142)\n",
      "[7/25][180/782] Loss_D: 0.0800 (0.3842) Loss_G: -0.1094 (0.2299) D(x): 0.5079 D(G(z)): 0.4898 / 0.4334 Acc: 34.3750 (28.7152)\n",
      "[7/25][181/782] Loss_D: 0.1218 (0.3842) Loss_G: -0.1768 (0.2298) D(x): 0.5042 D(G(z)): 0.4761 / 0.4850 Acc: 34.3750 (28.7162)\n",
      "[7/25][182/782] Loss_D: 0.1212 (0.3841) Loss_G: -0.2412 (0.2297) D(x): 0.5073 D(G(z)): 0.4652 / 0.4971 Acc: 29.6875 (28.7164)\n",
      "[7/25][183/782] Loss_D: -0.0723 (0.3840) Loss_G: -0.1401 (0.2297) D(x): 0.5476 D(G(z)): 0.4815 / 0.4550 Acc: 40.6250 (28.7185)\n",
      "[7/25][184/782] Loss_D: 0.0170 (0.3840) Loss_G: -0.1645 (0.2296) D(x): 0.5016 D(G(z)): 0.4447 / 0.4573 Acc: 32.8125 (28.7192)\n",
      "[7/25][185/782] Loss_D: 0.1017 (0.3839) Loss_G: -0.2950 (0.2295) D(x): 0.5067 D(G(z)): 0.4966 / 0.5293 Acc: 34.3750 (28.7202)\n",
      "[7/25][186/782] Loss_D: 0.1015 (0.3839) Loss_G: -0.2176 (0.2294) D(x): 0.5571 D(G(z)): 0.5308 / 0.4885 Acc: 32.8125 (28.7209)\n",
      "[7/25][187/782] Loss_D: 0.0146 (0.3838) Loss_G: -0.1337 (0.2294) D(x): 0.5665 D(G(z)): 0.4744 / 0.4506 Acc: 31.2500 (28.7214)\n",
      "[7/25][188/782] Loss_D: -0.0557 (0.3837) Loss_G: -0.1457 (0.2293) D(x): 0.5467 D(G(z)): 0.4673 / 0.4441 Acc: 34.3750 (28.7224)\n",
      "[7/25][189/782] Loss_D: -0.1282 (0.3836) Loss_G: -0.1238 (0.2292) D(x): 0.5246 D(G(z)): 0.4600 / 0.4429 Acc: 48.4375 (28.7258)\n",
      "[7/25][190/782] Loss_D: -0.0110 (0.3836) Loss_G: -0.1176 (0.2292) D(x): 0.5258 D(G(z)): 0.4387 / 0.4493 Acc: 34.3750 (28.7268)\n",
      "[7/25][191/782] Loss_D: -0.0198 (0.3835) Loss_G: -0.0962 (0.2291) D(x): 0.5282 D(G(z)): 0.4953 / 0.4411 Acc: 45.3125 (28.7298)\n",
      "[7/25][192/782] Loss_D: -0.0385 (0.3834) Loss_G: -0.1398 (0.2290) D(x): 0.5471 D(G(z)): 0.4571 / 0.4655 Acc: 34.3750 (28.7308)\n",
      "[7/25][193/782] Loss_D: 0.0084 (0.3834) Loss_G: -0.1505 (0.2290) D(x): 0.5272 D(G(z)): 0.4691 / 0.4699 Acc: 37.5000 (28.7323)\n",
      "[7/25][194/782] Loss_D: -0.0134 (0.3833) Loss_G: -0.1546 (0.2289) D(x): 0.5395 D(G(z)): 0.4466 / 0.4641 Acc: 31.2500 (28.7327)\n",
      "[7/25][195/782] Loss_D: 0.0748 (0.3832) Loss_G: -0.1867 (0.2288) D(x): 0.5692 D(G(z)): 0.4828 / 0.4771 Acc: 25.0000 (28.7321)\n",
      "[7/25][196/782] Loss_D: 0.0893 (0.3832) Loss_G: -0.1788 (0.2288) D(x): 0.4931 D(G(z)): 0.4434 / 0.4794 Acc: 32.8125 (28.7328)\n",
      "[7/25][197/782] Loss_D: 0.0061 (0.3831) Loss_G: -0.1204 (0.2287) D(x): 0.5431 D(G(z)): 0.4575 / 0.4383 Acc: 28.1250 (28.7327)\n",
      "[7/25][198/782] Loss_D: 0.0177 (0.3831) Loss_G: -0.1343 (0.2286) D(x): 0.5682 D(G(z)): 0.4869 / 0.4584 Acc: 31.2500 (28.7331)\n",
      "[7/25][199/782] Loss_D: 0.0660 (0.3830) Loss_G: -0.1725 (0.2286) D(x): 0.5371 D(G(z)): 0.4699 / 0.4792 Acc: 29.6875 (28.7333)\n",
      "[7/25][200/782] Loss_D: -0.0192 (0.3829) Loss_G: -0.1010 (0.2285) D(x): 0.5147 D(G(z)): 0.4566 / 0.4445 Acc: 40.6250 (28.7354)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[7/25][201/782] Loss_D: 0.1693 (0.3829) Loss_G: -0.1013 (0.2285) D(x): 0.5109 D(G(z)): 0.4685 / 0.4538 Acc: 26.5625 (28.7350)\n",
      "[7/25][202/782] Loss_D: -0.0045 (0.3828) Loss_G: -0.1688 (0.2284) D(x): 0.5342 D(G(z)): 0.5082 / 0.4833 Acc: 45.3125 (28.7379)\n",
      "[7/25][203/782] Loss_D: -0.2170 (0.3827) Loss_G: -0.0615 (0.2283) D(x): 0.5565 D(G(z)): 0.4713 / 0.4309 Acc: 51.5625 (28.7420)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/25][204/782] Loss_D: -0.0597 (0.3826) Loss_G: -0.2090 (0.2283) D(x): 0.5152 D(G(z)): 0.4411 / 0.4828 Acc: 40.6250 (28.7441)\n",
      "[7/25][205/782] Loss_D: -0.0422 (0.3826) Loss_G: -0.1956 (0.2282) D(x): 0.5356 D(G(z)): 0.4538 / 0.4870 Acc: 39.0625 (28.7459)\n",
      "[7/25][206/782] Loss_D: 0.2257 (0.3825) Loss_G: -0.3124 (0.2281) D(x): 0.4804 D(G(z)): 0.5134 / 0.5196 Acc: 32.8125 (28.7466)\n",
      "[7/25][207/782] Loss_D: 0.0404 (0.3825) Loss_G: -0.1473 (0.2280) D(x): 0.5414 D(G(z)): 0.4863 / 0.4565 Acc: 34.3750 (28.7476)\n",
      "[7/25][208/782] Loss_D: -0.1165 (0.3824) Loss_G: -0.1487 (0.2280) D(x): 0.5171 D(G(z)): 0.4664 / 0.4633 Acc: 51.5625 (28.7516)\n",
      "[7/25][209/782] Loss_D: -0.0149 (0.3823) Loss_G: -0.1991 (0.2279) D(x): 0.5467 D(G(z)): 0.5146 / 0.4813 Acc: 45.3125 (28.7545)\n",
      "[7/25][210/782] Loss_D: -0.0609 (0.3822) Loss_G: -0.1275 (0.2278) D(x): 0.5262 D(G(z)): 0.4313 / 0.4419 Acc: 34.3750 (28.7555)\n",
      "[7/25][211/782] Loss_D: 0.1054 (0.3822) Loss_G: -0.1460 (0.2277) D(x): 0.5135 D(G(z)): 0.4896 / 0.4450 Acc: 32.8125 (28.7562)\n",
      "[7/25][212/782] Loss_D: 0.1229 (0.3821) Loss_G: -0.1766 (0.2277) D(x): 0.5131 D(G(z)): 0.4907 / 0.4681 Acc: 29.6875 (28.7564)\n",
      "[7/25][213/782] Loss_D: -0.0334 (0.3821) Loss_G: -0.1145 (0.2276) D(x): 0.5485 D(G(z)): 0.4902 / 0.4453 Acc: 39.0625 (28.7582)\n",
      "[7/25][214/782] Loss_D: -0.0681 (0.3820) Loss_G: -0.1853 (0.2275) D(x): 0.5386 D(G(z)): 0.4450 / 0.4702 Acc: 40.6250 (28.7603)\n",
      "[7/25][215/782] Loss_D: -0.0250 (0.3819) Loss_G: -0.1294 (0.2275) D(x): 0.5501 D(G(z)): 0.4943 / 0.4498 Acc: 34.3750 (28.7613)\n",
      "[7/25][216/782] Loss_D: 0.0033 (0.3819) Loss_G: -0.1438 (0.2274) D(x): 0.5056 D(G(z)): 0.4748 / 0.4524 Acc: 43.7500 (28.7639)\n",
      "[7/25][217/782] Loss_D: 0.0699 (0.3818) Loss_G: -0.0969 (0.2274) D(x): 0.4971 D(G(z)): 0.4512 / 0.4580 Acc: 31.2500 (28.7643)\n",
      "[7/25][218/782] Loss_D: 0.0566 (0.3817) Loss_G: -0.0599 (0.2273) D(x): 0.5187 D(G(z)): 0.4600 / 0.4362 Acc: 31.2500 (28.7648)\n",
      "[7/25][219/782] Loss_D: -0.0863 (0.3817) Loss_G: -0.1669 (0.2272) D(x): 0.5423 D(G(z)): 0.4406 / 0.4539 Acc: 35.9375 (28.7660)\n",
      "[7/25][220/782] Loss_D: -0.0770 (0.3816) Loss_G: -0.1628 (0.2272) D(x): 0.5818 D(G(z)): 0.4795 / 0.4768 Acc: 35.9375 (28.7673)\n",
      "[7/25][221/782] Loss_D: 0.0816 (0.3815) Loss_G: -0.0469 (0.2271) D(x): 0.5243 D(G(z)): 0.4799 / 0.4307 Acc: 37.5000 (28.7688)\n",
      "[7/25][222/782] Loss_D: -0.1189 (0.3814) Loss_G: -0.0571 (0.2271) D(x): 0.5369 D(G(z)): 0.4204 / 0.4151 Acc: 34.3750 (28.7698)\n",
      "[7/25][223/782] Loss_D: 0.1556 (0.3814) Loss_G: -0.0998 (0.2270) D(x): 0.5453 D(G(z)): 0.4944 / 0.4501 Acc: 23.4375 (28.7689)\n",
      "[7/25][224/782] Loss_D: 0.1194 (0.3814) Loss_G: -0.1659 (0.2269) D(x): 0.4924 D(G(z)): 0.4787 / 0.4681 Acc: 42.1875 (28.7712)\n",
      "[7/25][225/782] Loss_D: -0.0613 (0.3813) Loss_G: -0.1221 (0.2269) D(x): 0.5295 D(G(z)): 0.4398 / 0.4443 Acc: 34.3750 (28.7722)\n",
      "[7/25][226/782] Loss_D: 0.1100 (0.3812) Loss_G: -0.1395 (0.2268) D(x): 0.5281 D(G(z)): 0.4928 / 0.4561 Acc: 31.2500 (28.7726)\n",
      "[7/25][227/782] Loss_D: 0.0831 (0.3812) Loss_G: -0.1709 (0.2268) D(x): 0.5210 D(G(z)): 0.4856 / 0.4727 Acc: 34.3750 (28.7736)\n",
      "[7/25][228/782] Loss_D: 0.1084 (0.3811) Loss_G: 0.0116 (0.2267) D(x): 0.5317 D(G(z)): 0.4858 / 0.4078 Acc: 32.8125 (28.7743)\n",
      "[7/25][229/782] Loss_D: 0.0855 (0.3811) Loss_G: -0.1403 (0.2266) D(x): 0.4666 D(G(z)): 0.4559 / 0.4564 Acc: 39.0625 (28.7761)\n",
      "[7/25][230/782] Loss_D: 0.0844 (0.3810) Loss_G: -0.2295 (0.2266) D(x): 0.5281 D(G(z)): 0.4602 / 0.5021 Acc: 32.8125 (28.7768)\n",
      "[7/25][231/782] Loss_D: -0.0653 (0.3809) Loss_G: -0.1889 (0.2265) D(x): 0.5699 D(G(z)): 0.4837 / 0.4763 Acc: 37.5000 (28.7784)\n",
      "[7/25][232/782] Loss_D: 0.0368 (0.3809) Loss_G: -0.1740 (0.2264) D(x): 0.5445 D(G(z)): 0.4504 / 0.4750 Acc: 28.1250 (28.7783)\n",
      "[7/25][233/782] Loss_D: -0.0360 (0.3808) Loss_G: -0.2328 (0.2263) D(x): 0.5227 D(G(z)): 0.4761 / 0.4994 Acc: 43.7500 (28.7809)\n",
      "[7/25][234/782] Loss_D: -0.0336 (0.3807) Loss_G: -0.1525 (0.2263) D(x): 0.5667 D(G(z)): 0.4946 / 0.4652 Acc: 35.9375 (28.7821)\n",
      "[7/25][235/782] Loss_D: 0.0435 (0.3807) Loss_G: -0.1272 (0.2262) D(x): 0.5307 D(G(z)): 0.4488 / 0.4458 Acc: 35.9375 (28.7834)\n",
      "[7/25][236/782] Loss_D: 0.1215 (0.3806) Loss_G: -0.1297 (0.2262) D(x): 0.4740 D(G(z)): 0.4515 / 0.4388 Acc: 31.2500 (28.7838)\n",
      "[7/25][237/782] Loss_D: 0.0353 (0.3806) Loss_G: -0.1335 (0.2261) D(x): 0.5296 D(G(z)): 0.4615 / 0.4719 Acc: 32.8125 (28.7845)\n",
      "[7/25][238/782] Loss_D: -0.1168 (0.3805) Loss_G: -0.1332 (0.2260) D(x): 0.5717 D(G(z)): 0.4758 / 0.4553 Acc: 40.6250 (28.7866)\n",
      "[7/25][239/782] Loss_D: -0.0161 (0.3804) Loss_G: -0.2222 (0.2259) D(x): 0.5350 D(G(z)): 0.4924 / 0.4884 Acc: 43.7500 (28.7892)\n",
      "[7/25][240/782] Loss_D: 0.0836 (0.3804) Loss_G: -0.1333 (0.2259) D(x): 0.5127 D(G(z)): 0.4606 / 0.4507 Acc: 34.3750 (28.7902)\n",
      "[7/25][241/782] Loss_D: -0.0612 (0.3803) Loss_G: -0.1548 (0.2258) D(x): 0.4988 D(G(z)): 0.4210 / 0.4656 Acc: 40.6250 (28.7923)\n",
      "[7/25][242/782] Loss_D: -0.0141 (0.3802) Loss_G: -0.2720 (0.2257) D(x): 0.5488 D(G(z)): 0.4670 / 0.5082 Acc: 32.8125 (28.7930)\n",
      "[7/25][243/782] Loss_D: 0.0486 (0.3802) Loss_G: -0.0808 (0.2257) D(x): 0.5016 D(G(z)): 0.5105 / 0.4441 Acc: 45.3125 (28.7959)\n",
      "[7/25][244/782] Loss_D: 0.0140 (0.3801) Loss_G: -0.1576 (0.2256) D(x): 0.5374 D(G(z)): 0.4967 / 0.4730 Acc: 39.0625 (28.7976)\n",
      "[7/25][245/782] Loss_D: 0.0722 (0.3800) Loss_G: -0.1513 (0.2255) D(x): 0.5126 D(G(z)): 0.4830 / 0.4598 Acc: 34.3750 (28.7986)\n",
      "[7/25][246/782] Loss_D: 0.1920 (0.3800) Loss_G: -0.1320 (0.2255) D(x): 0.4976 D(G(z)): 0.5140 / 0.4516 Acc: 32.8125 (28.7993)\n",
      "[7/25][247/782] Loss_D: -0.0187 (0.3799) Loss_G: -0.0685 (0.2254) D(x): 0.5369 D(G(z)): 0.4602 / 0.4195 Acc: 32.8125 (28.8000)\n",
      "[7/25][248/782] Loss_D: 0.2588 (0.3799) Loss_G: -0.1145 (0.2254) D(x): 0.4933 D(G(z)): 0.4889 / 0.4527 Acc: 28.1250 (28.7999)\n",
      "[7/25][249/782] Loss_D: 0.0108 (0.3799) Loss_G: -0.1807 (0.2253) D(x): 0.5376 D(G(z)): 0.4755 / 0.4618 Acc: 35.9375 (28.8012)\n",
      "[7/25][250/782] Loss_D: 0.1176 (0.3798) Loss_G: -0.1225 (0.2252) D(x): 0.5316 D(G(z)): 0.4590 / 0.4652 Acc: 29.6875 (28.8013)\n",
      "[7/25][251/782] Loss_D: -0.0845 (0.3797) Loss_G: -0.1736 (0.2252) D(x): 0.5657 D(G(z)): 0.4644 / 0.4703 Acc: 35.9375 (28.8026)\n",
      "[7/25][252/782] Loss_D: -0.1050 (0.3796) Loss_G: -0.0625 (0.2251) D(x): 0.5850 D(G(z)): 0.4882 / 0.4183 Acc: 39.0625 (28.8043)\n",
      "[7/25][253/782] Loss_D: -0.0693 (0.3796) Loss_G: 0.0421 (0.2251) D(x): 0.5835 D(G(z)): 0.4690 / 0.3824 Acc: 32.8125 (28.8050)\n",
      "[7/25][254/782] Loss_D: 0.1943 (0.3795) Loss_G: -0.1250 (0.2250) D(x): 0.4317 D(G(z)): 0.4273 / 0.4611 Acc: 35.9375 (28.8063)\n",
      "[7/25][255/782] Loss_D: -0.0495 (0.3795) Loss_G: -0.2117 (0.2250) D(x): 0.5232 D(G(z)): 0.4121 / 0.4889 Acc: 35.9375 (28.8075)\n",
      "[7/25][256/782] Loss_D: 0.0950 (0.3794) Loss_G: -0.2176 (0.2249) D(x): 0.5709 D(G(z)): 0.5168 / 0.4842 Acc: 25.0000 (28.8069)\n",
      "[7/25][257/782] Loss_D: 0.0627 (0.3794) Loss_G: -0.1302 (0.2248) D(x): 0.5344 D(G(z)): 0.4734 / 0.4497 Acc: 29.6875 (28.8070)\n",
      "[7/25][258/782] Loss_D: -0.0474 (0.3793) Loss_G: -0.1712 (0.2247) D(x): 0.5377 D(G(z)): 0.4602 / 0.4691 Acc: 37.5000 (28.8085)\n",
      "[7/25][259/782] Loss_D: 0.1388 (0.3792) Loss_G: -0.1309 (0.2247) D(x): 0.5170 D(G(z)): 0.4692 / 0.4479 Acc: 23.4375 (28.8076)\n",
      "[7/25][260/782] Loss_D: -0.0298 (0.3792) Loss_G: -0.1475 (0.2246) D(x): 0.5694 D(G(z)): 0.4738 / 0.4457 Acc: 31.2500 (28.8080)\n",
      "[7/25][261/782] Loss_D: 0.0277 (0.3791) Loss_G: -0.2092 (0.2245) D(x): 0.5230 D(G(z)): 0.4841 / 0.4869 Acc: 39.0625 (28.8098)\n",
      "[7/25][262/782] Loss_D: -0.0028 (0.3790) Loss_G: -0.0910 (0.2245) D(x): 0.5442 D(G(z)): 0.4805 / 0.4258 Acc: 32.8125 (28.8105)\n",
      "[7/25][263/782] Loss_D: 0.1083 (0.3790) Loss_G: -0.0952 (0.2244) D(x): 0.5550 D(G(z)): 0.4846 / 0.4441 Acc: 26.5625 (28.8101)\n",
      "[7/25][264/782] Loss_D: 0.0485 (0.3789) Loss_G: -0.0603 (0.2244) D(x): 0.4684 D(G(z)): 0.4063 / 0.4210 Acc: 29.6875 (28.8103)\n",
      "[7/25][265/782] Loss_D: -0.0463 (0.3789) Loss_G: -0.1890 (0.2243) D(x): 0.5566 D(G(z)): 0.4619 / 0.4714 Acc: 34.3750 (28.8112)\n",
      "[7/25][266/782] Loss_D: -0.0069 (0.3788) Loss_G: -0.1842 (0.2242) D(x): 0.5252 D(G(z)): 0.4772 / 0.4724 Acc: 37.5000 (28.8128)\n",
      "[7/25][267/782] Loss_D: -0.0015 (0.3787) Loss_G: -0.1411 (0.2242) D(x): 0.5669 D(G(z)): 0.4850 / 0.4564 Acc: 35.9375 (28.8140)\n",
      "[7/25][268/782] Loss_D: -0.0988 (0.3786) Loss_G: -0.1421 (0.2241) D(x): 0.5541 D(G(z)): 0.4497 / 0.4632 Acc: 40.6250 (28.8161)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/25][269/782] Loss_D: 0.1033 (0.3786) Loss_G: -0.2209 (0.2240) D(x): 0.5103 D(G(z)): 0.4571 / 0.4986 Acc: 28.1250 (28.8159)\n",
      "[7/25][270/782] Loss_D: -0.0406 (0.3785) Loss_G: -0.1787 (0.2240) D(x): 0.5220 D(G(z)): 0.4723 / 0.4632 Acc: 42.1875 (28.8183)\n",
      "[7/25][271/782] Loss_D: 0.1321 (0.3785) Loss_G: -0.3207 (0.2239) D(x): 0.5226 D(G(z)): 0.5081 / 0.5314 Acc: 35.9375 (28.8195)\n",
      "[7/25][272/782] Loss_D: 0.0833 (0.3784) Loss_G: -0.2075 (0.2238) D(x): 0.5044 D(G(z)): 0.4983 / 0.4783 Acc: 42.1875 (28.8218)\n",
      "[7/25][273/782] Loss_D: 0.0976 (0.3784) Loss_G: -0.1210 (0.2237) D(x): 0.5268 D(G(z)): 0.4957 / 0.4436 Acc: 31.2500 (28.8223)\n",
      "[7/25][274/782] Loss_D: 0.1758 (0.3783) Loss_G: -0.0792 (0.2237) D(x): 0.5136 D(G(z)): 0.4808 / 0.4513 Acc: 28.1250 (28.8221)\n",
      "[7/25][275/782] Loss_D: -0.0036 (0.3783) Loss_G: -0.2169 (0.2236) D(x): 0.5118 D(G(z)): 0.4624 / 0.4928 Acc: 37.5000 (28.8236)\n",
      "[7/25][276/782] Loss_D: 0.1187 (0.3782) Loss_G: -0.1173 (0.2235) D(x): 0.5107 D(G(z)): 0.5064 / 0.4505 Acc: 35.9375 (28.8249)\n",
      "[7/25][277/782] Loss_D: -0.0156 (0.3782) Loss_G: 0.0404 (0.2235) D(x): 0.5353 D(G(z)): 0.4449 / 0.3856 Acc: 32.8125 (28.8256)\n",
      "[7/25][278/782] Loss_D: 0.0253 (0.3781) Loss_G: -0.2088 (0.2234) D(x): 0.5203 D(G(z)): 0.4453 / 0.4883 Acc: 31.2500 (28.8260)\n",
      "[7/25][279/782] Loss_D: -0.0057 (0.3780) Loss_G: -0.0675 (0.2234) D(x): 0.5503 D(G(z)): 0.4928 / 0.4267 Acc: 37.5000 (28.8275)\n",
      "[7/25][280/782] Loss_D: 0.1307 (0.3780) Loss_G: -0.0040 (0.2233) D(x): 0.4966 D(G(z)): 0.4838 / 0.3939 Acc: 32.8125 (28.8282)\n",
      "[7/25][281/782] Loss_D: -0.1281 (0.3779) Loss_G: -0.1529 (0.2233) D(x): 0.5310 D(G(z)): 0.4402 / 0.4520 Acc: 39.0625 (28.8300)\n",
      "[7/25][282/782] Loss_D: -0.0990 (0.3778) Loss_G: -0.1833 (0.2232) D(x): 0.5593 D(G(z)): 0.4754 / 0.4705 Acc: 40.6250 (28.8320)\n",
      "[7/25][283/782] Loss_D: -0.0015 (0.3778) Loss_G: -0.0470 (0.2232) D(x): 0.5314 D(G(z)): 0.4723 / 0.4271 Acc: 42.1875 (28.8343)\n",
      "[7/25][284/782] Loss_D: 0.2456 (0.3777) Loss_G: -0.1404 (0.2231) D(x): 0.4928 D(G(z)): 0.4802 / 0.4604 Acc: 29.6875 (28.8345)\n",
      "[7/25][285/782] Loss_D: -0.1091 (0.3776) Loss_G: -0.0133 (0.2231) D(x): 0.5293 D(G(z)): 0.4241 / 0.4171 Acc: 40.6250 (28.8365)\n",
      "[7/25][286/782] Loss_D: 0.0497 (0.3776) Loss_G: -0.2522 (0.2230) D(x): 0.5159 D(G(z)): 0.4545 / 0.5115 Acc: 31.2500 (28.8370)\n",
      "[7/25][287/782] Loss_D: -0.0412 (0.3775) Loss_G: -0.2126 (0.2229) D(x): 0.5176 D(G(z)): 0.4862 / 0.4882 Acc: 50.0000 (28.8406)\n",
      "[7/25][288/782] Loss_D: 0.0243 (0.3775) Loss_G: -0.2820 (0.2228) D(x): 0.5341 D(G(z)): 0.5006 / 0.5058 Acc: 39.0625 (28.8424)\n",
      "[7/25][289/782] Loss_D: 0.1900 (0.3774) Loss_G: -0.0756 (0.2228) D(x): 0.5639 D(G(z)): 0.5595 / 0.4176 Acc: 32.8125 (28.8431)\n",
      "[7/25][290/782] Loss_D: 0.2059 (0.3774) Loss_G: -0.1913 (0.2227) D(x): 0.5069 D(G(z)): 0.5045 / 0.4718 Acc: 28.1250 (28.8430)\n",
      "[7/25][291/782] Loss_D: 0.0138 (0.3773) Loss_G: -0.0182 (0.2226) D(x): 0.4689 D(G(z)): 0.4521 / 0.4090 Acc: 45.3125 (28.8458)\n",
      "[7/25][292/782] Loss_D: 0.1117 (0.3773) Loss_G: -0.1642 (0.2226) D(x): 0.4959 D(G(z)): 0.4707 / 0.4664 Acc: 31.2500 (28.8462)\n",
      "[7/25][293/782] Loss_D: 0.1258 (0.3772) Loss_G: -0.0645 (0.2225) D(x): 0.5150 D(G(z)): 0.4895 / 0.4238 Acc: 26.5625 (28.8458)\n",
      "[7/25][294/782] Loss_D: 0.1658 (0.3772) Loss_G: -0.2504 (0.2225) D(x): 0.4859 D(G(z)): 0.4681 / 0.5006 Acc: 28.1250 (28.8457)\n",
      "[7/25][295/782] Loss_D: -0.0448 (0.3771) Loss_G: -0.1549 (0.2224) D(x): 0.5401 D(G(z)): 0.4364 / 0.4451 Acc: 34.3750 (28.8467)\n",
      "[7/25][296/782] Loss_D: -0.0084 (0.3771) Loss_G: -0.1701 (0.2223) D(x): 0.5431 D(G(z)): 0.4863 / 0.4577 Acc: 35.9375 (28.8479)\n",
      "[7/25][297/782] Loss_D: 0.1335 (0.3770) Loss_G: -0.1448 (0.2223) D(x): 0.5471 D(G(z)): 0.5055 / 0.4530 Acc: 25.0000 (28.8472)\n",
      "[7/25][298/782] Loss_D: -0.0461 (0.3769) Loss_G: -0.0964 (0.2222) D(x): 0.5216 D(G(z)): 0.4481 / 0.4375 Acc: 40.6250 (28.8493)\n",
      "[7/25][299/782] Loss_D: 0.2148 (0.3769) Loss_G: -0.0929 (0.2221) D(x): 0.4781 D(G(z)): 0.4873 / 0.4332 Acc: 31.2500 (28.8497)\n",
      "[7/25][300/782] Loss_D: 0.0591 (0.3769) Loss_G: -0.0424 (0.2221) D(x): 0.5327 D(G(z)): 0.5044 / 0.4225 Acc: 40.6250 (28.8517)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[7/25][301/782] Loss_D: -0.0580 (0.3768) Loss_G: -0.0331 (0.2221) D(x): 0.5244 D(G(z)): 0.4757 / 0.4264 Acc: 46.8750 (28.8549)\n",
      "[7/25][302/782] Loss_D: 0.1579 (0.3768) Loss_G: -0.1482 (0.2220) D(x): 0.4923 D(G(z)): 0.4689 / 0.4571 Acc: 29.6875 (28.8550)\n",
      "[7/25][303/782] Loss_D: 0.0719 (0.3767) Loss_G: -0.1570 (0.2219) D(x): 0.5207 D(G(z)): 0.4982 / 0.4599 Acc: 43.7500 (28.8576)\n",
      "[7/25][304/782] Loss_D: -0.0654 (0.3766) Loss_G: -0.0375 (0.2219) D(x): 0.5692 D(G(z)): 0.4752 / 0.4166 Acc: 34.3750 (28.8585)\n",
      "[7/25][305/782] Loss_D: -0.0663 (0.3765) Loss_G: 0.0341 (0.2218) D(x): 0.5195 D(G(z)): 0.4614 / 0.3904 Acc: 43.7500 (28.8611)\n",
      "[7/25][306/782] Loss_D: 0.0422 (0.3765) Loss_G: 0.0143 (0.2218) D(x): 0.5057 D(G(z)): 0.4442 / 0.4089 Acc: 32.8125 (28.8618)\n",
      "[7/25][307/782] Loss_D: -0.1102 (0.3764) Loss_G: -0.1070 (0.2218) D(x): 0.5722 D(G(z)): 0.4733 / 0.4310 Acc: 37.5000 (28.8633)\n",
      "[7/25][308/782] Loss_D: -0.0706 (0.3763) Loss_G: 0.0070 (0.2217) D(x): 0.5141 D(G(z)): 0.4288 / 0.4044 Acc: 40.6250 (28.8653)\n",
      "[7/25][309/782] Loss_D: 0.0473 (0.3763) Loss_G: -0.0758 (0.2217) D(x): 0.5112 D(G(z)): 0.4670 / 0.4399 Acc: 35.9375 (28.8665)\n",
      "[7/25][310/782] Loss_D: 0.0075 (0.3762) Loss_G: -0.0255 (0.2216) D(x): 0.5403 D(G(z)): 0.4897 / 0.4121 Acc: 39.0625 (28.8683)\n",
      "[7/25][311/782] Loss_D: 0.0862 (0.3762) Loss_G: -0.0821 (0.2216) D(x): 0.4873 D(G(z)): 0.4503 / 0.4242 Acc: 31.2500 (28.8687)\n",
      "[7/25][312/782] Loss_D: 0.0980 (0.3761) Loss_G: -0.1127 (0.2215) D(x): 0.5497 D(G(z)): 0.4928 / 0.4456 Acc: 28.1250 (28.8686)\n",
      "[7/25][313/782] Loss_D: 0.0740 (0.3761) Loss_G: -0.1898 (0.2214) D(x): 0.5243 D(G(z)): 0.4731 / 0.4868 Acc: 35.9375 (28.8698)\n",
      "[7/25][314/782] Loss_D: -0.0415 (0.3760) Loss_G: -0.0142 (0.2214) D(x): 0.5072 D(G(z)): 0.4429 / 0.4088 Acc: 37.5000 (28.8713)\n",
      "[7/25][315/782] Loss_D: 0.1507 (0.3759) Loss_G: -0.1136 (0.2213) D(x): 0.5313 D(G(z)): 0.5018 / 0.4647 Acc: 28.1250 (28.8712)\n",
      "[7/25][316/782] Loss_D: 0.1011 (0.3759) Loss_G: -0.1834 (0.2213) D(x): 0.5290 D(G(z)): 0.4650 / 0.4790 Acc: 28.1250 (28.8710)\n",
      "[7/25][317/782] Loss_D: -0.0737 (0.3758) Loss_G: -0.0940 (0.2212) D(x): 0.5843 D(G(z)): 0.4653 / 0.4421 Acc: 35.9375 (28.8723)\n",
      "[7/25][318/782] Loss_D: 0.0093 (0.3758) Loss_G: -0.0762 (0.2212) D(x): 0.4986 D(G(z)): 0.4451 / 0.4237 Acc: 42.1875 (28.8746)\n",
      "[7/25][319/782] Loss_D: 0.0380 (0.3757) Loss_G: -0.2357 (0.2211) D(x): 0.4935 D(G(z)): 0.4540 / 0.4995 Acc: 35.9375 (28.8758)\n",
      "[7/25][320/782] Loss_D: 0.2827 (0.3757) Loss_G: -0.3279 (0.2210) D(x): 0.4679 D(G(z)): 0.5320 / 0.5399 Acc: 34.3750 (28.8767)\n",
      "[7/25][321/782] Loss_D: 0.2772 (0.3757) Loss_G: -0.1422 (0.2209) D(x): 0.5299 D(G(z)): 0.5582 / 0.4732 Acc: 28.1250 (28.8766)\n",
      "[7/25][322/782] Loss_D: 0.0287 (0.3756) Loss_G: -0.1267 (0.2209) D(x): 0.5226 D(G(z)): 0.4789 / 0.4494 Acc: 39.0625 (28.8784)\n",
      "[7/25][323/782] Loss_D: 0.0395 (0.3755) Loss_G: 0.0401 (0.2208) D(x): 0.5353 D(G(z)): 0.4516 / 0.4164 Acc: 31.2500 (28.8788)\n",
      "[7/25][324/782] Loss_D: 0.0700 (0.3755) Loss_G: -0.1677 (0.2208) D(x): 0.5224 D(G(z)): 0.4874 / 0.4778 Acc: 35.9375 (28.8800)\n",
      "[7/25][325/782] Loss_D: 0.0299 (0.3754) Loss_G: -0.1696 (0.2207) D(x): 0.4554 D(G(z)): 0.4061 / 0.4660 Acc: 37.5000 (28.8815)\n",
      "[7/25][326/782] Loss_D: -0.0756 (0.3754) Loss_G: -0.1877 (0.2206) D(x): 0.6038 D(G(z)): 0.4775 / 0.4677 Acc: 29.6875 (28.8816)\n",
      "[7/25][327/782] Loss_D: 0.1156 (0.3753) Loss_G: -0.0048 (0.2206) D(x): 0.5204 D(G(z)): 0.5012 / 0.4186 Acc: 35.9375 (28.8828)\n",
      "[7/25][328/782] Loss_D: -0.0227 (0.3752) Loss_G: -0.1076 (0.2205) D(x): 0.5076 D(G(z)): 0.4241 / 0.4311 Acc: 35.9375 (28.8840)\n",
      "[7/25][329/782] Loss_D: -0.0888 (0.3752) Loss_G: -0.1872 (0.2205) D(x): 0.5732 D(G(z)): 0.4840 / 0.4703 Acc: 39.0625 (28.8858)\n",
      "[7/25][330/782] Loss_D: -0.0507 (0.3751) Loss_G: -0.1196 (0.2204) D(x): 0.5320 D(G(z)): 0.4185 / 0.4378 Acc: 31.2500 (28.8862)\n",
      "[7/25][331/782] Loss_D: -0.0974 (0.3750) Loss_G: 0.0781 (0.2204) D(x): 0.5644 D(G(z)): 0.4550 / 0.3836 Acc: 39.0625 (28.8879)\n",
      "[7/25][332/782] Loss_D: -0.0865 (0.3749) Loss_G: -0.0813 (0.2203) D(x): 0.5927 D(G(z)): 0.4409 / 0.4485 Acc: 32.8125 (28.8886)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/25][333/782] Loss_D: -0.2381 (0.3748) Loss_G: -0.0510 (0.2203) D(x): 0.5848 D(G(z)): 0.4329 / 0.4167 Acc: 46.8750 (28.8917)\n",
      "[7/25][334/782] Loss_D: -0.1418 (0.3747) Loss_G: -0.1117 (0.2202) D(x): 0.5284 D(G(z)): 0.4242 / 0.4426 Acc: 40.6250 (28.8937)\n",
      "[7/25][335/782] Loss_D: -0.1170 (0.3747) Loss_G: -0.1679 (0.2202) D(x): 0.5844 D(G(z)): 0.4189 / 0.4690 Acc: 29.6875 (28.8939)\n",
      "[7/25][336/782] Loss_D: 0.0553 (0.3746) Loss_G: -0.0196 (0.2201) D(x): 0.5743 D(G(z)): 0.4858 / 0.4258 Acc: 32.8125 (28.8946)\n",
      "[7/25][337/782] Loss_D: 0.1118 (0.3746) Loss_G: -0.1169 (0.2201) D(x): 0.4978 D(G(z)): 0.4966 / 0.4604 Acc: 39.0625 (28.8963)\n",
      "[7/25][338/782] Loss_D: 0.1802 (0.3745) Loss_G: -0.2097 (0.2200) D(x): 0.5324 D(G(z)): 0.5474 / 0.4904 Acc: 37.5000 (28.8978)\n",
      "[7/25][339/782] Loss_D: 0.0623 (0.3745) Loss_G: -0.2048 (0.2199) D(x): 0.5134 D(G(z)): 0.4718 / 0.4829 Acc: 35.9375 (28.8990)\n",
      "[7/25][340/782] Loss_D: 0.1222 (0.3744) Loss_G: -0.1393 (0.2199) D(x): 0.4873 D(G(z)): 0.4803 / 0.4669 Acc: 37.5000 (28.9005)\n",
      "[7/25][341/782] Loss_D: 0.0072 (0.3744) Loss_G: -0.2003 (0.2198) D(x): 0.5523 D(G(z)): 0.4948 / 0.4771 Acc: 32.8125 (28.9011)\n",
      "[7/25][342/782] Loss_D: 0.2567 (0.3743) Loss_G: -0.1489 (0.2197) D(x): 0.4940 D(G(z)): 0.5208 / 0.4533 Acc: 29.6875 (28.9013)\n",
      "[7/25][343/782] Loss_D: 0.0001 (0.3743) Loss_G: -0.2530 (0.2196) D(x): 0.5444 D(G(z)): 0.4921 / 0.4992 Acc: 39.0625 (28.9030)\n",
      "[7/25][344/782] Loss_D: 0.4269 (0.3743) Loss_G: -0.1293 (0.2196) D(x): 0.4691 D(G(z)): 0.5325 / 0.4568 Acc: 32.8125 (28.9037)\n",
      "[7/25][345/782] Loss_D: -0.0793 (0.3742) Loss_G: -0.1550 (0.2195) D(x): 0.5180 D(G(z)): 0.4188 / 0.4506 Acc: 35.9375 (28.9049)\n",
      "[7/25][346/782] Loss_D: 0.0542 (0.3741) Loss_G: -0.0426 (0.2195) D(x): 0.4833 D(G(z)): 0.4428 / 0.4348 Acc: 42.1875 (28.9072)\n",
      "[7/25][347/782] Loss_D: 0.1540 (0.3741) Loss_G: -0.2348 (0.2194) D(x): 0.5460 D(G(z)): 0.5008 / 0.5069 Acc: 28.1250 (28.9071)\n",
      "[7/25][348/782] Loss_D: 0.0378 (0.3741) Loss_G: -0.0790 (0.2193) D(x): 0.5305 D(G(z)): 0.4829 / 0.4289 Acc: 39.0625 (28.9088)\n",
      "[7/25][349/782] Loss_D: -0.0853 (0.3740) Loss_G: -0.0784 (0.2193) D(x): 0.5367 D(G(z)): 0.4532 / 0.4303 Acc: 42.1875 (28.9111)\n",
      "[7/25][350/782] Loss_D: 0.0838 (0.3739) Loss_G: -0.1106 (0.2192) D(x): 0.4742 D(G(z)): 0.4835 / 0.4565 Acc: 45.3125 (28.9139)\n",
      "[7/25][351/782] Loss_D: -0.0795 (0.3738) Loss_G: -0.1248 (0.2192) D(x): 0.6187 D(G(z)): 0.4864 / 0.4527 Acc: 34.3750 (28.9148)\n",
      "[7/25][352/782] Loss_D: 0.2131 (0.3738) Loss_G: -0.0986 (0.2191) D(x): 0.5278 D(G(z)): 0.4919 / 0.4397 Acc: 23.4375 (28.9139)\n",
      "[7/25][353/782] Loss_D: 0.0072 (0.3738) Loss_G: -0.1225 (0.2191) D(x): 0.5442 D(G(z)): 0.4941 / 0.4451 Acc: 35.9375 (28.9151)\n",
      "[7/25][354/782] Loss_D: 0.0700 (0.3737) Loss_G: -0.1375 (0.2190) D(x): 0.5158 D(G(z)): 0.4478 / 0.4712 Acc: 29.6875 (28.9152)\n",
      "[7/25][355/782] Loss_D: 0.1053 (0.3737) Loss_G: 0.0212 (0.2190) D(x): 0.5364 D(G(z)): 0.4975 / 0.4029 Acc: 32.8125 (28.9159)\n",
      "[7/25][356/782] Loss_D: 0.1870 (0.3736) Loss_G: -0.1053 (0.2189) D(x): 0.4728 D(G(z)): 0.4599 / 0.4463 Acc: 34.3750 (28.9168)\n",
      "[7/25][357/782] Loss_D: 0.2299 (0.3736) Loss_G: -0.1434 (0.2188) D(x): 0.5094 D(G(z)): 0.4853 / 0.4795 Acc: 20.3125 (28.9154)\n",
      "[7/25][358/782] Loss_D: 0.2025 (0.3736) Loss_G: -0.1394 (0.2188) D(x): 0.4824 D(G(z)): 0.4890 / 0.4647 Acc: 29.6875 (28.9155)\n",
      "[7/25][359/782] Loss_D: 0.0392 (0.3735) Loss_G: -0.2869 (0.2187) D(x): 0.5350 D(G(z)): 0.4979 / 0.5277 Acc: 42.1875 (28.9178)\n",
      "[7/25][360/782] Loss_D: 0.1443 (0.3735) Loss_G: -0.0759 (0.2186) D(x): 0.5728 D(G(z)): 0.5640 / 0.4525 Acc: 39.0625 (28.9195)\n",
      "[7/25][361/782] Loss_D: 0.1283 (0.3734) Loss_G: 0.0576 (0.2186) D(x): 0.5102 D(G(z)): 0.4680 / 0.3969 Acc: 28.1250 (28.9194)\n",
      "[7/25][362/782] Loss_D: -0.1273 (0.3733) Loss_G: -0.0337 (0.2186) D(x): 0.5069 D(G(z)): 0.4487 / 0.4176 Acc: 51.5625 (28.9232)\n",
      "[7/25][363/782] Loss_D: 0.0225 (0.3733) Loss_G: -0.1013 (0.2185) D(x): 0.5087 D(G(z)): 0.4313 / 0.4329 Acc: 29.6875 (28.9234)\n",
      "[7/25][364/782] Loss_D: 0.0491 (0.3732) Loss_G: -0.1175 (0.2185) D(x): 0.5530 D(G(z)): 0.4646 / 0.4482 Acc: 32.8125 (28.9240)\n",
      "[7/25][365/782] Loss_D: 0.0563 (0.3732) Loss_G: -0.0768 (0.2184) D(x): 0.5333 D(G(z)): 0.4662 / 0.4371 Acc: 34.3750 (28.9250)\n",
      "[7/25][366/782] Loss_D: 0.1183 (0.3731) Loss_G: -0.0748 (0.2184) D(x): 0.5150 D(G(z)): 0.5001 / 0.4366 Acc: 37.5000 (28.9264)\n",
      "[7/25][367/782] Loss_D: 0.0646 (0.3731) Loss_G: -0.1631 (0.2183) D(x): 0.5545 D(G(z)): 0.5443 / 0.4732 Acc: 46.8750 (28.9295)\n",
      "[7/25][368/782] Loss_D: -0.1122 (0.3730) Loss_G: 0.0849 (0.2183) D(x): 0.5969 D(G(z)): 0.4937 / 0.3625 Acc: 42.1875 (28.9318)\n",
      "[7/25][369/782] Loss_D: -0.0818 (0.3729) Loss_G: 0.1390 (0.2183) D(x): 0.5351 D(G(z)): 0.4073 / 0.3547 Acc: 32.8125 (28.9325)\n",
      "[7/25][370/782] Loss_D: 0.0939 (0.3729) Loss_G: -0.0888 (0.2182) D(x): 0.4431 D(G(z)): 0.3857 / 0.4303 Acc: 31.2500 (28.9328)\n",
      "[7/25][371/782] Loss_D: 0.0592 (0.3728) Loss_G: -0.0506 (0.2182) D(x): 0.4997 D(G(z)): 0.4837 / 0.4175 Acc: 39.0625 (28.9346)\n",
      "[7/25][372/782] Loss_D: 0.1356 (0.3728) Loss_G: -0.2003 (0.2181) D(x): 0.5090 D(G(z)): 0.4845 / 0.4761 Acc: 29.6875 (28.9347)\n",
      "[7/25][373/782] Loss_D: 0.1354 (0.3727) Loss_G: -0.2496 (0.2180) D(x): 0.5259 D(G(z)): 0.5001 / 0.5103 Acc: 32.8125 (28.9354)\n",
      "[7/25][374/782] Loss_D: -0.0028 (0.3727) Loss_G: -0.1198 (0.2180) D(x): 0.5494 D(G(z)): 0.5026 / 0.4558 Acc: 43.7500 (28.9379)\n",
      "[7/25][375/782] Loss_D: 0.0853 (0.3726) Loss_G: -0.2256 (0.2179) D(x): 0.5232 D(G(z)): 0.4675 / 0.5068 Acc: 32.8125 (28.9386)\n",
      "[7/25][376/782] Loss_D: -0.1544 (0.3725) Loss_G: -0.0531 (0.2178) D(x): 0.5288 D(G(z)): 0.4067 / 0.4152 Acc: 40.6250 (28.9406)\n",
      "[7/25][377/782] Loss_D: -0.0307 (0.3725) Loss_G: -0.1857 (0.2178) D(x): 0.5447 D(G(z)): 0.5065 / 0.4825 Acc: 48.4375 (28.9439)\n",
      "[7/25][378/782] Loss_D: 0.0519 (0.3724) Loss_G: -0.2306 (0.2177) D(x): 0.5544 D(G(z)): 0.4942 / 0.4854 Acc: 34.3750 (28.9448)\n",
      "[7/25][379/782] Loss_D: 0.2537 (0.3724) Loss_G: -0.1199 (0.2176) D(x): 0.4794 D(G(z)): 0.5235 / 0.4419 Acc: 34.3750 (28.9458)\n",
      "[7/25][380/782] Loss_D: 0.1303 (0.3723) Loss_G: -0.1662 (0.2176) D(x): 0.4917 D(G(z)): 0.4857 / 0.4648 Acc: 35.9375 (28.9469)\n",
      "[7/25][381/782] Loss_D: 0.1157 (0.3723) Loss_G: -0.1160 (0.2175) D(x): 0.5364 D(G(z)): 0.4829 / 0.4418 Acc: 29.6875 (28.9471)\n",
      "[7/25][382/782] Loss_D: 0.1819 (0.3723) Loss_G: -0.2611 (0.2174) D(x): 0.5174 D(G(z)): 0.5233 / 0.5180 Acc: 35.9375 (28.9483)\n",
      "[7/25][383/782] Loss_D: 0.0831 (0.3722) Loss_G: -0.1581 (0.2174) D(x): 0.5253 D(G(z)): 0.4640 / 0.4585 Acc: 25.0000 (28.9476)\n",
      "[7/25][384/782] Loss_D: 0.0536 (0.3722) Loss_G: -0.1690 (0.2173) D(x): 0.5484 D(G(z)): 0.5117 / 0.4813 Acc: 34.3750 (28.9485)\n",
      "[7/25][385/782] Loss_D: 0.0776 (0.3721) Loss_G: -0.2888 (0.2172) D(x): 0.5125 D(G(z)): 0.4809 / 0.5066 Acc: 34.3750 (28.9494)\n",
      "[7/25][386/782] Loss_D: 0.3586 (0.3721) Loss_G: -0.1842 (0.2171) D(x): 0.4704 D(G(z)): 0.4846 / 0.5025 Acc: 17.1875 (28.9474)\n",
      "[7/25][387/782] Loss_D: 0.0270 (0.3721) Loss_G: -0.0906 (0.2171) D(x): 0.5619 D(G(z)): 0.5238 / 0.4292 Acc: 37.5000 (28.9489)\n",
      "[7/25][388/782] Loss_D: 0.1758 (0.3720) Loss_G: -0.1776 (0.2170) D(x): 0.4827 D(G(z)): 0.4865 / 0.4729 Acc: 31.2500 (28.9493)\n",
      "[7/25][389/782] Loss_D: 0.0481 (0.3720) Loss_G: -0.1240 (0.2170) D(x): 0.4925 D(G(z)): 0.4345 / 0.4647 Acc: 32.8125 (28.9499)\n",
      "[7/25][390/782] Loss_D: 0.1711 (0.3719) Loss_G: -0.1849 (0.2169) D(x): 0.4910 D(G(z)): 0.5151 / 0.4592 Acc: 34.3750 (28.9509)\n",
      "[7/25][391/782] Loss_D: -0.0537 (0.3719) Loss_G: -0.1720 (0.2168) D(x): 0.5664 D(G(z)): 0.4986 / 0.4631 Acc: 40.6250 (28.9529)\n",
      "[7/25][392/782] Loss_D: -0.0533 (0.3718) Loss_G: -0.1025 (0.2168) D(x): 0.5232 D(G(z)): 0.4729 / 0.4406 Acc: 43.7500 (28.9554)\n",
      "[7/25][393/782] Loss_D: -0.1597 (0.3717) Loss_G: -0.1157 (0.2167) D(x): 0.5675 D(G(z)): 0.4497 / 0.4412 Acc: 42.1875 (28.9576)\n",
      "[7/25][394/782] Loss_D: -0.0604 (0.3716) Loss_G: -0.0794 (0.2167) D(x): 0.5291 D(G(z)): 0.4454 / 0.4238 Acc: 35.9375 (28.9588)\n",
      "[7/25][395/782] Loss_D: 0.0682 (0.3716) Loss_G: -0.1279 (0.2166) D(x): 0.5232 D(G(z)): 0.4745 / 0.4403 Acc: 32.8125 (28.9595)\n",
      "[7/25][396/782] Loss_D: -0.0293 (0.3715) Loss_G: -0.0744 (0.2166) D(x): 0.5740 D(G(z)): 0.4750 / 0.4203 Acc: 29.6875 (28.9596)\n",
      "[7/25][397/782] Loss_D: 0.0805 (0.3715) Loss_G: -0.0967 (0.2165) D(x): 0.4966 D(G(z)): 0.4539 / 0.4384 Acc: 29.6875 (28.9597)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/25][398/782] Loss_D: 0.0962 (0.3714) Loss_G: -0.1506 (0.2164) D(x): 0.5050 D(G(z)): 0.4745 / 0.4588 Acc: 31.2500 (28.9601)\n",
      "[7/25][399/782] Loss_D: 0.0821 (0.3714) Loss_G: -0.1292 (0.2164) D(x): 0.5167 D(G(z)): 0.4764 / 0.4647 Acc: 35.9375 (28.9613)\n",
      "[7/25][400/782] Loss_D: -0.0561 (0.3713) Loss_G: -0.1548 (0.2163) D(x): 0.5170 D(G(z)): 0.4248 / 0.4760 Acc: 39.0625 (28.9630)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[7/25][401/782] Loss_D: 0.0034 (0.3712) Loss_G: -0.1742 (0.2163) D(x): 0.5700 D(G(z)): 0.4914 / 0.4824 Acc: 29.6875 (28.9632)\n",
      "[7/25][402/782] Loss_D: -0.0344 (0.3712) Loss_G: -0.1759 (0.2162) D(x): 0.5855 D(G(z)): 0.4862 / 0.4840 Acc: 29.6875 (28.9633)\n",
      "[7/25][403/782] Loss_D: 0.1246 (0.3711) Loss_G: -0.2695 (0.2161) D(x): 0.5243 D(G(z)): 0.5279 / 0.5093 Acc: 40.6250 (28.9653)\n",
      "[7/25][404/782] Loss_D: 0.1039 (0.3711) Loss_G: -0.1158 (0.2160) D(x): 0.5097 D(G(z)): 0.4792 / 0.4649 Acc: 32.8125 (28.9659)\n",
      "[7/25][405/782] Loss_D: 0.0217 (0.3710) Loss_G: -0.0075 (0.2160) D(x): 0.5127 D(G(z)): 0.4415 / 0.4140 Acc: 32.8125 (28.9666)\n",
      "[7/25][406/782] Loss_D: 0.0676 (0.3710) Loss_G: -0.1707 (0.2159) D(x): 0.5023 D(G(z)): 0.4660 / 0.4614 Acc: 37.5000 (28.9680)\n",
      "[7/25][407/782] Loss_D: -0.1004 (0.3709) Loss_G: -0.0636 (0.2159) D(x): 0.5619 D(G(z)): 0.4865 / 0.4109 Acc: 45.3125 (28.9708)\n",
      "[7/25][408/782] Loss_D: -0.0485 (0.3708) Loss_G: -0.0010 (0.2159) D(x): 0.5241 D(G(z)): 0.3981 / 0.4300 Acc: 28.1250 (28.9707)\n",
      "[7/25][409/782] Loss_D: -0.0619 (0.3707) Loss_G: -0.0626 (0.2158) D(x): 0.5397 D(G(z)): 0.4397 / 0.4348 Acc: 37.5000 (28.9721)\n",
      "[7/25][410/782] Loss_D: -0.1438 (0.3706) Loss_G: -0.0624 (0.2158) D(x): 0.5861 D(G(z)): 0.4377 / 0.4501 Acc: 40.6250 (28.9741)\n",
      "[7/25][411/782] Loss_D: 0.2234 (0.3706) Loss_G: -0.1058 (0.2157) D(x): 0.4984 D(G(z)): 0.4716 / 0.4572 Acc: 21.8750 (28.9729)\n",
      "[7/25][412/782] Loss_D: 0.0333 (0.3706) Loss_G: -0.0176 (0.2157) D(x): 0.5811 D(G(z)): 0.5051 / 0.4056 Acc: 31.2500 (28.9733)\n",
      "[7/25][413/782] Loss_D: -0.1050 (0.3705) Loss_G: 0.0448 (0.2156) D(x): 0.5551 D(G(z)): 0.4331 / 0.3849 Acc: 35.9375 (28.9745)\n",
      "[7/25][414/782] Loss_D: -0.0725 (0.3704) Loss_G: 0.0318 (0.2156) D(x): 0.5614 D(G(z)): 0.4279 / 0.3970 Acc: 26.5625 (28.9740)\n",
      "[7/25][415/782] Loss_D: -0.1018 (0.3703) Loss_G: -0.0801 (0.2156) D(x): 0.5234 D(G(z)): 0.3950 / 0.4181 Acc: 31.2500 (28.9744)\n",
      "[7/25][416/782] Loss_D: -0.0587 (0.3703) Loss_G: -0.1093 (0.2155) D(x): 0.5438 D(G(z)): 0.5133 / 0.4505 Acc: 46.8750 (28.9775)\n",
      "[7/25][417/782] Loss_D: -0.0521 (0.3702) Loss_G: -0.0815 (0.2155) D(x): 0.5484 D(G(z)): 0.4760 / 0.4269 Acc: 39.0625 (28.9792)\n",
      "[7/25][418/782] Loss_D: 0.0308 (0.3701) Loss_G: -0.1406 (0.2154) D(x): 0.5045 D(G(z)): 0.4814 / 0.4525 Acc: 42.1875 (28.9814)\n",
      "[7/25][419/782] Loss_D: 0.0603 (0.3701) Loss_G: 0.0350 (0.2154) D(x): 0.5339 D(G(z)): 0.4536 / 0.3931 Acc: 32.8125 (28.9821)\n",
      "[7/25][420/782] Loss_D: 0.2850 (0.3701) Loss_G: -0.0286 (0.2153) D(x): 0.5151 D(G(z)): 0.5328 / 0.4371 Acc: 28.1250 (28.9819)\n",
      "[7/25][421/782] Loss_D: 0.0965 (0.3700) Loss_G: -0.1885 (0.2153) D(x): 0.4751 D(G(z)): 0.4693 / 0.4787 Acc: 43.7500 (28.9844)\n",
      "[7/25][422/782] Loss_D: 0.0995 (0.3700) Loss_G: -0.1917 (0.2152) D(x): 0.5193 D(G(z)): 0.4961 / 0.4804 Acc: 35.9375 (28.9856)\n",
      "[7/25][423/782] Loss_D: 0.0234 (0.3699) Loss_G: -0.1734 (0.2151) D(x): 0.5597 D(G(z)): 0.5144 / 0.4602 Acc: 35.9375 (28.9868)\n",
      "[7/25][424/782] Loss_D: 0.0966 (0.3699) Loss_G: -0.1690 (0.2151) D(x): 0.5129 D(G(z)): 0.4985 / 0.4767 Acc: 37.5000 (28.9882)\n",
      "[7/25][425/782] Loss_D: 0.2171 (0.3698) Loss_G: -0.1177 (0.2150) D(x): 0.4629 D(G(z)): 0.4728 / 0.4463 Acc: 32.8125 (28.9889)\n",
      "[7/25][426/782] Loss_D: 0.1874 (0.3698) Loss_G: -0.1925 (0.2149) D(x): 0.4767 D(G(z)): 0.4978 / 0.4634 Acc: 32.8125 (28.9895)\n",
      "[7/25][427/782] Loss_D: -0.0322 (0.3697) Loss_G: -0.1988 (0.2149) D(x): 0.5309 D(G(z)): 0.4675 / 0.4719 Acc: 42.1875 (28.9918)\n",
      "[7/25][428/782] Loss_D: 0.0290 (0.3697) Loss_G: -0.1138 (0.2148) D(x): 0.5233 D(G(z)): 0.5077 / 0.4605 Acc: 43.7500 (28.9943)\n",
      "[7/25][429/782] Loss_D: -0.0884 (0.3696) Loss_G: -0.2630 (0.2147) D(x): 0.5226 D(G(z)): 0.4813 / 0.5174 Acc: 45.3125 (28.9970)\n",
      "[7/25][430/782] Loss_D: 0.1490 (0.3696) Loss_G: -0.0597 (0.2147) D(x): 0.5444 D(G(z)): 0.4839 / 0.4419 Acc: 26.5625 (28.9966)\n",
      "[7/25][431/782] Loss_D: 0.0204 (0.3695) Loss_G: -0.0294 (0.2146) D(x): 0.5118 D(G(z)): 0.4429 / 0.4169 Acc: 31.2500 (28.9970)\n",
      "[7/25][432/782] Loss_D: -0.0022 (0.3694) Loss_G: -0.1020 (0.2146) D(x): 0.5118 D(G(z)): 0.4520 / 0.4425 Acc: 39.0625 (28.9987)\n",
      "[7/25][433/782] Loss_D: -0.0247 (0.3694) Loss_G: -0.0136 (0.2145) D(x): 0.5320 D(G(z)): 0.4477 / 0.4111 Acc: 37.5000 (29.0001)\n",
      "[7/25][434/782] Loss_D: 0.0510 (0.3693) Loss_G: -0.0667 (0.2145) D(x): 0.4777 D(G(z)): 0.4159 / 0.4332 Acc: 32.8125 (29.0008)\n",
      "[7/25][435/782] Loss_D: 0.0758 (0.3693) Loss_G: -0.3009 (0.2144) D(x): 0.5357 D(G(z)): 0.4815 / 0.5184 Acc: 28.1250 (29.0006)\n",
      "[7/25][436/782] Loss_D: 0.0414 (0.3692) Loss_G: -0.1485 (0.2143) D(x): 0.5937 D(G(z)): 0.5044 / 0.4616 Acc: 29.6875 (29.0008)\n",
      "[7/25][437/782] Loss_D: -0.0006 (0.3692) Loss_G: -0.0743 (0.2143) D(x): 0.5267 D(G(z)): 0.4422 / 0.4281 Acc: 31.2500 (29.0011)\n",
      "[7/25][438/782] Loss_D: 0.0236 (0.3691) Loss_G: -0.1492 (0.2142) D(x): 0.5078 D(G(z)): 0.4453 / 0.4563 Acc: 35.9375 (29.0023)\n",
      "[7/25][439/782] Loss_D: 0.0633 (0.3690) Loss_G: -0.1469 (0.2142) D(x): 0.5136 D(G(z)): 0.4570 / 0.4553 Acc: 29.6875 (29.0024)\n",
      "[7/25][440/782] Loss_D: -0.1897 (0.3689) Loss_G: -0.2033 (0.2141) D(x): 0.5650 D(G(z)): 0.4544 / 0.4720 Acc: 42.1875 (29.0046)\n",
      "[7/25][441/782] Loss_D: -0.1514 (0.3689) Loss_G: -0.1245 (0.2140) D(x): 0.5571 D(G(z)): 0.4655 / 0.4411 Acc: 43.7500 (29.0071)\n",
      "[7/25][442/782] Loss_D: 0.0742 (0.3688) Loss_G: -0.0490 (0.2140) D(x): 0.4933 D(G(z)): 0.4827 / 0.4188 Acc: 37.5000 (29.0086)\n",
      "[7/25][443/782] Loss_D: 0.0300 (0.3688) Loss_G: -0.0608 (0.2140) D(x): 0.5324 D(G(z)): 0.5029 / 0.4324 Acc: 46.8750 (29.0116)\n",
      "[7/25][444/782] Loss_D: 0.1239 (0.3687) Loss_G: -0.0980 (0.2139) D(x): 0.4407 D(G(z)): 0.4265 / 0.4411 Acc: 37.5000 (29.0130)\n",
      "[7/25][445/782] Loss_D: 0.1045 (0.3687) Loss_G: -0.2263 (0.2138) D(x): 0.5293 D(G(z)): 0.5025 / 0.5021 Acc: 39.0625 (29.0147)\n",
      "[7/25][446/782] Loss_D: 0.1199 (0.3686) Loss_G: -0.1735 (0.2138) D(x): 0.5550 D(G(z)): 0.4840 / 0.4767 Acc: 29.6875 (29.0148)\n",
      "[7/25][447/782] Loss_D: 0.1005 (0.3686) Loss_G: -0.1141 (0.2137) D(x): 0.5145 D(G(z)): 0.4893 / 0.4536 Acc: 35.9375 (29.0160)\n",
      "[7/25][448/782] Loss_D: 0.0702 (0.3685) Loss_G: 0.0032 (0.2137) D(x): 0.5138 D(G(z)): 0.4916 / 0.3903 Acc: 37.5000 (29.0174)\n",
      "[7/25][449/782] Loss_D: -0.1679 (0.3684) Loss_G: -0.0308 (0.2136) D(x): 0.5260 D(G(z)): 0.3990 / 0.4210 Acc: 42.1875 (29.0197)\n",
      "[7/25][450/782] Loss_D: -0.2152 (0.3683) Loss_G: -0.0938 (0.2136) D(x): 0.5333 D(G(z)): 0.4011 / 0.4325 Acc: 43.7500 (29.0222)\n",
      "[7/25][451/782] Loss_D: -0.2128 (0.3682) Loss_G: -0.2127 (0.2135) D(x): 0.5766 D(G(z)): 0.4182 / 0.4900 Acc: 37.5000 (29.0236)\n",
      "[7/25][452/782] Loss_D: -0.0723 (0.3682) Loss_G: -0.0828 (0.2135) D(x): 0.5906 D(G(z)): 0.4617 / 0.4506 Acc: 32.8125 (29.0242)\n",
      "[7/25][453/782] Loss_D: -0.0376 (0.3681) Loss_G: -0.1557 (0.2134) D(x): 0.5457 D(G(z)): 0.4650 / 0.4599 Acc: 35.9375 (29.0254)\n",
      "[7/25][454/782] Loss_D: -0.0511 (0.3680) Loss_G: -0.1297 (0.2133) D(x): 0.5947 D(G(z)): 0.5162 / 0.4427 Acc: 37.5000 (29.0268)\n",
      "[7/25][455/782] Loss_D: 0.2912 (0.3680) Loss_G: -0.1075 (0.2133) D(x): 0.4574 D(G(z)): 0.4720 / 0.4430 Acc: 26.5625 (29.0264)\n",
      "[7/25][456/782] Loss_D: 0.0494 (0.3680) Loss_G: -0.0618 (0.2132) D(x): 0.5386 D(G(z)): 0.4161 / 0.4355 Acc: 21.8750 (29.0252)\n",
      "[7/25][457/782] Loss_D: 0.0923 (0.3679) Loss_G: -0.1201 (0.2132) D(x): 0.5008 D(G(z)): 0.4613 / 0.4528 Acc: 32.8125 (29.0258)\n",
      "[7/25][458/782] Loss_D: 0.0352 (0.3679) Loss_G: -0.1653 (0.2131) D(x): 0.5168 D(G(z)): 0.4885 / 0.4829 Acc: 37.5000 (29.0273)\n",
      "[7/25][459/782] Loss_D: 0.1479 (0.3678) Loss_G: -0.2392 (0.2130) D(x): 0.5574 D(G(z)): 0.5140 / 0.5066 Acc: 26.5625 (29.0268)\n",
      "[7/25][460/782] Loss_D: -0.0392 (0.3678) Loss_G: -0.1827 (0.2130) D(x): 0.5479 D(G(z)): 0.4959 / 0.4762 Acc: 40.6250 (29.0288)\n",
      "[7/25][461/782] Loss_D: 0.2082 (0.3677) Loss_G: -0.0823 (0.2129) D(x): 0.4989 D(G(z)): 0.5014 / 0.4437 Acc: 34.3750 (29.0297)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/25][462/782] Loss_D: 0.1167 (0.3677) Loss_G: -0.2014 (0.2129) D(x): 0.5150 D(G(z)): 0.4549 / 0.4786 Acc: 25.0000 (29.0290)\n",
      "[7/25][463/782] Loss_D: -0.0253 (0.3676) Loss_G: -0.2349 (0.2128) D(x): 0.5253 D(G(z)): 0.4783 / 0.4937 Acc: 42.1875 (29.0312)\n",
      "[7/25][464/782] Loss_D: 0.1164 (0.3676) Loss_G: -0.1247 (0.2127) D(x): 0.5494 D(G(z)): 0.5331 / 0.4537 Acc: 34.3750 (29.0321)\n",
      "[7/25][465/782] Loss_D: 0.2589 (0.3676) Loss_G: -0.1821 (0.2127) D(x): 0.4452 D(G(z)): 0.4737 / 0.4740 Acc: 28.1250 (29.0320)\n",
      "[7/25][466/782] Loss_D: 0.1287 (0.3675) Loss_G: -0.0937 (0.2126) D(x): 0.4821 D(G(z)): 0.5114 / 0.4544 Acc: 42.1875 (29.0342)\n",
      "[7/25][467/782] Loss_D: 0.1767 (0.3675) Loss_G: -0.1816 (0.2125) D(x): 0.4918 D(G(z)): 0.5073 / 0.4910 Acc: 39.0625 (29.0359)\n",
      "[7/25][468/782] Loss_D: 0.1247 (0.3674) Loss_G: -0.1273 (0.2125) D(x): 0.5431 D(G(z)): 0.5124 / 0.4586 Acc: 31.2500 (29.0363)\n",
      "[7/25][469/782] Loss_D: 0.1262 (0.3674) Loss_G: -0.0903 (0.2124) D(x): 0.5167 D(G(z)): 0.4652 / 0.4341 Acc: 32.8125 (29.0369)\n",
      "[7/25][470/782] Loss_D: 0.0523 (0.3674) Loss_G: -0.1835 (0.2124) D(x): 0.4936 D(G(z)): 0.4410 / 0.4793 Acc: 35.9375 (29.0381)\n",
      "[7/25][471/782] Loss_D: -0.0998 (0.3673) Loss_G: -0.0389 (0.2123) D(x): 0.4918 D(G(z)): 0.4317 / 0.4108 Acc: 48.4375 (29.0413)\n",
      "[7/25][472/782] Loss_D: 0.0791 (0.3672) Loss_G: -0.2428 (0.2122) D(x): 0.5150 D(G(z)): 0.4933 / 0.5008 Acc: 37.5000 (29.0427)\n",
      "[7/25][473/782] Loss_D: -0.0067 (0.3672) Loss_G: -0.1647 (0.2122) D(x): 0.5722 D(G(z)): 0.5170 / 0.4790 Acc: 42.1875 (29.0450)\n",
      "[7/25][474/782] Loss_D: -0.0718 (0.3671) Loss_G: -0.1679 (0.2121) D(x): 0.5363 D(G(z)): 0.4693 / 0.4532 Acc: 40.6250 (29.0469)\n",
      "[7/25][475/782] Loss_D: 0.0763 (0.3670) Loss_G: -0.0982 (0.2121) D(x): 0.5224 D(G(z)): 0.4821 / 0.4380 Acc: 32.8125 (29.0475)\n",
      "[7/25][476/782] Loss_D: -0.0410 (0.3670) Loss_G: -0.1096 (0.2120) D(x): 0.5821 D(G(z)): 0.4729 / 0.4362 Acc: 32.8125 (29.0482)\n",
      "[7/25][477/782] Loss_D: 0.1144 (0.3669) Loss_G: -0.1547 (0.2119) D(x): 0.4954 D(G(z)): 0.4480 / 0.4728 Acc: 28.1250 (29.0480)\n",
      "[7/25][478/782] Loss_D: -0.1867 (0.3668) Loss_G: -0.2095 (0.2119) D(x): 0.5459 D(G(z)): 0.4638 / 0.4793 Acc: 51.5625 (29.0518)\n",
      "[7/25][479/782] Loss_D: -0.0456 (0.3668) Loss_G: -0.1912 (0.2118) D(x): 0.5812 D(G(z)): 0.4847 / 0.4650 Acc: 31.2500 (29.0522)\n",
      "[7/25][480/782] Loss_D: -0.1297 (0.3667) Loss_G: -0.0459 (0.2118) D(x): 0.5668 D(G(z)): 0.4875 / 0.4293 Acc: 48.4375 (29.0554)\n",
      "[7/25][481/782] Loss_D: -0.0563 (0.3666) Loss_G: -0.1512 (0.2117) D(x): 0.5289 D(G(z)): 0.4572 / 0.4451 Acc: 37.5000 (29.0568)\n",
      "[7/25][482/782] Loss_D: 0.0938 (0.3666) Loss_G: -0.1524 (0.2116) D(x): 0.5067 D(G(z)): 0.4751 / 0.4538 Acc: 35.9375 (29.0580)\n",
      "[7/25][483/782] Loss_D: -0.0302 (0.3665) Loss_G: -0.2280 (0.2116) D(x): 0.5297 D(G(z)): 0.4732 / 0.4902 Acc: 39.0625 (29.0597)\n",
      "[7/25][484/782] Loss_D: 0.1084 (0.3665) Loss_G: -0.1672 (0.2115) D(x): 0.5292 D(G(z)): 0.4875 / 0.4602 Acc: 28.1250 (29.0595)\n",
      "[7/25][485/782] Loss_D: -0.1113 (0.3664) Loss_G: -0.1582 (0.2114) D(x): 0.5437 D(G(z)): 0.4549 / 0.4608 Acc: 43.7500 (29.0620)\n",
      "[7/25][486/782] Loss_D: -0.0919 (0.3663) Loss_G: -0.0481 (0.2114) D(x): 0.5405 D(G(z)): 0.4607 / 0.4160 Acc: 43.7500 (29.0644)\n",
      "[7/25][487/782] Loss_D: -0.1944 (0.3662) Loss_G: -0.1694 (0.2113) D(x): 0.5513 D(G(z)): 0.4514 / 0.4696 Acc: 50.0000 (29.0680)\n",
      "[7/25][488/782] Loss_D: 0.0127 (0.3661) Loss_G: -0.0192 (0.2113) D(x): 0.5321 D(G(z)): 0.4531 / 0.4257 Acc: 31.2500 (29.0683)\n",
      "[7/25][489/782] Loss_D: 0.0104 (0.3661) Loss_G: -0.1662 (0.2112) D(x): 0.5013 D(G(z)): 0.4143 / 0.4748 Acc: 32.8125 (29.0689)\n",
      "[7/25][490/782] Loss_D: -0.1557 (0.3660) Loss_G: -0.2160 (0.2112) D(x): 0.5676 D(G(z)): 0.4422 / 0.4866 Acc: 39.0625 (29.0706)\n",
      "[7/25][491/782] Loss_D: -0.0697 (0.3659) Loss_G: -0.1573 (0.2111) D(x): 0.5256 D(G(z)): 0.4526 / 0.4540 Acc: 40.6250 (29.0726)\n",
      "[7/25][492/782] Loss_D: -0.1938 (0.3658) Loss_G: -0.0767 (0.2111) D(x): 0.5713 D(G(z)): 0.4441 / 0.4238 Acc: 45.3125 (29.0753)\n",
      "[7/25][493/782] Loss_D: -0.0253 (0.3658) Loss_G: -0.0956 (0.2110) D(x): 0.5858 D(G(z)): 0.5034 / 0.4305 Acc: 35.9375 (29.0764)\n",
      "[7/25][494/782] Loss_D: -0.0755 (0.3657) Loss_G: -0.0782 (0.2110) D(x): 0.5442 D(G(z)): 0.3846 / 0.4324 Acc: 28.1250 (29.0763)\n",
      "[7/25][495/782] Loss_D: 0.0481 (0.3656) Loss_G: -0.1369 (0.2109) D(x): 0.5118 D(G(z)): 0.4510 / 0.4442 Acc: 34.3750 (29.0772)\n",
      "[7/25][496/782] Loss_D: -0.1001 (0.3656) Loss_G: -0.2137 (0.2108) D(x): 0.5527 D(G(z)): 0.4341 / 0.4807 Acc: 32.8125 (29.0778)\n",
      "[7/25][497/782] Loss_D: -0.0846 (0.3655) Loss_G: -0.2515 (0.2107) D(x): 0.5589 D(G(z)): 0.5009 / 0.4961 Acc: 45.3125 (29.0805)\n",
      "[7/25][498/782] Loss_D: -0.0672 (0.3654) Loss_G: -0.1047 (0.2107) D(x): 0.5448 D(G(z)): 0.4643 / 0.4303 Acc: 42.1875 (29.0827)\n",
      "[7/25][499/782] Loss_D: -0.0927 (0.3653) Loss_G: -0.0687 (0.2106) D(x): 0.5743 D(G(z)): 0.4716 / 0.4206 Acc: 35.9375 (29.0838)\n",
      "[7/25][500/782] Loss_D: 0.0280 (0.3653) Loss_G: -0.0933 (0.2106) D(x): 0.5205 D(G(z)): 0.4639 / 0.4596 Acc: 39.0625 (29.0855)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[7/25][501/782] Loss_D: 0.0617 (0.3652) Loss_G: -0.1224 (0.2105) D(x): 0.5355 D(G(z)): 0.4869 / 0.4671 Acc: 37.5000 (29.0869)\n",
      "[7/25][502/782] Loss_D: 0.2440 (0.3652) Loss_G: -0.1105 (0.2105) D(x): 0.4907 D(G(z)): 0.5246 / 0.4555 Acc: 43.7500 (29.0894)\n",
      "[7/25][503/782] Loss_D: 0.0931 (0.3652) Loss_G: -0.0938 (0.2104) D(x): 0.4961 D(G(z)): 0.4995 / 0.4353 Acc: 42.1875 (29.0916)\n",
      "[7/25][504/782] Loss_D: 0.0250 (0.3651) Loss_G: -0.1043 (0.2104) D(x): 0.4828 D(G(z)): 0.4320 / 0.4348 Acc: 35.9375 (29.0927)\n",
      "[7/25][505/782] Loss_D: 0.1159 (0.3651) Loss_G: -0.1455 (0.2103) D(x): 0.4934 D(G(z)): 0.4540 / 0.4683 Acc: 32.8125 (29.0933)\n",
      "[7/25][506/782] Loss_D: 0.0562 (0.3650) Loss_G: -0.3062 (0.2102) D(x): 0.5193 D(G(z)): 0.4876 / 0.5251 Acc: 37.5000 (29.0947)\n",
      "[7/25][507/782] Loss_D: 0.1542 (0.3650) Loss_G: -0.1745 (0.2102) D(x): 0.5370 D(G(z)): 0.5616 / 0.4794 Acc: 40.6250 (29.0967)\n",
      "[7/25][508/782] Loss_D: 0.0396 (0.3649) Loss_G: -0.1768 (0.2101) D(x): 0.4928 D(G(z)): 0.4781 / 0.4547 Acc: 40.6250 (29.0986)\n",
      "[7/25][509/782] Loss_D: 0.1792 (0.3649) Loss_G: -0.1520 (0.2100) D(x): 0.4960 D(G(z)): 0.5061 / 0.4721 Acc: 35.9375 (29.0997)\n",
      "[7/25][510/782] Loss_D: 0.0111 (0.3648) Loss_G: -0.1250 (0.2100) D(x): 0.5454 D(G(z)): 0.4719 / 0.4613 Acc: 34.3750 (29.1006)\n",
      "[7/25][511/782] Loss_D: 0.0839 (0.3648) Loss_G: -0.0903 (0.2099) D(x): 0.5008 D(G(z)): 0.4892 / 0.4572 Acc: 43.7500 (29.1031)\n",
      "[7/25][512/782] Loss_D: -0.1188 (0.3647) Loss_G: -0.0606 (0.2099) D(x): 0.5238 D(G(z)): 0.4557 / 0.4171 Acc: 43.7500 (29.1055)\n",
      "[7/25][513/782] Loss_D: 0.0671 (0.3647) Loss_G: -0.1185 (0.2098) D(x): 0.4799 D(G(z)): 0.4395 / 0.4516 Acc: 35.9375 (29.1067)\n",
      "[7/25][514/782] Loss_D: 0.1799 (0.3646) Loss_G: -0.1853 (0.2098) D(x): 0.4836 D(G(z)): 0.4785 / 0.4672 Acc: 29.6875 (29.1067)\n",
      "[7/25][515/782] Loss_D: 0.0079 (0.3646) Loss_G: -0.2207 (0.2097) D(x): 0.5051 D(G(z)): 0.4614 / 0.4906 Acc: 43.7500 (29.1092)\n",
      "[7/25][516/782] Loss_D: -0.0059 (0.3645) Loss_G: -0.1945 (0.2096) D(x): 0.5588 D(G(z)): 0.4981 / 0.4845 Acc: 35.9375 (29.1103)\n",
      "[7/25][517/782] Loss_D: 0.1924 (0.3645) Loss_G: -0.2216 (0.2096) D(x): 0.5202 D(G(z)): 0.4875 / 0.4837 Acc: 29.6875 (29.1104)\n",
      "[7/25][518/782] Loss_D: 0.2099 (0.3644) Loss_G: -0.1851 (0.2095) D(x): 0.5154 D(G(z)): 0.5140 / 0.4655 Acc: 28.1250 (29.1103)\n",
      "[7/25][519/782] Loss_D: 0.0133 (0.3644) Loss_G: -0.1669 (0.2094) D(x): 0.5034 D(G(z)): 0.4398 / 0.4633 Acc: 35.9375 (29.1114)\n",
      "[7/25][520/782] Loss_D: 0.0882 (0.3643) Loss_G: -0.1929 (0.2094) D(x): 0.5431 D(G(z)): 0.4812 / 0.4826 Acc: 31.2500 (29.1118)\n",
      "[7/25][521/782] Loss_D: 0.0048 (0.3643) Loss_G: -0.0646 (0.2093) D(x): 0.5438 D(G(z)): 0.4659 / 0.4376 Acc: 31.2500 (29.1121)\n",
      "[7/25][522/782] Loss_D: -0.0467 (0.3642) Loss_G: -0.1107 (0.2093) D(x): 0.5197 D(G(z)): 0.4588 / 0.4654 Acc: 46.8750 (29.1151)\n",
      "[7/25][523/782] Loss_D: 0.0142 (0.3642) Loss_G: -0.1219 (0.2092) D(x): 0.5169 D(G(z)): 0.4649 / 0.4440 Acc: 34.3750 (29.1160)\n",
      "[7/25][524/782] Loss_D: 0.0253 (0.3641) Loss_G: -0.3007 (0.2091) D(x): 0.5465 D(G(z)): 0.5113 / 0.5207 Acc: 43.7500 (29.1184)\n",
      "[7/25][525/782] Loss_D: 0.0287 (0.3640) Loss_G: -0.1795 (0.2091) D(x): 0.5299 D(G(z)): 0.4790 / 0.4764 Acc: 39.0625 (29.1201)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/25][526/782] Loss_D: 0.0348 (0.3640) Loss_G: -0.0806 (0.2090) D(x): 0.4949 D(G(z)): 0.4994 / 0.4321 Acc: 45.3125 (29.1228)\n",
      "[7/25][527/782] Loss_D: 0.1184 (0.3639) Loss_G: -0.2561 (0.2089) D(x): 0.4578 D(G(z)): 0.5097 / 0.5084 Acc: 48.4375 (29.1260)\n",
      "[7/25][528/782] Loss_D: 0.1200 (0.3639) Loss_G: -0.0867 (0.2089) D(x): 0.5225 D(G(z)): 0.4860 / 0.4467 Acc: 29.6875 (29.1261)\n",
      "[7/25][529/782] Loss_D: 0.0830 (0.3639) Loss_G: -0.2534 (0.2088) D(x): 0.5275 D(G(z)): 0.4975 / 0.5071 Acc: 37.5000 (29.1275)\n",
      "[7/25][530/782] Loss_D: -0.1395 (0.3638) Loss_G: -0.2222 (0.2087) D(x): 0.5642 D(G(z)): 0.4701 / 0.4963 Acc: 40.6250 (29.1294)\n",
      "[7/25][531/782] Loss_D: 0.1027 (0.3637) Loss_G: -0.1508 (0.2087) D(x): 0.5221 D(G(z)): 0.4692 / 0.4502 Acc: 26.5625 (29.1289)\n",
      "[7/25][532/782] Loss_D: 0.1423 (0.3637) Loss_G: -0.2985 (0.2086) D(x): 0.4995 D(G(z)): 0.4876 / 0.5286 Acc: 31.2500 (29.1293)\n",
      "[7/25][533/782] Loss_D: 0.1699 (0.3637) Loss_G: -0.2664 (0.2085) D(x): 0.5152 D(G(z)): 0.5368 / 0.5046 Acc: 35.9375 (29.1304)\n",
      "[7/25][534/782] Loss_D: -0.0224 (0.3636) Loss_G: -0.2058 (0.2085) D(x): 0.5767 D(G(z)): 0.5200 / 0.4822 Acc: 43.7500 (29.1329)\n",
      "[7/25][535/782] Loss_D: -0.1636 (0.3635) Loss_G: -0.0309 (0.2084) D(x): 0.5765 D(G(z)): 0.4658 / 0.4129 Acc: 46.8750 (29.1358)\n",
      "[7/25][536/782] Loss_D: 0.0470 (0.3635) Loss_G: -0.1301 (0.2084) D(x): 0.5209 D(G(z)): 0.4235 / 0.4507 Acc: 21.8750 (29.1346)\n",
      "[7/25][537/782] Loss_D: 0.1944 (0.3634) Loss_G: -0.2081 (0.2083) D(x): 0.4783 D(G(z)): 0.5068 / 0.4838 Acc: 35.9375 (29.1357)\n",
      "[7/25][538/782] Loss_D: 0.2362 (0.3634) Loss_G: -0.2039 (0.2082) D(x): 0.4945 D(G(z)): 0.5045 / 0.4699 Acc: 28.1250 (29.1356)\n",
      "[7/25][539/782] Loss_D: 0.0828 (0.3634) Loss_G: -0.1175 (0.2082) D(x): 0.5393 D(G(z)): 0.5028 / 0.4606 Acc: 37.5000 (29.1370)\n",
      "[7/25][540/782] Loss_D: 0.1412 (0.3633) Loss_G: -0.0609 (0.2081) D(x): 0.4972 D(G(z)): 0.4916 / 0.4442 Acc: 32.8125 (29.1376)\n",
      "[7/25][541/782] Loss_D: -0.0053 (0.3633) Loss_G: -0.0559 (0.2081) D(x): 0.5253 D(G(z)): 0.4696 / 0.4313 Acc: 37.5000 (29.1390)\n",
      "[7/25][542/782] Loss_D: 0.0452 (0.3632) Loss_G: -0.0518 (0.2080) D(x): 0.4807 D(G(z)): 0.4312 / 0.4226 Acc: 37.5000 (29.1404)\n",
      "[7/25][543/782] Loss_D: 0.1476 (0.3632) Loss_G: -0.0997 (0.2080) D(x): 0.4851 D(G(z)): 0.4949 / 0.4595 Acc: 39.0625 (29.1420)\n",
      "[7/25][544/782] Loss_D: 0.0343 (0.3631) Loss_G: -0.1843 (0.2079) D(x): 0.4905 D(G(z)): 0.4874 / 0.4759 Acc: 50.0000 (29.1455)\n",
      "[7/25][545/782] Loss_D: 0.0429 (0.3631) Loss_G: -0.2212 (0.2078) D(x): 0.5630 D(G(z)): 0.5099 / 0.4841 Acc: 34.3750 (29.1463)\n",
      "[7/25][546/782] Loss_D: 0.0070 (0.3630) Loss_G: 0.0193 (0.2078) D(x): 0.5672 D(G(z)): 0.4880 / 0.3925 Acc: 32.8125 (29.1469)\n",
      "[7/25][547/782] Loss_D: -0.0805 (0.3629) Loss_G: 0.0113 (0.2078) D(x): 0.4951 D(G(z)): 0.4029 / 0.3963 Acc: 40.6250 (29.1489)\n",
      "[7/25][548/782] Loss_D: -0.0427 (0.3629) Loss_G: -0.1091 (0.2077) D(x): 0.4866 D(G(z)): 0.4443 / 0.4540 Acc: 46.8750 (29.1518)\n",
      "[7/25][549/782] Loss_D: 0.1194 (0.3628) Loss_G: -0.2199 (0.2077) D(x): 0.5078 D(G(z)): 0.4644 / 0.4906 Acc: 31.2500 (29.1521)\n",
      "[7/25][550/782] Loss_D: 0.0967 (0.3628) Loss_G: -0.0743 (0.2076) D(x): 0.5169 D(G(z)): 0.5348 / 0.4343 Acc: 46.8750 (29.1551)\n",
      "[7/25][551/782] Loss_D: -0.0143 (0.3627) Loss_G: -0.0528 (0.2076) D(x): 0.5570 D(G(z)): 0.4900 / 0.4351 Acc: 37.5000 (29.1565)\n",
      "[7/25][552/782] Loss_D: 0.0237 (0.3627) Loss_G: 0.0542 (0.2075) D(x): 0.5479 D(G(z)): 0.4525 / 0.4000 Acc: 34.3750 (29.1573)\n",
      "[7/25][553/782] Loss_D: 0.0439 (0.3626) Loss_G: -0.1327 (0.2075) D(x): 0.4508 D(G(z)): 0.3931 / 0.4633 Acc: 35.9375 (29.1585)\n",
      "[7/25][554/782] Loss_D: 0.1083 (0.3626) Loss_G: -0.1395 (0.2074) D(x): 0.5069 D(G(z)): 0.4659 / 0.4673 Acc: 35.9375 (29.1596)\n",
      "[7/25][555/782] Loss_D: -0.0281 (0.3625) Loss_G: -0.1449 (0.2074) D(x): 0.5830 D(G(z)): 0.4820 / 0.4694 Acc: 37.5000 (29.1610)\n",
      "[7/25][556/782] Loss_D: -0.2395 (0.3624) Loss_G: -0.0571 (0.2073) D(x): 0.5750 D(G(z)): 0.4630 / 0.4224 Acc: 48.4375 (29.1642)\n",
      "[7/25][557/782] Loss_D: -0.0556 (0.3623) Loss_G: -0.0611 (0.2073) D(x): 0.5006 D(G(z)): 0.4398 / 0.4191 Acc: 42.1875 (29.1663)\n",
      "[7/25][558/782] Loss_D: 0.0536 (0.3623) Loss_G: -0.2159 (0.2072) D(x): 0.5065 D(G(z)): 0.4733 / 0.4860 Acc: 39.0625 (29.1680)\n",
      "[7/25][559/782] Loss_D: -0.0224 (0.3622) Loss_G: -0.0743 (0.2072) D(x): 0.5516 D(G(z)): 0.4814 / 0.4253 Acc: 42.1875 (29.1701)\n",
      "[7/25][560/782] Loss_D: 0.0532 (0.3622) Loss_G: -0.0648 (0.2071) D(x): 0.4877 D(G(z)): 0.4460 / 0.4303 Acc: 34.3750 (29.1710)\n",
      "[7/25][561/782] Loss_D: -0.0525 (0.3621) Loss_G: -0.1715 (0.2071) D(x): 0.5097 D(G(z)): 0.4369 / 0.4735 Acc: 39.0625 (29.1726)\n",
      "[7/25][562/782] Loss_D: 0.0106 (0.3620) Loss_G: -0.1655 (0.2070) D(x): 0.5566 D(G(z)): 0.4830 / 0.4792 Acc: 34.3750 (29.1735)\n",
      "[7/25][563/782] Loss_D: 0.0248 (0.3620) Loss_G: -0.1451 (0.2069) D(x): 0.5357 D(G(z)): 0.4882 / 0.4629 Acc: 43.7500 (29.1759)\n",
      "[7/25][564/782] Loss_D: -0.0983 (0.3619) Loss_G: -0.0991 (0.2069) D(x): 0.5629 D(G(z)): 0.4763 / 0.4400 Acc: 42.1875 (29.1781)\n",
      "[7/25][565/782] Loss_D: 0.0762 (0.3619) Loss_G: -0.1659 (0.2068) D(x): 0.5195 D(G(z)): 0.4547 / 0.4713 Acc: 26.5625 (29.1776)\n",
      "[7/25][566/782] Loss_D: -0.0479 (0.3618) Loss_G: -0.0965 (0.2068) D(x): 0.5504 D(G(z)): 0.4941 / 0.4493 Acc: 40.6250 (29.1795)\n",
      "[7/25][567/782] Loss_D: -0.1082 (0.3617) Loss_G: -0.0279 (0.2067) D(x): 0.5636 D(G(z)): 0.4638 / 0.4000 Acc: 35.9375 (29.1806)\n",
      "[7/25][568/782] Loss_D: 0.0860 (0.3617) Loss_G: -0.0469 (0.2067) D(x): 0.4928 D(G(z)): 0.4418 / 0.4235 Acc: 37.5000 (29.1820)\n",
      "[7/25][569/782] Loss_D: -0.0778 (0.3616) Loss_G: -0.0871 (0.2066) D(x): 0.5021 D(G(z)): 0.4084 / 0.4247 Acc: 40.6250 (29.1839)\n",
      "[7/25][570/782] Loss_D: 0.0459 (0.3615) Loss_G: -0.2066 (0.2066) D(x): 0.5647 D(G(z)): 0.4894 / 0.4756 Acc: 29.6875 (29.1840)\n",
      "[7/25][571/782] Loss_D: -0.1872 (0.3615) Loss_G: -0.1637 (0.2065) D(x): 0.5880 D(G(z)): 0.4668 / 0.4612 Acc: 40.6250 (29.1859)\n",
      "[7/25][572/782] Loss_D: 0.0493 (0.3614) Loss_G: -0.0901 (0.2065) D(x): 0.5422 D(G(z)): 0.5158 / 0.4303 Acc: 40.6250 (29.1878)\n",
      "[7/25][573/782] Loss_D: -0.0189 (0.3613) Loss_G: 0.0457 (0.2064) D(x): 0.5444 D(G(z)): 0.4779 / 0.3930 Acc: 39.0625 (29.1894)\n",
      "[7/25][574/782] Loss_D: 0.0651 (0.3613) Loss_G: -0.0937 (0.2064) D(x): 0.4797 D(G(z)): 0.4605 / 0.4377 Acc: 39.0625 (29.1910)\n",
      "[7/25][575/782] Loss_D: -0.0225 (0.3612) Loss_G: -0.0944 (0.2063) D(x): 0.5024 D(G(z)): 0.4522 / 0.4347 Acc: 42.1875 (29.1932)\n",
      "[7/25][576/782] Loss_D: -0.0225 (0.3612) Loss_G: -0.2412 (0.2063) D(x): 0.5393 D(G(z)): 0.4881 / 0.4955 Acc: 42.1875 (29.1953)\n",
      "[7/25][577/782] Loss_D: -0.0096 (0.3611) Loss_G: -0.1920 (0.2062) D(x): 0.5637 D(G(z)): 0.4524 / 0.4927 Acc: 31.2500 (29.1957)\n",
      "[7/25][578/782] Loss_D: -0.0294 (0.3610) Loss_G: -0.1907 (0.2061) D(x): 0.5824 D(G(z)): 0.5253 / 0.4739 Acc: 39.0625 (29.1973)\n",
      "[7/25][579/782] Loss_D: 0.0449 (0.3610) Loss_G: -0.1243 (0.2061) D(x): 0.4781 D(G(z)): 0.4554 / 0.4530 Acc: 39.0625 (29.1989)\n",
      "[7/25][580/782] Loss_D: -0.1292 (0.3609) Loss_G: -0.1221 (0.2060) D(x): 0.5635 D(G(z)): 0.4509 / 0.4478 Acc: 39.0625 (29.2006)\n",
      "[7/25][581/782] Loss_D: 0.0111 (0.3608) Loss_G: -0.2015 (0.2060) D(x): 0.5181 D(G(z)): 0.4878 / 0.4820 Acc: 39.0625 (29.2022)\n",
      "[7/25][582/782] Loss_D: 0.0597 (0.3608) Loss_G: -0.1471 (0.2059) D(x): 0.5327 D(G(z)): 0.5095 / 0.4546 Acc: 40.6250 (29.2041)\n",
      "[7/25][583/782] Loss_D: 0.0946 (0.3608) Loss_G: -0.1662 (0.2058) D(x): 0.4842 D(G(z)): 0.4597 / 0.4629 Acc: 34.3750 (29.2049)\n",
      "[7/25][584/782] Loss_D: 0.0362 (0.3607) Loss_G: -0.1203 (0.2058) D(x): 0.5170 D(G(z)): 0.5039 / 0.4387 Acc: 42.1875 (29.2071)\n",
      "[7/25][585/782] Loss_D: 0.1882 (0.3607) Loss_G: -0.1960 (0.2057) D(x): 0.4990 D(G(z)): 0.5212 / 0.4754 Acc: 35.9375 (29.2082)\n",
      "[7/25][586/782] Loss_D: 0.0222 (0.3606) Loss_G: -0.0679 (0.2057) D(x): 0.5194 D(G(z)): 0.4420 / 0.4346 Acc: 32.8125 (29.2088)\n",
      "[7/25][587/782] Loss_D: 0.0477 (0.3606) Loss_G: -0.3012 (0.2056) D(x): 0.5155 D(G(z)): 0.4779 / 0.5250 Acc: 35.9375 (29.2099)\n",
      "[7/25][588/782] Loss_D: 0.1220 (0.3605) Loss_G: -0.0759 (0.2055) D(x): 0.5300 D(G(z)): 0.5133 / 0.4244 Acc: 35.9375 (29.2110)\n",
      "[7/25][589/782] Loss_D: -0.1183 (0.3604) Loss_G: -0.1144 (0.2055) D(x): 0.5528 D(G(z)): 0.4651 / 0.4467 Acc: 45.3125 (29.2136)\n",
      "[7/25][590/782] Loss_D: -0.1110 (0.3604) Loss_G: -0.0598 (0.2054) D(x): 0.5579 D(G(z)): 0.4737 / 0.4204 Acc: 40.6250 (29.2155)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/25][591/782] Loss_D: 0.0341 (0.3603) Loss_G: -0.1839 (0.2054) D(x): 0.4678 D(G(z)): 0.4391 / 0.4633 Acc: 42.1875 (29.2177)\n",
      "[7/25][592/782] Loss_D: -0.1374 (0.3602) Loss_G: -0.2361 (0.2053) D(x): 0.5406 D(G(z)): 0.4720 / 0.4819 Acc: 46.8750 (29.2206)\n",
      "[7/25][593/782] Loss_D: -0.1026 (0.3602) Loss_G: -0.0959 (0.2053) D(x): 0.5716 D(G(z)): 0.5179 / 0.4284 Acc: 48.4375 (29.2237)\n",
      "[7/25][594/782] Loss_D: 0.0211 (0.3601) Loss_G: -0.1107 (0.2052) D(x): 0.5455 D(G(z)): 0.4883 / 0.4480 Acc: 35.9375 (29.2249)\n",
      "[7/25][595/782] Loss_D: 0.0124 (0.3600) Loss_G: 0.0101 (0.2052) D(x): 0.5121 D(G(z)): 0.4741 / 0.3942 Acc: 39.0625 (29.2265)\n",
      "[7/25][596/782] Loss_D: 0.1998 (0.3600) Loss_G: -0.1670 (0.2051) D(x): 0.5011 D(G(z)): 0.4910 / 0.4671 Acc: 26.5625 (29.2260)\n",
      "[7/25][597/782] Loss_D: 0.0544 (0.3600) Loss_G: -0.0444 (0.2051) D(x): 0.5116 D(G(z)): 0.4620 / 0.4159 Acc: 31.2500 (29.2264)\n",
      "[7/25][598/782] Loss_D: 0.1443 (0.3599) Loss_G: -0.2126 (0.2050) D(x): 0.4951 D(G(z)): 0.5062 / 0.4797 Acc: 37.5000 (29.2277)\n",
      "[7/25][599/782] Loss_D: 0.0924 (0.3599) Loss_G: 0.0138 (0.2050) D(x): 0.5510 D(G(z)): 0.4944 / 0.3996 Acc: 26.5625 (29.2273)\n",
      "[7/25][600/782] Loss_D: 0.0950 (0.3598) Loss_G: -0.1024 (0.2049) D(x): 0.4846 D(G(z)): 0.4916 / 0.4410 Acc: 45.3125 (29.2299)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[7/25][601/782] Loss_D: 0.1436 (0.3598) Loss_G: -0.1392 (0.2049) D(x): 0.4813 D(G(z)): 0.4687 / 0.4646 Acc: 31.2500 (29.2303)\n",
      "[7/25][602/782] Loss_D: 0.0373 (0.3598) Loss_G: 0.0070 (0.2048) D(x): 0.5386 D(G(z)): 0.4898 / 0.4051 Acc: 34.3750 (29.2311)\n",
      "[7/25][603/782] Loss_D: 0.0775 (0.3597) Loss_G: -0.2349 (0.2048) D(x): 0.5048 D(G(z)): 0.4631 / 0.4988 Acc: 34.3750 (29.2320)\n",
      "[7/25][604/782] Loss_D: 0.0384 (0.3597) Loss_G: -0.0603 (0.2047) D(x): 0.5577 D(G(z)): 0.5014 / 0.4241 Acc: 31.2500 (29.2323)\n",
      "[7/25][605/782] Loss_D: 0.0963 (0.3596) Loss_G: -0.0612 (0.2047) D(x): 0.5029 D(G(z)): 0.4732 / 0.4165 Acc: 35.9375 (29.2334)\n",
      "[7/25][606/782] Loss_D: 0.0080 (0.3596) Loss_G: -0.1113 (0.2046) D(x): 0.4843 D(G(z)): 0.4103 / 0.4663 Acc: 37.5000 (29.2348)\n",
      "[7/25][607/782] Loss_D: 0.2246 (0.3595) Loss_G: -0.1455 (0.2046) D(x): 0.4807 D(G(z)): 0.5062 / 0.4801 Acc: 34.3750 (29.2356)\n",
      "[7/25][608/782] Loss_D: 0.0781 (0.3595) Loss_G: -0.3138 (0.2045) D(x): 0.5581 D(G(z)): 0.5268 / 0.5216 Acc: 34.3750 (29.2364)\n",
      "[7/25][609/782] Loss_D: 0.0008 (0.3594) Loss_G: 0.0061 (0.2044) D(x): 0.5591 D(G(z)): 0.4913 / 0.3930 Acc: 34.3750 (29.2373)\n",
      "[7/25][610/782] Loss_D: 0.1195 (0.3594) Loss_G: -0.0697 (0.2044) D(x): 0.4951 D(G(z)): 0.4711 / 0.4223 Acc: 29.6875 (29.2374)\n",
      "[7/25][611/782] Loss_D: 0.0008 (0.3593) Loss_G: -0.1372 (0.2043) D(x): 0.5059 D(G(z)): 0.4130 / 0.4433 Acc: 31.2500 (29.2377)\n",
      "[7/25][612/782] Loss_D: 0.0135 (0.3593) Loss_G: -0.1394 (0.2043) D(x): 0.4767 D(G(z)): 0.4708 / 0.4516 Acc: 46.8750 (29.2406)\n",
      "[7/25][613/782] Loss_D: 0.0148 (0.3592) Loss_G: -0.1810 (0.2042) D(x): 0.5209 D(G(z)): 0.5057 / 0.4669 Acc: 42.1875 (29.2427)\n",
      "[7/25][614/782] Loss_D: 0.0870 (0.3592) Loss_G: -0.2178 (0.2042) D(x): 0.5219 D(G(z)): 0.4979 / 0.4817 Acc: 37.5000 (29.2441)\n",
      "[7/25][615/782] Loss_D: 0.0361 (0.3591) Loss_G: -0.1779 (0.2041) D(x): 0.5447 D(G(z)): 0.5040 / 0.4689 Acc: 37.5000 (29.2454)\n",
      "[7/25][616/782] Loss_D: -0.0344 (0.3591) Loss_G: -0.1952 (0.2040) D(x): 0.5325 D(G(z)): 0.4531 / 0.4751 Acc: 37.5000 (29.2468)\n",
      "[7/25][617/782] Loss_D: 0.0716 (0.3590) Loss_G: -0.2366 (0.2040) D(x): 0.5698 D(G(z)): 0.5102 / 0.5072 Acc: 32.8125 (29.2474)\n",
      "[7/25][618/782] Loss_D: -0.1170 (0.3589) Loss_G: -0.1618 (0.2039) D(x): 0.5018 D(G(z)): 0.4714 / 0.4605 Acc: 53.1250 (29.2513)\n",
      "[7/25][619/782] Loss_D: 0.1138 (0.3589) Loss_G: -0.1529 (0.2038) D(x): 0.5056 D(G(z)): 0.4856 / 0.4638 Acc: 39.0625 (29.2529)\n",
      "[7/25][620/782] Loss_D: 0.0178 (0.3588) Loss_G: -0.1316 (0.2038) D(x): 0.5023 D(G(z)): 0.4594 / 0.4506 Acc: 37.5000 (29.2543)\n",
      "[7/25][621/782] Loss_D: 0.1221 (0.3588) Loss_G: -0.0590 (0.2037) D(x): 0.5655 D(G(z)): 0.4877 / 0.4395 Acc: 28.1250 (29.2541)\n",
      "[7/25][622/782] Loss_D: -0.1714 (0.3587) Loss_G: -0.0311 (0.2037) D(x): 0.5533 D(G(z)): 0.4357 / 0.4022 Acc: 40.6250 (29.2559)\n",
      "[7/25][623/782] Loss_D: -0.0432 (0.3586) Loss_G: -0.0798 (0.2037) D(x): 0.5503 D(G(z)): 0.4258 / 0.4300 Acc: 28.1250 (29.2557)\n",
      "[7/25][624/782] Loss_D: -0.0212 (0.3586) Loss_G: -0.1331 (0.2036) D(x): 0.5425 D(G(z)): 0.4828 / 0.4639 Acc: 42.1875 (29.2579)\n",
      "[7/25][625/782] Loss_D: -0.1513 (0.3585) Loss_G: -0.1048 (0.2035) D(x): 0.5644 D(G(z)): 0.4372 / 0.4370 Acc: 39.0625 (29.2595)\n",
      "[7/25][626/782] Loss_D: 0.0096 (0.3584) Loss_G: -0.2167 (0.2035) D(x): 0.5710 D(G(z)): 0.4679 / 0.4821 Acc: 28.1250 (29.2593)\n",
      "[7/25][627/782] Loss_D: -0.0126 (0.3584) Loss_G: -0.0903 (0.2034) D(x): 0.5671 D(G(z)): 0.5078 / 0.4496 Acc: 39.0625 (29.2609)\n",
      "[7/25][628/782] Loss_D: 0.0902 (0.3583) Loss_G: -0.0686 (0.2034) D(x): 0.5051 D(G(z)): 0.4591 / 0.4223 Acc: 29.6875 (29.2610)\n",
      "[7/25][629/782] Loss_D: 0.0152 (0.3583) Loss_G: -0.1799 (0.2033) D(x): 0.4707 D(G(z)): 0.4459 / 0.4659 Acc: 42.1875 (29.2631)\n",
      "[7/25][630/782] Loss_D: 0.0941 (0.3582) Loss_G: -0.2677 (0.2032) D(x): 0.5271 D(G(z)): 0.5275 / 0.5149 Acc: 43.7500 (29.2655)\n",
      "[7/25][631/782] Loss_D: 0.1254 (0.3582) Loss_G: -0.3037 (0.2032) D(x): 0.5671 D(G(z)): 0.5304 / 0.5163 Acc: 26.5625 (29.2650)\n",
      "[7/25][632/782] Loss_D: 0.1345 (0.3582) Loss_G: -0.1376 (0.2031) D(x): 0.5623 D(G(z)): 0.5454 / 0.4595 Acc: 37.5000 (29.2664)\n",
      "[7/25][633/782] Loss_D: 0.1810 (0.3581) Loss_G: -0.1425 (0.2030) D(x): 0.4334 D(G(z)): 0.4705 / 0.4709 Acc: 40.6250 (29.2682)\n",
      "[7/25][634/782] Loss_D: 0.0488 (0.3581) Loss_G: -0.0758 (0.2030) D(x): 0.5564 D(G(z)): 0.5177 / 0.4202 Acc: 37.5000 (29.2696)\n",
      "[7/25][635/782] Loss_D: 0.2019 (0.3581) Loss_G: -0.1971 (0.2029) D(x): 0.4909 D(G(z)): 0.5234 / 0.4901 Acc: 35.9375 (29.2707)\n",
      "[7/25][636/782] Loss_D: 0.1631 (0.3580) Loss_G: -0.2059 (0.2029) D(x): 0.4580 D(G(z)): 0.4478 / 0.4870 Acc: 29.6875 (29.2707)\n",
      "[7/25][637/782] Loss_D: -0.0366 (0.3580) Loss_G: -0.2563 (0.2028) D(x): 0.5268 D(G(z)): 0.4794 / 0.5051 Acc: 43.7500 (29.2731)\n",
      "[7/25][638/782] Loss_D: -0.0119 (0.3579) Loss_G: -0.2091 (0.2027) D(x): 0.5375 D(G(z)): 0.4918 / 0.4807 Acc: 42.1875 (29.2752)\n",
      "[7/25][639/782] Loss_D: 0.0341 (0.3578) Loss_G: -0.1706 (0.2027) D(x): 0.5264 D(G(z)): 0.4911 / 0.4684 Acc: 40.6250 (29.2771)\n",
      "[7/25][640/782] Loss_D: 0.0985 (0.3578) Loss_G: -0.0981 (0.2026) D(x): 0.5048 D(G(z)): 0.4903 / 0.4333 Acc: 35.9375 (29.2782)\n",
      "[7/25][641/782] Loss_D: -0.0342 (0.3577) Loss_G: -0.1457 (0.2026) D(x): 0.5258 D(G(z)): 0.4506 / 0.4618 Acc: 34.3750 (29.2790)\n",
      "[7/25][642/782] Loss_D: 0.0406 (0.3577) Loss_G: -0.0150 (0.2025) D(x): 0.5452 D(G(z)): 0.4639 / 0.4134 Acc: 29.6875 (29.2791)\n",
      "[7/25][643/782] Loss_D: -0.0994 (0.3576) Loss_G: -0.1540 (0.2025) D(x): 0.5472 D(G(z)): 0.4686 / 0.4786 Acc: 42.1875 (29.2812)\n",
      "[7/25][644/782] Loss_D: 0.0642 (0.3576) Loss_G: -0.1344 (0.2024) D(x): 0.5105 D(G(z)): 0.4404 / 0.4611 Acc: 28.1250 (29.2810)\n",
      "[7/25][645/782] Loss_D: 0.0557 (0.3575) Loss_G: -0.1334 (0.2024) D(x): 0.5272 D(G(z)): 0.5160 / 0.4616 Acc: 42.1875 (29.2831)\n",
      "[7/25][646/782] Loss_D: 0.0459 (0.3575) Loss_G: -0.1369 (0.2023) D(x): 0.5405 D(G(z)): 0.4973 / 0.4511 Acc: 40.6250 (29.2849)\n",
      "[7/25][647/782] Loss_D: -0.0666 (0.3574) Loss_G: -0.1032 (0.2023) D(x): 0.5214 D(G(z)): 0.4467 / 0.4477 Acc: 42.1875 (29.2870)\n",
      "[7/25][648/782] Loss_D: 0.0558 (0.3573) Loss_G: -0.1188 (0.2022) D(x): 0.5291 D(G(z)): 0.4931 / 0.4505 Acc: 37.5000 (29.2884)\n",
      "[7/25][649/782] Loss_D: -0.1146 (0.3573) Loss_G: -0.2251 (0.2021) D(x): 0.5029 D(G(z)): 0.4199 / 0.4957 Acc: 43.7500 (29.2908)\n",
      "[7/25][650/782] Loss_D: -0.1493 (0.3572) Loss_G: -0.2051 (0.2021) D(x): 0.5611 D(G(z)): 0.4587 / 0.4759 Acc: 43.7500 (29.2931)\n",
      "[7/25][651/782] Loss_D: -0.0125 (0.3571) Loss_G: -0.1663 (0.2020) D(x): 0.5354 D(G(z)): 0.4746 / 0.4631 Acc: 39.0625 (29.2947)\n",
      "[7/25][652/782] Loss_D: 0.1647 (0.3571) Loss_G: -0.0390 (0.2020) D(x): 0.5294 D(G(z)): 0.4992 / 0.4258 Acc: 28.1250 (29.2945)\n",
      "[7/25][653/782] Loss_D: -0.0519 (0.3570) Loss_G: -0.1334 (0.2019) D(x): 0.5402 D(G(z)): 0.4291 / 0.4681 Acc: 31.2500 (29.2948)\n",
      "[7/25][654/782] Loss_D: -0.0472 (0.3570) Loss_G: -0.1866 (0.2018) D(x): 0.4910 D(G(z)): 0.4195 / 0.4709 Acc: 40.6250 (29.2967)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/25][655/782] Loss_D: 0.1208 (0.3569) Loss_G: -0.1889 (0.2018) D(x): 0.5458 D(G(z)): 0.5276 / 0.4831 Acc: 39.0625 (29.2983)\n",
      "[7/25][656/782] Loss_D: 0.0030 (0.3569) Loss_G: -0.1597 (0.2017) D(x): 0.5332 D(G(z)): 0.4829 / 0.4679 Acc: 43.7500 (29.3006)\n",
      "[7/25][657/782] Loss_D: -0.0055 (0.3568) Loss_G: 0.0384 (0.2017) D(x): 0.5536 D(G(z)): 0.4647 / 0.3974 Acc: 31.2500 (29.3010)\n",
      "[7/25][658/782] Loss_D: 0.1016 (0.3568) Loss_G: -0.0451 (0.2017) D(x): 0.4658 D(G(z)): 0.4263 / 0.4180 Acc: 31.2500 (29.3013)\n",
      "[7/25][659/782] Loss_D: 0.0223 (0.3567) Loss_G: -0.1988 (0.2016) D(x): 0.4723 D(G(z)): 0.3998 / 0.4867 Acc: 34.3750 (29.3021)\n",
      "[7/25][660/782] Loss_D: 0.0494 (0.3567) Loss_G: -0.1914 (0.2015) D(x): 0.5307 D(G(z)): 0.4849 / 0.5035 Acc: 37.5000 (29.3034)\n",
      "[7/25][661/782] Loss_D: 0.1006 (0.3566) Loss_G: -0.2276 (0.2015) D(x): 0.5492 D(G(z)): 0.5317 / 0.4925 Acc: 39.0625 (29.3050)\n",
      "[7/25][662/782] Loss_D: 0.1292 (0.3566) Loss_G: -0.2038 (0.2014) D(x): 0.5445 D(G(z)): 0.5265 / 0.4791 Acc: 37.5000 (29.3064)\n",
      "[7/25][663/782] Loss_D: -0.0331 (0.3565) Loss_G: -0.1986 (0.2013) D(x): 0.4877 D(G(z)): 0.4514 / 0.4772 Acc: 48.4375 (29.3095)\n",
      "[7/25][664/782] Loss_D: 0.0284 (0.3565) Loss_G: -0.0571 (0.2013) D(x): 0.4947 D(G(z)): 0.4555 / 0.4332 Acc: 39.0625 (29.3111)\n",
      "[7/25][665/782] Loss_D: 0.0470 (0.3564) Loss_G: -0.0769 (0.2012) D(x): 0.5056 D(G(z)): 0.4632 / 0.4234 Acc: 39.0625 (29.3127)\n",
      "[7/25][666/782] Loss_D: 0.1051 (0.3564) Loss_G: -0.0962 (0.2012) D(x): 0.5502 D(G(z)): 0.4845 / 0.4298 Acc: 25.0000 (29.3120)\n",
      "[7/25][667/782] Loss_D: 0.1710 (0.3563) Loss_G: -0.0565 (0.2011) D(x): 0.4889 D(G(z)): 0.5002 / 0.4146 Acc: 37.5000 (29.3133)\n",
      "[7/25][668/782] Loss_D: 0.1329 (0.3563) Loss_G: -0.2329 (0.2011) D(x): 0.4385 D(G(z)): 0.4559 / 0.5069 Acc: 45.3125 (29.3159)\n",
      "[7/25][669/782] Loss_D: -0.0005 (0.3562) Loss_G: -0.2154 (0.2010) D(x): 0.5467 D(G(z)): 0.5068 / 0.4966 Acc: 43.7500 (29.3182)\n",
      "[7/25][670/782] Loss_D: -0.0282 (0.3562) Loss_G: 0.0096 (0.2010) D(x): 0.5827 D(G(z)): 0.4505 / 0.3968 Acc: 23.4375 (29.3173)\n",
      "[7/25][671/782] Loss_D: 0.0069 (0.3561) Loss_G: -0.1381 (0.2009) D(x): 0.4908 D(G(z)): 0.4123 / 0.4519 Acc: 32.8125 (29.3178)\n",
      "[7/25][672/782] Loss_D: 0.0271 (0.3561) Loss_G: -0.2108 (0.2009) D(x): 0.5456 D(G(z)): 0.4771 / 0.4758 Acc: 34.3750 (29.3187)\n",
      "[7/25][673/782] Loss_D: 0.0399 (0.3560) Loss_G: -0.0145 (0.2008) D(x): 0.5454 D(G(z)): 0.4602 / 0.4064 Acc: 31.2500 (29.3190)\n",
      "[7/25][674/782] Loss_D: -0.2145 (0.3559) Loss_G: -0.0898 (0.2008) D(x): 0.5197 D(G(z)): 0.4089 / 0.4349 Acc: 48.4375 (29.3221)\n",
      "[7/25][675/782] Loss_D: -0.0145 (0.3559) Loss_G: -0.2278 (0.2007) D(x): 0.5084 D(G(z)): 0.4584 / 0.4864 Acc: 37.5000 (29.3234)\n",
      "[7/25][676/782] Loss_D: -0.0066 (0.3558) Loss_G: -0.1819 (0.2006) D(x): 0.5621 D(G(z)): 0.5054 / 0.4797 Acc: 40.6250 (29.3253)\n",
      "[7/25][677/782] Loss_D: -0.0905 (0.3557) Loss_G: -0.1886 (0.2006) D(x): 0.5435 D(G(z)): 0.4514 / 0.4736 Acc: 35.9375 (29.3263)\n",
      "[7/25][678/782] Loss_D: 0.0685 (0.3557) Loss_G: -0.2130 (0.2005) D(x): 0.5174 D(G(z)): 0.4809 / 0.4793 Acc: 34.3750 (29.3272)\n",
      "[7/25][679/782] Loss_D: 0.1429 (0.3557) Loss_G: -0.2690 (0.2004) D(x): 0.4567 D(G(z)): 0.4631 / 0.5165 Acc: 35.9375 (29.3282)\n",
      "[7/25][680/782] Loss_D: -0.0036 (0.3556) Loss_G: -0.1778 (0.2004) D(x): 0.5736 D(G(z)): 0.5226 / 0.4608 Acc: 42.1875 (29.3303)\n",
      "[7/25][681/782] Loss_D: -0.0096 (0.3555) Loss_G: -0.1772 (0.2003) D(x): 0.5311 D(G(z)): 0.4683 / 0.4647 Acc: 34.3750 (29.3311)\n",
      "[7/25][682/782] Loss_D: -0.1664 (0.3555) Loss_G: -0.2134 (0.2002) D(x): 0.5338 D(G(z)): 0.4791 / 0.4719 Acc: 53.1250 (29.3350)\n",
      "[7/25][683/782] Loss_D: -0.0885 (0.3554) Loss_G: -0.2444 (0.2002) D(x): 0.5200 D(G(z)): 0.4305 / 0.4925 Acc: 40.6250 (29.3368)\n",
      "[7/25][684/782] Loss_D: -0.0225 (0.3553) Loss_G: -0.1249 (0.2001) D(x): 0.5266 D(G(z)): 0.4479 / 0.4401 Acc: 39.0625 (29.3384)\n",
      "[7/25][685/782] Loss_D: 0.0890 (0.3553) Loss_G: -0.1834 (0.2001) D(x): 0.5304 D(G(z)): 0.4716 / 0.4687 Acc: 31.2500 (29.3387)\n",
      "[7/25][686/782] Loss_D: 0.0031 (0.3552) Loss_G: -0.1350 (0.2000) D(x): 0.5634 D(G(z)): 0.4833 / 0.4618 Acc: 31.2500 (29.3390)\n",
      "[7/25][687/782] Loss_D: 0.2302 (0.3552) Loss_G: -0.1879 (0.1999) D(x): 0.4992 D(G(z)): 0.4749 / 0.4863 Acc: 23.4375 (29.3381)\n",
      "[7/25][688/782] Loss_D: 0.0911 (0.3552) Loss_G: -0.1694 (0.1999) D(x): 0.5244 D(G(z)): 0.4832 / 0.4658 Acc: 34.3750 (29.3389)\n",
      "[7/25][689/782] Loss_D: 0.1622 (0.3551) Loss_G: -0.1802 (0.1998) D(x): 0.5414 D(G(z)): 0.5250 / 0.4601 Acc: 29.6875 (29.3390)\n",
      "[7/25][690/782] Loss_D: -0.0325 (0.3551) Loss_G: -0.1302 (0.1998) D(x): 0.5455 D(G(z)): 0.4688 / 0.4409 Acc: 34.3750 (29.3398)\n",
      "[7/25][691/782] Loss_D: -0.1127 (0.3550) Loss_G: -0.2279 (0.1997) D(x): 0.5088 D(G(z)): 0.4429 / 0.4972 Acc: 48.4375 (29.3429)\n",
      "[7/25][692/782] Loss_D: -0.0158 (0.3549) Loss_G: -0.1166 (0.1996) D(x): 0.5644 D(G(z)): 0.4775 / 0.4455 Acc: 29.6875 (29.3429)\n",
      "[7/25][693/782] Loss_D: 0.1518 (0.3549) Loss_G: -0.1615 (0.1996) D(x): 0.5445 D(G(z)): 0.4750 / 0.4604 Acc: 20.3125 (29.3415)\n",
      "[7/25][694/782] Loss_D: -0.0237 (0.3548) Loss_G: -0.2281 (0.1995) D(x): 0.5838 D(G(z)): 0.4608 / 0.4928 Acc: 26.5625 (29.3410)\n",
      "[7/25][695/782] Loss_D: -0.0826 (0.3548) Loss_G: -0.1808 (0.1995) D(x): 0.5437 D(G(z)): 0.4522 / 0.4628 Acc: 34.3750 (29.3418)\n",
      "[7/25][696/782] Loss_D: 0.0073 (0.3547) Loss_G: -0.1481 (0.1994) D(x): 0.5156 D(G(z)): 0.4827 / 0.4507 Acc: 37.5000 (29.3431)\n",
      "[7/25][697/782] Loss_D: -0.1120 (0.3546) Loss_G: -0.1085 (0.1993) D(x): 0.5539 D(G(z)): 0.5190 / 0.4549 Acc: 54.6875 (29.3473)\n",
      "[7/25][698/782] Loss_D: -0.0739 (0.3546) Loss_G: -0.1353 (0.1993) D(x): 0.5241 D(G(z)): 0.4327 / 0.4585 Acc: 39.0625 (29.3488)\n",
      "[7/25][699/782] Loss_D: -0.1627 (0.3545) Loss_G: -0.1705 (0.1992) D(x): 0.5419 D(G(z)): 0.4131 / 0.4582 Acc: 40.6250 (29.3507)\n",
      "[7/25][700/782] Loss_D: -0.1033 (0.3544) Loss_G: -0.1323 (0.1992) D(x): 0.5604 D(G(z)): 0.4582 / 0.4668 Acc: 42.1875 (29.3527)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[7/25][701/782] Loss_D: -0.0021 (0.3543) Loss_G: -0.1472 (0.1991) D(x): 0.5545 D(G(z)): 0.4854 / 0.4669 Acc: 40.6250 (29.3546)\n",
      "[7/25][702/782] Loss_D: -0.0290 (0.3543) Loss_G: -0.2009 (0.1991) D(x): 0.5448 D(G(z)): 0.4845 / 0.4700 Acc: 42.1875 (29.3566)\n",
      "[7/25][703/782] Loss_D: 0.0316 (0.3542) Loss_G: -0.1426 (0.1990) D(x): 0.4965 D(G(z)): 0.4922 / 0.4702 Acc: 43.7500 (29.3590)\n",
      "[7/25][704/782] Loss_D: 0.1045 (0.3542) Loss_G: -0.1306 (0.1990) D(x): 0.4641 D(G(z)): 0.4601 / 0.4384 Acc: 37.5000 (29.3603)\n",
      "[7/25][705/782] Loss_D: -0.0037 (0.3541) Loss_G: -0.1559 (0.1989) D(x): 0.5242 D(G(z)): 0.4692 / 0.4597 Acc: 35.9375 (29.3613)\n",
      "[7/25][706/782] Loss_D: 0.0730 (0.3541) Loss_G: -0.1980 (0.1988) D(x): 0.5439 D(G(z)): 0.4931 / 0.4753 Acc: 35.9375 (29.3624)\n",
      "[7/25][707/782] Loss_D: 0.0892 (0.3540) Loss_G: -0.0596 (0.1988) D(x): 0.5404 D(G(z)): 0.4998 / 0.4206 Acc: 34.3750 (29.3632)\n",
      "[7/25][708/782] Loss_D: -0.0420 (0.3540) Loss_G: -0.1541 (0.1987) D(x): 0.5187 D(G(z)): 0.4872 / 0.4661 Acc: 48.4375 (29.3663)\n",
      "[7/25][709/782] Loss_D: 0.1428 (0.3539) Loss_G: -0.1896 (0.1987) D(x): 0.5499 D(G(z)): 0.5250 / 0.4825 Acc: 32.8125 (29.3669)\n",
      "[7/25][710/782] Loss_D: 0.0594 (0.3539) Loss_G: -0.0625 (0.1986) D(x): 0.4951 D(G(z)): 0.4942 / 0.4261 Acc: 48.4375 (29.3699)\n",
      "[7/25][711/782] Loss_D: 0.1445 (0.3539) Loss_G: -0.0763 (0.1986) D(x): 0.4782 D(G(z)): 0.4647 / 0.4376 Acc: 34.3750 (29.3708)\n",
      "[7/25][712/782] Loss_D: 0.0526 (0.3538) Loss_G: -0.2199 (0.1985) D(x): 0.4857 D(G(z)): 0.4734 / 0.5030 Acc: 42.1875 (29.3728)\n",
      "[7/25][713/782] Loss_D: 0.2882 (0.3538) Loss_G: -0.1732 (0.1985) D(x): 0.4669 D(G(z)): 0.4640 / 0.4883 Acc: 31.2500 (29.3731)\n",
      "[7/25][714/782] Loss_D: 0.0256 (0.3538) Loss_G: -0.2248 (0.1984) D(x): 0.5632 D(G(z)): 0.5275 / 0.4923 Acc: 42.1875 (29.3752)\n",
      "[7/25][715/782] Loss_D: -0.0319 (0.3537) Loss_G: -0.1452 (0.1983) D(x): 0.5398 D(G(z)): 0.4841 / 0.4603 Acc: 42.1875 (29.3773)\n",
      "[7/25][716/782] Loss_D: 0.0791 (0.3536) Loss_G: -0.0808 (0.1983) D(x): 0.4886 D(G(z)): 0.4935 / 0.4405 Acc: 50.0000 (29.3806)\n",
      "[7/25][717/782] Loss_D: 0.0624 (0.3536) Loss_G: -0.1582 (0.1982) D(x): 0.4674 D(G(z)): 0.4283 / 0.4734 Acc: 40.6250 (29.3824)\n",
      "[7/25][718/782] Loss_D: 0.1181 (0.3536) Loss_G: -0.1243 (0.1982) D(x): 0.5016 D(G(z)): 0.5018 / 0.4512 Acc: 40.6250 (29.3842)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/25][719/782] Loss_D: 0.0677 (0.3535) Loss_G: -0.1336 (0.1981) D(x): 0.5243 D(G(z)): 0.4869 / 0.4567 Acc: 34.3750 (29.3850)\n",
      "[7/25][720/782] Loss_D: -0.0216 (0.3535) Loss_G: -0.1157 (0.1981) D(x): 0.5722 D(G(z)): 0.4966 / 0.4359 Acc: 37.5000 (29.3863)\n",
      "[7/25][721/782] Loss_D: -0.0800 (0.3534) Loss_G: -0.0979 (0.1980) D(x): 0.5083 D(G(z)): 0.4170 / 0.4396 Acc: 39.0625 (29.3879)\n",
      "[7/25][722/782] Loss_D: -0.0378 (0.3533) Loss_G: -0.1392 (0.1980) D(x): 0.5446 D(G(z)): 0.4662 / 0.4554 Acc: 40.6250 (29.3897)\n",
      "[7/25][723/782] Loss_D: -0.0192 (0.3533) Loss_G: -0.1730 (0.1979) D(x): 0.5124 D(G(z)): 0.4499 / 0.4654 Acc: 37.5000 (29.3910)\n",
      "[7/25][724/782] Loss_D: -0.0809 (0.3532) Loss_G: -0.1127 (0.1979) D(x): 0.5552 D(G(z)): 0.4679 / 0.4345 Acc: 39.0625 (29.3926)\n",
      "[7/25][725/782] Loss_D: 0.0667 (0.3531) Loss_G: -0.2101 (0.1978) D(x): 0.5274 D(G(z)): 0.4783 / 0.4889 Acc: 31.2500 (29.3929)\n",
      "[7/25][726/782] Loss_D: 0.0169 (0.3531) Loss_G: -0.1454 (0.1977) D(x): 0.5388 D(G(z)): 0.4943 / 0.4647 Acc: 43.7500 (29.3952)\n",
      "[7/25][727/782] Loss_D: -0.0297 (0.3530) Loss_G: -0.1158 (0.1977) D(x): 0.5125 D(G(z)): 0.4599 / 0.4349 Acc: 39.0625 (29.3968)\n",
      "[7/25][728/782] Loss_D: 0.0425 (0.3530) Loss_G: -0.1843 (0.1976) D(x): 0.5145 D(G(z)): 0.4746 / 0.4750 Acc: 45.3125 (29.3993)\n",
      "[7/25][729/782] Loss_D: 0.1946 (0.3530) Loss_G: -0.1782 (0.1976) D(x): 0.4848 D(G(z)): 0.4708 / 0.4829 Acc: 29.6875 (29.3994)\n",
      "[7/25][730/782] Loss_D: 0.0863 (0.3529) Loss_G: -0.2098 (0.1975) D(x): 0.5194 D(G(z)): 0.5007 / 0.4796 Acc: 40.6250 (29.4012)\n",
      "[7/25][731/782] Loss_D: 0.0964 (0.3529) Loss_G: -0.1581 (0.1974) D(x): 0.5197 D(G(z)): 0.4995 / 0.4611 Acc: 37.5000 (29.4025)\n",
      "[7/25][732/782] Loss_D: 0.1826 (0.3528) Loss_G: -0.2411 (0.1974) D(x): 0.5209 D(G(z)): 0.4846 / 0.4988 Acc: 21.8750 (29.4013)\n",
      "[7/25][733/782] Loss_D: 0.0604 (0.3528) Loss_G: -0.0999 (0.1973) D(x): 0.5171 D(G(z)): 0.4840 / 0.4387 Acc: 35.9375 (29.4023)\n",
      "[7/25][734/782] Loss_D: 0.0937 (0.3528) Loss_G: -0.0921 (0.1973) D(x): 0.5205 D(G(z)): 0.4902 / 0.4466 Acc: 37.5000 (29.4036)\n",
      "[7/25][735/782] Loss_D: 0.2010 (0.3527) Loss_G: -0.2310 (0.1972) D(x): 0.4391 D(G(z)): 0.4685 / 0.5029 Acc: 42.1875 (29.4057)\n",
      "[7/25][736/782] Loss_D: 0.0211 (0.3527) Loss_G: -0.2027 (0.1971) D(x): 0.5338 D(G(z)): 0.4895 / 0.4893 Acc: 46.8750 (29.4085)\n",
      "[7/25][737/782] Loss_D: -0.0051 (0.3526) Loss_G: -0.2690 (0.1971) D(x): 0.5205 D(G(z)): 0.4953 / 0.5150 Acc: 45.3125 (29.4111)\n",
      "[7/25][738/782] Loss_D: 0.1182 (0.3526) Loss_G: -0.0942 (0.1970) D(x): 0.4806 D(G(z)): 0.4857 / 0.4441 Acc: 39.0625 (29.4126)\n",
      "[7/25][739/782] Loss_D: 0.0312 (0.3525) Loss_G: -0.1025 (0.1970) D(x): 0.5178 D(G(z)): 0.4625 / 0.4405 Acc: 34.3750 (29.4134)\n",
      "[7/25][740/782] Loss_D: -0.0851 (0.3525) Loss_G: -0.0619 (0.1969) D(x): 0.5348 D(G(z)): 0.4411 / 0.4183 Acc: 34.3750 (29.4142)\n",
      "[7/25][741/782] Loss_D: 0.0200 (0.3524) Loss_G: -0.1797 (0.1969) D(x): 0.4894 D(G(z)): 0.4717 / 0.4681 Acc: 40.6250 (29.4160)\n",
      "[7/25][742/782] Loss_D: -0.0228 (0.3523) Loss_G: -0.1143 (0.1968) D(x): 0.5521 D(G(z)): 0.4745 / 0.4588 Acc: 32.8125 (29.4166)\n",
      "[7/25][743/782] Loss_D: -0.0457 (0.3523) Loss_G: -0.2453 (0.1968) D(x): 0.5774 D(G(z)): 0.4906 / 0.5057 Acc: 39.0625 (29.4181)\n",
      "[7/25][744/782] Loss_D: -0.1652 (0.3522) Loss_G: -0.0461 (0.1967) D(x): 0.5368 D(G(z)): 0.4371 / 0.4297 Acc: 46.8750 (29.4209)\n",
      "[7/25][745/782] Loss_D: 0.0450 (0.3521) Loss_G: -0.0573 (0.1967) D(x): 0.5386 D(G(z)): 0.4529 / 0.4355 Acc: 28.1250 (29.4207)\n",
      "[7/25][746/782] Loss_D: -0.2282 (0.3521) Loss_G: -0.0306 (0.1966) D(x): 0.5754 D(G(z)): 0.4149 / 0.4070 Acc: 40.6250 (29.4225)\n",
      "[7/25][747/782] Loss_D: -0.2539 (0.3520) Loss_G: -0.1709 (0.1966) D(x): 0.5778 D(G(z)): 0.4285 / 0.4637 Acc: 45.3125 (29.4251)\n",
      "[7/25][748/782] Loss_D: 0.0323 (0.3519) Loss_G: -0.2326 (0.1965) D(x): 0.5320 D(G(z)): 0.5105 / 0.4929 Acc: 42.1875 (29.4271)\n",
      "[7/25][749/782] Loss_D: 0.0527 (0.3519) Loss_G: -0.0456 (0.1965) D(x): 0.5546 D(G(z)): 0.4760 / 0.4392 Acc: 29.6875 (29.4272)\n",
      "[7/25][750/782] Loss_D: -0.0663 (0.3518) Loss_G: -0.1097 (0.1964) D(x): 0.5423 D(G(z)): 0.4896 / 0.4496 Acc: 43.7500 (29.4295)\n",
      "[7/25][751/782] Loss_D: -0.0627 (0.3517) Loss_G: -0.1786 (0.1964) D(x): 0.5394 D(G(z)): 0.4780 / 0.4648 Acc: 43.7500 (29.4318)\n",
      "[7/25][752/782] Loss_D: 0.0469 (0.3517) Loss_G: -0.1794 (0.1963) D(x): 0.5235 D(G(z)): 0.4619 / 0.4790 Acc: 34.3750 (29.4326)\n",
      "[7/25][753/782] Loss_D: 0.0398 (0.3516) Loss_G: -0.1256 (0.1962) D(x): 0.5498 D(G(z)): 0.5002 / 0.4353 Acc: 35.9375 (29.4336)\n",
      "[7/25][754/782] Loss_D: -0.0373 (0.3516) Loss_G: -0.0336 (0.1962) D(x): 0.5320 D(G(z)): 0.5045 / 0.4065 Acc: 45.3125 (29.4362)\n",
      "[7/25][755/782] Loss_D: 0.0274 (0.3515) Loss_G: -0.1732 (0.1961) D(x): 0.4932 D(G(z)): 0.4631 / 0.4683 Acc: 37.5000 (29.4374)\n",
      "[7/25][756/782] Loss_D: 0.0992 (0.3515) Loss_G: -0.1617 (0.1961) D(x): 0.5002 D(G(z)): 0.4874 / 0.4679 Acc: 32.8125 (29.4380)\n",
      "[7/25][757/782] Loss_D: 0.0336 (0.3514) Loss_G: -0.1610 (0.1960) D(x): 0.5158 D(G(z)): 0.4883 / 0.4682 Acc: 37.5000 (29.4393)\n",
      "[7/25][758/782] Loss_D: -0.0262 (0.3514) Loss_G: -0.1917 (0.1960) D(x): 0.5160 D(G(z)): 0.4719 / 0.4769 Acc: 43.7500 (29.4416)\n",
      "[7/25][759/782] Loss_D: 0.1194 (0.3513) Loss_G: -0.1222 (0.1959) D(x): 0.5157 D(G(z)): 0.4997 / 0.4527 Acc: 34.3750 (29.4424)\n",
      "[7/25][760/782] Loss_D: 0.0142 (0.3513) Loss_G: -0.2733 (0.1958) D(x): 0.5320 D(G(z)): 0.4642 / 0.5124 Acc: 37.5000 (29.4437)\n",
      "[7/25][761/782] Loss_D: -0.1489 (0.3512) Loss_G: -0.0766 (0.1958) D(x): 0.5772 D(G(z)): 0.4971 / 0.4238 Acc: 46.8750 (29.4465)\n",
      "[7/25][762/782] Loss_D: 0.0057 (0.3511) Loss_G: -0.0547 (0.1958) D(x): 0.5248 D(G(z)): 0.4288 / 0.4182 Acc: 31.2500 (29.4467)\n",
      "[7/25][763/782] Loss_D: -0.0223 (0.3511) Loss_G: -0.0898 (0.1957) D(x): 0.5149 D(G(z)): 0.4397 / 0.4292 Acc: 35.9375 (29.4478)\n",
      "[7/25][764/782] Loss_D: 0.1325 (0.3510) Loss_G: -0.0368 (0.1957) D(x): 0.5255 D(G(z)): 0.4610 / 0.4151 Acc: 21.8750 (29.4466)\n",
      "[7/25][765/782] Loss_D: 0.0171 (0.3510) Loss_G: -0.1571 (0.1956) D(x): 0.5356 D(G(z)): 0.4912 / 0.4587 Acc: 34.3750 (29.4474)\n",
      "[7/25][766/782] Loss_D: -0.1187 (0.3509) Loss_G: -0.1921 (0.1956) D(x): 0.5489 D(G(z)): 0.4481 / 0.4831 Acc: 40.6250 (29.4492)\n",
      "[7/25][767/782] Loss_D: -0.0313 (0.3508) Loss_G: -0.1398 (0.1955) D(x): 0.5127 D(G(z)): 0.4314 / 0.4425 Acc: 35.9375 (29.4502)\n",
      "[7/25][768/782] Loss_D: 0.1786 (0.3508) Loss_G: -0.0483 (0.1955) D(x): 0.5632 D(G(z)): 0.5238 / 0.4112 Acc: 26.5625 (29.4497)\n",
      "[7/25][769/782] Loss_D: -0.0496 (0.3508) Loss_G: -0.0189 (0.1954) D(x): 0.5346 D(G(z)): 0.4581 / 0.4090 Acc: 39.0625 (29.4513)\n",
      "[7/25][770/782] Loss_D: 0.1427 (0.3507) Loss_G: -0.0726 (0.1954) D(x): 0.4888 D(G(z)): 0.4625 / 0.4379 Acc: 32.8125 (29.4518)\n",
      "[7/25][771/782] Loss_D: 0.1298 (0.3507) Loss_G: -0.1569 (0.1953) D(x): 0.5182 D(G(z)): 0.4722 / 0.4688 Acc: 26.5625 (29.4513)\n",
      "[7/25][772/782] Loss_D: -0.0074 (0.3506) Loss_G: -0.1594 (0.1953) D(x): 0.5496 D(G(z)): 0.4614 / 0.4510 Acc: 34.3750 (29.4521)\n",
      "[7/25][773/782] Loss_D: -0.1004 (0.3506) Loss_G: -0.0881 (0.1952) D(x): 0.5622 D(G(z)): 0.4564 / 0.4332 Acc: 42.1875 (29.4542)\n",
      "[7/25][774/782] Loss_D: -0.0459 (0.3505) Loss_G: -0.1900 (0.1952) D(x): 0.5570 D(G(z)): 0.4924 / 0.4648 Acc: 40.6250 (29.4560)\n",
      "[7/25][775/782] Loss_D: 0.1880 (0.3505) Loss_G: -0.0806 (0.1951) D(x): 0.5325 D(G(z)): 0.5326 / 0.4323 Acc: 35.9375 (29.4570)\n",
      "[7/25][776/782] Loss_D: -0.0196 (0.3504) Loss_G: -0.0505 (0.1951) D(x): 0.5191 D(G(z)): 0.4753 / 0.4151 Acc: 46.8750 (29.4598)\n",
      "[7/25][777/782] Loss_D: 0.0142 (0.3504) Loss_G: -0.0759 (0.1950) D(x): 0.5323 D(G(z)): 0.4984 / 0.4373 Acc: 42.1875 (29.4618)\n",
      "[7/25][778/782] Loss_D: 0.1942 (0.3503) Loss_G: -0.0856 (0.1950) D(x): 0.4713 D(G(z)): 0.4613 / 0.4461 Acc: 32.8125 (29.4624)\n",
      "[7/25][779/782] Loss_D: 0.0440 (0.3503) Loss_G: -0.1120 (0.1950) D(x): 0.5041 D(G(z)): 0.4647 / 0.4487 Acc: 34.3750 (29.4631)\n",
      "[7/25][780/782] Loss_D: -0.0627 (0.3502) Loss_G: -0.2130 (0.1949) D(x): 0.5358 D(G(z)): 0.4709 / 0.4921 Acc: 40.6250 (29.4649)\n",
      "[7/25][781/782] Loss_D: 0.0293 (0.3502) Loss_G: -0.1772 (0.1948) D(x): 0.5218 D(G(z)): 0.4201 / 0.5054 Acc: 25.0000 (29.4642)\n",
      "[8/25][0/782] Loss_D: 0.1213 (0.3501) Loss_G: -0.1308 (0.1948) D(x): 0.5690 D(G(z)): 0.5029 / 0.4456 Acc: 25.0000 (29.4635)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/25][1/782] Loss_D: 0.0373 (0.3501) Loss_G: -0.1841 (0.1947) D(x): 0.5253 D(G(z)): 0.4502 / 0.4750 Acc: 31.2500 (29.4638)\n",
      "[8/25][2/782] Loss_D: -0.0402 (0.3500) Loss_G: -0.0704 (0.1947) D(x): 0.5800 D(G(z)): 0.4703 / 0.4352 Acc: 31.2500 (29.4641)\n",
      "[8/25][3/782] Loss_D: -0.0600 (0.3499) Loss_G: -0.0877 (0.1946) D(x): 0.5210 D(G(z)): 0.4409 / 0.4543 Acc: 42.1875 (29.4661)\n",
      "[8/25][4/782] Loss_D: -0.0928 (0.3499) Loss_G: -0.1435 (0.1946) D(x): 0.5295 D(G(z)): 0.4320 / 0.4652 Acc: 40.6250 (29.4679)\n",
      "[8/25][5/782] Loss_D: -0.0162 (0.3498) Loss_G: -0.0553 (0.1945) D(x): 0.5480 D(G(z)): 0.4739 / 0.4311 Acc: 37.5000 (29.4692)\n",
      "[8/25][6/782] Loss_D: -0.0116 (0.3498) Loss_G: 0.0004 (0.1945) D(x): 0.5595 D(G(z)): 0.4746 / 0.4253 Acc: 37.5000 (29.4705)\n",
      "[8/25][7/782] Loss_D: -0.0747 (0.3497) Loss_G: -0.0303 (0.1945) D(x): 0.5606 D(G(z)): 0.4760 / 0.4145 Acc: 37.5000 (29.4717)\n",
      "[8/25][8/782] Loss_D: -0.0664 (0.3496) Loss_G: -0.0782 (0.1944) D(x): 0.4904 D(G(z)): 0.4470 / 0.4319 Acc: 48.4375 (29.4748)\n",
      "[8/25][9/782] Loss_D: -0.1009 (0.3496) Loss_G: -0.0286 (0.1944) D(x): 0.5400 D(G(z)): 0.4900 / 0.4066 Acc: 48.4375 (29.4778)\n",
      "[8/25][10/782] Loss_D: 0.0269 (0.3495) Loss_G: -0.0606 (0.1943) D(x): 0.5132 D(G(z)): 0.4325 / 0.4415 Acc: 35.9375 (29.4788)\n",
      "[8/25][11/782] Loss_D: 0.1998 (0.3495) Loss_G: -0.1212 (0.1943) D(x): 0.4984 D(G(z)): 0.4736 / 0.4403 Acc: 23.4375 (29.4779)\n",
      "[8/25][12/782] Loss_D: 0.0704 (0.3494) Loss_G: -0.1004 (0.1942) D(x): 0.5287 D(G(z)): 0.4764 / 0.4386 Acc: 34.3750 (29.4786)\n",
      "[8/25][13/782] Loss_D: 0.0130 (0.3494) Loss_G: -0.2284 (0.1942) D(x): 0.4999 D(G(z)): 0.4808 / 0.4907 Acc: 42.1875 (29.4807)\n",
      "[8/25][14/782] Loss_D: -0.0111 (0.3493) Loss_G: -0.2538 (0.1941) D(x): 0.4909 D(G(z)): 0.4379 / 0.5025 Acc: 39.0625 (29.4822)\n",
      "[8/25][15/782] Loss_D: 0.1231 (0.3493) Loss_G: -0.2034 (0.1940) D(x): 0.5141 D(G(z)): 0.5333 / 0.4821 Acc: 45.3125 (29.4847)\n",
      "[8/25][16/782] Loss_D: -0.0284 (0.3492) Loss_G: -0.2561 (0.1940) D(x): 0.5029 D(G(z)): 0.4579 / 0.5097 Acc: 48.4375 (29.4877)\n",
      "[8/25][17/782] Loss_D: 0.0109 (0.3492) Loss_G: -0.2363 (0.1939) D(x): 0.5603 D(G(z)): 0.5076 / 0.4891 Acc: 37.5000 (29.4890)\n",
      "[8/25][18/782] Loss_D: 0.1473 (0.3491) Loss_G: -0.2134 (0.1938) D(x): 0.4956 D(G(z)): 0.5155 / 0.4754 Acc: 37.5000 (29.4903)\n",
      "[8/25][19/782] Loss_D: 0.0791 (0.3491) Loss_G: -0.0822 (0.1938) D(x): 0.4782 D(G(z)): 0.4951 / 0.4221 Acc: 50.0000 (29.4936)\n",
      "[8/25][20/782] Loss_D: 0.1442 (0.3491) Loss_G: -0.1345 (0.1937) D(x): 0.4816 D(G(z)): 0.4464 / 0.4592 Acc: 28.1250 (29.4933)\n",
      "[8/25][21/782] Loss_D: -0.0621 (0.3490) Loss_G: -0.0906 (0.1937) D(x): 0.5362 D(G(z)): 0.4949 / 0.4370 Acc: 45.3125 (29.4959)\n",
      "[8/25][22/782] Loss_D: 0.0801 (0.3490) Loss_G: -0.0579 (0.1937) D(x): 0.5384 D(G(z)): 0.4980 / 0.4240 Acc: 32.8125 (29.4964)\n",
      "[8/25][23/782] Loss_D: -0.0093 (0.3489) Loss_G: -0.0362 (0.1936) D(x): 0.5174 D(G(z)): 0.4496 / 0.4100 Acc: 39.0625 (29.4979)\n",
      "[8/25][24/782] Loss_D: -0.0018 (0.3488) Loss_G: -0.0237 (0.1936) D(x): 0.5104 D(G(z)): 0.4549 / 0.4052 Acc: 37.5000 (29.4992)\n",
      "[8/25][25/782] Loss_D: -0.0608 (0.3488) Loss_G: -0.1883 (0.1935) D(x): 0.5019 D(G(z)): 0.4183 / 0.4688 Acc: 40.6250 (29.5010)\n",
      "[8/25][26/782] Loss_D: -0.0244 (0.3487) Loss_G: -0.1339 (0.1935) D(x): 0.5349 D(G(z)): 0.4743 / 0.4440 Acc: 37.5000 (29.5022)\n",
      "[8/25][27/782] Loss_D: -0.0079 (0.3487) Loss_G: -0.2000 (0.1934) D(x): 0.5787 D(G(z)): 0.4887 / 0.4796 Acc: 29.6875 (29.5023)\n",
      "[8/25][28/782] Loss_D: -0.1595 (0.3486) Loss_G: -0.0903 (0.1934) D(x): 0.5908 D(G(z)): 0.4780 / 0.4409 Acc: 42.1875 (29.5043)\n",
      "[8/25][29/782] Loss_D: -0.0694 (0.3485) Loss_G: -0.2156 (0.1933) D(x): 0.5056 D(G(z)): 0.4503 / 0.4759 Acc: 43.7500 (29.5065)\n",
      "[8/25][30/782] Loss_D: -0.0550 (0.3485) Loss_G: -0.1967 (0.1932) D(x): 0.5292 D(G(z)): 0.4637 / 0.4915 Acc: 42.1875 (29.5086)\n",
      "[8/25][31/782] Loss_D: 0.1594 (0.3484) Loss_G: -0.0972 (0.1932) D(x): 0.5184 D(G(z)): 0.5143 / 0.4505 Acc: 35.9375 (29.5096)\n",
      "[8/25][32/782] Loss_D: 0.1887 (0.3484) Loss_G: -0.1593 (0.1931) D(x): 0.5116 D(G(z)): 0.5406 / 0.4572 Acc: 35.9375 (29.5106)\n",
      "[8/25][33/782] Loss_D: 0.0653 (0.3484) Loss_G: -0.1355 (0.1931) D(x): 0.4802 D(G(z)): 0.4785 / 0.4453 Acc: 39.0625 (29.5121)\n",
      "[8/25][34/782] Loss_D: 0.2100 (0.3483) Loss_G: -0.0787 (0.1930) D(x): 0.5044 D(G(z)): 0.5052 / 0.4286 Acc: 28.1250 (29.5119)\n",
      "[8/25][35/782] Loss_D: -0.0021 (0.3483) Loss_G: -0.2369 (0.1930) D(x): 0.4621 D(G(z)): 0.4152 / 0.4888 Acc: 39.0625 (29.5134)\n",
      "[8/25][36/782] Loss_D: 0.0638 (0.3482) Loss_G: -0.1606 (0.1929) D(x): 0.5377 D(G(z)): 0.4969 / 0.4625 Acc: 37.5000 (29.5147)\n",
      "[8/25][37/782] Loss_D: 0.0088 (0.3482) Loss_G: -0.0920 (0.1929) D(x): 0.5500 D(G(z)): 0.4936 / 0.4590 Acc: 40.6250 (29.5165)\n",
      "[8/25][38/782] Loss_D: 0.0046 (0.3481) Loss_G: -0.1143 (0.1928) D(x): 0.5361 D(G(z)): 0.4988 / 0.4385 Acc: 42.1875 (29.5185)\n",
      "[8/25][39/782] Loss_D: 0.0602 (0.3481) Loss_G: -0.0174 (0.1928) D(x): 0.4799 D(G(z)): 0.4233 / 0.4116 Acc: 35.9375 (29.5195)\n",
      "[8/25][40/782] Loss_D: 0.1504 (0.3480) Loss_G: -0.1792 (0.1927) D(x): 0.4988 D(G(z)): 0.4579 / 0.4799 Acc: 29.6875 (29.5195)\n",
      "[8/25][41/782] Loss_D: -0.1342 (0.3480) Loss_G: -0.1906 (0.1927) D(x): 0.5812 D(G(z)): 0.4526 / 0.4779 Acc: 39.0625 (29.5210)\n",
      "[8/25][42/782] Loss_D: 0.0542 (0.3479) Loss_G: -0.0950 (0.1926) D(x): 0.5669 D(G(z)): 0.5109 / 0.4374 Acc: 35.9375 (29.5220)\n",
      "[8/25][43/782] Loss_D: 0.0802 (0.3479) Loss_G: -0.0608 (0.1926) D(x): 0.4962 D(G(z)): 0.4604 / 0.4250 Acc: 39.0625 (29.5236)\n",
      "[8/25][44/782] Loss_D: -0.1300 (0.3478) Loss_G: -0.1187 (0.1925) D(x): 0.5255 D(G(z)): 0.4321 / 0.4470 Acc: 45.3125 (29.5261)\n",
      "[8/25][45/782] Loss_D: -0.2294 (0.3477) Loss_G: -0.0429 (0.1925) D(x): 0.5867 D(G(z)): 0.4855 / 0.4100 Acc: 54.6875 (29.5301)\n",
      "[8/25][46/782] Loss_D: 0.1287 (0.3477) Loss_G: -0.1140 (0.1924) D(x): 0.4906 D(G(z)): 0.4627 / 0.4476 Acc: 32.8125 (29.5306)\n",
      "[8/25][47/782] Loss_D: 0.0585 (0.3476) Loss_G: -0.0399 (0.1924) D(x): 0.5372 D(G(z)): 0.4725 / 0.4166 Acc: 34.3750 (29.5313)\n",
      "[8/25][48/782] Loss_D: 0.0594 (0.3476) Loss_G: -0.1061 (0.1924) D(x): 0.5218 D(G(z)): 0.5057 / 0.4512 Acc: 40.6250 (29.5331)\n",
      "[8/25][49/782] Loss_D: 0.1469 (0.3476) Loss_G: -0.1468 (0.1923) D(x): 0.4907 D(G(z)): 0.4615 / 0.4601 Acc: 34.3750 (29.5339)\n",
      "[8/25][50/782] Loss_D: 0.0701 (0.3475) Loss_G: -0.1775 (0.1923) D(x): 0.5053 D(G(z)): 0.4672 / 0.4690 Acc: 35.9375 (29.5349)\n",
      "[8/25][51/782] Loss_D: 0.0487 (0.3475) Loss_G: -0.1761 (0.1922) D(x): 0.5262 D(G(z)): 0.4668 / 0.4885 Acc: 37.5000 (29.5362)\n",
      "[8/25][52/782] Loss_D: -0.0078 (0.3474) Loss_G: -0.1622 (0.1921) D(x): 0.5536 D(G(z)): 0.4987 / 0.4860 Acc: 34.3750 (29.5369)\n",
      "[8/25][53/782] Loss_D: 0.0300 (0.3474) Loss_G: -0.0960 (0.1921) D(x): 0.5379 D(G(z)): 0.4808 / 0.4378 Acc: 39.0625 (29.5384)\n",
      "[8/25][54/782] Loss_D: 0.1137 (0.3473) Loss_G: -0.1467 (0.1920) D(x): 0.4840 D(G(z)): 0.5175 / 0.4576 Acc: 48.4375 (29.5414)\n",
      "[8/25][55/782] Loss_D: 0.0923 (0.3473) Loss_G: -0.1510 (0.1920) D(x): 0.5124 D(G(z)): 0.4993 / 0.4641 Acc: 37.5000 (29.5427)\n",
      "[8/25][56/782] Loss_D: 0.0378 (0.3472) Loss_G: -0.2115 (0.1919) D(x): 0.4924 D(G(z)): 0.4662 / 0.4915 Acc: 45.3125 (29.5452)\n",
      "[8/25][57/782] Loss_D: 0.1184 (0.3472) Loss_G: -0.2669 (0.1918) D(x): 0.5312 D(G(z)): 0.4955 / 0.5066 Acc: 32.8125 (29.5457)\n",
      "[8/25][58/782] Loss_D: 0.1073 (0.3472) Loss_G: -0.2050 (0.1918) D(x): 0.5148 D(G(z)): 0.5016 / 0.4805 Acc: 35.9375 (29.5467)\n",
      "[8/25][59/782] Loss_D: 0.1363 (0.3471) Loss_G: -0.0557 (0.1917) D(x): 0.5177 D(G(z)): 0.5041 / 0.4251 Acc: 31.2500 (29.5470)\n",
      "[8/25][60/782] Loss_D: -0.1238 (0.3470) Loss_G: -0.1069 (0.1917) D(x): 0.5134 D(G(z)): 0.4431 / 0.4505 Acc: 46.8750 (29.5497)\n",
      "[8/25][61/782] Loss_D: 0.1643 (0.3470) Loss_G: -0.0313 (0.1917) D(x): 0.5094 D(G(z)): 0.5008 / 0.4274 Acc: 31.2500 (29.5500)\n",
      "[8/25][62/782] Loss_D: -0.1321 (0.3469) Loss_G: -0.0912 (0.1916) D(x): 0.4954 D(G(z)): 0.4377 / 0.4285 Acc: 50.0000 (29.5532)\n",
      "[8/25][63/782] Loss_D: 0.0727 (0.3469) Loss_G: -0.1456 (0.1916) D(x): 0.5466 D(G(z)): 0.5104 / 0.4686 Acc: 35.9375 (29.5542)\n",
      "[8/25][64/782] Loss_D: 0.0331 (0.3468) Loss_G: -0.0221 (0.1915) D(x): 0.5407 D(G(z)): 0.4882 / 0.4211 Acc: 40.6250 (29.5560)\n",
      "[8/25][65/782] Loss_D: 0.0142 (0.3468) Loss_G: -0.1287 (0.1915) D(x): 0.5010 D(G(z)): 0.4232 / 0.4662 Acc: 35.9375 (29.5570)\n",
      "[8/25][66/782] Loss_D: 0.0531 (0.3467) Loss_G: -0.1820 (0.1914) D(x): 0.5012 D(G(z)): 0.4863 / 0.4654 Acc: 42.1875 (29.5590)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/25][67/782] Loss_D: -0.0820 (0.3467) Loss_G: -0.1574 (0.1914) D(x): 0.5380 D(G(z)): 0.4952 / 0.4478 Acc: 48.4375 (29.5620)\n",
      "[8/25][68/782] Loss_D: 0.1540 (0.3466) Loss_G: -0.1703 (0.1913) D(x): 0.4856 D(G(z)): 0.4470 / 0.4656 Acc: 29.6875 (29.5620)\n",
      "[8/25][69/782] Loss_D: -0.0537 (0.3466) Loss_G: -0.1688 (0.1913) D(x): 0.5312 D(G(z)): 0.4662 / 0.4704 Acc: 42.1875 (29.5640)\n",
      "[8/25][70/782] Loss_D: 0.1685 (0.3466) Loss_G: -0.2091 (0.1912) D(x): 0.5048 D(G(z)): 0.4929 / 0.4799 Acc: 28.1250 (29.5638)\n",
      "[8/25][71/782] Loss_D: 0.0654 (0.3465) Loss_G: -0.1419 (0.1911) D(x): 0.5298 D(G(z)): 0.4812 / 0.4569 Acc: 35.9375 (29.5648)\n",
      "[8/25][72/782] Loss_D: 0.0467 (0.3465) Loss_G: -0.1146 (0.1911) D(x): 0.5139 D(G(z)): 0.4562 / 0.4511 Acc: 32.8125 (29.5653)\n",
      "[8/25][73/782] Loss_D: 0.0848 (0.3464) Loss_G: -0.2275 (0.1910) D(x): 0.4809 D(G(z)): 0.4737 / 0.4771 Acc: 37.5000 (29.5665)\n",
      "[8/25][74/782] Loss_D: -0.0515 (0.3464) Loss_G: -0.1506 (0.1910) D(x): 0.5484 D(G(z)): 0.4796 / 0.4754 Acc: 39.0625 (29.5680)\n",
      "[8/25][75/782] Loss_D: -0.0157 (0.3463) Loss_G: -0.1432 (0.1909) D(x): 0.5191 D(G(z)): 0.4648 / 0.4481 Acc: 37.5000 (29.5693)\n",
      "[8/25][76/782] Loss_D: 0.0267 (0.3463) Loss_G: -0.1198 (0.1909) D(x): 0.5243 D(G(z)): 0.4881 / 0.4413 Acc: 40.6250 (29.5710)\n",
      "[8/25][77/782] Loss_D: 0.0189 (0.3462) Loss_G: -0.0561 (0.1908) D(x): 0.5164 D(G(z)): 0.4683 / 0.4203 Acc: 34.3750 (29.5718)\n",
      "[8/25][78/782] Loss_D: 0.1778 (0.3462) Loss_G: -0.1244 (0.1908) D(x): 0.5057 D(G(z)): 0.5011 / 0.4442 Acc: 29.6875 (29.5718)\n",
      "[8/25][79/782] Loss_D: -0.1316 (0.3461) Loss_G: -0.0977 (0.1907) D(x): 0.5587 D(G(z)): 0.4474 / 0.4296 Acc: 37.5000 (29.5731)\n",
      "[8/25][80/782] Loss_D: 0.0096 (0.3460) Loss_G: -0.0471 (0.1907) D(x): 0.5039 D(G(z)): 0.4394 / 0.4280 Acc: 37.5000 (29.5743)\n",
      "[8/25][81/782] Loss_D: 0.0418 (0.3460) Loss_G: -0.1499 (0.1906) D(x): 0.5059 D(G(z)): 0.4362 / 0.4501 Acc: 29.6875 (29.5743)\n",
      "[8/25][82/782] Loss_D: 0.1416 (0.3460) Loss_G: -0.1521 (0.1906) D(x): 0.5591 D(G(z)): 0.4927 / 0.4610 Acc: 18.7500 (29.5726)\n",
      "[8/25][83/782] Loss_D: -0.1588 (0.3459) Loss_G: -0.0823 (0.1905) D(x): 0.5603 D(G(z)): 0.4440 / 0.4210 Acc: 35.9375 (29.5736)\n",
      "[8/25][84/782] Loss_D: -0.1180 (0.3458) Loss_G: -0.1585 (0.1905) D(x): 0.5425 D(G(z)): 0.4707 / 0.4776 Acc: 48.4375 (29.5766)\n",
      "[8/25][85/782] Loss_D: -0.0066 (0.3458) Loss_G: -0.2136 (0.1904) D(x): 0.4934 D(G(z)): 0.4321 / 0.4815 Acc: 35.9375 (29.5776)\n",
      "[8/25][86/782] Loss_D: 0.1418 (0.3457) Loss_G: -0.2338 (0.1904) D(x): 0.5450 D(G(z)): 0.4978 / 0.4943 Acc: 26.5625 (29.5771)\n",
      "[8/25][87/782] Loss_D: 0.1593 (0.3457) Loss_G: -0.1465 (0.1903) D(x): 0.5466 D(G(z)): 0.5090 / 0.4620 Acc: 25.0000 (29.5764)\n",
      "[8/25][88/782] Loss_D: 0.0519 (0.3457) Loss_G: -0.1026 (0.1903) D(x): 0.4986 D(G(z)): 0.4800 / 0.4486 Acc: 39.0625 (29.5779)\n",
      "[8/25][89/782] Loss_D: 0.0540 (0.3456) Loss_G: -0.0805 (0.1902) D(x): 0.5418 D(G(z)): 0.4750 / 0.4493 Acc: 39.0625 (29.5794)\n",
      "[8/25][90/782] Loss_D: -0.1149 (0.3455) Loss_G: -0.1511 (0.1902) D(x): 0.5107 D(G(z)): 0.4463 / 0.4521 Acc: 48.4375 (29.5824)\n",
      "[8/25][91/782] Loss_D: 0.1164 (0.3455) Loss_G: -0.2114 (0.1901) D(x): 0.5273 D(G(z)): 0.4884 / 0.4735 Acc: 26.5625 (29.5819)\n",
      "[8/25][92/782] Loss_D: 0.1126 (0.3455) Loss_G: -0.1554 (0.1900) D(x): 0.4679 D(G(z)): 0.4630 / 0.4567 Acc: 37.5000 (29.5832)\n",
      "[8/25][93/782] Loss_D: -0.0071 (0.3454) Loss_G: -0.2481 (0.1900) D(x): 0.5145 D(G(z)): 0.4423 / 0.5125 Acc: 39.0625 (29.5846)\n",
      "[8/25][94/782] Loss_D: 0.0707 (0.3454) Loss_G: -0.2446 (0.1899) D(x): 0.5619 D(G(z)): 0.5306 / 0.5027 Acc: 34.3750 (29.5854)\n",
      "[8/25][95/782] Loss_D: 0.0268 (0.3453) Loss_G: -0.1975 (0.1898) D(x): 0.5541 D(G(z)): 0.5024 / 0.4681 Acc: 34.3750 (29.5862)\n",
      "[8/25][96/782] Loss_D: -0.0914 (0.3452) Loss_G: -0.0558 (0.1898) D(x): 0.4904 D(G(z)): 0.4329 / 0.4344 Acc: 51.5625 (29.5896)\n",
      "[8/25][97/782] Loss_D: -0.0680 (0.3452) Loss_G: -0.0529 (0.1898) D(x): 0.4969 D(G(z)): 0.4419 / 0.4122 Acc: 45.3125 (29.5921)\n",
      "[8/25][98/782] Loss_D: -0.0933 (0.3451) Loss_G: -0.1757 (0.1897) D(x): 0.5337 D(G(z)): 0.4356 / 0.4687 Acc: 40.6250 (29.5938)\n",
      "[8/25][99/782] Loss_D: -0.0328 (0.3450) Loss_G: -0.1476 (0.1897) D(x): 0.5454 D(G(z)): 0.4563 / 0.4538 Acc: 31.2500 (29.5941)\n",
      "[8/25][100/782] Loss_D: 0.0595 (0.3450) Loss_G: -0.1401 (0.1896) D(x): 0.5508 D(G(z)): 0.4684 / 0.4532 Acc: 25.0000 (29.5934)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[8/25][101/782] Loss_D: -0.1342 (0.3449) Loss_G: -0.0695 (0.1896) D(x): 0.5332 D(G(z)): 0.4304 / 0.4311 Acc: 40.6250 (29.5951)\n",
      "[8/25][102/782] Loss_D: 0.1179 (0.3449) Loss_G: -0.0695 (0.1895) D(x): 0.5369 D(G(z)): 0.5180 / 0.4266 Acc: 35.9375 (29.5961)\n",
      "[8/25][103/782] Loss_D: 0.0903 (0.3449) Loss_G: -0.0807 (0.1895) D(x): 0.5021 D(G(z)): 0.4766 / 0.4384 Acc: 32.8125 (29.5966)\n",
      "[8/25][104/782] Loss_D: -0.0174 (0.3448) Loss_G: -0.1531 (0.1894) D(x): 0.4922 D(G(z)): 0.4401 / 0.4672 Acc: 43.7500 (29.5988)\n",
      "[8/25][105/782] Loss_D: -0.0721 (0.3447) Loss_G: -0.0653 (0.1894) D(x): 0.5424 D(G(z)): 0.4848 / 0.4325 Acc: 45.3125 (29.6013)\n",
      "[8/25][106/782] Loss_D: -0.1347 (0.3447) Loss_G: -0.0460 (0.1894) D(x): 0.5268 D(G(z)): 0.4423 / 0.4130 Acc: 45.3125 (29.6038)\n",
      "[8/25][107/782] Loss_D: 0.0630 (0.3446) Loss_G: -0.0797 (0.1893) D(x): 0.5471 D(G(z)): 0.4901 / 0.4344 Acc: 32.8125 (29.6043)\n",
      "[8/25][108/782] Loss_D: 0.0846 (0.3446) Loss_G: -0.0332 (0.1893) D(x): 0.4944 D(G(z)): 0.4881 / 0.4412 Acc: 40.6250 (29.6060)\n",
      "[8/25][109/782] Loss_D: -0.1659 (0.3445) Loss_G: -0.1216 (0.1892) D(x): 0.5445 D(G(z)): 0.4197 / 0.4384 Acc: 43.7500 (29.6082)\n",
      "[8/25][110/782] Loss_D: 0.0482 (0.3444) Loss_G: -0.1042 (0.1892) D(x): 0.5104 D(G(z)): 0.4871 / 0.4373 Acc: 40.6250 (29.6100)\n",
      "[8/25][111/782] Loss_D: 0.0918 (0.3444) Loss_G: -0.1287 (0.1891) D(x): 0.5463 D(G(z)): 0.5042 / 0.4482 Acc: 31.2500 (29.6102)\n",
      "[8/25][112/782] Loss_D: -0.0124 (0.3443) Loss_G: -0.1199 (0.1891) D(x): 0.5273 D(G(z)): 0.4880 / 0.4419 Acc: 42.1875 (29.6122)\n",
      "[8/25][113/782] Loss_D: -0.0023 (0.3443) Loss_G: -0.1163 (0.1890) D(x): 0.5338 D(G(z)): 0.4261 / 0.4330 Acc: 25.0000 (29.6115)\n",
      "[8/25][114/782] Loss_D: 0.0542 (0.3442) Loss_G: -0.1494 (0.1890) D(x): 0.5149 D(G(z)): 0.4660 / 0.4504 Acc: 32.8125 (29.6120)\n",
      "[8/25][115/782] Loss_D: -0.0112 (0.3442) Loss_G: -0.2007 (0.1889) D(x): 0.5117 D(G(z)): 0.4486 / 0.4733 Acc: 37.5000 (29.6132)\n",
      "[8/25][116/782] Loss_D: 0.1420 (0.3442) Loss_G: -0.1807 (0.1889) D(x): 0.5157 D(G(z)): 0.4877 / 0.4807 Acc: 31.2500 (29.6135)\n",
      "[8/25][117/782] Loss_D: 0.1389 (0.3441) Loss_G: -0.1683 (0.1888) D(x): 0.4957 D(G(z)): 0.4992 / 0.4682 Acc: 35.9375 (29.6144)\n",
      "[8/25][118/782] Loss_D: 0.0367 (0.3441) Loss_G: -0.2091 (0.1887) D(x): 0.5204 D(G(z)): 0.4673 / 0.4849 Acc: 32.8125 (29.6150)\n",
      "[8/25][119/782] Loss_D: -0.0118 (0.3440) Loss_G: -0.1083 (0.1887) D(x): 0.5834 D(G(z)): 0.5141 / 0.4534 Acc: 34.3750 (29.6157)\n",
      "[8/25][120/782] Loss_D: -0.0640 (0.3440) Loss_G: -0.1503 (0.1886) D(x): 0.5038 D(G(z)): 0.4396 / 0.4463 Acc: 39.0625 (29.6172)\n",
      "[8/25][121/782] Loss_D: 0.0076 (0.3439) Loss_G: -0.2325 (0.1886) D(x): 0.4672 D(G(z)): 0.4446 / 0.4868 Acc: 42.1875 (29.6191)\n",
      "[8/25][122/782] Loss_D: 0.1353 (0.3439) Loss_G: -0.2522 (0.1885) D(x): 0.5230 D(G(z)): 0.4945 / 0.4974 Acc: 29.6875 (29.6192)\n",
      "[8/25][123/782] Loss_D: -0.0126 (0.3438) Loss_G: -0.2058 (0.1884) D(x): 0.5533 D(G(z)): 0.4796 / 0.4883 Acc: 34.3750 (29.6199)\n",
      "[8/25][124/782] Loss_D: -0.2168 (0.3437) Loss_G: -0.1603 (0.1884) D(x): 0.5894 D(G(z)): 0.4946 / 0.4620 Acc: 57.8125 (29.6243)\n",
      "[8/25][125/782] Loss_D: 0.0597 (0.3437) Loss_G: -0.0921 (0.1883) D(x): 0.5302 D(G(z)): 0.4744 / 0.4390 Acc: 34.3750 (29.6251)\n",
      "[8/25][126/782] Loss_D: 0.1749 (0.3437) Loss_G: -0.1208 (0.1883) D(x): 0.4958 D(G(z)): 0.4798 / 0.4786 Acc: 35.9375 (29.6261)\n",
      "[8/25][127/782] Loss_D: 0.0709 (0.3436) Loss_G: -0.1426 (0.1882) D(x): 0.5301 D(G(z)): 0.4852 / 0.4733 Acc: 34.3750 (29.6268)\n",
      "[8/25][128/782] Loss_D: 0.0332 (0.3436) Loss_G: -0.1290 (0.1882) D(x): 0.5393 D(G(z)): 0.4772 / 0.4488 Acc: 34.3750 (29.6275)\n",
      "[8/25][129/782] Loss_D: 0.2098 (0.3435) Loss_G: -0.1733 (0.1881) D(x): 0.4996 D(G(z)): 0.5340 / 0.4652 Acc: 34.3750 (29.6283)\n",
      "[8/25][130/782] Loss_D: 0.0882 (0.3435) Loss_G: -0.1579 (0.1881) D(x): 0.4726 D(G(z)): 0.4687 / 0.4587 Acc: 40.6250 (29.6300)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/25][131/782] Loss_D: 0.0780 (0.3435) Loss_G: -0.1000 (0.1880) D(x): 0.4950 D(G(z)): 0.4556 / 0.4390 Acc: 29.6875 (29.6300)\n",
      "[8/25][132/782] Loss_D: 0.0636 (0.3434) Loss_G: -0.1920 (0.1880) D(x): 0.5484 D(G(z)): 0.4592 / 0.4821 Acc: 28.1250 (29.6298)\n",
      "[8/25][133/782] Loss_D: 0.1366 (0.3434) Loss_G: -0.1835 (0.1879) D(x): 0.5646 D(G(z)): 0.4906 / 0.4654 Acc: 20.3125 (29.6283)\n",
      "[8/25][134/782] Loss_D: 0.0148 (0.3433) Loss_G: -0.1715 (0.1879) D(x): 0.5409 D(G(z)): 0.4992 / 0.4560 Acc: 40.6250 (29.6300)\n",
      "[8/25][135/782] Loss_D: -0.1903 (0.3433) Loss_G: -0.1155 (0.1878) D(x): 0.5058 D(G(z)): 0.4141 / 0.4341 Acc: 48.4375 (29.6330)\n",
      "[8/25][136/782] Loss_D: -0.0162 (0.3432) Loss_G: -0.1745 (0.1878) D(x): 0.5220 D(G(z)): 0.4582 / 0.4704 Acc: 34.3750 (29.6337)\n",
      "[8/25][137/782] Loss_D: -0.1866 (0.3431) Loss_G: -0.1039 (0.1877) D(x): 0.5331 D(G(z)): 0.4075 / 0.4454 Acc: 43.7500 (29.6359)\n",
      "[8/25][138/782] Loss_D: -0.0077 (0.3431) Loss_G: -0.2459 (0.1876) D(x): 0.5469 D(G(z)): 0.5026 / 0.4955 Acc: 42.1875 (29.6379)\n",
      "[8/25][139/782] Loss_D: -0.0326 (0.3430) Loss_G: -0.2041 (0.1876) D(x): 0.5227 D(G(z)): 0.4504 / 0.4892 Acc: 40.6250 (29.6396)\n",
      "[8/25][140/782] Loss_D: -0.1372 (0.3429) Loss_G: -0.2133 (0.1875) D(x): 0.5471 D(G(z)): 0.4402 / 0.4772 Acc: 40.6250 (29.6413)\n",
      "[8/25][141/782] Loss_D: 0.0742 (0.3429) Loss_G: -0.1614 (0.1875) D(x): 0.5404 D(G(z)): 0.5080 / 0.4615 Acc: 34.3750 (29.6421)\n",
      "[8/25][142/782] Loss_D: 0.1390 (0.3429) Loss_G: -0.1269 (0.1874) D(x): 0.5147 D(G(z)): 0.4665 / 0.4502 Acc: 23.4375 (29.6411)\n",
      "[8/25][143/782] Loss_D: -0.0425 (0.3428) Loss_G: -0.2403 (0.1874) D(x): 0.5469 D(G(z)): 0.4833 / 0.5133 Acc: 40.6250 (29.6428)\n",
      "[8/25][144/782] Loss_D: -0.1377 (0.3427) Loss_G: -0.1286 (0.1873) D(x): 0.5621 D(G(z)): 0.4742 / 0.4412 Acc: 42.1875 (29.6448)\n",
      "[8/25][145/782] Loss_D: 0.0715 (0.3427) Loss_G: -0.1387 (0.1873) D(x): 0.5374 D(G(z)): 0.4833 / 0.4628 Acc: 35.9375 (29.6458)\n",
      "[8/25][146/782] Loss_D: -0.0286 (0.3426) Loss_G: -0.1837 (0.1872) D(x): 0.5505 D(G(z)): 0.4857 / 0.4612 Acc: 37.5000 (29.6470)\n",
      "[8/25][147/782] Loss_D: 0.1016 (0.3426) Loss_G: 0.0073 (0.1872) D(x): 0.4817 D(G(z)): 0.4816 / 0.4005 Acc: 46.8750 (29.6497)\n",
      "[8/25][148/782] Loss_D: 0.1084 (0.3425) Loss_G: -0.1419 (0.1871) D(x): 0.4888 D(G(z)): 0.4512 / 0.4471 Acc: 29.6875 (29.6497)\n",
      "[8/25][149/782] Loss_D: -0.1631 (0.3425) Loss_G: -0.1810 (0.1871) D(x): 0.5176 D(G(z)): 0.4294 / 0.4641 Acc: 45.3125 (29.6521)\n",
      "[8/25][150/782] Loss_D: -0.0225 (0.3424) Loss_G: -0.1465 (0.1870) D(x): 0.6028 D(G(z)): 0.5130 / 0.4592 Acc: 35.9375 (29.6531)\n",
      "[8/25][151/782] Loss_D: 0.2526 (0.3424) Loss_G: -0.1751 (0.1870) D(x): 0.4776 D(G(z)): 0.4706 / 0.4647 Acc: 23.4375 (29.6521)\n",
      "[8/25][152/782] Loss_D: 0.0324 (0.3423) Loss_G: -0.1726 (0.1869) D(x): 0.5212 D(G(z)): 0.4620 / 0.4734 Acc: 35.9375 (29.6531)\n",
      "[8/25][153/782] Loss_D: 0.0535 (0.3423) Loss_G: -0.1860 (0.1868) D(x): 0.5310 D(G(z)): 0.4829 / 0.4833 Acc: 35.9375 (29.6541)\n",
      "[8/25][154/782] Loss_D: 0.1338 (0.3423) Loss_G: -0.2184 (0.1868) D(x): 0.5113 D(G(z)): 0.4886 / 0.4996 Acc: 32.8125 (29.6546)\n",
      "[8/25][155/782] Loss_D: -0.0617 (0.3422) Loss_G: -0.1662 (0.1867) D(x): 0.5480 D(G(z)): 0.4964 / 0.4584 Acc: 45.3125 (29.6570)\n",
      "[8/25][156/782] Loss_D: -0.0250 (0.3421) Loss_G: -0.0194 (0.1867) D(x): 0.5236 D(G(z)): 0.4760 / 0.3989 Acc: 42.1875 (29.6590)\n",
      "[8/25][157/782] Loss_D: -0.1062 (0.3421) Loss_G: -0.0980 (0.1866) D(x): 0.5411 D(G(z)): 0.4246 / 0.4423 Acc: 35.9375 (29.6600)\n",
      "[8/25][158/782] Loss_D: 0.0113 (0.3420) Loss_G: -0.1163 (0.1866) D(x): 0.5080 D(G(z)): 0.4788 / 0.4558 Acc: 40.6250 (29.6617)\n",
      "[8/25][159/782] Loss_D: -0.0080 (0.3420) Loss_G: -0.1793 (0.1865) D(x): 0.5654 D(G(z)): 0.4874 / 0.4853 Acc: 32.8125 (29.6622)\n",
      "[8/25][160/782] Loss_D: 0.0538 (0.3419) Loss_G: -0.1322 (0.1865) D(x): 0.5184 D(G(z)): 0.4999 / 0.4590 Acc: 40.6250 (29.6639)\n",
      "[8/25][161/782] Loss_D: 0.0102 (0.3419) Loss_G: -0.2234 (0.1864) D(x): 0.5289 D(G(z)): 0.4626 / 0.5082 Acc: 32.8125 (29.6644)\n",
      "[8/25][162/782] Loss_D: 0.0848 (0.3418) Loss_G: -0.2638 (0.1864) D(x): 0.5561 D(G(z)): 0.5187 / 0.5067 Acc: 34.3750 (29.6651)\n",
      "[8/25][163/782] Loss_D: 0.0665 (0.3418) Loss_G: -0.1666 (0.1863) D(x): 0.5329 D(G(z)): 0.4641 / 0.4571 Acc: 31.2500 (29.6654)\n",
      "[8/25][164/782] Loss_D: 0.0444 (0.3417) Loss_G: -0.1033 (0.1863) D(x): 0.5399 D(G(z)): 0.5002 / 0.4330 Acc: 40.6250 (29.6671)\n",
      "[8/25][165/782] Loss_D: 0.0060 (0.3417) Loss_G: -0.1098 (0.1862) D(x): 0.4878 D(G(z)): 0.4335 / 0.4326 Acc: 35.9375 (29.6680)\n",
      "[8/25][166/782] Loss_D: 0.1227 (0.3417) Loss_G: -0.1395 (0.1862) D(x): 0.4911 D(G(z)): 0.4643 / 0.4670 Acc: 29.6875 (29.6680)\n",
      "[8/25][167/782] Loss_D: 0.1696 (0.3416) Loss_G: -0.2536 (0.1861) D(x): 0.4766 D(G(z)): 0.4900 / 0.4992 Acc: 34.3750 (29.6688)\n",
      "[8/25][168/782] Loss_D: -0.0061 (0.3416) Loss_G: -0.2023 (0.1860) D(x): 0.5535 D(G(z)): 0.5021 / 0.4777 Acc: 37.5000 (29.6700)\n",
      "[8/25][169/782] Loss_D: 0.0965 (0.3415) Loss_G: -0.0877 (0.1860) D(x): 0.5112 D(G(z)): 0.4823 / 0.4363 Acc: 35.9375 (29.6710)\n",
      "[8/25][170/782] Loss_D: 0.0342 (0.3415) Loss_G: -0.2052 (0.1859) D(x): 0.5007 D(G(z)): 0.4811 / 0.4820 Acc: 40.6250 (29.6727)\n",
      "[8/25][171/782] Loss_D: 0.0836 (0.3415) Loss_G: -0.1454 (0.1859) D(x): 0.5010 D(G(z)): 0.4916 / 0.4554 Acc: 39.0625 (29.6741)\n",
      "[8/25][172/782] Loss_D: -0.0744 (0.3414) Loss_G: -0.1875 (0.1858) D(x): 0.5612 D(G(z)): 0.4306 / 0.4750 Acc: 29.6875 (29.6741)\n",
      "[8/25][173/782] Loss_D: 0.0710 (0.3413) Loss_G: -0.0606 (0.1858) D(x): 0.5283 D(G(z)): 0.4886 / 0.4391 Acc: 37.5000 (29.6753)\n",
      "[8/25][174/782] Loss_D: 0.0607 (0.3413) Loss_G: -0.1131 (0.1857) D(x): 0.5049 D(G(z)): 0.4548 / 0.4519 Acc: 35.9375 (29.6763)\n",
      "[8/25][175/782] Loss_D: 0.0941 (0.3413) Loss_G: -0.1785 (0.1857) D(x): 0.4683 D(G(z)): 0.4840 / 0.4822 Acc: 48.4375 (29.6792)\n",
      "[8/25][176/782] Loss_D: 0.1230 (0.3412) Loss_G: -0.1792 (0.1856) D(x): 0.5553 D(G(z)): 0.5250 / 0.4750 Acc: 34.3750 (29.6800)\n",
      "[8/25][177/782] Loss_D: -0.1324 (0.3412) Loss_G: -0.0369 (0.1856) D(x): 0.5457 D(G(z)): 0.4650 / 0.4084 Acc: 43.7500 (29.6822)\n",
      "[8/25][178/782] Loss_D: 0.0982 (0.3411) Loss_G: -0.0708 (0.1855) D(x): 0.5031 D(G(z)): 0.4864 / 0.4269 Acc: 34.3750 (29.6829)\n",
      "[8/25][179/782] Loss_D: 0.1172 (0.3411) Loss_G: -0.1662 (0.1855) D(x): 0.4764 D(G(z)): 0.4618 / 0.4673 Acc: 35.9375 (29.6839)\n",
      "[8/25][180/782] Loss_D: -0.0073 (0.3410) Loss_G: -0.0936 (0.1854) D(x): 0.5506 D(G(z)): 0.5016 / 0.4394 Acc: 42.1875 (29.6858)\n",
      "[8/25][181/782] Loss_D: -0.0536 (0.3410) Loss_G: -0.2312 (0.1854) D(x): 0.4789 D(G(z)): 0.4219 / 0.4928 Acc: 42.1875 (29.6877)\n",
      "[8/25][182/782] Loss_D: 0.0320 (0.3409) Loss_G: -0.2421 (0.1853) D(x): 0.5651 D(G(z)): 0.5232 / 0.4912 Acc: 34.3750 (29.6885)\n",
      "[8/25][183/782] Loss_D: 0.1765 (0.3409) Loss_G: -0.2393 (0.1852) D(x): 0.5123 D(G(z)): 0.5285 / 0.4951 Acc: 34.3750 (29.6892)\n",
      "[8/25][184/782] Loss_D: -0.0692 (0.3408) Loss_G: -0.1968 (0.1852) D(x): 0.5410 D(G(z)): 0.4612 / 0.4696 Acc: 39.0625 (29.6907)\n",
      "[8/25][185/782] Loss_D: 0.1256 (0.3408) Loss_G: -0.0908 (0.1851) D(x): 0.4937 D(G(z)): 0.4655 / 0.4315 Acc: 32.8125 (29.6911)\n",
      "[8/25][186/782] Loss_D: 0.0040 (0.3407) Loss_G: -0.1791 (0.1851) D(x): 0.4845 D(G(z)): 0.4581 / 0.4661 Acc: 45.3125 (29.6936)\n",
      "[8/25][187/782] Loss_D: -0.0303 (0.3407) Loss_G: -0.1563 (0.1850) D(x): 0.5522 D(G(z)): 0.4599 / 0.4691 Acc: 34.3750 (29.6943)\n",
      "[8/25][188/782] Loss_D: 0.0167 (0.3406) Loss_G: -0.1853 (0.1850) D(x): 0.5088 D(G(z)): 0.4819 / 0.4715 Acc: 43.7500 (29.6965)\n",
      "[8/25][189/782] Loss_D: 0.0165 (0.3406) Loss_G: -0.2569 (0.1849) D(x): 0.5216 D(G(z)): 0.4964 / 0.5155 Acc: 45.3125 (29.6989)\n",
      "[8/25][190/782] Loss_D: -0.1602 (0.3405) Loss_G: -0.1516 (0.1849) D(x): 0.5549 D(G(z)): 0.4599 / 0.4502 Acc: 40.6250 (29.7006)\n",
      "[8/25][191/782] Loss_D: 0.1857 (0.3405) Loss_G: -0.1115 (0.1848) D(x): 0.5165 D(G(z)): 0.5280 / 0.4455 Acc: 34.3750 (29.7013)\n",
      "[8/25][192/782] Loss_D: 0.0802 (0.3404) Loss_G: -0.2231 (0.1847) D(x): 0.5372 D(G(z)): 0.5092 / 0.4783 Acc: 32.8125 (29.7018)\n",
      "[8/25][193/782] Loss_D: -0.0280 (0.3404) Loss_G: -0.0808 (0.1847) D(x): 0.5377 D(G(z)): 0.4640 / 0.4368 Acc: 34.3750 (29.7025)\n",
      "[8/25][194/782] Loss_D: -0.0428 (0.3403) Loss_G: -0.0874 (0.1847) D(x): 0.5474 D(G(z)): 0.4780 / 0.4304 Acc: 40.6250 (29.7042)\n",
      "[8/25][195/782] Loss_D: -0.1489 (0.3403) Loss_G: -0.1177 (0.1846) D(x): 0.5655 D(G(z)): 0.4691 / 0.4472 Acc: 42.1875 (29.7061)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/25][196/782] Loss_D: 0.1561 (0.3402) Loss_G: -0.0826 (0.1846) D(x): 0.5121 D(G(z)): 0.4800 / 0.4303 Acc: 28.1250 (29.7059)\n",
      "[8/25][197/782] Loss_D: 0.0253 (0.3402) Loss_G: -0.0614 (0.1845) D(x): 0.4790 D(G(z)): 0.4618 / 0.4205 Acc: 45.3125 (29.7083)\n",
      "[8/25][198/782] Loss_D: -0.0725 (0.3401) Loss_G: -0.1780 (0.1845) D(x): 0.5437 D(G(z)): 0.4910 / 0.4783 Acc: 45.3125 (29.7107)\n",
      "[8/25][199/782] Loss_D: -0.0980 (0.3400) Loss_G: -0.0983 (0.1844) D(x): 0.5130 D(G(z)): 0.4748 / 0.4418 Acc: 48.4375 (29.7136)\n",
      "[8/25][200/782] Loss_D: -0.0061 (0.3400) Loss_G: -0.2591 (0.1844) D(x): 0.4958 D(G(z)): 0.4696 / 0.5120 Acc: 40.6250 (29.7153)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[8/25][201/782] Loss_D: 0.0499 (0.3399) Loss_G: -0.1857 (0.1843) D(x): 0.5604 D(G(z)): 0.4930 / 0.4676 Acc: 29.6875 (29.7153)\n",
      "[8/25][202/782] Loss_D: -0.0202 (0.3399) Loss_G: -0.1755 (0.1843) D(x): 0.5275 D(G(z)): 0.4663 / 0.4714 Acc: 39.0625 (29.7168)\n",
      "[8/25][203/782] Loss_D: 0.1333 (0.3399) Loss_G: -0.1113 (0.1842) D(x): 0.5297 D(G(z)): 0.4943 / 0.4420 Acc: 34.3750 (29.7175)\n",
      "[8/25][204/782] Loss_D: -0.0011 (0.3398) Loss_G: -0.0948 (0.1842) D(x): 0.5249 D(G(z)): 0.4444 / 0.4378 Acc: 34.3750 (29.7182)\n",
      "[8/25][205/782] Loss_D: 0.0059 (0.3398) Loss_G: -0.1362 (0.1841) D(x): 0.5380 D(G(z)): 0.4990 / 0.4611 Acc: 43.7500 (29.7204)\n",
      "[8/25][206/782] Loss_D: 0.0305 (0.3397) Loss_G: -0.0996 (0.1841) D(x): 0.5502 D(G(z)): 0.4792 / 0.4398 Acc: 34.3750 (29.7211)\n",
      "[8/25][207/782] Loss_D: -0.0032 (0.3397) Loss_G: -0.0656 (0.1840) D(x): 0.5719 D(G(z)): 0.4935 / 0.4238 Acc: 31.2500 (29.7213)\n",
      "[8/25][208/782] Loss_D: -0.0936 (0.3396) Loss_G: -0.0593 (0.1840) D(x): 0.5024 D(G(z)): 0.4225 / 0.4206 Acc: 43.7500 (29.7235)\n",
      "[8/25][209/782] Loss_D: -0.1694 (0.3395) Loss_G: -0.0513 (0.1840) D(x): 0.5513 D(G(z)): 0.4256 / 0.4147 Acc: 37.5000 (29.7247)\n",
      "[8/25][210/782] Loss_D: 0.0378 (0.3395) Loss_G: -0.1506 (0.1839) D(x): 0.4862 D(G(z)): 0.4628 / 0.4622 Acc: 42.1875 (29.7266)\n",
      "[8/25][211/782] Loss_D: 0.0996 (0.3394) Loss_G: -0.1853 (0.1839) D(x): 0.5274 D(G(z)): 0.4884 / 0.4711 Acc: 32.8125 (29.7271)\n",
      "[8/25][212/782] Loss_D: -0.0416 (0.3394) Loss_G: -0.2311 (0.1838) D(x): 0.5463 D(G(z)): 0.4898 / 0.4841 Acc: 39.0625 (29.7286)\n",
      "[8/25][213/782] Loss_D: -0.0292 (0.3393) Loss_G: -0.1777 (0.1837) D(x): 0.5278 D(G(z)): 0.4852 / 0.4586 Acc: 40.6250 (29.7302)\n",
      "[8/25][214/782] Loss_D: 0.0158 (0.3393) Loss_G: -0.0655 (0.1837) D(x): 0.5587 D(G(z)): 0.5108 / 0.4311 Acc: 35.9375 (29.7312)\n",
      "[8/25][215/782] Loss_D: 0.0194 (0.3392) Loss_G: -0.0955 (0.1837) D(x): 0.4710 D(G(z)): 0.4386 / 0.4286 Acc: 43.7500 (29.7334)\n",
      "[8/25][216/782] Loss_D: -0.1757 (0.3391) Loss_G: -0.1245 (0.1836) D(x): 0.5227 D(G(z)): 0.4521 / 0.4467 Acc: 51.5625 (29.7367)\n",
      "[8/25][217/782] Loss_D: 0.0202 (0.3391) Loss_G: -0.1371 (0.1836) D(x): 0.5567 D(G(z)): 0.4882 / 0.4519 Acc: 32.8125 (29.7372)\n",
      "[8/25][218/782] Loss_D: -0.0867 (0.3390) Loss_G: -0.1820 (0.1835) D(x): 0.5457 D(G(z)): 0.4343 / 0.4632 Acc: 34.3750 (29.7379)\n",
      "[8/25][219/782] Loss_D: -0.0687 (0.3389) Loss_G: -0.0915 (0.1835) D(x): 0.5204 D(G(z)): 0.4298 / 0.4374 Acc: 39.0625 (29.7394)\n",
      "[8/25][220/782] Loss_D: 0.0181 (0.3389) Loss_G: -0.1084 (0.1834) D(x): 0.5126 D(G(z)): 0.4569 / 0.4442 Acc: 35.9375 (29.7403)\n",
      "[8/25][221/782] Loss_D: -0.0609 (0.3388) Loss_G: -0.1886 (0.1834) D(x): 0.5118 D(G(z)): 0.4674 / 0.4681 Acc: 45.3125 (29.7427)\n",
      "[8/25][222/782] Loss_D: 0.1372 (0.3388) Loss_G: -0.2367 (0.1833) D(x): 0.5432 D(G(z)): 0.4914 / 0.4901 Acc: 23.4375 (29.7418)\n",
      "[8/25][223/782] Loss_D: -0.0243 (0.3388) Loss_G: -0.1125 (0.1832) D(x): 0.5368 D(G(z)): 0.4958 / 0.4342 Acc: 43.7500 (29.7439)\n",
      "[8/25][224/782] Loss_D: -0.1451 (0.3387) Loss_G: -0.1694 (0.1832) D(x): 0.5288 D(G(z)): 0.4197 / 0.4734 Acc: 40.6250 (29.7456)\n",
      "[8/25][225/782] Loss_D: 0.0402 (0.3386) Loss_G: -0.2208 (0.1831) D(x): 0.5242 D(G(z)): 0.4862 / 0.4832 Acc: 35.9375 (29.7466)\n",
      "[8/25][226/782] Loss_D: -0.0539 (0.3386) Loss_G: -0.1631 (0.1831) D(x): 0.5291 D(G(z)): 0.4497 / 0.4663 Acc: 40.6250 (29.7482)\n",
      "[8/25][227/782] Loss_D: -0.1455 (0.3385) Loss_G: -0.1940 (0.1830) D(x): 0.5808 D(G(z)): 0.4502 / 0.4724 Acc: 35.9375 (29.7492)\n",
      "[8/25][228/782] Loss_D: 0.0632 (0.3385) Loss_G: -0.0723 (0.1830) D(x): 0.5409 D(G(z)): 0.4893 / 0.4402 Acc: 35.9375 (29.7501)\n",
      "[8/25][229/782] Loss_D: 0.0303 (0.3384) Loss_G: -0.1142 (0.1829) D(x): 0.5026 D(G(z)): 0.4548 / 0.4366 Acc: 35.9375 (29.7511)\n",
      "[8/25][230/782] Loss_D: -0.0940 (0.3383) Loss_G: -0.1588 (0.1829) D(x): 0.5267 D(G(z)): 0.4265 / 0.4595 Acc: 35.9375 (29.7521)\n",
      "[8/25][231/782] Loss_D: 0.1279 (0.3383) Loss_G: -0.1709 (0.1828) D(x): 0.5092 D(G(z)): 0.4733 / 0.4778 Acc: 31.2500 (29.7523)\n",
      "[8/25][232/782] Loss_D: -0.0573 (0.3382) Loss_G: -0.2090 (0.1828) D(x): 0.5851 D(G(z)): 0.4966 / 0.4863 Acc: 35.9375 (29.7532)\n",
      "[8/25][233/782] Loss_D: 0.0629 (0.3382) Loss_G: -0.0770 (0.1827) D(x): 0.5139 D(G(z)): 0.4868 / 0.4592 Acc: 42.1875 (29.7552)\n",
      "[8/25][234/782] Loss_D: -0.0225 (0.3381) Loss_G: -0.1143 (0.1827) D(x): 0.4882 D(G(z)): 0.4376 / 0.4647 Acc: 43.7500 (29.7573)\n",
      "[8/25][235/782] Loss_D: 0.0758 (0.3381) Loss_G: -0.1307 (0.1826) D(x): 0.5365 D(G(z)): 0.5006 / 0.4486 Acc: 32.8125 (29.7578)\n",
      "[8/25][236/782] Loss_D: -0.0865 (0.3380) Loss_G: -0.0864 (0.1826) D(x): 0.5630 D(G(z)): 0.4960 / 0.4239 Acc: 42.1875 (29.7597)\n",
      "[8/25][237/782] Loss_D: 0.0052 (0.3380) Loss_G: -0.2191 (0.1825) D(x): 0.4729 D(G(z)): 0.4434 / 0.4951 Acc: 42.1875 (29.7616)\n",
      "[8/25][238/782] Loss_D: -0.0198 (0.3379) Loss_G: -0.1790 (0.1825) D(x): 0.5627 D(G(z)): 0.5146 / 0.4732 Acc: 40.6250 (29.7633)\n",
      "[8/25][239/782] Loss_D: -0.0365 (0.3379) Loss_G: -0.0265 (0.1824) D(x): 0.5076 D(G(z)): 0.4346 / 0.3919 Acc: 37.5000 (29.7645)\n",
      "[8/25][240/782] Loss_D: 0.0503 (0.3378) Loss_G: -0.1591 (0.1824) D(x): 0.4659 D(G(z)): 0.4479 / 0.4667 Acc: 39.0625 (29.7659)\n",
      "[8/25][241/782] Loss_D: -0.0288 (0.3378) Loss_G: -0.0548 (0.1823) D(x): 0.5951 D(G(z)): 0.5226 / 0.4381 Acc: 43.7500 (29.7681)\n",
      "[8/25][242/782] Loss_D: 0.0258 (0.3377) Loss_G: -0.0845 (0.1823) D(x): 0.5254 D(G(z)): 0.4902 / 0.4391 Acc: 40.6250 (29.7697)\n",
      "[8/25][243/782] Loss_D: -0.0296 (0.3377) Loss_G: -0.1312 (0.1823) D(x): 0.4749 D(G(z)): 0.4753 / 0.4654 Acc: 53.1250 (29.7733)\n",
      "[8/25][244/782] Loss_D: 0.0460 (0.3376) Loss_G: -0.1538 (0.1822) D(x): 0.4878 D(G(z)): 0.4566 / 0.4601 Acc: 35.9375 (29.7743)\n",
      "[8/25][245/782] Loss_D: 0.0417 (0.3376) Loss_G: -0.2114 (0.1821) D(x): 0.5197 D(G(z)): 0.4767 / 0.4810 Acc: 35.9375 (29.7752)\n",
      "[8/25][246/782] Loss_D: 0.0479 (0.3375) Loss_G: -0.1405 (0.1821) D(x): 0.5604 D(G(z)): 0.5026 / 0.4562 Acc: 35.9375 (29.7762)\n",
      "[8/25][247/782] Loss_D: 0.1200 (0.3375) Loss_G: -0.1793 (0.1820) D(x): 0.5078 D(G(z)): 0.4854 / 0.4575 Acc: 26.5625 (29.7757)\n",
      "[8/25][248/782] Loss_D: 0.1587 (0.3375) Loss_G: -0.2124 (0.1820) D(x): 0.5010 D(G(z)): 0.5035 / 0.4894 Acc: 32.8125 (29.7761)\n",
      "[8/25][249/782] Loss_D: -0.0590 (0.3374) Loss_G: -0.1860 (0.1819) D(x): 0.5308 D(G(z)): 0.4657 / 0.4566 Acc: 43.7500 (29.7783)\n",
      "[8/25][250/782] Loss_D: -0.2285 (0.3373) Loss_G: -0.1995 (0.1819) D(x): 0.5731 D(G(z)): 0.4562 / 0.4836 Acc: 46.8750 (29.7809)\n",
      "[8/25][251/782] Loss_D: 0.1153 (0.3373) Loss_G: -0.0933 (0.1818) D(x): 0.5113 D(G(z)): 0.4820 / 0.4444 Acc: 32.8125 (29.7814)\n",
      "[8/25][252/782] Loss_D: 0.0292 (0.3372) Loss_G: -0.1558 (0.1818) D(x): 0.5251 D(G(z)): 0.4738 / 0.4465 Acc: 35.9375 (29.7823)\n",
      "[8/25][253/782] Loss_D: 0.1015 (0.3372) Loss_G: -0.0793 (0.1817) D(x): 0.4945 D(G(z)): 0.4625 / 0.4399 Acc: 32.8125 (29.7828)\n",
      "[8/25][254/782] Loss_D: 0.1107 (0.3372) Loss_G: -0.2583 (0.1817) D(x): 0.5426 D(G(z)): 0.4849 / 0.5013 Acc: 28.1250 (29.7825)\n",
      "[8/25][255/782] Loss_D: 0.1114 (0.3371) Loss_G: -0.0780 (0.1816) D(x): 0.5020 D(G(z)): 0.4854 / 0.4371 Acc: 37.5000 (29.7837)\n",
      "[8/25][256/782] Loss_D: 0.0300 (0.3371) Loss_G: -0.2010 (0.1816) D(x): 0.5237 D(G(z)): 0.4391 / 0.5007 Acc: 32.8125 (29.7842)\n",
      "[8/25][257/782] Loss_D: -0.0658 (0.3370) Loss_G: -0.2276 (0.1815) D(x): 0.5323 D(G(z)): 0.4621 / 0.5136 Acc: 40.6250 (29.7858)\n",
      "[8/25][258/782] Loss_D: 0.0109 (0.3370) Loss_G: -0.0984 (0.1815) D(x): 0.5660 D(G(z)): 0.5010 / 0.4597 Acc: 42.1875 (29.7877)\n",
      "[8/25][259/782] Loss_D: -0.0281 (0.3369) Loss_G: -0.0696 (0.1814) D(x): 0.5600 D(G(z)): 0.5002 / 0.4347 Acc: 40.6250 (29.7894)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/25][260/782] Loss_D: -0.0188 (0.3369) Loss_G: -0.1285 (0.1814) D(x): 0.5115 D(G(z)): 0.4287 / 0.4520 Acc: 34.3750 (29.7901)\n",
      "[8/25][261/782] Loss_D: 0.2555 (0.3369) Loss_G: -0.0926 (0.1813) D(x): 0.4786 D(G(z)): 0.4875 / 0.4431 Acc: 28.1250 (29.7899)\n",
      "[8/25][262/782] Loss_D: -0.0575 (0.3368) Loss_G: -0.0798 (0.1813) D(x): 0.5261 D(G(z)): 0.4468 / 0.4415 Acc: 37.5000 (29.7910)\n",
      "[8/25][263/782] Loss_D: -0.1689 (0.3367) Loss_G: -0.1760 (0.1812) D(x): 0.5426 D(G(z)): 0.4641 / 0.4589 Acc: 48.4375 (29.7939)\n",
      "[8/25][264/782] Loss_D: 0.1897 (0.3367) Loss_G: -0.2222 (0.1812) D(x): 0.5009 D(G(z)): 0.5166 / 0.4947 Acc: 39.0625 (29.7953)\n",
      "[8/25][265/782] Loss_D: 0.0157 (0.3366) Loss_G: 0.0143 (0.1811) D(x): 0.5558 D(G(z)): 0.4594 / 0.4112 Acc: 35.9375 (29.7963)\n",
      "[8/25][266/782] Loss_D: -0.0510 (0.3366) Loss_G: -0.2073 (0.1811) D(x): 0.5207 D(G(z)): 0.4431 / 0.4828 Acc: 35.9375 (29.7972)\n",
      "[8/25][267/782] Loss_D: 0.0269 (0.3365) Loss_G: -0.1494 (0.1810) D(x): 0.5471 D(G(z)): 0.5024 / 0.4548 Acc: 35.9375 (29.7981)\n",
      "[8/25][268/782] Loss_D: 0.1388 (0.3365) Loss_G: -0.0958 (0.1810) D(x): 0.4823 D(G(z)): 0.4321 / 0.4505 Acc: 28.1250 (29.7979)\n",
      "[8/25][269/782] Loss_D: -0.0908 (0.3364) Loss_G: -0.1142 (0.1810) D(x): 0.5328 D(G(z)): 0.4721 / 0.4583 Acc: 45.3125 (29.8003)\n",
      "[8/25][270/782] Loss_D: 0.0424 (0.3364) Loss_G: -0.2618 (0.1809) D(x): 0.5531 D(G(z)): 0.5091 / 0.4989 Acc: 35.9375 (29.8012)\n",
      "[8/25][271/782] Loss_D: 0.1127 (0.3364) Loss_G: -0.1912 (0.1808) D(x): 0.5055 D(G(z)): 0.4816 / 0.4814 Acc: 29.6875 (29.8012)\n",
      "[8/25][272/782] Loss_D: -0.0708 (0.3363) Loss_G: -0.1127 (0.1808) D(x): 0.5433 D(G(z)): 0.4615 / 0.4432 Acc: 39.0625 (29.8026)\n",
      "[8/25][273/782] Loss_D: -0.0342 (0.3362) Loss_G: -0.1604 (0.1807) D(x): 0.5014 D(G(z)): 0.4509 / 0.4693 Acc: 39.0625 (29.8040)\n",
      "[8/25][274/782] Loss_D: -0.0860 (0.3362) Loss_G: -0.0533 (0.1807) D(x): 0.5628 D(G(z)): 0.4493 / 0.4225 Acc: 35.9375 (29.8050)\n",
      "[8/25][275/782] Loss_D: 0.0187 (0.3361) Loss_G: -0.0669 (0.1807) D(x): 0.5420 D(G(z)): 0.4695 / 0.4199 Acc: 32.8125 (29.8054)\n",
      "[8/25][276/782] Loss_D: -0.1519 (0.3361) Loss_G: -0.1666 (0.1806) D(x): 0.5213 D(G(z)): 0.4022 / 0.4823 Acc: 39.0625 (29.8068)\n",
      "[8/25][277/782] Loss_D: 0.0969 (0.3360) Loss_G: -0.2009 (0.1805) D(x): 0.5250 D(G(z)): 0.4897 / 0.4935 Acc: 32.8125 (29.8073)\n",
      "[8/25][278/782] Loss_D: -0.0091 (0.3360) Loss_G: -0.0958 (0.1805) D(x): 0.5850 D(G(z)): 0.5330 / 0.4406 Acc: 39.0625 (29.8087)\n",
      "[8/25][279/782] Loss_D: 0.0759 (0.3359) Loss_G: 0.0649 (0.1805) D(x): 0.5155 D(G(z)): 0.4847 / 0.3886 Acc: 37.5000 (29.8099)\n",
      "[8/25][280/782] Loss_D: -0.1406 (0.3359) Loss_G: -0.0168 (0.1805) D(x): 0.5029 D(G(z)): 0.4238 / 0.4108 Acc: 48.4375 (29.8127)\n",
      "[8/25][281/782] Loss_D: 0.1227 (0.3358) Loss_G: -0.0781 (0.1804) D(x): 0.4683 D(G(z)): 0.4412 / 0.4463 Acc: 39.0625 (29.8142)\n",
      "[8/25][282/782] Loss_D: 0.0826 (0.3358) Loss_G: -0.2804 (0.1803) D(x): 0.5237 D(G(z)): 0.5034 / 0.5247 Acc: 35.9375 (29.8151)\n",
      "[8/25][283/782] Loss_D: 0.2190 (0.3358) Loss_G: -0.2768 (0.1803) D(x): 0.5200 D(G(z)): 0.5676 / 0.5298 Acc: 40.6250 (29.8168)\n",
      "[8/25][284/782] Loss_D: -0.0592 (0.3357) Loss_G: -0.0889 (0.1802) D(x): 0.5542 D(G(z)): 0.4827 / 0.4409 Acc: 40.6250 (29.8184)\n",
      "[8/25][285/782] Loss_D: 0.0223 (0.3357) Loss_G: -0.1428 (0.1802) D(x): 0.5295 D(G(z)): 0.4824 / 0.4522 Acc: 42.1875 (29.8203)\n",
      "[8/25][286/782] Loss_D: -0.0531 (0.3356) Loss_G: -0.0390 (0.1801) D(x): 0.5180 D(G(z)): 0.4403 / 0.4128 Acc: 37.5000 (29.8215)\n",
      "[8/25][287/782] Loss_D: -0.0355 (0.3355) Loss_G: -0.1546 (0.1801) D(x): 0.5074 D(G(z)): 0.4729 / 0.4603 Acc: 46.8750 (29.8241)\n",
      "[8/25][288/782] Loss_D: 0.0221 (0.3355) Loss_G: -0.1712 (0.1800) D(x): 0.5173 D(G(z)): 0.4777 / 0.4726 Acc: 40.6250 (29.8257)\n",
      "[8/25][289/782] Loss_D: 0.0936 (0.3355) Loss_G: -0.1517 (0.1800) D(x): 0.5317 D(G(z)): 0.5003 / 0.4732 Acc: 35.9375 (29.8267)\n",
      "[8/25][290/782] Loss_D: 0.0263 (0.3354) Loss_G: -0.2289 (0.1799) D(x): 0.5114 D(G(z)): 0.4669 / 0.4899 Acc: 34.3750 (29.8274)\n",
      "[8/25][291/782] Loss_D: 0.0827 (0.3354) Loss_G: 0.0012 (0.1799) D(x): 0.5386 D(G(z)): 0.4648 / 0.4066 Acc: 23.4375 (29.8264)\n",
      "[8/25][292/782] Loss_D: -0.1187 (0.3353) Loss_G: -0.0336 (0.1799) D(x): 0.5533 D(G(z)): 0.4415 / 0.4354 Acc: 43.7500 (29.8285)\n",
      "[8/25][293/782] Loss_D: 0.0185 (0.3353) Loss_G: -0.0084 (0.1798) D(x): 0.5216 D(G(z)): 0.4712 / 0.4016 Acc: 35.9375 (29.8294)\n",
      "[8/25][294/782] Loss_D: 0.0031 (0.3352) Loss_G: -0.1047 (0.1798) D(x): 0.5580 D(G(z)): 0.4833 / 0.4561 Acc: 34.3750 (29.8301)\n",
      "[8/25][295/782] Loss_D: 0.0599 (0.3352) Loss_G: -0.0979 (0.1798) D(x): 0.4889 D(G(z)): 0.4634 / 0.4429 Acc: 43.7500 (29.8323)\n",
      "[8/25][296/782] Loss_D: -0.1302 (0.3351) Loss_G: -0.1301 (0.1797) D(x): 0.5616 D(G(z)): 0.4920 / 0.4511 Acc: 46.8750 (29.8349)\n",
      "[8/25][297/782] Loss_D: -0.0723 (0.3350) Loss_G: -0.0607 (0.1797) D(x): 0.5204 D(G(z)): 0.4565 / 0.4220 Acc: 42.1875 (29.8367)\n",
      "[8/25][298/782] Loss_D: 0.1772 (0.3350) Loss_G: -0.2466 (0.1796) D(x): 0.4724 D(G(z)): 0.4562 / 0.5366 Acc: 31.2500 (29.8370)\n",
      "[8/25][299/782] Loss_D: 0.0684 (0.3350) Loss_G: -0.2205 (0.1795) D(x): 0.4796 D(G(z)): 0.4549 / 0.5047 Acc: 37.5000 (29.8381)\n",
      "[8/25][300/782] Loss_D: 0.0539 (0.3349) Loss_G: -0.2105 (0.1795) D(x): 0.5645 D(G(z)): 0.5215 / 0.4925 Acc: 34.3750 (29.8388)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[8/25][301/782] Loss_D: 0.3124 (0.3349) Loss_G: -0.1003 (0.1794) D(x): 0.4946 D(G(z)): 0.5126 / 0.4454 Acc: 29.6875 (29.8388)\n",
      "[8/25][302/782] Loss_D: 0.0645 (0.3349) Loss_G: -0.1785 (0.1794) D(x): 0.5384 D(G(z)): 0.4891 / 0.4779 Acc: 37.5000 (29.8400)\n",
      "[8/25][303/782] Loss_D: 0.0643 (0.3348) Loss_G: -0.0808 (0.1793) D(x): 0.5386 D(G(z)): 0.5067 / 0.4362 Acc: 32.8125 (29.8404)\n",
      "[8/25][304/782] Loss_D: -0.1072 (0.3348) Loss_G: -0.1187 (0.1793) D(x): 0.5024 D(G(z)): 0.4330 / 0.4451 Acc: 46.8750 (29.8430)\n",
      "[8/25][305/782] Loss_D: -0.0104 (0.3347) Loss_G: -0.1502 (0.1793) D(x): 0.5234 D(G(z)): 0.4454 / 0.4627 Acc: 34.3750 (29.8437)\n",
      "[8/25][306/782] Loss_D: -0.1212 (0.3346) Loss_G: -0.1993 (0.1792) D(x): 0.5384 D(G(z)): 0.4225 / 0.4836 Acc: 39.0625 (29.8451)\n",
      "[8/25][307/782] Loss_D: -0.0951 (0.3346) Loss_G: -0.1485 (0.1791) D(x): 0.5677 D(G(z)): 0.4656 / 0.4617 Acc: 42.1875 (29.8470)\n",
      "[8/25][308/782] Loss_D: -0.0578 (0.3345) Loss_G: -0.2605 (0.1791) D(x): 0.5314 D(G(z)): 0.4499 / 0.5051 Acc: 34.3750 (29.8477)\n",
      "[8/25][309/782] Loss_D: 0.0734 (0.3345) Loss_G: -0.3192 (0.1790) D(x): 0.5301 D(G(z)): 0.5097 / 0.5259 Acc: 35.9375 (29.8486)\n",
      "[8/25][310/782] Loss_D: 0.0297 (0.3344) Loss_G: -0.0969 (0.1790) D(x): 0.5521 D(G(z)): 0.4726 / 0.4304 Acc: 29.6875 (29.8486)\n",
      "[8/25][311/782] Loss_D: 0.1177 (0.3344) Loss_G: -0.0496 (0.1789) D(x): 0.5192 D(G(z)): 0.4830 / 0.4239 Acc: 28.1250 (29.8483)\n",
      "[8/25][312/782] Loss_D: 0.0164 (0.3344) Loss_G: -0.1468 (0.1789) D(x): 0.4481 D(G(z)): 0.3990 / 0.4589 Acc: 43.7500 (29.8504)\n",
      "[8/25][313/782] Loss_D: 0.0023 (0.3343) Loss_G: -0.1712 (0.1788) D(x): 0.5731 D(G(z)): 0.5195 / 0.4720 Acc: 37.5000 (29.8516)\n",
      "[8/25][314/782] Loss_D: 0.0523 (0.3343) Loss_G: -0.1376 (0.1788) D(x): 0.4859 D(G(z)): 0.4474 / 0.4491 Acc: 39.0625 (29.8530)\n",
      "[8/25][315/782] Loss_D: -0.0237 (0.3342) Loss_G: -0.1684 (0.1787) D(x): 0.5491 D(G(z)): 0.4766 / 0.4562 Acc: 37.5000 (29.8542)\n",
      "[8/25][316/782] Loss_D: 0.0048 (0.3342) Loss_G: -0.2160 (0.1787) D(x): 0.5534 D(G(z)): 0.4918 / 0.4761 Acc: 35.9375 (29.8551)\n",
      "[8/25][317/782] Loss_D: -0.0287 (0.3341) Loss_G: -0.1362 (0.1786) D(x): 0.5403 D(G(z)): 0.4879 / 0.4575 Acc: 42.1875 (29.8570)\n",
      "[8/25][318/782] Loss_D: -0.0553 (0.3340) Loss_G: -0.0038 (0.1786) D(x): 0.5411 D(G(z)): 0.4599 / 0.4126 Acc: 39.0625 (29.8584)\n",
      "[8/25][319/782] Loss_D: 0.1441 (0.3340) Loss_G: -0.1238 (0.1785) D(x): 0.4596 D(G(z)): 0.4729 / 0.4509 Acc: 37.5000 (29.8595)\n",
      "[8/25][320/782] Loss_D: -0.0158 (0.3340) Loss_G: -0.1289 (0.1785) D(x): 0.5341 D(G(z)): 0.4951 / 0.4595 Acc: 43.7500 (29.8616)\n",
      "[8/25][321/782] Loss_D: 0.0791 (0.3339) Loss_G: -0.1700 (0.1784) D(x): 0.5132 D(G(z)): 0.4812 / 0.4797 Acc: 34.3750 (29.8623)\n",
      "[8/25][322/782] Loss_D: 0.1313 (0.3339) Loss_G: -0.1365 (0.1784) D(x): 0.5086 D(G(z)): 0.4925 / 0.4475 Acc: 32.8125 (29.8628)\n",
      "[8/25][323/782] Loss_D: -0.0544 (0.3338) Loss_G: -0.2698 (0.1783) D(x): 0.5064 D(G(z)): 0.4595 / 0.5037 Acc: 43.7500 (29.8649)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/25][324/782] Loss_D: -0.0055 (0.3338) Loss_G: -0.2720 (0.1783) D(x): 0.5166 D(G(z)): 0.4531 / 0.5128 Acc: 34.3750 (29.8656)\n",
      "[8/25][325/782] Loss_D: 0.0606 (0.3337) Loss_G: -0.2481 (0.1782) D(x): 0.5508 D(G(z)): 0.5167 / 0.5073 Acc: 32.8125 (29.8660)\n",
      "[8/25][326/782] Loss_D: 0.0503 (0.3337) Loss_G: -0.0926 (0.1782) D(x): 0.5615 D(G(z)): 0.5327 / 0.4458 Acc: 37.5000 (29.8672)\n",
      "[8/25][327/782] Loss_D: 0.2004 (0.3337) Loss_G: -0.1323 (0.1781) D(x): 0.5190 D(G(z)): 0.4780 / 0.4557 Acc: 20.3125 (29.8657)\n",
      "[8/25][328/782] Loss_D: -0.0805 (0.3336) Loss_G: -0.0382 (0.1781) D(x): 0.5542 D(G(z)): 0.4478 / 0.4043 Acc: 37.5000 (29.8669)\n",
      "[8/25][329/782] Loss_D: -0.1106 (0.3335) Loss_G: -0.0062 (0.1780) D(x): 0.5419 D(G(z)): 0.4079 / 0.3913 Acc: 32.8125 (29.8673)\n",
      "[8/25][330/782] Loss_D: 0.0434 (0.3335) Loss_G: -0.1232 (0.1780) D(x): 0.5203 D(G(z)): 0.4645 / 0.4436 Acc: 31.2500 (29.8675)\n",
      "[8/25][331/782] Loss_D: -0.1919 (0.3334) Loss_G: -0.1118 (0.1780) D(x): 0.5621 D(G(z)): 0.4549 / 0.4351 Acc: 46.8750 (29.8701)\n",
      "[8/25][332/782] Loss_D: -0.0766 (0.3334) Loss_G: -0.0986 (0.1779) D(x): 0.5561 D(G(z)): 0.4834 / 0.4502 Acc: 42.1875 (29.8720)\n",
      "[8/25][333/782] Loss_D: -0.0716 (0.3333) Loss_G: -0.2248 (0.1779) D(x): 0.5118 D(G(z)): 0.4640 / 0.4896 Acc: 45.3125 (29.8743)\n",
      "[8/25][334/782] Loss_D: -0.0326 (0.3332) Loss_G: -0.1956 (0.1778) D(x): 0.5169 D(G(z)): 0.4506 / 0.4661 Acc: 35.9375 (29.8753)\n",
      "[8/25][335/782] Loss_D: -0.1619 (0.3332) Loss_G: -0.2106 (0.1777) D(x): 0.5786 D(G(z)): 0.4964 / 0.4900 Acc: 50.0000 (29.8783)\n",
      "[8/25][336/782] Loss_D: 0.0831 (0.3331) Loss_G: -0.1459 (0.1777) D(x): 0.5265 D(G(z)): 0.4861 / 0.4642 Acc: 31.2500 (29.8785)\n",
      "[8/25][337/782] Loss_D: 0.1360 (0.3331) Loss_G: -0.1446 (0.1776) D(x): 0.5359 D(G(z)): 0.5267 / 0.4721 Acc: 39.0625 (29.8799)\n",
      "[8/25][338/782] Loss_D: 0.0965 (0.3331) Loss_G: -0.1019 (0.1776) D(x): 0.4901 D(G(z)): 0.4570 / 0.4402 Acc: 35.9375 (29.8808)\n",
      "[8/25][339/782] Loss_D: -0.0154 (0.3330) Loss_G: -0.1121 (0.1776) D(x): 0.5227 D(G(z)): 0.4680 / 0.4433 Acc: 42.1875 (29.8827)\n",
      "[8/25][340/782] Loss_D: 0.0639 (0.3330) Loss_G: 0.0223 (0.1775) D(x): 0.5053 D(G(z)): 0.4780 / 0.4213 Acc: 45.3125 (29.8850)\n",
      "[8/25][341/782] Loss_D: 0.2086 (0.3329) Loss_G: -0.1203 (0.1775) D(x): 0.4754 D(G(z)): 0.4447 / 0.4526 Acc: 21.8750 (29.8838)\n",
      "[8/25][342/782] Loss_D: 0.0593 (0.3329) Loss_G: -0.1612 (0.1774) D(x): 0.5320 D(G(z)): 0.4876 / 0.4784 Acc: 35.9375 (29.8847)\n",
      "[8/25][343/782] Loss_D: 0.0319 (0.3329) Loss_G: -0.1133 (0.1774) D(x): 0.5324 D(G(z)): 0.4879 / 0.4444 Acc: 34.3750 (29.8854)\n",
      "[8/25][344/782] Loss_D: 0.0972 (0.3328) Loss_G: -0.1610 (0.1773) D(x): 0.5135 D(G(z)): 0.5077 / 0.4731 Acc: 46.8750 (29.8880)\n",
      "[8/25][345/782] Loss_D: -0.0444 (0.3328) Loss_G: -0.1185 (0.1773) D(x): 0.5170 D(G(z)): 0.4754 / 0.4641 Acc: 45.3125 (29.8903)\n",
      "[8/25][346/782] Loss_D: -0.1028 (0.3327) Loss_G: -0.0623 (0.1773) D(x): 0.5124 D(G(z)): 0.4381 / 0.4170 Acc: 43.7500 (29.8924)\n",
      "[8/25][347/782] Loss_D: -0.1671 (0.3326) Loss_G: -0.0902 (0.1772) D(x): 0.5808 D(G(z)): 0.4630 / 0.4311 Acc: 43.7500 (29.8945)\n",
      "[8/25][348/782] Loss_D: 0.0157 (0.3326) Loss_G: -0.1536 (0.1772) D(x): 0.5001 D(G(z)): 0.4864 / 0.4675 Acc: 45.3125 (29.8969)\n",
      "[8/25][349/782] Loss_D: 0.0612 (0.3325) Loss_G: -0.0738 (0.1771) D(x): 0.5000 D(G(z)): 0.4667 / 0.4396 Acc: 35.9375 (29.8978)\n",
      "[8/25][350/782] Loss_D: -0.0253 (0.3325) Loss_G: -0.1418 (0.1771) D(x): 0.5423 D(G(z)): 0.4576 / 0.4714 Acc: 39.0625 (29.8992)\n",
      "[8/25][351/782] Loss_D: -0.0703 (0.3324) Loss_G: -0.1526 (0.1770) D(x): 0.5716 D(G(z)): 0.4689 / 0.4550 Acc: 34.3750 (29.8998)\n",
      "[8/25][352/782] Loss_D: -0.1194 (0.3324) Loss_G: -0.0209 (0.1770) D(x): 0.5411 D(G(z)): 0.4364 / 0.4179 Acc: 40.6250 (29.9015)\n",
      "[8/25][353/782] Loss_D: -0.1203 (0.3323) Loss_G: -0.1502 (0.1769) D(x): 0.4802 D(G(z)): 0.4025 / 0.4548 Acc: 50.0000 (29.9045)\n",
      "[8/25][354/782] Loss_D: 0.1173 (0.3323) Loss_G: -0.2292 (0.1769) D(x): 0.5097 D(G(z)): 0.5038 / 0.5089 Acc: 39.0625 (29.9059)\n",
      "[8/25][355/782] Loss_D: 0.0544 (0.3322) Loss_G: -0.1703 (0.1768) D(x): 0.6000 D(G(z)): 0.5306 / 0.4720 Acc: 32.8125 (29.9063)\n",
      "[8/25][356/782] Loss_D: -0.1490 (0.3321) Loss_G: -0.0289 (0.1768) D(x): 0.5573 D(G(z)): 0.4368 / 0.4116 Acc: 37.5000 (29.9075)\n",
      "[8/25][357/782] Loss_D: -0.0465 (0.3321) Loss_G: -0.1548 (0.1768) D(x): 0.5131 D(G(z)): 0.4412 / 0.4682 Acc: 43.7500 (29.9096)\n",
      "[8/25][358/782] Loss_D: -0.0843 (0.3320) Loss_G: -0.1789 (0.1767) D(x): 0.5124 D(G(z)): 0.4380 / 0.4773 Acc: 46.8750 (29.9121)\n",
      "[8/25][359/782] Loss_D: 0.0671 (0.3320) Loss_G: -0.1235 (0.1767) D(x): 0.5375 D(G(z)): 0.5018 / 0.4717 Acc: 32.8125 (29.9126)\n",
      "[8/25][360/782] Loss_D: 0.1060 (0.3319) Loss_G: -0.1528 (0.1766) D(x): 0.4993 D(G(z)): 0.4738 / 0.4590 Acc: 32.8125 (29.9130)\n",
      "[8/25][361/782] Loss_D: 0.0758 (0.3319) Loss_G: -0.2174 (0.1765) D(x): 0.4764 D(G(z)): 0.5058 / 0.4964 Acc: 50.0000 (29.9160)\n",
      "[8/25][362/782] Loss_D: -0.0138 (0.3319) Loss_G: -0.2562 (0.1765) D(x): 0.5175 D(G(z)): 0.4793 / 0.5030 Acc: 45.3125 (29.9184)\n",
      "[8/25][363/782] Loss_D: -0.0394 (0.3318) Loss_G: -0.2645 (0.1764) D(x): 0.5773 D(G(z)): 0.4911 / 0.4984 Acc: 34.3750 (29.9190)\n",
      "[8/25][364/782] Loss_D: 0.0085 (0.3317) Loss_G: -0.0676 (0.1764) D(x): 0.5498 D(G(z)): 0.4708 / 0.4266 Acc: 34.3750 (29.9197)\n",
      "[8/25][365/782] Loss_D: 0.0266 (0.3317) Loss_G: -0.1061 (0.1763) D(x): 0.5416 D(G(z)): 0.4687 / 0.4420 Acc: 35.9375 (29.9206)\n",
      "[8/25][366/782] Loss_D: 0.0271 (0.3317) Loss_G: 0.0085 (0.1763) D(x): 0.5563 D(G(z)): 0.4811 / 0.4099 Acc: 32.8125 (29.9211)\n",
      "[8/25][367/782] Loss_D: 0.0472 (0.3316) Loss_G: -0.1694 (0.1763) D(x): 0.4401 D(G(z)): 0.3991 / 0.4551 Acc: 40.6250 (29.9227)\n",
      "[8/25][368/782] Loss_D: 0.0370 (0.3316) Loss_G: -0.1658 (0.1762) D(x): 0.5471 D(G(z)): 0.4629 / 0.4576 Acc: 28.1250 (29.9224)\n",
      "[8/25][369/782] Loss_D: 0.0140 (0.3315) Loss_G: -0.0551 (0.1762) D(x): 0.5252 D(G(z)): 0.4992 / 0.4277 Acc: 42.1875 (29.9243)\n",
      "[8/25][370/782] Loss_D: -0.0828 (0.3315) Loss_G: -0.1671 (0.1761) D(x): 0.5316 D(G(z)): 0.4375 / 0.4700 Acc: 35.9375 (29.9252)\n",
      "[8/25][371/782] Loss_D: 0.0108 (0.3314) Loss_G: -0.1427 (0.1761) D(x): 0.5471 D(G(z)): 0.5189 / 0.4572 Acc: 39.0625 (29.9265)\n",
      "[8/25][372/782] Loss_D: -0.0042 (0.3314) Loss_G: -0.1773 (0.1760) D(x): 0.5460 D(G(z)): 0.5057 / 0.4688 Acc: 39.0625 (29.9279)\n",
      "[8/25][373/782] Loss_D: -0.0112 (0.3313) Loss_G: -0.1594 (0.1760) D(x): 0.5140 D(G(z)): 0.4546 / 0.4740 Acc: 37.5000 (29.9291)\n",
      "[8/25][374/782] Loss_D: 0.0234 (0.3313) Loss_G: -0.0844 (0.1759) D(x): 0.5143 D(G(z)): 0.5042 / 0.4417 Acc: 45.3125 (29.9314)\n",
      "[8/25][375/782] Loss_D: -0.0718 (0.3312) Loss_G: -0.1183 (0.1759) D(x): 0.5261 D(G(z)): 0.4466 / 0.4511 Acc: 40.6250 (29.9330)\n",
      "[8/25][376/782] Loss_D: -0.1237 (0.3311) Loss_G: -0.1852 (0.1758) D(x): 0.5278 D(G(z)): 0.4450 / 0.4810 Acc: 46.8750 (29.9355)\n",
      "[8/25][377/782] Loss_D: 0.0751 (0.3311) Loss_G: -0.2034 (0.1758) D(x): 0.5411 D(G(z)): 0.4675 / 0.4762 Acc: 25.0000 (29.9348)\n",
      "[8/25][378/782] Loss_D: -0.0373 (0.3310) Loss_G: -0.2011 (0.1757) D(x): 0.5485 D(G(z)): 0.4675 / 0.4766 Acc: 35.9375 (29.9357)\n",
      "[8/25][379/782] Loss_D: -0.0854 (0.3310) Loss_G: -0.2836 (0.1756) D(x): 0.5118 D(G(z)): 0.4421 / 0.5123 Acc: 43.7500 (29.9378)\n",
      "[8/25][380/782] Loss_D: -0.0709 (0.3309) Loss_G: -0.1956 (0.1756) D(x): 0.5737 D(G(z)): 0.5084 / 0.4703 Acc: 42.1875 (29.9396)\n",
      "[8/25][381/782] Loss_D: -0.0408 (0.3309) Loss_G: -0.0630 (0.1756) D(x): 0.5025 D(G(z)): 0.4862 / 0.4252 Acc: 51.5625 (29.9429)\n",
      "[8/25][382/782] Loss_D: 0.0660 (0.3308) Loss_G: -0.1550 (0.1755) D(x): 0.5177 D(G(z)): 0.4988 / 0.4543 Acc: 40.6250 (29.9445)\n",
      "[8/25][383/782] Loss_D: -0.1236 (0.3308) Loss_G: -0.0599 (0.1755) D(x): 0.5072 D(G(z)): 0.4515 / 0.4174 Acc: 46.8750 (29.9471)\n",
      "[8/25][384/782] Loss_D: 0.0240 (0.3307) Loss_G: -0.1974 (0.1754) D(x): 0.5560 D(G(z)): 0.4751 / 0.4756 Acc: 29.6875 (29.9470)\n",
      "[8/25][385/782] Loss_D: -0.1433 (0.3306) Loss_G: -0.1717 (0.1754) D(x): 0.5446 D(G(z)): 0.4629 / 0.4592 Acc: 45.3125 (29.9493)\n",
      "[8/25][386/782] Loss_D: 0.0187 (0.3306) Loss_G: -0.1085 (0.1753) D(x): 0.5243 D(G(z)): 0.4869 / 0.4632 Acc: 39.0625 (29.9507)\n",
      "[8/25][387/782] Loss_D: -0.0315 (0.3305) Loss_G: -0.1602 (0.1753) D(x): 0.5157 D(G(z)): 0.4380 / 0.4628 Acc: 37.5000 (29.9518)\n",
      "[8/25][388/782] Loss_D: -0.1630 (0.3305) Loss_G: -0.1764 (0.1752) D(x): 0.5391 D(G(z)): 0.4529 / 0.4782 Acc: 45.3125 (29.9541)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/25][389/782] Loss_D: -0.0902 (0.3304) Loss_G: -0.1081 (0.1752) D(x): 0.6028 D(G(z)): 0.4997 / 0.4480 Acc: 40.6250 (29.9558)\n",
      "[8/25][390/782] Loss_D: -0.0601 (0.3303) Loss_G: 0.0187 (0.1751) D(x): 0.5331 D(G(z)): 0.4622 / 0.4103 Acc: 37.5000 (29.9569)\n",
      "[8/25][391/782] Loss_D: -0.0606 (0.3303) Loss_G: -0.1719 (0.1751) D(x): 0.5041 D(G(z)): 0.4418 / 0.4752 Acc: 42.1875 (29.9587)\n",
      "[8/25][392/782] Loss_D: -0.0427 (0.3302) Loss_G: -0.0127 (0.1751) D(x): 0.5371 D(G(z)): 0.4539 / 0.4306 Acc: 42.1875 (29.9606)\n",
      "[8/25][393/782] Loss_D: 0.0568 (0.3302) Loss_G: -0.1097 (0.1750) D(x): 0.5128 D(G(z)): 0.4504 / 0.4495 Acc: 31.2500 (29.9608)\n",
      "[8/25][394/782] Loss_D: -0.1214 (0.3301) Loss_G: -0.1250 (0.1750) D(x): 0.5693 D(G(z)): 0.4618 / 0.4697 Acc: 40.6250 (29.9624)\n",
      "[8/25][395/782] Loss_D: 0.1652 (0.3301) Loss_G: -0.2128 (0.1749) D(x): 0.5177 D(G(z)): 0.4937 / 0.4929 Acc: 28.1250 (29.9621)\n",
      "[8/25][396/782] Loss_D: -0.0540 (0.3300) Loss_G: -0.2028 (0.1749) D(x): 0.5926 D(G(z)): 0.5243 / 0.4835 Acc: 40.6250 (29.9637)\n",
      "[8/25][397/782] Loss_D: 0.0026 (0.3300) Loss_G: -0.1048 (0.1748) D(x): 0.5042 D(G(z)): 0.4543 / 0.4524 Acc: 40.6250 (29.9653)\n",
      "[8/25][398/782] Loss_D: 0.2308 (0.3300) Loss_G: -0.1913 (0.1748) D(x): 0.4520 D(G(z)): 0.4682 / 0.4886 Acc: 35.9375 (29.9662)\n",
      "[8/25][399/782] Loss_D: 0.0471 (0.3299) Loss_G: -0.0606 (0.1747) D(x): 0.5093 D(G(z)): 0.4734 / 0.4398 Acc: 37.5000 (29.9673)\n",
      "[8/25][400/782] Loss_D: -0.0083 (0.3299) Loss_G: -0.1950 (0.1747) D(x): 0.5320 D(G(z)): 0.4734 / 0.4757 Acc: 35.9375 (29.9682)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[8/25][401/782] Loss_D: 0.0472 (0.3298) Loss_G: -0.2248 (0.1746) D(x): 0.5519 D(G(z)): 0.5119 / 0.4931 Acc: 39.0625 (29.9696)\n",
      "[8/25][402/782] Loss_D: 0.0683 (0.3298) Loss_G: -0.1756 (0.1746) D(x): 0.5682 D(G(z)): 0.5076 / 0.4692 Acc: 29.6875 (29.9695)\n",
      "[8/25][403/782] Loss_D: 0.0740 (0.3298) Loss_G: -0.1228 (0.1745) D(x): 0.4924 D(G(z)): 0.4475 / 0.4397 Acc: 35.9375 (29.9704)\n",
      "[8/25][404/782] Loss_D: -0.0300 (0.3297) Loss_G: -0.1125 (0.1745) D(x): 0.5156 D(G(z)): 0.4652 / 0.4353 Acc: 40.6250 (29.9720)\n",
      "[8/25][405/782] Loss_D: -0.1392 (0.3296) Loss_G: -0.0620 (0.1744) D(x): 0.5350 D(G(z)): 0.4381 / 0.4115 Acc: 46.8750 (29.9746)\n",
      "[8/25][406/782] Loss_D: 0.0135 (0.3296) Loss_G: -0.1943 (0.1744) D(x): 0.4898 D(G(z)): 0.4543 / 0.4727 Acc: 40.6250 (29.9762)\n",
      "[8/25][407/782] Loss_D: -0.0106 (0.3295) Loss_G: -0.0429 (0.1744) D(x): 0.5850 D(G(z)): 0.4943 / 0.4211 Acc: 35.9375 (29.9771)\n",
      "[8/25][408/782] Loss_D: -0.1004 (0.3295) Loss_G: -0.1073 (0.1743) D(x): 0.5230 D(G(z)): 0.4747 / 0.4321 Acc: 50.0000 (29.9801)\n",
      "[8/25][409/782] Loss_D: 0.0822 (0.3294) Loss_G: -0.0880 (0.1743) D(x): 0.5207 D(G(z)): 0.4406 / 0.4465 Acc: 31.2500 (29.9803)\n",
      "[8/25][410/782] Loss_D: 0.1397 (0.3294) Loss_G: -0.0099 (0.1742) D(x): 0.5177 D(G(z)): 0.4774 / 0.4195 Acc: 28.1250 (29.9800)\n",
      "[8/25][411/782] Loss_D: 0.1161 (0.3294) Loss_G: -0.1342 (0.1742) D(x): 0.4850 D(G(z)): 0.4608 / 0.4605 Acc: 39.0625 (29.9813)\n",
      "[8/25][412/782] Loss_D: -0.0078 (0.3293) Loss_G: -0.1691 (0.1741) D(x): 0.4941 D(G(z)): 0.4383 / 0.4698 Acc: 40.6250 (29.9829)\n",
      "[8/25][413/782] Loss_D: 0.0871 (0.3293) Loss_G: -0.2820 (0.1741) D(x): 0.5420 D(G(z)): 0.4940 / 0.5200 Acc: 34.3750 (29.9836)\n",
      "[8/25][414/782] Loss_D: 0.0702 (0.3292) Loss_G: -0.1642 (0.1740) D(x): 0.6116 D(G(z)): 0.5410 / 0.4597 Acc: 32.8125 (29.9840)\n",
      "[8/25][415/782] Loss_D: -0.0098 (0.3292) Loss_G: -0.0246 (0.1740) D(x): 0.5398 D(G(z)): 0.4818 / 0.4034 Acc: 37.5000 (29.9852)\n",
      "[8/25][416/782] Loss_D: 0.0803 (0.3292) Loss_G: -0.1482 (0.1739) D(x): 0.4827 D(G(z)): 0.4075 / 0.4640 Acc: 25.0000 (29.9844)\n",
      "[8/25][417/782] Loss_D: -0.0302 (0.3291) Loss_G: -0.1383 (0.1739) D(x): 0.5084 D(G(z)): 0.4426 / 0.4574 Acc: 40.6250 (29.9860)\n",
      "[8/25][418/782] Loss_D: -0.0844 (0.3290) Loss_G: -0.1368 (0.1739) D(x): 0.5680 D(G(z)): 0.4899 / 0.4511 Acc: 40.6250 (29.9876)\n",
      "[8/25][419/782] Loss_D: 0.0847 (0.3290) Loss_G: -0.2349 (0.1738) D(x): 0.4815 D(G(z)): 0.4708 / 0.4828 Acc: 34.3750 (29.9883)\n",
      "[8/25][420/782] Loss_D: 0.0062 (0.3290) Loss_G: -0.1352 (0.1737) D(x): 0.5544 D(G(z)): 0.4927 / 0.4474 Acc: 37.5000 (29.9894)\n",
      "[8/25][421/782] Loss_D: 0.0751 (0.3289) Loss_G: -0.0907 (0.1737) D(x): 0.4980 D(G(z)): 0.4544 / 0.4381 Acc: 34.3750 (29.9900)\n",
      "[8/25][422/782] Loss_D: 0.1735 (0.3289) Loss_G: -0.1749 (0.1737) D(x): 0.5045 D(G(z)): 0.4794 / 0.4709 Acc: 29.6875 (29.9900)\n",
      "[8/25][423/782] Loss_D: 0.0407 (0.3288) Loss_G: -0.0916 (0.1736) D(x): 0.5102 D(G(z)): 0.4605 / 0.4643 Acc: 34.3750 (29.9906)\n",
      "[8/25][424/782] Loss_D: -0.1340 (0.3288) Loss_G: -0.2114 (0.1736) D(x): 0.5500 D(G(z)): 0.4683 / 0.4832 Acc: 43.7500 (29.9927)\n",
      "[8/25][425/782] Loss_D: -0.1775 (0.3287) Loss_G: 0.0312 (0.1735) D(x): 0.5953 D(G(z)): 0.4876 / 0.4105 Acc: 46.8750 (29.9952)\n",
      "[8/25][426/782] Loss_D: -0.1736 (0.3286) Loss_G: 0.0533 (0.1735) D(x): 0.5523 D(G(z)): 0.4280 / 0.3960 Acc: 46.8750 (29.9978)\n",
      "[8/25][427/782] Loss_D: -0.0978 (0.3286) Loss_G: -0.1310 (0.1735) D(x): 0.5056 D(G(z)): 0.4000 / 0.4484 Acc: 43.7500 (29.9998)\n",
      "[8/25][428/782] Loss_D: -0.0334 (0.3285) Loss_G: -0.1250 (0.1734) D(x): 0.5698 D(G(z)): 0.5106 / 0.4543 Acc: 42.1875 (30.0016)\n",
      "[8/25][429/782] Loss_D: 0.0840 (0.3285) Loss_G: -0.0518 (0.1734) D(x): 0.5438 D(G(z)): 0.4693 / 0.4239 Acc: 23.4375 (30.0007)\n",
      "[8/25][430/782] Loss_D: -0.0537 (0.3284) Loss_G: -0.1431 (0.1733) D(x): 0.5357 D(G(z)): 0.4495 / 0.4670 Acc: 35.9375 (30.0015)\n",
      "[8/25][431/782] Loss_D: -0.0310 (0.3284) Loss_G: -0.1286 (0.1733) D(x): 0.5340 D(G(z)): 0.4368 / 0.4503 Acc: 31.2500 (30.0017)\n",
      "[8/25][432/782] Loss_D: 0.0850 (0.3283) Loss_G: -0.2258 (0.1732) D(x): 0.5365 D(G(z)): 0.5037 / 0.4829 Acc: 32.8125 (30.0021)\n",
      "[8/25][433/782] Loss_D: -0.1268 (0.3283) Loss_G: -0.1609 (0.1732) D(x): 0.4946 D(G(z)): 0.4457 / 0.4555 Acc: 48.4375 (30.0049)\n",
      "[8/25][434/782] Loss_D: -0.0648 (0.3282) Loss_G: 0.0158 (0.1732) D(x): 0.5607 D(G(z)): 0.4876 / 0.3995 Acc: 42.1875 (30.0067)\n",
      "[8/25][435/782] Loss_D: -0.0954 (0.3281) Loss_G: -0.0889 (0.1731) D(x): 0.5078 D(G(z)): 0.4323 / 0.4450 Acc: 42.1875 (30.0085)\n",
      "[8/25][436/782] Loss_D: 0.0109 (0.3281) Loss_G: -0.1308 (0.1731) D(x): 0.5231 D(G(z)): 0.4655 / 0.4438 Acc: 32.8125 (30.0090)\n",
      "[8/25][437/782] Loss_D: -0.0987 (0.3280) Loss_G: -0.1293 (0.1730) D(x): 0.5180 D(G(z)): 0.4481 / 0.4486 Acc: 46.8750 (30.0115)\n",
      "[8/25][438/782] Loss_D: -0.0290 (0.3280) Loss_G: -0.2089 (0.1730) D(x): 0.5535 D(G(z)): 0.4911 / 0.4926 Acc: 42.1875 (30.0133)\n",
      "[8/25][439/782] Loss_D: 0.1263 (0.3279) Loss_G: -0.0892 (0.1729) D(x): 0.5535 D(G(z)): 0.5497 / 0.4415 Acc: 34.3750 (30.0140)\n",
      "[8/25][440/782] Loss_D: -0.0498 (0.3279) Loss_G: 0.0201 (0.1729) D(x): 0.5534 D(G(z)): 0.4632 / 0.3975 Acc: 42.1875 (30.0158)\n",
      "[8/25][441/782] Loss_D: 0.0923 (0.3278) Loss_G: -0.1017 (0.1729) D(x): 0.5068 D(G(z)): 0.4347 / 0.4314 Acc: 26.5625 (30.0153)\n",
      "[8/25][442/782] Loss_D: 0.2387 (0.3278) Loss_G: -0.1657 (0.1728) D(x): 0.4604 D(G(z)): 0.4927 / 0.4872 Acc: 43.7500 (30.0173)\n",
      "[8/25][443/782] Loss_D: -0.0483 (0.3278) Loss_G: -0.0288 (0.1728) D(x): 0.5426 D(G(z)): 0.4774 / 0.4177 Acc: 40.6250 (30.0189)\n",
      "[8/25][444/782] Loss_D: 0.1419 (0.3278) Loss_G: -0.0491 (0.1728) D(x): 0.5363 D(G(z)): 0.4952 / 0.4138 Acc: 29.6875 (30.0188)\n",
      "[8/25][445/782] Loss_D: -0.0382 (0.3277) Loss_G: -0.0487 (0.1727) D(x): 0.4627 D(G(z)): 0.4242 / 0.4180 Acc: 42.1875 (30.0207)\n",
      "[8/25][446/782] Loss_D: 0.1109 (0.3277) Loss_G: -0.2688 (0.1727) D(x): 0.5167 D(G(z)): 0.4984 / 0.5139 Acc: 32.8125 (30.0211)\n",
      "[8/25][447/782] Loss_D: -0.0288 (0.3276) Loss_G: -0.2113 (0.1726) D(x): 0.5496 D(G(z)): 0.5291 / 0.5040 Acc: 51.5625 (30.0243)\n",
      "[8/25][448/782] Loss_D: -0.0606 (0.3276) Loss_G: 0.0428 (0.1726) D(x): 0.5743 D(G(z)): 0.5293 / 0.3896 Acc: 46.8750 (30.0268)\n",
      "[8/25][449/782] Loss_D: 0.1333 (0.3275) Loss_G: -0.0577 (0.1726) D(x): 0.4555 D(G(z)): 0.4367 / 0.4302 Acc: 32.8125 (30.0272)\n",
      "[8/25][450/782] Loss_D: 0.0267 (0.3275) Loss_G: -0.2247 (0.1725) D(x): 0.4884 D(G(z)): 0.4577 / 0.4841 Acc: 40.6250 (30.0288)\n",
      "[8/25][451/782] Loss_D: 0.1012 (0.3274) Loss_G: -0.2919 (0.1724) D(x): 0.5209 D(G(z)): 0.5228 / 0.5285 Acc: 39.0625 (30.0301)\n",
      "[8/25][452/782] Loss_D: -0.0919 (0.3274) Loss_G: -0.0688 (0.1724) D(x): 0.5530 D(G(z)): 0.4522 / 0.4436 Acc: 39.0625 (30.0315)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/25][453/782] Loss_D: -0.2879 (0.3273) Loss_G: -0.1114 (0.1723) D(x): 0.5477 D(G(z)): 0.3939 / 0.4504 Acc: 45.3125 (30.0338)\n",
      "[8/25][454/782] Loss_D: -0.0240 (0.3272) Loss_G: -0.0841 (0.1723) D(x): 0.5793 D(G(z)): 0.4777 / 0.4449 Acc: 28.1250 (30.0335)\n",
      "[8/25][455/782] Loss_D: 0.1505 (0.3272) Loss_G: -0.1105 (0.1723) D(x): 0.5238 D(G(z)): 0.5211 / 0.4541 Acc: 42.1875 (30.0353)\n",
      "[8/25][456/782] Loss_D: -0.0757 (0.3272) Loss_G: -0.0674 (0.1722) D(x): 0.5230 D(G(z)): 0.4462 / 0.4454 Acc: 40.6250 (30.0369)\n",
      "[8/25][457/782] Loss_D: 0.0332 (0.3271) Loss_G: -0.0938 (0.1722) D(x): 0.4970 D(G(z)): 0.4577 / 0.4493 Acc: 37.5000 (30.0380)\n",
      "[8/25][458/782] Loss_D: -0.0663 (0.3271) Loss_G: -0.1613 (0.1721) D(x): 0.5578 D(G(z)): 0.4544 / 0.4725 Acc: 37.5000 (30.0391)\n",
      "[8/25][459/782] Loss_D: 0.0087 (0.3270) Loss_G: -0.1715 (0.1721) D(x): 0.5594 D(G(z)): 0.4846 / 0.4595 Acc: 34.3750 (30.0397)\n",
      "[8/25][460/782] Loss_D: -0.0749 (0.3269) Loss_G: -0.0894 (0.1721) D(x): 0.5354 D(G(z)): 0.4386 / 0.4358 Acc: 37.5000 (30.0408)\n",
      "[8/25][461/782] Loss_D: 0.0765 (0.3269) Loss_G: -0.1151 (0.1720) D(x): 0.5358 D(G(z)): 0.4531 / 0.4607 Acc: 28.1250 (30.0406)\n",
      "[8/25][462/782] Loss_D: -0.0210 (0.3269) Loss_G: -0.0996 (0.1720) D(x): 0.5613 D(G(z)): 0.4605 / 0.4595 Acc: 35.9375 (30.0414)\n",
      "[8/25][463/782] Loss_D: 0.0765 (0.3268) Loss_G: -0.2023 (0.1719) D(x): 0.5035 D(G(z)): 0.4775 / 0.4835 Acc: 37.5000 (30.0426)\n",
      "[8/25][464/782] Loss_D: -0.1342 (0.3267) Loss_G: -0.1648 (0.1719) D(x): 0.5361 D(G(z)): 0.4647 / 0.4765 Acc: 48.4375 (30.0453)\n",
      "[8/25][465/782] Loss_D: -0.0681 (0.3267) Loss_G: -0.1548 (0.1718) D(x): 0.5215 D(G(z)): 0.4645 / 0.4668 Acc: 40.6250 (30.0469)\n",
      "[8/25][466/782] Loss_D: 0.1668 (0.3267) Loss_G: -0.1640 (0.1718) D(x): 0.5316 D(G(z)): 0.5264 / 0.4615 Acc: 40.6250 (30.0484)\n",
      "[8/25][467/782] Loss_D: 0.0198 (0.3266) Loss_G: -0.1328 (0.1717) D(x): 0.5201 D(G(z)): 0.4594 / 0.4601 Acc: 35.9375 (30.0493)\n",
      "[8/25][468/782] Loss_D: 0.0234 (0.3266) Loss_G: -0.1993 (0.1717) D(x): 0.5256 D(G(z)): 0.4807 / 0.4814 Acc: 37.5000 (30.0504)\n",
      "[8/25][469/782] Loss_D: 0.0427 (0.3265) Loss_G: -0.1234 (0.1716) D(x): 0.5395 D(G(z)): 0.5132 / 0.4479 Acc: 39.0625 (30.0518)\n",
      "[8/25][470/782] Loss_D: 0.1498 (0.3265) Loss_G: -0.0807 (0.1716) D(x): 0.4779 D(G(z)): 0.4782 / 0.4346 Acc: 32.8125 (30.0522)\n",
      "[8/25][471/782] Loss_D: 0.0489 (0.3265) Loss_G: -0.1508 (0.1715) D(x): 0.5275 D(G(z)): 0.5099 / 0.4525 Acc: 42.1875 (30.0540)\n",
      "[8/25][472/782] Loss_D: 0.0838 (0.3264) Loss_G: 0.0341 (0.1715) D(x): 0.5120 D(G(z)): 0.4631 / 0.4164 Acc: 29.6875 (30.0539)\n",
      "[8/25][473/782] Loss_D: -0.0740 (0.3264) Loss_G: -0.0906 (0.1715) D(x): 0.5310 D(G(z)): 0.4488 / 0.4546 Acc: 40.6250 (30.0555)\n",
      "[8/25][474/782] Loss_D: 0.0979 (0.3263) Loss_G: -0.1557 (0.1714) D(x): 0.5499 D(G(z)): 0.5046 / 0.4626 Acc: 31.2500 (30.0557)\n",
      "[8/25][475/782] Loss_D: -0.0095 (0.3263) Loss_G: -0.1259 (0.1714) D(x): 0.5135 D(G(z)): 0.4491 / 0.4699 Acc: 37.5000 (30.0568)\n",
      "[8/25][476/782] Loss_D: -0.0139 (0.3262) Loss_G: -0.2384 (0.1713) D(x): 0.5482 D(G(z)): 0.4828 / 0.4893 Acc: 35.9375 (30.0576)\n",
      "[8/25][477/782] Loss_D: -0.0983 (0.3262) Loss_G: -0.0116 (0.1713) D(x): 0.5649 D(G(z)): 0.4851 / 0.4121 Acc: 43.7500 (30.0597)\n",
      "[8/25][478/782] Loss_D: -0.1310 (0.3261) Loss_G: -0.1051 (0.1713) D(x): 0.5168 D(G(z)): 0.4360 / 0.4477 Acc: 46.8750 (30.0622)\n",
      "[8/25][479/782] Loss_D: 0.1310 (0.3261) Loss_G: -0.2650 (0.1712) D(x): 0.4606 D(G(z)): 0.4773 / 0.5084 Acc: 42.1875 (30.0640)\n",
      "[8/25][480/782] Loss_D: 0.0689 (0.3260) Loss_G: -0.1636 (0.1711) D(x): 0.5422 D(G(z)): 0.5376 / 0.4589 Acc: 37.5000 (30.0651)\n",
      "[8/25][481/782] Loss_D: -0.0919 (0.3260) Loss_G: -0.0798 (0.1711) D(x): 0.4837 D(G(z)): 0.4312 / 0.4356 Acc: 46.8750 (30.0676)\n",
      "[8/25][482/782] Loss_D: -0.0544 (0.3259) Loss_G: -0.1566 (0.1711) D(x): 0.5482 D(G(z)): 0.5051 / 0.4720 Acc: 46.8750 (30.0701)\n",
      "[8/25][483/782] Loss_D: 0.0032 (0.3259) Loss_G: -0.1059 (0.1710) D(x): 0.5186 D(G(z)): 0.4712 / 0.4496 Acc: 37.5000 (30.0712)\n",
      "[8/25][484/782] Loss_D: 0.0543 (0.3258) Loss_G: -0.1152 (0.1710) D(x): 0.5237 D(G(z)): 0.5103 / 0.4709 Acc: 45.3125 (30.0734)\n",
      "[8/25][485/782] Loss_D: 0.1918 (0.3258) Loss_G: -0.0623 (0.1709) D(x): 0.5005 D(G(z)): 0.4955 / 0.4375 Acc: 35.9375 (30.0743)\n",
      "[8/25][486/782] Loss_D: -0.1189 (0.3257) Loss_G: -0.1310 (0.1709) D(x): 0.5240 D(G(z)): 0.4200 / 0.4527 Acc: 40.6250 (30.0759)\n",
      "[8/25][487/782] Loss_D: -0.0881 (0.3257) Loss_G: -0.1458 (0.1708) D(x): 0.5014 D(G(z)): 0.4156 / 0.4572 Acc: 42.1875 (30.0777)\n",
      "[8/25][488/782] Loss_D: -0.0845 (0.3256) Loss_G: -0.1431 (0.1708) D(x): 0.5442 D(G(z)): 0.4461 / 0.4693 Acc: 37.5000 (30.0788)\n",
      "[8/25][489/782] Loss_D: -0.0296 (0.3256) Loss_G: -0.1950 (0.1707) D(x): 0.5817 D(G(z)): 0.5085 / 0.4701 Acc: 34.3750 (30.0794)\n",
      "[8/25][490/782] Loss_D: -0.0587 (0.3255) Loss_G: -0.0305 (0.1707) D(x): 0.5808 D(G(z)): 0.4808 / 0.4329 Acc: 40.6250 (30.0810)\n",
      "[8/25][491/782] Loss_D: 0.1111 (0.3255) Loss_G: -0.0154 (0.1707) D(x): 0.5307 D(G(z)): 0.4792 / 0.4062 Acc: 32.8125 (30.0814)\n",
      "[8/25][492/782] Loss_D: -0.0269 (0.3254) Loss_G: -0.0548 (0.1707) D(x): 0.5320 D(G(z)): 0.4494 / 0.4130 Acc: 35.9375 (30.0822)\n",
      "[8/25][493/782] Loss_D: -0.0509 (0.3254) Loss_G: -0.0954 (0.1706) D(x): 0.4807 D(G(z)): 0.3922 / 0.4517 Acc: 39.0625 (30.0836)\n",
      "[8/25][494/782] Loss_D: -0.1057 (0.3253) Loss_G: -0.1946 (0.1706) D(x): 0.5215 D(G(z)): 0.4633 / 0.4797 Acc: 46.8750 (30.0861)\n",
      "[8/25][495/782] Loss_D: -0.0144 (0.3253) Loss_G: -0.0229 (0.1705) D(x): 0.6107 D(G(z)): 0.5062 / 0.4007 Acc: 32.8125 (30.0865)\n",
      "[8/25][496/782] Loss_D: -0.0780 (0.3252) Loss_G: -0.0803 (0.1705) D(x): 0.5239 D(G(z)): 0.4464 / 0.4317 Acc: 42.1875 (30.0882)\n",
      "[8/25][497/782] Loss_D: -0.1785 (0.3251) Loss_G: 0.0019 (0.1705) D(x): 0.6019 D(G(z)): 0.4356 / 0.4097 Acc: 39.0625 (30.0896)\n",
      "[8/25][498/782] Loss_D: 0.0668 (0.3251) Loss_G: -0.0568 (0.1704) D(x): 0.5215 D(G(z)): 0.5146 / 0.4361 Acc: 42.1875 (30.0914)\n",
      "[8/25][499/782] Loss_D: 0.1961 (0.3251) Loss_G: -0.1396 (0.1704) D(x): 0.4739 D(G(z)): 0.4350 / 0.4665 Acc: 25.0000 (30.0906)\n",
      "[8/25][500/782] Loss_D: 0.0980 (0.3250) Loss_G: -0.1137 (0.1703) D(x): 0.5075 D(G(z)): 0.5417 / 0.4447 Acc: 48.4375 (30.0933)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[8/25][501/782] Loss_D: 0.0294 (0.3250) Loss_G: -0.0947 (0.1703) D(x): 0.5169 D(G(z)): 0.4797 / 0.4532 Acc: 37.5000 (30.0944)\n",
      "[8/25][502/782] Loss_D: 0.1010 (0.3250) Loss_G: -0.2374 (0.1702) D(x): 0.5253 D(G(z)): 0.5014 / 0.4918 Acc: 35.9375 (30.0953)\n",
      "[8/25][503/782] Loss_D: 0.0139 (0.3249) Loss_G: -0.1609 (0.1702) D(x): 0.5431 D(G(z)): 0.4891 / 0.4605 Acc: 37.5000 (30.0964)\n",
      "[8/25][504/782] Loss_D: -0.0274 (0.3249) Loss_G: -0.1544 (0.1701) D(x): 0.4897 D(G(z)): 0.4690 / 0.4647 Acc: 48.4375 (30.0991)\n",
      "[8/25][505/782] Loss_D: -0.1004 (0.3248) Loss_G: -0.0855 (0.1701) D(x): 0.5433 D(G(z)): 0.4531 / 0.4396 Acc: 42.1875 (30.1009)\n",
      "[8/25][506/782] Loss_D: 0.0991 (0.3248) Loss_G: -0.0599 (0.1701) D(x): 0.5220 D(G(z)): 0.5101 / 0.4195 Acc: 39.0625 (30.1022)\n",
      "[8/25][507/782] Loss_D: 0.0086 (0.3247) Loss_G: -0.0842 (0.1700) D(x): 0.5499 D(G(z)): 0.4901 / 0.4474 Acc: 39.0625 (30.1035)\n",
      "[8/25][508/782] Loss_D: 0.1425 (0.3247) Loss_G: -0.0968 (0.1700) D(x): 0.5233 D(G(z)): 0.4772 / 0.4404 Acc: 26.5625 (30.1030)\n",
      "[8/25][509/782] Loss_D: -0.0858 (0.3246) Loss_G: -0.0035 (0.1700) D(x): 0.4832 D(G(z)): 0.4323 / 0.4006 Acc: 50.0000 (30.1060)\n",
      "[8/25][510/782] Loss_D: -0.0181 (0.3246) Loss_G: -0.1405 (0.1699) D(x): 0.5541 D(G(z)): 0.4872 / 0.4620 Acc: 39.0625 (30.1073)\n",
      "[8/25][511/782] Loss_D: 0.0531 (0.3245) Loss_G: -0.0885 (0.1699) D(x): 0.5400 D(G(z)): 0.4899 / 0.4319 Acc: 35.9375 (30.1081)\n",
      "[8/25][512/782] Loss_D: 0.0085 (0.3245) Loss_G: -0.0891 (0.1699) D(x): 0.5067 D(G(z)): 0.4811 / 0.4504 Acc: 40.6250 (30.1097)\n",
      "[8/25][513/782] Loss_D: 0.0510 (0.3245) Loss_G: -0.0449 (0.1698) D(x): 0.5543 D(G(z)): 0.4898 / 0.4386 Acc: 31.2500 (30.1099)\n",
      "[8/25][514/782] Loss_D: -0.1073 (0.3244) Loss_G: -0.0139 (0.1698) D(x): 0.5261 D(G(z)): 0.4232 / 0.4051 Acc: 40.6250 (30.1114)\n",
      "[8/25][515/782] Loss_D: -0.0817 (0.3243) Loss_G: -0.0623 (0.1698) D(x): 0.5701 D(G(z)): 0.4700 / 0.4435 Acc: 42.1875 (30.1132)\n",
      "[8/25][516/782] Loss_D: 0.0677 (0.3243) Loss_G: -0.0810 (0.1697) D(x): 0.4706 D(G(z)): 0.4719 / 0.4269 Acc: 43.7500 (30.1152)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/25][517/782] Loss_D: 0.1444 (0.3243) Loss_G: -0.2249 (0.1697) D(x): 0.5054 D(G(z)): 0.4981 / 0.5059 Acc: 37.5000 (30.1163)\n",
      "[8/25][518/782] Loss_D: 0.0935 (0.3242) Loss_G: -0.1455 (0.1696) D(x): 0.5219 D(G(z)): 0.4680 / 0.4596 Acc: 32.8125 (30.1167)\n",
      "[8/25][519/782] Loss_D: 0.0454 (0.3242) Loss_G: -0.1399 (0.1696) D(x): 0.5485 D(G(z)): 0.5028 / 0.4543 Acc: 42.1875 (30.1185)\n",
      "[8/25][520/782] Loss_D: -0.0673 (0.3241) Loss_G: -0.1520 (0.1695) D(x): 0.5295 D(G(z)): 0.4764 / 0.4482 Acc: 42.1875 (30.1203)\n",
      "[8/25][521/782] Loss_D: -0.0005 (0.3241) Loss_G: -0.0685 (0.1695) D(x): 0.5198 D(G(z)): 0.4534 / 0.4159 Acc: 39.0625 (30.1216)\n",
      "[8/25][522/782] Loss_D: 0.1024 (0.3241) Loss_G: -0.0334 (0.1695) D(x): 0.5095 D(G(z)): 0.4771 / 0.4254 Acc: 31.2500 (30.1217)\n",
      "[8/25][523/782] Loss_D: 0.0852 (0.3240) Loss_G: -0.0554 (0.1694) D(x): 0.4748 D(G(z)): 0.4261 / 0.4206 Acc: 39.0625 (30.1231)\n",
      "[8/25][524/782] Loss_D: 0.0295 (0.3240) Loss_G: -0.0442 (0.1694) D(x): 0.5527 D(G(z)): 0.4997 / 0.4142 Acc: 32.8125 (30.1235)\n",
      "[8/25][525/782] Loss_D: 0.0088 (0.3239) Loss_G: -0.1380 (0.1693) D(x): 0.5585 D(G(z)): 0.5113 / 0.4541 Acc: 37.5000 (30.1245)\n",
      "[8/25][526/782] Loss_D: 0.0195 (0.3239) Loss_G: 0.0024 (0.1693) D(x): 0.5480 D(G(z)): 0.4691 / 0.4006 Acc: 32.8125 (30.1249)\n",
      "[8/25][527/782] Loss_D: -0.1418 (0.3238) Loss_G: -0.0100 (0.1693) D(x): 0.5167 D(G(z)): 0.3788 / 0.3927 Acc: 32.8125 (30.1253)\n",
      "[8/25][528/782] Loss_D: -0.0419 (0.3238) Loss_G: -0.1855 (0.1692) D(x): 0.4966 D(G(z)): 0.4397 / 0.4835 Acc: 40.6250 (30.1269)\n",
      "[8/25][529/782] Loss_D: 0.0738 (0.3237) Loss_G: -0.2017 (0.1692) D(x): 0.5308 D(G(z)): 0.5023 / 0.4767 Acc: 39.0625 (30.1282)\n",
      "[8/25][530/782] Loss_D: 0.1372 (0.3237) Loss_G: -0.1378 (0.1691) D(x): 0.4976 D(G(z)): 0.5098 / 0.4419 Acc: 35.9375 (30.1291)\n",
      "[8/25][531/782] Loss_D: 0.0280 (0.3236) Loss_G: -0.1744 (0.1691) D(x): 0.5466 D(G(z)): 0.4737 / 0.4692 Acc: 32.8125 (30.1295)\n",
      "[8/25][532/782] Loss_D: 0.0897 (0.3236) Loss_G: -0.1066 (0.1691) D(x): 0.5376 D(G(z)): 0.5073 / 0.4521 Acc: 39.0625 (30.1308)\n",
      "[8/25][533/782] Loss_D: -0.0127 (0.3236) Loss_G: -0.0718 (0.1690) D(x): 0.5236 D(G(z)): 0.4375 / 0.4163 Acc: 32.8125 (30.1312)\n",
      "[8/25][534/782] Loss_D: 0.0966 (0.3235) Loss_G: -0.1017 (0.1690) D(x): 0.4942 D(G(z)): 0.4858 / 0.4446 Acc: 39.0625 (30.1325)\n",
      "[8/25][535/782] Loss_D: -0.0507 (0.3235) Loss_G: -0.1173 (0.1689) D(x): 0.5292 D(G(z)): 0.4419 / 0.4446 Acc: 34.3750 (30.1331)\n",
      "[8/25][536/782] Loss_D: -0.0871 (0.3234) Loss_G: -0.1558 (0.1689) D(x): 0.5383 D(G(z)): 0.4766 / 0.4658 Acc: 43.7500 (30.1351)\n",
      "[8/25][537/782] Loss_D: 0.1917 (0.3234) Loss_G: -0.1162 (0.1688) D(x): 0.5417 D(G(z)): 0.5388 / 0.4447 Acc: 34.3750 (30.1357)\n",
      "[8/25][538/782] Loss_D: 0.0887 (0.3234) Loss_G: -0.1813 (0.1688) D(x): 0.4794 D(G(z)): 0.4495 / 0.4699 Acc: 35.9375 (30.1366)\n",
      "[8/25][539/782] Loss_D: -0.2520 (0.3233) Loss_G: -0.1206 (0.1688) D(x): 0.5550 D(G(z)): 0.4351 / 0.4738 Acc: 50.0000 (30.1395)\n",
      "[8/25][540/782] Loss_D: -0.0479 (0.3232) Loss_G: -0.2236 (0.1687) D(x): 0.5504 D(G(z)): 0.4702 / 0.4866 Acc: 34.3750 (30.1401)\n",
      "[8/25][541/782] Loss_D: 0.0460 (0.3232) Loss_G: -0.1111 (0.1687) D(x): 0.5600 D(G(z)): 0.5067 / 0.4368 Acc: 34.3750 (30.1408)\n",
      "[8/25][542/782] Loss_D: 0.0825 (0.3231) Loss_G: -0.0855 (0.1686) D(x): 0.4818 D(G(z)): 0.4509 / 0.4460 Acc: 39.0625 (30.1421)\n",
      "[8/25][543/782] Loss_D: -0.1102 (0.3231) Loss_G: -0.1136 (0.1686) D(x): 0.5174 D(G(z)): 0.4585 / 0.4539 Acc: 48.4375 (30.1448)\n",
      "[8/25][544/782] Loss_D: 0.2484 (0.3231) Loss_G: -0.2098 (0.1685) D(x): 0.5081 D(G(z)): 0.5388 / 0.5014 Acc: 34.3750 (30.1454)\n",
      "[8/25][545/782] Loss_D: -0.1391 (0.3230) Loss_G: -0.0681 (0.1685) D(x): 0.5658 D(G(z)): 0.4638 / 0.4292 Acc: 42.1875 (30.1472)\n",
      "[8/25][546/782] Loss_D: -0.0738 (0.3229) Loss_G: -0.1001 (0.1684) D(x): 0.5616 D(G(z)): 0.4386 / 0.4424 Acc: 31.2500 (30.1473)\n",
      "[8/25][547/782] Loss_D: -0.1416 (0.3229) Loss_G: -0.0582 (0.1684) D(x): 0.5776 D(G(z)): 0.4876 / 0.4390 Acc: 46.8750 (30.1498)\n",
      "[8/25][548/782] Loss_D: 0.0685 (0.3228) Loss_G: -0.1222 (0.1684) D(x): 0.5117 D(G(z)): 0.4757 / 0.4611 Acc: 37.5000 (30.1509)\n",
      "[8/25][549/782] Loss_D: -0.1017 (0.3228) Loss_G: -0.0009 (0.1683) D(x): 0.5476 D(G(z)): 0.4909 / 0.3954 Acc: 51.5625 (30.1540)\n",
      "[8/25][550/782] Loss_D: 0.2083 (0.3228) Loss_G: -0.0684 (0.1683) D(x): 0.4741 D(G(z)): 0.4701 / 0.4374 Acc: 28.1250 (30.1537)\n",
      "[8/25][551/782] Loss_D: 0.0169 (0.3227) Loss_G: -0.0698 (0.1683) D(x): 0.5338 D(G(z)): 0.4624 / 0.4431 Acc: 31.2500 (30.1539)\n",
      "[8/25][552/782] Loss_D: -0.2116 (0.3226) Loss_G: -0.0904 (0.1682) D(x): 0.5220 D(G(z)): 0.4078 / 0.4451 Acc: 46.8750 (30.1563)\n",
      "[8/25][553/782] Loss_D: -0.0458 (0.3226) Loss_G: -0.1246 (0.1682) D(x): 0.5243 D(G(z)): 0.4607 / 0.4541 Acc: 40.6250 (30.1579)\n",
      "[8/25][554/782] Loss_D: -0.1610 (0.3225) Loss_G: -0.1185 (0.1682) D(x): 0.5913 D(G(z)): 0.5018 / 0.4358 Acc: 48.4375 (30.1605)\n",
      "[8/25][555/782] Loss_D: -0.0727 (0.3225) Loss_G: -0.1294 (0.1681) D(x): 0.5632 D(G(z)): 0.4382 / 0.4566 Acc: 34.3750 (30.1612)\n",
      "[8/25][556/782] Loss_D: -0.1372 (0.3224) Loss_G: 0.0124 (0.1681) D(x): 0.5255 D(G(z)): 0.4156 / 0.3962 Acc: 43.7500 (30.1632)\n",
      "[8/25][557/782] Loss_D: -0.0957 (0.3223) Loss_G: -0.2097 (0.1680) D(x): 0.5241 D(G(z)): 0.4613 / 0.4702 Acc: 46.8750 (30.1656)\n",
      "[8/25][558/782] Loss_D: -0.0133 (0.3223) Loss_G: -0.2174 (0.1680) D(x): 0.5581 D(G(z)): 0.5081 / 0.4841 Acc: 39.0625 (30.1669)\n",
      "[8/25][559/782] Loss_D: 0.0872 (0.3222) Loss_G: -0.0979 (0.1679) D(x): 0.5467 D(G(z)): 0.5004 / 0.4357 Acc: 28.1250 (30.1666)\n",
      "[8/25][560/782] Loss_D: 0.1265 (0.3222) Loss_G: -0.0082 (0.1679) D(x): 0.5293 D(G(z)): 0.4984 / 0.4088 Acc: 32.8125 (30.1670)\n",
      "[8/25][561/782] Loss_D: 0.1061 (0.3222) Loss_G: -0.2044 (0.1679) D(x): 0.4409 D(G(z)): 0.4026 / 0.4780 Acc: 37.5000 (30.1681)\n",
      "[8/25][562/782] Loss_D: -0.0724 (0.3221) Loss_G: -0.2449 (0.1678) D(x): 0.5347 D(G(z)): 0.5214 / 0.4886 Acc: 53.1250 (30.1714)\n",
      "[8/25][563/782] Loss_D: 0.0401 (0.3221) Loss_G: -0.2100 (0.1677) D(x): 0.5080 D(G(z)): 0.4630 / 0.4762 Acc: 37.5000 (30.1725)\n",
      "[8/25][564/782] Loss_D: 0.0040 (0.3220) Loss_G: -0.0939 (0.1677) D(x): 0.5928 D(G(z)): 0.5141 / 0.4435 Acc: 32.8125 (30.1729)\n",
      "[8/25][565/782] Loss_D: -0.1376 (0.3220) Loss_G: 0.0976 (0.1677) D(x): 0.5362 D(G(z)): 0.4298 / 0.3811 Acc: 42.1875 (30.1747)\n",
      "[8/25][566/782] Loss_D: -0.0407 (0.3219) Loss_G: -0.0796 (0.1677) D(x): 0.5056 D(G(z)): 0.4119 / 0.4327 Acc: 32.8125 (30.1751)\n",
      "[8/25][567/782] Loss_D: -0.1890 (0.3218) Loss_G: -0.0069 (0.1676) D(x): 0.5141 D(G(z)): 0.4149 / 0.4138 Acc: 50.0000 (30.1780)\n",
      "[8/25][568/782] Loss_D: -0.0047 (0.3218) Loss_G: -0.1043 (0.1676) D(x): 0.5517 D(G(z)): 0.4382 / 0.4371 Acc: 26.5625 (30.1774)\n",
      "[8/25][569/782] Loss_D: -0.1350 (0.3217) Loss_G: -0.0328 (0.1676) D(x): 0.6149 D(G(z)): 0.4706 / 0.4249 Acc: 34.3750 (30.1780)\n",
      "[8/25][570/782] Loss_D: -0.0512 (0.3217) Loss_G: -0.0711 (0.1675) D(x): 0.5109 D(G(z)): 0.4304 / 0.4277 Acc: 40.6250 (30.1796)\n",
      "[8/25][571/782] Loss_D: -0.0833 (0.3216) Loss_G: -0.1051 (0.1675) D(x): 0.5439 D(G(z)): 0.4402 / 0.4443 Acc: 40.6250 (30.1811)\n",
      "[8/25][572/782] Loss_D: -0.1686 (0.3215) Loss_G: -0.0738 (0.1674) D(x): 0.5584 D(G(z)): 0.4382 / 0.4544 Acc: 40.6250 (30.1826)\n",
      "[8/25][573/782] Loss_D: -0.0272 (0.3215) Loss_G: 0.0320 (0.1674) D(x): 0.5828 D(G(z)): 0.4935 / 0.4009 Acc: 39.0625 (30.1839)\n",
      "[8/25][574/782] Loss_D: -0.0309 (0.3214) Loss_G: 0.0450 (0.1674) D(x): 0.5315 D(G(z)): 0.4613 / 0.3780 Acc: 34.3750 (30.1845)\n",
      "[8/25][575/782] Loss_D: 0.0590 (0.3214) Loss_G: -0.1189 (0.1674) D(x): 0.4697 D(G(z)): 0.4010 / 0.4427 Acc: 35.9375 (30.1854)\n",
      "[8/25][576/782] Loss_D: 0.0354 (0.3214) Loss_G: -0.2037 (0.1673) D(x): 0.5325 D(G(z)): 0.4634 / 0.4811 Acc: 31.2500 (30.1855)\n",
      "[8/25][577/782] Loss_D: 0.0180 (0.3213) Loss_G: -0.3193 (0.1672) D(x): 0.5372 D(G(z)): 0.4911 / 0.5295 Acc: 42.1875 (30.1873)\n",
      "[8/25][578/782] Loss_D: -0.0452 (0.3213) Loss_G: -0.0499 (0.1672) D(x): 0.5735 D(G(z)): 0.4998 / 0.4346 Acc: 40.6250 (30.1888)\n",
      "[8/25][579/782] Loss_D: -0.0372 (0.3212) Loss_G: -0.0574 (0.1672) D(x): 0.5442 D(G(z)): 0.4597 / 0.4315 Acc: 39.0625 (30.1901)\n",
      "[8/25][580/782] Loss_D: -0.0360 (0.3212) Loss_G: -0.0469 (0.1671) D(x): 0.5154 D(G(z)): 0.4418 / 0.4301 Acc: 43.7500 (30.1921)\n",
      "[8/25][581/782] Loss_D: -0.0044 (0.3211) Loss_G: -0.0461 (0.1671) D(x): 0.5141 D(G(z)): 0.4725 / 0.4190 Acc: 40.6250 (30.1936)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/25][582/782] Loss_D: 0.0109 (0.3211) Loss_G: -0.2198 (0.1671) D(x): 0.5104 D(G(z)): 0.4750 / 0.4848 Acc: 39.0625 (30.1949)\n",
      "[8/25][583/782] Loss_D: 0.0055 (0.3210) Loss_G: -0.2863 (0.1670) D(x): 0.4959 D(G(z)): 0.4857 / 0.5156 Acc: 45.3125 (30.1971)\n",
      "[8/25][584/782] Loss_D: -0.0097 (0.3210) Loss_G: 0.0189 (0.1670) D(x): 0.5699 D(G(z)): 0.5080 / 0.4009 Acc: 35.9375 (30.1980)\n",
      "[8/25][585/782] Loss_D: -0.0894 (0.3209) Loss_G: -0.1408 (0.1669) D(x): 0.5099 D(G(z)): 0.4443 / 0.4648 Acc: 42.1875 (30.1997)\n",
      "[8/25][586/782] Loss_D: -0.0169 (0.3209) Loss_G: -0.1231 (0.1669) D(x): 0.4994 D(G(z)): 0.4486 / 0.4532 Acc: 40.6250 (30.2013)\n",
      "[8/25][587/782] Loss_D: -0.0593 (0.3208) Loss_G: -0.1723 (0.1668) D(x): 0.4840 D(G(z)): 0.4494 / 0.4679 Acc: 45.3125 (30.2035)\n",
      "[8/25][588/782] Loss_D: -0.1032 (0.3207) Loss_G: -0.2001 (0.1668) D(x): 0.5666 D(G(z)): 0.4836 / 0.4805 Acc: 45.3125 (30.2057)\n",
      "[8/25][589/782] Loss_D: -0.0232 (0.3207) Loss_G: -0.1506 (0.1667) D(x): 0.5510 D(G(z)): 0.4803 / 0.4543 Acc: 40.6250 (30.2072)\n",
      "[8/25][590/782] Loss_D: -0.1067 (0.3206) Loss_G: -0.0491 (0.1667) D(x): 0.5316 D(G(z)): 0.4515 / 0.4132 Acc: 43.7500 (30.2092)\n",
      "[8/25][591/782] Loss_D: -0.0713 (0.3206) Loss_G: -0.1982 (0.1667) D(x): 0.5148 D(G(z)): 0.4673 / 0.4818 Acc: 45.3125 (30.2114)\n",
      "[8/25][592/782] Loss_D: -0.0196 (0.3205) Loss_G: -0.0748 (0.1666) D(x): 0.4871 D(G(z)): 0.4532 / 0.4280 Acc: 45.3125 (30.2136)\n",
      "[8/25][593/782] Loss_D: 0.0168 (0.3205) Loss_G: -0.1772 (0.1666) D(x): 0.5498 D(G(z)): 0.5023 / 0.4826 Acc: 42.1875 (30.2153)\n",
      "[8/25][594/782] Loss_D: -0.0979 (0.3204) Loss_G: -0.1367 (0.1665) D(x): 0.5165 D(G(z)): 0.4287 / 0.4533 Acc: 39.0625 (30.2166)\n",
      "[8/25][595/782] Loss_D: 0.1266 (0.3204) Loss_G: -0.0880 (0.1665) D(x): 0.4767 D(G(z)): 0.4602 / 0.4381 Acc: 34.3750 (30.2172)\n",
      "[8/25][596/782] Loss_D: 0.0050 (0.3203) Loss_G: -0.1292 (0.1664) D(x): 0.5590 D(G(z)): 0.4898 / 0.4554 Acc: 35.9375 (30.2181)\n",
      "[8/25][597/782] Loss_D: 0.0166 (0.3203) Loss_G: -0.1341 (0.1664) D(x): 0.5458 D(G(z)): 0.4811 / 0.4581 Acc: 40.6250 (30.2196)\n",
      "[8/25][598/782] Loss_D: -0.0942 (0.3202) Loss_G: -0.1935 (0.1663) D(x): 0.5731 D(G(z)): 0.4682 / 0.4737 Acc: 37.5000 (30.2206)\n",
      "[8/25][599/782] Loss_D: -0.0015 (0.3202) Loss_G: -0.0575 (0.1663) D(x): 0.5374 D(G(z)): 0.4602 / 0.4308 Acc: 35.9375 (30.2215)\n",
      "[8/25][600/782] Loss_D: -0.0378 (0.3201) Loss_G: -0.1947 (0.1663) D(x): 0.5108 D(G(z)): 0.4338 / 0.4865 Acc: 40.6250 (30.2230)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[8/25][601/782] Loss_D: 0.0445 (0.3201) Loss_G: -0.0826 (0.1662) D(x): 0.5493 D(G(z)): 0.4869 / 0.4353 Acc: 31.2500 (30.2231)\n",
      "[8/25][602/782] Loss_D: -0.0411 (0.3200) Loss_G: -0.0556 (0.1662) D(x): 0.5241 D(G(z)): 0.4833 / 0.4340 Acc: 45.3125 (30.2253)\n",
      "[8/25][603/782] Loss_D: -0.0288 (0.3200) Loss_G: -0.2462 (0.1661) D(x): 0.5098 D(G(z)): 0.4689 / 0.5091 Acc: 42.1875 (30.2271)\n",
      "[8/25][604/782] Loss_D: 0.0110 (0.3199) Loss_G: -0.1466 (0.1661) D(x): 0.5465 D(G(z)): 0.4991 / 0.4747 Acc: 37.5000 (30.2281)\n",
      "[8/25][605/782] Loss_D: 0.0953 (0.3199) Loss_G: -0.1271 (0.1660) D(x): 0.4710 D(G(z)): 0.4541 / 0.4563 Acc: 39.0625 (30.2294)\n",
      "[8/25][606/782] Loss_D: 0.1894 (0.3199) Loss_G: -0.1482 (0.1660) D(x): 0.5119 D(G(z)): 0.5382 / 0.4773 Acc: 42.1875 (30.2312)\n",
      "[8/25][607/782] Loss_D: -0.0976 (0.3198) Loss_G: -0.0207 (0.1660) D(x): 0.5775 D(G(z)): 0.5025 / 0.4226 Acc: 50.0000 (30.2341)\n",
      "[8/25][608/782] Loss_D: 0.0887 (0.3198) Loss_G: -0.0740 (0.1659) D(x): 0.5057 D(G(z)): 0.4379 / 0.4340 Acc: 28.1250 (30.2337)\n",
      "[8/25][609/782] Loss_D: 0.0022 (0.3198) Loss_G: -0.2113 (0.1659) D(x): 0.4971 D(G(z)): 0.4239 / 0.4805 Acc: 40.6250 (30.2353)\n",
      "[8/25][610/782] Loss_D: 0.0407 (0.3197) Loss_G: -0.1023 (0.1658) D(x): 0.5907 D(G(z)): 0.4915 / 0.4486 Acc: 31.2500 (30.2354)\n",
      "[8/25][611/782] Loss_D: 0.0634 (0.3197) Loss_G: -0.1008 (0.1658) D(x): 0.5106 D(G(z)): 0.4304 / 0.4360 Acc: 28.1250 (30.2351)\n",
      "[8/25][612/782] Loss_D: 0.1351 (0.3197) Loss_G: -0.1731 (0.1658) D(x): 0.5204 D(G(z)): 0.5108 / 0.4779 Acc: 32.8125 (30.2355)\n",
      "[8/25][613/782] Loss_D: -0.2233 (0.3196) Loss_G: 0.0081 (0.1657) D(x): 0.5694 D(G(z)): 0.4067 / 0.4069 Acc: 40.6250 (30.2370)\n",
      "[8/25][614/782] Loss_D: -0.0326 (0.3195) Loss_G: -0.0895 (0.1657) D(x): 0.5017 D(G(z)): 0.4351 / 0.4470 Acc: 43.7500 (30.2390)\n",
      "[8/25][615/782] Loss_D: -0.0188 (0.3195) Loss_G: -0.0849 (0.1657) D(x): 0.5567 D(G(z)): 0.5136 / 0.4530 Acc: 43.7500 (30.2409)\n",
      "[8/25][616/782] Loss_D: 0.0514 (0.3194) Loss_G: -0.0811 (0.1656) D(x): 0.5403 D(G(z)): 0.4733 / 0.4350 Acc: 32.8125 (30.2413)\n",
      "[8/25][617/782] Loss_D: 0.0303 (0.3194) Loss_G: -0.0154 (0.1656) D(x): 0.4791 D(G(z)): 0.4486 / 0.4189 Acc: 42.1875 (30.2430)\n",
      "[8/25][618/782] Loss_D: -0.0221 (0.3193) Loss_G: -0.0698 (0.1656) D(x): 0.5175 D(G(z)): 0.4561 / 0.4253 Acc: 40.6250 (30.2445)\n",
      "[8/25][619/782] Loss_D: 0.0027 (0.3193) Loss_G: -0.0520 (0.1655) D(x): 0.6236 D(G(z)): 0.5118 / 0.4234 Acc: 26.5625 (30.2440)\n",
      "[8/25][620/782] Loss_D: 0.0808 (0.3193) Loss_G: 0.0515 (0.1655) D(x): 0.5125 D(G(z)): 0.4504 / 0.3960 Acc: 37.5000 (30.2451)\n",
      "[8/25][621/782] Loss_D: -0.1040 (0.3192) Loss_G: -0.1173 (0.1655) D(x): 0.5098 D(G(z)): 0.4237 / 0.4463 Acc: 45.3125 (30.2473)\n",
      "[8/25][622/782] Loss_D: 0.1029 (0.3192) Loss_G: -0.1866 (0.1654) D(x): 0.5304 D(G(z)): 0.5053 / 0.4763 Acc: 35.9375 (30.2481)\n",
      "[8/25][623/782] Loss_D: 0.0337 (0.3191) Loss_G: -0.0534 (0.1654) D(x): 0.5301 D(G(z)): 0.4650 / 0.4296 Acc: 35.9375 (30.2489)\n",
      "[8/25][624/782] Loss_D: -0.0549 (0.3191) Loss_G: -0.0663 (0.1654) D(x): 0.5374 D(G(z)): 0.4548 / 0.4185 Acc: 39.0625 (30.2502)\n",
      "[8/25][625/782] Loss_D: -0.0647 (0.3190) Loss_G: -0.0972 (0.1653) D(x): 0.5331 D(G(z)): 0.4530 / 0.4316 Acc: 43.7500 (30.2522)\n",
      "[8/25][626/782] Loss_D: 0.0636 (0.3190) Loss_G: -0.0879 (0.1653) D(x): 0.5303 D(G(z)): 0.4987 / 0.4420 Acc: 37.5000 (30.2532)\n",
      "[8/25][627/782] Loss_D: 0.0315 (0.3189) Loss_G: -0.0655 (0.1652) D(x): 0.5024 D(G(z)): 0.4401 / 0.4233 Acc: 34.3750 (30.2538)\n",
      "[8/25][628/782] Loss_D: -0.0237 (0.3189) Loss_G: -0.1766 (0.1652) D(x): 0.5006 D(G(z)): 0.4518 / 0.4888 Acc: 46.8750 (30.2562)\n",
      "[8/25][629/782] Loss_D: -0.1643 (0.3188) Loss_G: -0.1590 (0.1651) D(x): 0.6102 D(G(z)): 0.5288 / 0.4616 Acc: 50.0000 (30.2591)\n",
      "[8/25][630/782] Loss_D: 0.0667 (0.3188) Loss_G: -0.0166 (0.1651) D(x): 0.5548 D(G(z)): 0.5037 / 0.4124 Acc: 37.5000 (30.2601)\n",
      "[8/25][631/782] Loss_D: -0.0547 (0.3187) Loss_G: 0.0682 (0.1651) D(x): 0.4781 D(G(z)): 0.3876 / 0.3768 Acc: 37.5000 (30.2612)\n",
      "[8/25][632/782] Loss_D: 0.0765 (0.3187) Loss_G: -0.1274 (0.1651) D(x): 0.5064 D(G(z)): 0.4620 / 0.4492 Acc: 37.5000 (30.2622)\n",
      "[8/25][633/782] Loss_D: 0.1096 (0.3187) Loss_G: -0.2233 (0.1650) D(x): 0.5155 D(G(z)): 0.4926 / 0.4771 Acc: 34.3750 (30.2628)\n",
      "[8/25][634/782] Loss_D: 0.0117 (0.3186) Loss_G: -0.1623 (0.1650) D(x): 0.5276 D(G(z)): 0.4602 / 0.4727 Acc: 39.0625 (30.2641)\n",
      "[8/25][635/782] Loss_D: 0.1520 (0.3186) Loss_G: -0.2141 (0.1649) D(x): 0.5508 D(G(z)): 0.5217 / 0.4740 Acc: 28.1250 (30.2638)\n",
      "[8/25][636/782] Loss_D: 0.0622 (0.3186) Loss_G: -0.0333 (0.1649) D(x): 0.5300 D(G(z)): 0.4795 / 0.4197 Acc: 39.0625 (30.2651)\n",
      "[8/25][637/782] Loss_D: 0.2173 (0.3185) Loss_G: -0.1289 (0.1648) D(x): 0.4939 D(G(z)): 0.5469 / 0.4536 Acc: 37.5000 (30.2661)\n",
      "[8/25][638/782] Loss_D: -0.0513 (0.3185) Loss_G: -0.1544 (0.1648) D(x): 0.5105 D(G(z)): 0.4809 / 0.4460 Acc: 51.5625 (30.2692)\n",
      "[8/25][639/782] Loss_D: -0.1118 (0.3184) Loss_G: -0.1692 (0.1647) D(x): 0.5281 D(G(z)): 0.4650 / 0.4755 Acc: 48.4375 (30.2719)\n",
      "[8/25][640/782] Loss_D: -0.0941 (0.3184) Loss_G: -0.1519 (0.1647) D(x): 0.5306 D(G(z)): 0.4737 / 0.4575 Acc: 50.0000 (30.2747)\n",
      "[8/25][641/782] Loss_D: -0.0314 (0.3183) Loss_G: -0.0837 (0.1647) D(x): 0.5397 D(G(z)): 0.4483 / 0.4443 Acc: 31.2500 (30.2749)\n",
      "[8/25][642/782] Loss_D: -0.1101 (0.3183) Loss_G: -0.0680 (0.1646) D(x): 0.5456 D(G(z)): 0.4637 / 0.4247 Acc: 42.1875 (30.2766)\n",
      "[8/25][643/782] Loss_D: -0.0996 (0.3182) Loss_G: 0.0544 (0.1646) D(x): 0.5834 D(G(z)): 0.4569 / 0.3744 Acc: 31.2500 (30.2767)\n",
      "[8/25][644/782] Loss_D: 0.1405 (0.3182) Loss_G: -0.0350 (0.1646) D(x): 0.5175 D(G(z)): 0.4799 / 0.4301 Acc: 28.1250 (30.2764)\n",
      "[8/25][645/782] Loss_D: -0.1083 (0.3181) Loss_G: -0.1196 (0.1645) D(x): 0.5241 D(G(z)): 0.4597 / 0.4484 Acc: 46.8750 (30.2788)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/25][646/782] Loss_D: -0.1540 (0.3180) Loss_G: -0.1456 (0.1645) D(x): 0.5465 D(G(z)): 0.4228 / 0.4607 Acc: 42.1875 (30.2805)\n",
      "[8/25][647/782] Loss_D: -0.2079 (0.3180) Loss_G: -0.1343 (0.1644) D(x): 0.5844 D(G(z)): 0.4434 / 0.4590 Acc: 40.6250 (30.2820)\n",
      "[8/25][648/782] Loss_D: -0.0954 (0.3179) Loss_G: -0.0043 (0.1644) D(x): 0.6005 D(G(z)): 0.4717 / 0.3943 Acc: 32.8125 (30.2824)\n",
      "[8/25][649/782] Loss_D: -0.1034 (0.3178) Loss_G: -0.0959 (0.1644) D(x): 0.5068 D(G(z)): 0.4298 / 0.4432 Acc: 43.7500 (30.2844)\n",
      "[8/25][650/782] Loss_D: -0.4093 (0.3177) Loss_G: -0.1134 (0.1643) D(x): 0.5992 D(G(z)): 0.4303 / 0.4412 Acc: 54.6875 (30.2879)\n",
      "[8/25][651/782] Loss_D: -0.0469 (0.3177) Loss_G: -0.1079 (0.1643) D(x): 0.5875 D(G(z)): 0.5038 / 0.4331 Acc: 39.0625 (30.2892)\n",
      "[8/25][652/782] Loss_D: 0.1070 (0.3176) Loss_G: -0.0020 (0.1643) D(x): 0.5390 D(G(z)): 0.4900 / 0.3991 Acc: 31.2500 (30.2893)\n",
      "[8/25][653/782] Loss_D: -0.0273 (0.3176) Loss_G: -0.0078 (0.1643) D(x): 0.5236 D(G(z)): 0.4467 / 0.4107 Acc: 40.6250 (30.2908)\n",
      "[8/25][654/782] Loss_D: -0.0266 (0.3175) Loss_G: -0.1185 (0.1642) D(x): 0.5449 D(G(z)): 0.4578 / 0.4432 Acc: 31.2500 (30.2909)\n",
      "[8/25][655/782] Loss_D: -0.0142 (0.3175) Loss_G: -0.0997 (0.1642) D(x): 0.5432 D(G(z)): 0.4601 / 0.4390 Acc: 31.2500 (30.2911)\n",
      "[8/25][656/782] Loss_D: -0.1478 (0.3174) Loss_G: -0.1922 (0.1641) D(x): 0.5407 D(G(z)): 0.4296 / 0.4856 Acc: 42.1875 (30.2928)\n",
      "[8/25][657/782] Loss_D: -0.1015 (0.3174) Loss_G: -0.1218 (0.1641) D(x): 0.5594 D(G(z)): 0.4754 / 0.4607 Acc: 42.1875 (30.2945)\n",
      "[8/25][658/782] Loss_D: -0.0441 (0.3173) Loss_G: -0.0996 (0.1640) D(x): 0.4978 D(G(z)): 0.4345 / 0.4353 Acc: 43.7500 (30.2965)\n",
      "[8/25][659/782] Loss_D: 0.0559 (0.3173) Loss_G: -0.2134 (0.1640) D(x): 0.5635 D(G(z)): 0.5061 / 0.4881 Acc: 34.3750 (30.2970)\n",
      "[8/25][660/782] Loss_D: 0.1800 (0.3173) Loss_G: -0.1421 (0.1639) D(x): 0.5576 D(G(z)): 0.5394 / 0.4692 Acc: 31.2500 (30.2972)\n",
      "[8/25][661/782] Loss_D: 0.0668 (0.3172) Loss_G: 0.0507 (0.1639) D(x): 0.4845 D(G(z)): 0.4401 / 0.3862 Acc: 37.5000 (30.2982)\n",
      "[8/25][662/782] Loss_D: 0.0721 (0.3172) Loss_G: -0.1566 (0.1639) D(x): 0.4541 D(G(z)): 0.4113 / 0.4733 Acc: 39.0625 (30.2995)\n",
      "[8/25][663/782] Loss_D: -0.1839 (0.3171) Loss_G: -0.2440 (0.1638) D(x): 0.5728 D(G(z)): 0.4389 / 0.5015 Acc: 37.5000 (30.3005)\n",
      "[8/25][664/782] Loss_D: -0.0185 (0.3171) Loss_G: -0.1093 (0.1638) D(x): 0.5694 D(G(z)): 0.5495 / 0.4476 Acc: 50.0000 (30.3034)\n",
      "[8/25][665/782] Loss_D: -0.2584 (0.3170) Loss_G: -0.0950 (0.1638) D(x): 0.5989 D(G(z)): 0.4010 / 0.4388 Acc: 37.5000 (30.3044)\n",
      "[8/25][666/782] Loss_D: -0.0464 (0.3169) Loss_G: 0.0081 (0.1637) D(x): 0.5093 D(G(z)): 0.4355 / 0.4030 Acc: 48.4375 (30.3070)\n",
      "[8/25][667/782] Loss_D: -0.1863 (0.3169) Loss_G: 0.0361 (0.1637) D(x): 0.5679 D(G(z)): 0.4177 / 0.3928 Acc: 39.0625 (30.3083)\n",
      "[8/25][668/782] Loss_D: -0.0471 (0.3168) Loss_G: -0.0916 (0.1637) D(x): 0.5642 D(G(z)): 0.4875 / 0.4440 Acc: 40.6250 (30.3098)\n",
      "[8/25][669/782] Loss_D: 0.0070 (0.3168) Loss_G: -0.0363 (0.1636) D(x): 0.5491 D(G(z)): 0.4927 / 0.4432 Acc: 42.1875 (30.3115)\n",
      "[8/25][670/782] Loss_D: 0.0898 (0.3167) Loss_G: -0.0678 (0.1636) D(x): 0.4998 D(G(z)): 0.5038 / 0.4349 Acc: 42.1875 (30.3132)\n",
      "[8/25][671/782] Loss_D: 0.0977 (0.3167) Loss_G: -0.0693 (0.1636) D(x): 0.5131 D(G(z)): 0.4940 / 0.4306 Acc: 32.8125 (30.3136)\n",
      "[8/25][672/782] Loss_D: 0.1481 (0.3167) Loss_G: -0.2511 (0.1635) D(x): 0.4742 D(G(z)): 0.4763 / 0.5121 Acc: 39.0625 (30.3148)\n",
      "[8/25][673/782] Loss_D: 0.1682 (0.3167) Loss_G: -0.2766 (0.1635) D(x): 0.4905 D(G(z)): 0.5156 / 0.5216 Acc: 39.0625 (30.3161)\n",
      "[8/25][674/782] Loss_D: -0.0167 (0.3166) Loss_G: -0.1612 (0.1634) D(x): 0.5402 D(G(z)): 0.4419 / 0.4672 Acc: 34.3750 (30.3167)\n",
      "[8/25][675/782] Loss_D: 0.1942 (0.3166) Loss_G: -0.1030 (0.1634) D(x): 0.5133 D(G(z)): 0.5191 / 0.4629 Acc: 39.0625 (30.3180)\n",
      "[8/25][676/782] Loss_D: -0.0440 (0.3165) Loss_G: -0.0970 (0.1633) D(x): 0.5186 D(G(z)): 0.4675 / 0.4376 Acc: 42.1875 (30.3197)\n",
      "[8/25][677/782] Loss_D: -0.0625 (0.3165) Loss_G: -0.0251 (0.1633) D(x): 0.5609 D(G(z)): 0.4571 / 0.4098 Acc: 32.8125 (30.3200)\n",
      "[8/25][678/782] Loss_D: -0.1574 (0.3164) Loss_G: -0.1170 (0.1633) D(x): 0.5333 D(G(z)): 0.4124 / 0.4575 Acc: 40.6250 (30.3215)\n",
      "[8/25][679/782] Loss_D: 0.0443 (0.3164) Loss_G: -0.0594 (0.1632) D(x): 0.4965 D(G(z)): 0.4509 / 0.4279 Acc: 40.6250 (30.3230)\n",
      "[8/25][680/782] Loss_D: -0.0053 (0.3163) Loss_G: -0.1250 (0.1632) D(x): 0.5352 D(G(z)): 0.4292 / 0.4399 Acc: 26.5625 (30.3225)\n",
      "[8/25][681/782] Loss_D: -0.1160 (0.3163) Loss_G: -0.2170 (0.1631) D(x): 0.5481 D(G(z)): 0.4883 / 0.4815 Acc: 51.5625 (30.3255)\n",
      "[8/25][682/782] Loss_D: 0.0133 (0.3162) Loss_G: -0.1476 (0.1631) D(x): 0.5836 D(G(z)): 0.4882 / 0.4530 Acc: 31.2500 (30.3257)\n",
      "[8/25][683/782] Loss_D: -0.0125 (0.3162) Loss_G: -0.1070 (0.1631) D(x): 0.5049 D(G(z)): 0.4538 / 0.4396 Acc: 39.0625 (30.3269)\n",
      "[8/25][684/782] Loss_D: -0.0544 (0.3161) Loss_G: -0.1194 (0.1630) D(x): 0.5502 D(G(z)): 0.4993 / 0.4370 Acc: 43.7500 (30.3288)\n",
      "[8/25][685/782] Loss_D: -0.1229 (0.3161) Loss_G: -0.1048 (0.1630) D(x): 0.5502 D(G(z)): 0.4352 / 0.4567 Acc: 39.0625 (30.3301)\n",
      "[8/25][686/782] Loss_D: -0.0518 (0.3160) Loss_G: -0.1198 (0.1629) D(x): 0.5062 D(G(z)): 0.4928 / 0.4461 Acc: 54.6875 (30.3336)\n",
      "[8/25][687/782] Loss_D: -0.0330 (0.3160) Loss_G: 0.0649 (0.1629) D(x): 0.5569 D(G(z)): 0.4629 / 0.3826 Acc: 32.8125 (30.3340)\n",
      "[8/25][688/782] Loss_D: 0.1147 (0.3159) Loss_G: -0.2000 (0.1629) D(x): 0.4613 D(G(z)): 0.4585 / 0.4697 Acc: 39.0625 (30.3352)\n",
      "[8/25][689/782] Loss_D: 0.0592 (0.3159) Loss_G: -0.2515 (0.1628) D(x): 0.5176 D(G(z)): 0.4840 / 0.5141 Acc: 39.0625 (30.3365)\n",
      "[8/25][690/782] Loss_D: 0.0523 (0.3159) Loss_G: -0.1418 (0.1628) D(x): 0.5354 D(G(z)): 0.5173 / 0.4646 Acc: 45.3125 (30.3386)\n",
      "[8/25][691/782] Loss_D: 0.0345 (0.3158) Loss_G: -0.0955 (0.1627) D(x): 0.5092 D(G(z)): 0.4849 / 0.4399 Acc: 37.5000 (30.3397)\n",
      "[8/25][692/782] Loss_D: -0.0656 (0.3158) Loss_G: -0.2162 (0.1627) D(x): 0.5173 D(G(z)): 0.3975 / 0.4835 Acc: 31.2500 (30.3398)\n",
      "[8/25][693/782] Loss_D: -0.1207 (0.3157) Loss_G: -0.1530 (0.1626) D(x): 0.5449 D(G(z)): 0.4371 / 0.4611 Acc: 39.0625 (30.3411)\n",
      "[8/25][694/782] Loss_D: -0.1035 (0.3156) Loss_G: -0.1568 (0.1626) D(x): 0.5892 D(G(z)): 0.4702 / 0.4617 Acc: 39.0625 (30.3423)\n",
      "[8/25][695/782] Loss_D: -0.0966 (0.3156) Loss_G: -0.0437 (0.1625) D(x): 0.5735 D(G(z)): 0.4942 / 0.4212 Acc: 45.3125 (30.3445)\n",
      "[8/25][696/782] Loss_D: -0.0450 (0.3155) Loss_G: 0.0073 (0.1625) D(x): 0.4903 D(G(z)): 0.4178 / 0.3941 Acc: 39.0625 (30.3457)\n",
      "[8/25][697/782] Loss_D: 0.0853 (0.3155) Loss_G: -0.1763 (0.1625) D(x): 0.4771 D(G(z)): 0.4517 / 0.4685 Acc: 35.9375 (30.3465)\n",
      "[8/25][698/782] Loss_D: -0.0692 (0.3154) Loss_G: -0.2222 (0.1624) D(x): 0.5364 D(G(z)): 0.4812 / 0.4924 Acc: 45.3125 (30.3487)\n",
      "[8/25][699/782] Loss_D: 0.0032 (0.3154) Loss_G: -0.1742 (0.1624) D(x): 0.5445 D(G(z)): 0.4516 / 0.4601 Acc: 28.1250 (30.3484)\n",
      "[8/25][700/782] Loss_D: -0.0023 (0.3153) Loss_G: -0.0473 (0.1623) D(x): 0.5520 D(G(z)): 0.4856 / 0.4290 Acc: 40.6250 (30.3498)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[8/25][701/782] Loss_D: -0.0593 (0.3153) Loss_G: -0.0046 (0.1623) D(x): 0.5477 D(G(z)): 0.4507 / 0.4045 Acc: 37.5000 (30.3509)\n",
      "[8/25][702/782] Loss_D: -0.0073 (0.3152) Loss_G: -0.1217 (0.1623) D(x): 0.5388 D(G(z)): 0.4606 / 0.4552 Acc: 37.5000 (30.3519)\n",
      "[8/25][703/782] Loss_D: -0.0734 (0.3152) Loss_G: -0.1388 (0.1622) D(x): 0.5400 D(G(z)): 0.4610 / 0.4597 Acc: 42.1875 (30.3536)\n",
      "[8/25][704/782] Loss_D: 0.0683 (0.3152) Loss_G: -0.2049 (0.1622) D(x): 0.5030 D(G(z)): 0.4653 / 0.4701 Acc: 39.0625 (30.3548)\n",
      "[8/25][705/782] Loss_D: -0.0354 (0.3151) Loss_G: -0.0975 (0.1621) D(x): 0.5426 D(G(z)): 0.4774 / 0.4386 Acc: 37.5000 (30.3559)\n",
      "[8/25][706/782] Loss_D: 0.0562 (0.3151) Loss_G: -0.1281 (0.1621) D(x): 0.5247 D(G(z)): 0.4917 / 0.4459 Acc: 37.5000 (30.3569)\n",
      "[8/25][707/782] Loss_D: -0.1560 (0.3150) Loss_G: -0.1281 (0.1621) D(x): 0.5444 D(G(z)): 0.4343 / 0.4588 Acc: 40.6250 (30.3584)\n",
      "[8/25][708/782] Loss_D: 0.1345 (0.3150) Loss_G: -0.0955 (0.1620) D(x): 0.4895 D(G(z)): 0.4475 / 0.4463 Acc: 29.6875 (30.3583)\n",
      "[8/25][709/782] Loss_D: 0.0708 (0.3149) Loss_G: 0.0271 (0.1620) D(x): 0.5808 D(G(z)): 0.5034 / 0.3914 Acc: 32.8125 (30.3586)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/25][710/782] Loss_D: 0.1480 (0.3149) Loss_G: -0.0910 (0.1620) D(x): 0.5079 D(G(z)): 0.5031 / 0.4388 Acc: 37.5000 (30.3596)\n",
      "[8/25][711/782] Loss_D: 0.0773 (0.3149) Loss_G: -0.1628 (0.1619) D(x): 0.4927 D(G(z)): 0.4436 / 0.4594 Acc: 32.8125 (30.3600)\n",
      "[8/25][712/782] Loss_D: -0.2776 (0.3148) Loss_G: -0.1519 (0.1619) D(x): 0.5274 D(G(z)): 0.3961 / 0.4561 Acc: 48.4375 (30.3626)\n",
      "[8/25][713/782] Loss_D: 0.0765 (0.3148) Loss_G: -0.2318 (0.1618) D(x): 0.4655 D(G(z)): 0.4410 / 0.4836 Acc: 37.5000 (30.3636)\n",
      "[8/25][714/782] Loss_D: 0.0037 (0.3147) Loss_G: -0.1781 (0.1618) D(x): 0.6210 D(G(z)): 0.5604 / 0.4689 Acc: 39.0625 (30.3649)\n",
      "[8/25][715/782] Loss_D: -0.0268 (0.3147) Loss_G: -0.1159 (0.1617) D(x): 0.5403 D(G(z)): 0.4654 / 0.4484 Acc: 35.9375 (30.3657)\n",
      "[8/25][716/782] Loss_D: -0.1639 (0.3146) Loss_G: -0.0685 (0.1617) D(x): 0.5664 D(G(z)): 0.4230 / 0.4181 Acc: 35.9375 (30.3665)\n",
      "[8/25][717/782] Loss_D: -0.0950 (0.3145) Loss_G: -0.1685 (0.1617) D(x): 0.5063 D(G(z)): 0.4467 / 0.4574 Acc: 43.7500 (30.3684)\n",
      "[8/25][718/782] Loss_D: 0.0074 (0.3145) Loss_G: -0.1019 (0.1616) D(x): 0.5519 D(G(z)): 0.5014 / 0.4385 Acc: 35.9375 (30.3692)\n",
      "[8/25][719/782] Loss_D: 0.0502 (0.3145) Loss_G: -0.0951 (0.1616) D(x): 0.5135 D(G(z)): 0.4595 / 0.4443 Acc: 37.5000 (30.3702)\n",
      "[8/25][720/782] Loss_D: -0.0124 (0.3144) Loss_G: -0.0722 (0.1615) D(x): 0.5488 D(G(z)): 0.4750 / 0.4360 Acc: 37.5000 (30.3712)\n",
      "[8/25][721/782] Loss_D: -0.0865 (0.3144) Loss_G: -0.0572 (0.1615) D(x): 0.5214 D(G(z)): 0.4377 / 0.4292 Acc: 42.1875 (30.3729)\n",
      "[8/25][722/782] Loss_D: 0.0944 (0.3143) Loss_G: -0.1873 (0.1615) D(x): 0.5181 D(G(z)): 0.4854 / 0.4637 Acc: 32.8125 (30.3733)\n",
      "[8/25][723/782] Loss_D: 0.1547 (0.3143) Loss_G: -0.2360 (0.1614) D(x): 0.5090 D(G(z)): 0.5108 / 0.5010 Acc: 35.9375 (30.3741)\n",
      "[8/25][724/782] Loss_D: 0.0553 (0.3143) Loss_G: -0.1181 (0.1614) D(x): 0.4924 D(G(z)): 0.4563 / 0.4454 Acc: 35.9375 (30.3749)\n",
      "[8/25][725/782] Loss_D: 0.1483 (0.3142) Loss_G: -0.2645 (0.1613) D(x): 0.5192 D(G(z)): 0.5357 / 0.5075 Acc: 37.5000 (30.3759)\n",
      "[8/25][726/782] Loss_D: 0.1572 (0.3142) Loss_G: -0.0705 (0.1613) D(x): 0.5298 D(G(z)): 0.5132 / 0.4406 Acc: 37.5000 (30.3769)\n",
      "[8/25][727/782] Loss_D: 0.2699 (0.3142) Loss_G: -0.1316 (0.1612) D(x): 0.4784 D(G(z)): 0.4845 / 0.4533 Acc: 26.5625 (30.3764)\n",
      "[8/25][728/782] Loss_D: 0.1545 (0.3142) Loss_G: -0.0706 (0.1612) D(x): 0.5509 D(G(z)): 0.5267 / 0.4255 Acc: 31.2500 (30.3765)\n",
      "[8/25][729/782] Loss_D: 0.0013 (0.3141) Loss_G: 0.0454 (0.1612) D(x): 0.5353 D(G(z)): 0.4694 / 0.3867 Acc: 35.9375 (30.3773)\n",
      "[8/25][730/782] Loss_D: -0.0183 (0.3141) Loss_G: -0.1166 (0.1611) D(x): 0.5079 D(G(z)): 0.4567 / 0.4596 Acc: 46.8750 (30.3796)\n",
      "[8/25][731/782] Loss_D: 0.1305 (0.3141) Loss_G: -0.1673 (0.1611) D(x): 0.4913 D(G(z)): 0.4571 / 0.4667 Acc: 31.2500 (30.3798)\n",
      "[8/25][732/782] Loss_D: -0.0160 (0.3140) Loss_G: -0.1258 (0.1611) D(x): 0.5489 D(G(z)): 0.4637 / 0.4476 Acc: 34.3750 (30.3803)\n",
      "[8/25][733/782] Loss_D: 0.0332 (0.3140) Loss_G: -0.0840 (0.1610) D(x): 0.5309 D(G(z)): 0.4900 / 0.4337 Acc: 37.5000 (30.3813)\n",
      "[8/25][734/782] Loss_D: 0.2724 (0.3140) Loss_G: -0.1880 (0.1610) D(x): 0.5273 D(G(z)): 0.5505 / 0.4766 Acc: 31.2500 (30.3815)\n",
      "[8/25][735/782] Loss_D: -0.0730 (0.3139) Loss_G: 0.0665 (0.1610) D(x): 0.5079 D(G(z)): 0.4497 / 0.3990 Acc: 45.3125 (30.3836)\n",
      "[8/25][736/782] Loss_D: -0.0047 (0.3139) Loss_G: -0.0844 (0.1609) D(x): 0.5109 D(G(z)): 0.4938 / 0.4492 Acc: 46.8750 (30.3860)\n",
      "[8/25][737/782] Loss_D: 0.1331 (0.3138) Loss_G: -0.0355 (0.1609) D(x): 0.4873 D(G(z)): 0.4936 / 0.4126 Acc: 35.9375 (30.3868)\n",
      "[8/25][738/782] Loss_D: -0.0049 (0.3138) Loss_G: -0.2305 (0.1608) D(x): 0.4598 D(G(z)): 0.4102 / 0.4870 Acc: 45.3125 (30.3889)\n",
      "[8/25][739/782] Loss_D: -0.0275 (0.3138) Loss_G: -0.1716 (0.1608) D(x): 0.5591 D(G(z)): 0.4640 / 0.4738 Acc: 35.9375 (30.3897)\n",
      "[8/25][740/782] Loss_D: 0.1083 (0.3137) Loss_G: -0.1661 (0.1607) D(x): 0.5751 D(G(z)): 0.4928 / 0.4600 Acc: 20.3125 (30.3882)\n",
      "[8/25][741/782] Loss_D: 0.0271 (0.3137) Loss_G: -0.0227 (0.1607) D(x): 0.6152 D(G(z)): 0.4901 / 0.4163 Acc: 21.8750 (30.3870)\n",
      "[8/25][742/782] Loss_D: -0.0172 (0.3136) Loss_G: 0.0234 (0.1607) D(x): 0.4717 D(G(z)): 0.4112 / 0.4001 Acc: 40.6250 (30.3885)\n",
      "[8/25][743/782] Loss_D: 0.0024 (0.3136) Loss_G: -0.0841 (0.1607) D(x): 0.5389 D(G(z)): 0.4551 / 0.4243 Acc: 32.8125 (30.3888)\n",
      "[8/25][744/782] Loss_D: -0.2398 (0.3135) Loss_G: 0.0050 (0.1606) D(x): 0.6197 D(G(z)): 0.4417 / 0.4009 Acc: 39.0625 (30.3901)\n",
      "[8/25][745/782] Loss_D: -0.3306 (0.3134) Loss_G: 0.0946 (0.1606) D(x): 0.6070 D(G(z)): 0.4230 / 0.3607 Acc: 43.7500 (30.3920)\n",
      "[8/25][746/782] Loss_D: 0.0862 (0.3134) Loss_G: -0.1377 (0.1606) D(x): 0.4757 D(G(z)): 0.5011 / 0.4483 Acc: 45.3125 (30.3941)\n",
      "[8/25][747/782] Loss_D: 0.2176 (0.3134) Loss_G: -0.0745 (0.1606) D(x): 0.5189 D(G(z)): 0.5176 / 0.4169 Acc: 31.2500 (30.3942)\n",
      "[8/25][748/782] Loss_D: 0.2676 (0.3134) Loss_G: -0.0859 (0.1605) D(x): 0.4698 D(G(z)): 0.5110 / 0.4229 Acc: 31.2500 (30.3944)\n",
      "[8/25][749/782] Loss_D: 0.1778 (0.3133) Loss_G: -0.1304 (0.1605) D(x): 0.4487 D(G(z)): 0.4652 / 0.4611 Acc: 39.0625 (30.3956)\n",
      "[8/25][750/782] Loss_D: 0.2962 (0.3133) Loss_G: -0.1718 (0.1604) D(x): 0.4794 D(G(z)): 0.5371 / 0.4844 Acc: 43.7500 (30.3975)\n",
      "[8/25][751/782] Loss_D: 0.1319 (0.3133) Loss_G: -0.0438 (0.1604) D(x): 0.5023 D(G(z)): 0.5051 / 0.4238 Acc: 40.6250 (30.3990)\n",
      "[8/25][752/782] Loss_D: 0.1364 (0.3133) Loss_G: -0.1062 (0.1604) D(x): 0.4817 D(G(z)): 0.4844 / 0.4606 Acc: 42.1875 (30.4006)\n",
      "[8/25][753/782] Loss_D: 0.2334 (0.3133) Loss_G: -0.0312 (0.1603) D(x): 0.4917 D(G(z)): 0.4711 / 0.4413 Acc: 25.0000 (30.3999)\n",
      "[8/25][754/782] Loss_D: 0.0120 (0.3132) Loss_G: -0.1521 (0.1603) D(x): 0.5037 D(G(z)): 0.4891 / 0.4706 Acc: 46.8750 (30.4022)\n",
      "[8/25][755/782] Loss_D: 0.0222 (0.3132) Loss_G: -0.0826 (0.1603) D(x): 0.5849 D(G(z)): 0.5112 / 0.4426 Acc: 35.9375 (30.4030)\n",
      "[8/25][756/782] Loss_D: 0.0264 (0.3132) Loss_G: -0.0468 (0.1602) D(x): 0.5337 D(G(z)): 0.4635 / 0.4208 Acc: 31.2500 (30.4031)\n",
      "[8/25][757/782] Loss_D: -0.0699 (0.3131) Loss_G: -0.0772 (0.1602) D(x): 0.5036 D(G(z)): 0.4311 / 0.4204 Acc: 42.1875 (30.4048)\n",
      "[8/25][758/782] Loss_D: 0.0261 (0.3131) Loss_G: -0.0898 (0.1602) D(x): 0.5260 D(G(z)): 0.4647 / 0.4415 Acc: 39.0625 (30.4060)\n",
      "[8/25][759/782] Loss_D: 0.0403 (0.3130) Loss_G: -0.1872 (0.1601) D(x): 0.5325 D(G(z)): 0.4770 / 0.4821 Acc: 37.5000 (30.4071)\n",
      "[8/25][760/782] Loss_D: -0.1240 (0.3130) Loss_G: -0.0105 (0.1601) D(x): 0.5264 D(G(z)): 0.4751 / 0.4220 Acc: 50.0000 (30.4099)\n",
      "[8/25][761/782] Loss_D: -0.0911 (0.3129) Loss_G: -0.0164 (0.1601) D(x): 0.5386 D(G(z)): 0.4123 / 0.4147 Acc: 31.2500 (30.4100)\n",
      "[8/25][762/782] Loss_D: 0.1039 (0.3129) Loss_G: -0.1556 (0.1600) D(x): 0.5403 D(G(z)): 0.5006 / 0.4640 Acc: 31.2500 (30.4101)\n",
      "[8/25][763/782] Loss_D: -0.1331 (0.3128) Loss_G: -0.0685 (0.1600) D(x): 0.5613 D(G(z)): 0.4515 / 0.4294 Acc: 45.3125 (30.4122)\n",
      "[8/25][764/782] Loss_D: -0.0232 (0.3128) Loss_G: 0.0123 (0.1600) D(x): 0.5895 D(G(z)): 0.4717 / 0.4007 Acc: 31.2500 (30.4123)\n",
      "[8/25][765/782] Loss_D: -0.1547 (0.3127) Loss_G: -0.0565 (0.1599) D(x): 0.5054 D(G(z)): 0.4106 / 0.4186 Acc: 43.7500 (30.4142)\n",
      "[8/25][766/782] Loss_D: -0.0906 (0.3126) Loss_G: -0.2362 (0.1599) D(x): 0.5221 D(G(z)): 0.4372 / 0.5047 Acc: 39.0625 (30.4155)\n",
      "[8/25][767/782] Loss_D: -0.0741 (0.3126) Loss_G: -0.1217 (0.1598) D(x): 0.5633 D(G(z)): 0.4608 / 0.4498 Acc: 43.7500 (30.4174)\n",
      "[8/25][768/782] Loss_D: 0.1712 (0.3126) Loss_G: -0.0097 (0.1598) D(x): 0.5481 D(G(z)): 0.5127 / 0.4326 Acc: 31.2500 (30.4175)\n",
      "[8/25][769/782] Loss_D: 0.2608 (0.3126) Loss_G: -0.0385 (0.1598) D(x): 0.5254 D(G(z)): 0.4992 / 0.4433 Acc: 25.0000 (30.4167)\n",
      "[8/25][770/782] Loss_D: 0.1259 (0.3125) Loss_G: 0.0210 (0.1598) D(x): 0.4594 D(G(z)): 0.4503 / 0.3930 Acc: 37.5000 (30.4177)\n",
      "[8/25][771/782] Loss_D: 0.0802 (0.3125) Loss_G: -0.0085 (0.1597) D(x): 0.4683 D(G(z)): 0.4339 / 0.4359 Acc: 39.0625 (30.4189)\n",
      "[8/25][772/782] Loss_D: -0.2846 (0.3124) Loss_G: -0.1226 (0.1597) D(x): 0.6218 D(G(z)): 0.4651 / 0.4689 Acc: 46.8750 (30.4213)\n",
      "[8/25][773/782] Loss_D: 0.0121 (0.3124) Loss_G: 0.0219 (0.1597) D(x): 0.5851 D(G(z)): 0.4925 / 0.4037 Acc: 31.2500 (30.4214)\n",
      "[8/25][774/782] Loss_D: 0.1351 (0.3123) Loss_G: -0.0466 (0.1596) D(x): 0.4884 D(G(z)): 0.4640 / 0.4249 Acc: 35.9375 (30.4222)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/25][775/782] Loss_D: -0.0665 (0.3123) Loss_G: -0.0996 (0.1596) D(x): 0.4780 D(G(z)): 0.4067 / 0.4471 Acc: 42.1875 (30.4239)\n",
      "[8/25][776/782] Loss_D: 0.0528 (0.3123) Loss_G: -0.1052 (0.1596) D(x): 0.5458 D(G(z)): 0.4864 / 0.4593 Acc: 32.8125 (30.4242)\n",
      "[8/25][777/782] Loss_D: 0.2913 (0.3122) Loss_G: -0.2022 (0.1595) D(x): 0.5068 D(G(z)): 0.5584 / 0.4810 Acc: 34.3750 (30.4248)\n",
      "[8/25][778/782] Loss_D: -0.0079 (0.3122) Loss_G: -0.0693 (0.1595) D(x): 0.5809 D(G(z)): 0.4700 / 0.4210 Acc: 29.6875 (30.4247)\n",
      "[8/25][779/782] Loss_D: 0.2387 (0.3122) Loss_G: -0.0816 (0.1595) D(x): 0.5144 D(G(z)): 0.4884 / 0.4469 Acc: 20.3125 (30.4232)\n",
      "[8/25][780/782] Loss_D: 0.0600 (0.3122) Loss_G: -0.1603 (0.1594) D(x): 0.4994 D(G(z)): 0.4397 / 0.4630 Acc: 34.3750 (30.4238)\n",
      "[8/25][781/782] Loss_D: 0.0944 (0.3121) Loss_G: -0.0065 (0.1594) D(x): 0.4818 D(G(z)): 0.4509 / 0.4771 Acc: 43.7500 (30.4257)\n",
      "[9/25][0/782] Loss_D: 0.2103 (0.3121) Loss_G: -0.1603 (0.1593) D(x): 0.5439 D(G(z)): 0.5441 / 0.4465 Acc: 35.9375 (30.4265)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[9/25][1/782] Loss_D: 0.1107 (0.3121) Loss_G: -0.0974 (0.1593) D(x): 0.5374 D(G(z)): 0.4951 / 0.4498 Acc: 29.6875 (30.4264)\n",
      "[9/25][2/782] Loss_D: 0.0820 (0.3120) Loss_G: -0.0756 (0.1593) D(x): 0.4957 D(G(z)): 0.4368 / 0.4184 Acc: 28.1250 (30.4260)\n",
      "[9/25][3/782] Loss_D: 0.1712 (0.3120) Loss_G: -0.0319 (0.1592) D(x): 0.4625 D(G(z)): 0.4727 / 0.4194 Acc: 39.0625 (30.4273)\n",
      "[9/25][4/782] Loss_D: 0.0697 (0.3120) Loss_G: -0.2362 (0.1592) D(x): 0.4934 D(G(z)): 0.4958 / 0.5135 Acc: 46.8750 (30.4296)\n",
      "[9/25][5/782] Loss_D: -0.1878 (0.3119) Loss_G: -0.0644 (0.1592) D(x): 0.6152 D(G(z)): 0.5082 / 0.4200 Acc: 46.8750 (30.4319)\n",
      "[9/25][6/782] Loss_D: -0.1202 (0.3119) Loss_G: -0.0009 (0.1591) D(x): 0.5283 D(G(z)): 0.4524 / 0.4142 Acc: 46.8750 (30.4343)\n",
      "[9/25][7/782] Loss_D: -0.1002 (0.3118) Loss_G: -0.0579 (0.1591) D(x): 0.5105 D(G(z)): 0.3847 / 0.4268 Acc: 39.0625 (30.4355)\n",
      "[9/25][8/782] Loss_D: -0.0437 (0.3118) Loss_G: -0.2331 (0.1590) D(x): 0.5676 D(G(z)): 0.4816 / 0.4973 Acc: 35.9375 (30.4363)\n",
      "[9/25][9/782] Loss_D: -0.0493 (0.3117) Loss_G: 0.0243 (0.1590) D(x): 0.6324 D(G(z)): 0.5246 / 0.3926 Acc: 34.3750 (30.4368)\n",
      "[9/25][10/782] Loss_D: -0.1509 (0.3116) Loss_G: -0.0043 (0.1590) D(x): 0.5599 D(G(z)): 0.4624 / 0.4148 Acc: 45.3125 (30.4389)\n",
      "[9/25][11/782] Loss_D: 0.0344 (0.3116) Loss_G: -0.0725 (0.1590) D(x): 0.5069 D(G(z)): 0.4378 / 0.4169 Acc: 35.9375 (30.4397)\n",
      "[9/25][12/782] Loss_D: 0.2060 (0.3116) Loss_G: -0.0046 (0.1589) D(x): 0.5173 D(G(z)): 0.4660 / 0.4125 Acc: 26.5625 (30.4392)\n",
      "[9/25][13/782] Loss_D: -0.2259 (0.3115) Loss_G: 0.0546 (0.1589) D(x): 0.5769 D(G(z)): 0.4065 / 0.3752 Acc: 39.0625 (30.4404)\n",
      "[9/25][14/782] Loss_D: -0.0029 (0.3115) Loss_G: -0.1096 (0.1589) D(x): 0.5410 D(G(z)): 0.4814 / 0.4557 Acc: 40.6250 (30.4418)\n",
      "[9/25][15/782] Loss_D: -0.1460 (0.3114) Loss_G: -0.0762 (0.1589) D(x): 0.5767 D(G(z)): 0.4442 / 0.4224 Acc: 37.5000 (30.4428)\n",
      "[9/25][16/782] Loss_D: 0.1238 (0.3114) Loss_G: -0.1314 (0.1588) D(x): 0.5069 D(G(z)): 0.4650 / 0.4477 Acc: 32.8125 (30.4432)\n",
      "[9/25][17/782] Loss_D: -0.1447 (0.3113) Loss_G: -0.0541 (0.1588) D(x): 0.5918 D(G(z)): 0.4417 / 0.4275 Acc: 35.9375 (30.4439)\n",
      "[9/25][18/782] Loss_D: -0.1198 (0.3112) Loss_G: -0.1934 (0.1587) D(x): 0.5160 D(G(z)): 0.3858 / 0.4836 Acc: 39.0625 (30.4452)\n",
      "[9/25][19/782] Loss_D: 0.0274 (0.3112) Loss_G: -0.0356 (0.1587) D(x): 0.5271 D(G(z)): 0.4680 / 0.4189 Acc: 34.3750 (30.4457)\n",
      "[9/25][20/782] Loss_D: -0.0390 (0.3112) Loss_G: -0.0741 (0.1587) D(x): 0.5407 D(G(z)): 0.4751 / 0.4376 Acc: 43.7500 (30.4476)\n",
      "[9/25][21/782] Loss_D: -0.1432 (0.3111) Loss_G: 0.0405 (0.1587) D(x): 0.6197 D(G(z)): 0.4656 / 0.3994 Acc: 35.9375 (30.4484)\n",
      "[9/25][22/782] Loss_D: -0.0521 (0.3110) Loss_G: -0.0942 (0.1586) D(x): 0.5129 D(G(z)): 0.4300 / 0.4251 Acc: 43.7500 (30.4503)\n",
      "[9/25][23/782] Loss_D: 0.2569 (0.3110) Loss_G: -0.2028 (0.1586) D(x): 0.4731 D(G(z)): 0.5050 / 0.4922 Acc: 32.8125 (30.4506)\n",
      "[9/25][24/782] Loss_D: 0.0047 (0.3110) Loss_G: -0.0879 (0.1585) D(x): 0.5539 D(G(z)): 0.4833 / 0.4418 Acc: 37.5000 (30.4516)\n",
      "[9/25][25/782] Loss_D: -0.0278 (0.3109) Loss_G: -0.0080 (0.1585) D(x): 0.5746 D(G(z)): 0.5029 / 0.3997 Acc: 37.5000 (30.4526)\n",
      "[9/25][26/782] Loss_D: 0.0810 (0.3109) Loss_G: 0.0509 (0.1585) D(x): 0.5490 D(G(z)): 0.4775 / 0.4001 Acc: 34.3750 (30.4532)\n",
      "[9/25][27/782] Loss_D: 0.2360 (0.3109) Loss_G: -0.1372 (0.1585) D(x): 0.4480 D(G(z)): 0.4436 / 0.4609 Acc: 35.9375 (30.4539)\n",
      "[9/25][28/782] Loss_D: 0.0596 (0.3109) Loss_G: -0.1215 (0.1584) D(x): 0.5194 D(G(z)): 0.4165 / 0.4754 Acc: 28.1250 (30.4536)\n",
      "[9/25][29/782] Loss_D: 0.0964 (0.3108) Loss_G: -0.2330 (0.1584) D(x): 0.5050 D(G(z)): 0.5061 / 0.4890 Acc: 43.7500 (30.4555)\n",
      "[9/25][30/782] Loss_D: 0.2094 (0.3108) Loss_G: -0.1132 (0.1583) D(x): 0.5414 D(G(z)): 0.5319 / 0.4502 Acc: 32.8125 (30.4558)\n",
      "[9/25][31/782] Loss_D: -0.0428 (0.3108) Loss_G: -0.0286 (0.1583) D(x): 0.5276 D(G(z)): 0.4676 / 0.4225 Acc: 42.1875 (30.4575)\n",
      "[9/25][32/782] Loss_D: -0.0444 (0.3107) Loss_G: -0.1017 (0.1583) D(x): 0.5700 D(G(z)): 0.4581 / 0.4408 Acc: 28.1250 (30.4571)\n",
      "[9/25][33/782] Loss_D: -0.0171 (0.3107) Loss_G: -0.0223 (0.1582) D(x): 0.5108 D(G(z)): 0.4623 / 0.4079 Acc: 43.7500 (30.4590)\n",
      "[9/25][34/782] Loss_D: -0.0817 (0.3106) Loss_G: -0.0710 (0.1582) D(x): 0.4807 D(G(z)): 0.4071 / 0.4401 Acc: 48.4375 (30.4616)\n",
      "[9/25][35/782] Loss_D: -0.0176 (0.3106) Loss_G: -0.2261 (0.1582) D(x): 0.5414 D(G(z)): 0.4314 / 0.4875 Acc: 28.1250 (30.4612)\n",
      "[9/25][36/782] Loss_D: -0.0015 (0.3105) Loss_G: -0.0121 (0.1581) D(x): 0.5691 D(G(z)): 0.4582 / 0.4288 Acc: 37.5000 (30.4622)\n",
      "[9/25][37/782] Loss_D: -0.1291 (0.3105) Loss_G: -0.1501 (0.1581) D(x): 0.5989 D(G(z)): 0.4655 / 0.4551 Acc: 35.9375 (30.4630)\n",
      "[9/25][38/782] Loss_D: -0.0520 (0.3104) Loss_G: 0.0656 (0.1581) D(x): 0.5766 D(G(z)): 0.4832 / 0.3909 Acc: 40.6250 (30.4644)\n",
      "[9/25][39/782] Loss_D: -0.0972 (0.3104) Loss_G: 0.0479 (0.1581) D(x): 0.5210 D(G(z)): 0.4438 / 0.3993 Acc: 46.8750 (30.4668)\n",
      "[9/25][40/782] Loss_D: 0.0896 (0.3103) Loss_G: -0.0195 (0.1580) D(x): 0.4624 D(G(z)): 0.4062 / 0.4411 Acc: 34.3750 (30.4673)\n",
      "[9/25][41/782] Loss_D: 0.0549 (0.3103) Loss_G: -0.1571 (0.1580) D(x): 0.4717 D(G(z)): 0.4675 / 0.4673 Acc: 46.8750 (30.4696)\n",
      "[9/25][42/782] Loss_D: -0.0302 (0.3102) Loss_G: -0.1893 (0.1579) D(x): 0.5838 D(G(z)): 0.5073 / 0.4860 Acc: 43.7500 (30.4715)\n",
      "[9/25][43/782] Loss_D: 0.0742 (0.3102) Loss_G: -0.1299 (0.1579) D(x): 0.6107 D(G(z)): 0.5543 / 0.4707 Acc: 39.0625 (30.4727)\n",
      "[9/25][44/782] Loss_D: -0.0846 (0.3101) Loss_G: -0.0785 (0.1579) D(x): 0.5021 D(G(z)): 0.4571 / 0.4357 Acc: 53.1250 (30.4759)\n",
      "[9/25][45/782] Loss_D: -0.1149 (0.3101) Loss_G: 0.0310 (0.1578) D(x): 0.5782 D(G(z)): 0.4404 / 0.4000 Acc: 34.3750 (30.4765)\n",
      "[9/25][46/782] Loss_D: 0.0485 (0.3101) Loss_G: -0.1835 (0.1578) D(x): 0.4979 D(G(z)): 0.5252 / 0.4710 Acc: 51.5625 (30.4794)\n",
      "[9/25][47/782] Loss_D: 0.1223 (0.3100) Loss_G: -0.2245 (0.1577) D(x): 0.4823 D(G(z)): 0.5061 / 0.4954 Acc: 45.3125 (30.4815)\n",
      "[9/25][48/782] Loss_D: 0.4587 (0.3100) Loss_G: -0.2081 (0.1577) D(x): 0.5056 D(G(z)): 0.5719 / 0.5230 Acc: 26.5625 (30.4810)\n",
      "[9/25][49/782] Loss_D: 0.3101 (0.3100) Loss_G: -0.0423 (0.1577) D(x): 0.4754 D(G(z)): 0.5007 / 0.4291 Acc: 32.8125 (30.4813)\n",
      "[9/25][50/782] Loss_D: 0.1235 (0.3100) Loss_G: -0.1126 (0.1576) D(x): 0.4505 D(G(z)): 0.4475 / 0.4619 Acc: 37.5000 (30.4823)\n",
      "[9/25][51/782] Loss_D: -0.0090 (0.3100) Loss_G: -0.2583 (0.1576) D(x): 0.4754 D(G(z)): 0.4360 / 0.5151 Acc: 43.7500 (30.4842)\n",
      "[9/25][52/782] Loss_D: 0.1971 (0.3100) Loss_G: -0.2065 (0.1575) D(x): 0.5409 D(G(z)): 0.5423 / 0.5102 Acc: 32.8125 (30.4845)\n",
      "[9/25][53/782] Loss_D: -0.0750 (0.3099) Loss_G: -0.2482 (0.1575) D(x): 0.5196 D(G(z)): 0.4998 / 0.4880 Acc: 51.5625 (30.4875)\n",
      "[9/25][54/782] Loss_D: 0.1202 (0.3099) Loss_G: -0.1166 (0.1574) D(x): 0.5155 D(G(z)): 0.4737 / 0.4500 Acc: 29.6875 (30.4874)\n",
      "[9/25][55/782] Loss_D: 0.0592 (0.3098) Loss_G: -0.1239 (0.1574) D(x): 0.5437 D(G(z)): 0.4715 / 0.4488 Acc: 26.5625 (30.4868)\n",
      "[9/25][56/782] Loss_D: 0.0357 (0.3098) Loss_G: -0.1354 (0.1573) D(x): 0.5121 D(G(z)): 0.4311 / 0.4617 Acc: 32.8125 (30.4871)\n",
      "[9/25][57/782] Loss_D: 0.0771 (0.3098) Loss_G: -0.1986 (0.1573) D(x): 0.5106 D(G(z)): 0.4979 / 0.4914 Acc: 42.1875 (30.4888)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/25][58/782] Loss_D: 0.0001 (0.3097) Loss_G: -0.0504 (0.1573) D(x): 0.5278 D(G(z)): 0.4826 / 0.4174 Acc: 40.6250 (30.4902)\n",
      "[9/25][59/782] Loss_D: -0.0743 (0.3097) Loss_G: -0.0392 (0.1572) D(x): 0.5650 D(G(z)): 0.4445 / 0.4302 Acc: 31.2500 (30.4903)\n",
      "[9/25][60/782] Loss_D: 0.2483 (0.3097) Loss_G: 0.0426 (0.1572) D(x): 0.4880 D(G(z)): 0.4934 / 0.3948 Acc: 31.2500 (30.4904)\n",
      "[9/25][61/782] Loss_D: -0.0952 (0.3096) Loss_G: -0.1413 (0.1572) D(x): 0.5374 D(G(z)): 0.4308 / 0.4573 Acc: 39.0625 (30.4916)\n",
      "[9/25][62/782] Loss_D: -0.0708 (0.3096) Loss_G: -0.1374 (0.1571) D(x): 0.5358 D(G(z)): 0.4514 / 0.4535 Acc: 35.9375 (30.4924)\n",
      "[9/25][63/782] Loss_D: -0.0250 (0.3095) Loss_G: -0.1593 (0.1571) D(x): 0.5578 D(G(z)): 0.5092 / 0.4592 Acc: 43.7500 (30.4943)\n",
      "[9/25][64/782] Loss_D: 0.1119 (0.3095) Loss_G: 0.0218 (0.1571) D(x): 0.5356 D(G(z)): 0.4554 / 0.3948 Acc: 23.4375 (30.4933)\n",
      "[9/25][65/782] Loss_D: -0.0073 (0.3094) Loss_G: -0.0779 (0.1570) D(x): 0.5128 D(G(z)): 0.4166 / 0.4321 Acc: 28.1250 (30.4929)\n",
      "[9/25][66/782] Loss_D: 0.0091 (0.3094) Loss_G: -0.0253 (0.1570) D(x): 0.5222 D(G(z)): 0.4697 / 0.4208 Acc: 37.5000 (30.4939)\n",
      "[9/25][67/782] Loss_D: -0.0153 (0.3093) Loss_G: -0.0979 (0.1570) D(x): 0.5445 D(G(z)): 0.4995 / 0.4487 Acc: 42.1875 (30.4956)\n",
      "[9/25][68/782] Loss_D: 0.0611 (0.3093) Loss_G: -0.1590 (0.1569) D(x): 0.5129 D(G(z)): 0.4242 / 0.4570 Acc: 28.1250 (30.4952)\n",
      "[9/25][69/782] Loss_D: -0.0425 (0.3093) Loss_G: 0.0323 (0.1569) D(x): 0.5865 D(G(z)): 0.5252 / 0.3879 Acc: 42.1875 (30.4969)\n",
      "[9/25][70/782] Loss_D: -0.0930 (0.3092) Loss_G: 0.0017 (0.1569) D(x): 0.5240 D(G(z)): 0.3815 / 0.3883 Acc: 31.2500 (30.4970)\n",
      "[9/25][71/782] Loss_D: -0.1565 (0.3091) Loss_G: -0.1687 (0.1568) D(x): 0.4956 D(G(z)): 0.4319 / 0.4702 Acc: 53.1250 (30.5002)\n",
      "[9/25][72/782] Loss_D: -0.1028 (0.3091) Loss_G: -0.0987 (0.1568) D(x): 0.5793 D(G(z)): 0.5049 / 0.4488 Acc: 43.7500 (30.5020)\n",
      "[9/25][73/782] Loss_D: -0.0626 (0.3090) Loss_G: -0.0073 (0.1568) D(x): 0.5980 D(G(z)): 0.4858 / 0.4023 Acc: 34.3750 (30.5026)\n",
      "[9/25][74/782] Loss_D: -0.0928 (0.3090) Loss_G: 0.0622 (0.1568) D(x): 0.5819 D(G(z)): 0.4476 / 0.3770 Acc: 35.9375 (30.5033)\n",
      "[9/25][75/782] Loss_D: -0.0240 (0.3089) Loss_G: 0.0774 (0.1568) D(x): 0.5051 D(G(z)): 0.3986 / 0.3718 Acc: 32.8125 (30.5037)\n",
      "[9/25][76/782] Loss_D: -0.2589 (0.3088) Loss_G: -0.1238 (0.1567) D(x): 0.5331 D(G(z)): 0.3878 / 0.4628 Acc: 50.0000 (30.5064)\n",
      "[9/25][77/782] Loss_D: -0.0250 (0.3088) Loss_G: -0.1659 (0.1567) D(x): 0.5680 D(G(z)): 0.4934 / 0.4715 Acc: 39.0625 (30.5076)\n",
      "[9/25][78/782] Loss_D: -0.1248 (0.3087) Loss_G: -0.0512 (0.1566) D(x): 0.5620 D(G(z)): 0.4476 / 0.4105 Acc: 39.0625 (30.5088)\n",
      "[9/25][79/782] Loss_D: -0.0734 (0.3087) Loss_G: -0.0773 (0.1566) D(x): 0.5380 D(G(z)): 0.4460 / 0.4561 Acc: 39.0625 (30.5100)\n",
      "[9/25][80/782] Loss_D: -0.0335 (0.3086) Loss_G: -0.0273 (0.1566) D(x): 0.5692 D(G(z)): 0.5218 / 0.4242 Acc: 51.5625 (30.5130)\n",
      "[9/25][81/782] Loss_D: 0.1534 (0.3086) Loss_G: -0.0885 (0.1566) D(x): 0.5200 D(G(z)): 0.4739 / 0.4349 Acc: 29.6875 (30.5129)\n",
      "[9/25][82/782] Loss_D: -0.0801 (0.3086) Loss_G: -0.0672 (0.1565) D(x): 0.5134 D(G(z)): 0.4685 / 0.4208 Acc: 48.4375 (30.5154)\n",
      "[9/25][83/782] Loss_D: 0.1169 (0.3085) Loss_G: -0.1710 (0.1565) D(x): 0.5017 D(G(z)): 0.4665 / 0.4665 Acc: 37.5000 (30.5164)\n",
      "[9/25][84/782] Loss_D: 0.1273 (0.3085) Loss_G: -0.1334 (0.1564) D(x): 0.4891 D(G(z)): 0.4875 / 0.4416 Acc: 35.9375 (30.5171)\n",
      "[9/25][85/782] Loss_D: -0.1400 (0.3084) Loss_G: -0.2185 (0.1564) D(x): 0.5379 D(G(z)): 0.4611 / 0.4958 Acc: 50.0000 (30.5199)\n",
      "[9/25][86/782] Loss_D: -0.0485 (0.3084) Loss_G: -0.1116 (0.1563) D(x): 0.6088 D(G(z)): 0.5423 / 0.4640 Acc: 43.7500 (30.5217)\n",
      "[9/25][87/782] Loss_D: -0.0422 (0.3083) Loss_G: -0.0798 (0.1563) D(x): 0.5297 D(G(z)): 0.4651 / 0.4327 Acc: 40.6250 (30.5231)\n",
      "[9/25][88/782] Loss_D: -0.0020 (0.3083) Loss_G: 0.1163 (0.1563) D(x): 0.4970 D(G(z)): 0.4116 / 0.3656 Acc: 35.9375 (30.5239)\n",
      "[9/25][89/782] Loss_D: 0.1299 (0.3083) Loss_G: -0.0420 (0.1563) D(x): 0.4775 D(G(z)): 0.4567 / 0.4339 Acc: 43.7500 (30.5257)\n",
      "[9/25][90/782] Loss_D: 0.0270 (0.3082) Loss_G: -0.2505 (0.1562) D(x): 0.5193 D(G(z)): 0.4676 / 0.5128 Acc: 37.5000 (30.5267)\n",
      "[9/25][91/782] Loss_D: 0.0235 (0.3082) Loss_G: -0.2449 (0.1562) D(x): 0.5459 D(G(z)): 0.4851 / 0.4952 Acc: 34.3750 (30.5273)\n",
      "[9/25][92/782] Loss_D: 0.1844 (0.3082) Loss_G: -0.1155 (0.1561) D(x): 0.5396 D(G(z)): 0.5182 / 0.4492 Acc: 29.6875 (30.5271)\n",
      "[9/25][93/782] Loss_D: 0.0871 (0.3081) Loss_G: -0.0792 (0.1561) D(x): 0.4790 D(G(z)): 0.4394 / 0.4583 Acc: 39.0625 (30.5283)\n",
      "[9/25][94/782] Loss_D: -0.0267 (0.3081) Loss_G: -0.1007 (0.1561) D(x): 0.5693 D(G(z)): 0.4687 / 0.4605 Acc: 35.9375 (30.5291)\n",
      "[9/25][95/782] Loss_D: -0.0891 (0.3080) Loss_G: 0.0637 (0.1560) D(x): 0.5608 D(G(z)): 0.4484 / 0.3978 Acc: 37.5000 (30.5301)\n",
      "[9/25][96/782] Loss_D: -0.0250 (0.3080) Loss_G: 0.1110 (0.1560) D(x): 0.5268 D(G(z)): 0.4521 / 0.3837 Acc: 40.6250 (30.5315)\n",
      "[9/25][97/782] Loss_D: -0.2759 (0.3079) Loss_G: -0.0497 (0.1560) D(x): 0.5387 D(G(z)): 0.4132 / 0.4256 Acc: 54.6875 (30.5349)\n",
      "[9/25][98/782] Loss_D: 0.3648 (0.3079) Loss_G: -0.2542 (0.1560) D(x): 0.4575 D(G(z)): 0.4759 / 0.5317 Acc: 28.1250 (30.5345)\n",
      "[9/25][99/782] Loss_D: -0.0174 (0.3079) Loss_G: -0.1396 (0.1559) D(x): 0.5670 D(G(z)): 0.5167 / 0.4653 Acc: 51.5625 (30.5375)\n",
      "[9/25][100/782] Loss_D: -0.0961 (0.3078) Loss_G: -0.0849 (0.1559) D(x): 0.5317 D(G(z)): 0.4472 / 0.4370 Acc: 45.3125 (30.5396)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[9/25][101/782] Loss_D: 0.0160 (0.3078) Loss_G: -0.1632 (0.1558) D(x): 0.5034 D(G(z)): 0.4593 / 0.4775 Acc: 45.3125 (30.5416)\n",
      "[9/25][102/782] Loss_D: 0.1326 (0.3078) Loss_G: -0.1023 (0.1558) D(x): 0.5650 D(G(z)): 0.5547 / 0.4496 Acc: 37.5000 (30.5426)\n",
      "[9/25][103/782] Loss_D: -0.1336 (0.3077) Loss_G: 0.0907 (0.1558) D(x): 0.5220 D(G(z)): 0.4375 / 0.3722 Acc: 46.8750 (30.5449)\n",
      "[9/25][104/782] Loss_D: -0.2454 (0.3076) Loss_G: -0.1764 (0.1557) D(x): 0.5025 D(G(z)): 0.3731 / 0.4854 Acc: 48.4375 (30.5474)\n",
      "[9/25][105/782] Loss_D: 0.0413 (0.3076) Loss_G: -0.1802 (0.1557) D(x): 0.5333 D(G(z)): 0.4948 / 0.4854 Acc: 45.3125 (30.5495)\n",
      "[9/25][106/782] Loss_D: 0.0286 (0.3075) Loss_G: -0.1506 (0.1556) D(x): 0.5519 D(G(z)): 0.4956 / 0.4709 Acc: 39.0625 (30.5506)\n",
      "[9/25][107/782] Loss_D: -0.0960 (0.3075) Loss_G: -0.0487 (0.1556) D(x): 0.5654 D(G(z)): 0.5116 / 0.4291 Acc: 50.0000 (30.5534)\n",
      "[9/25][108/782] Loss_D: 0.1143 (0.3075) Loss_G: 0.0731 (0.1556) D(x): 0.4734 D(G(z)): 0.4441 / 0.3924 Acc: 35.9375 (30.5541)\n",
      "[9/25][109/782] Loss_D: 0.1617 (0.3074) Loss_G: -0.1278 (0.1556) D(x): 0.4298 D(G(z)): 0.4294 / 0.4742 Acc: 40.6250 (30.5555)\n",
      "[9/25][110/782] Loss_D: 0.2108 (0.3074) Loss_G: -0.0909 (0.1555) D(x): 0.4797 D(G(z)): 0.4989 / 0.4546 Acc: 39.0625 (30.5567)\n",
      "[9/25][111/782] Loss_D: 0.0015 (0.3074) Loss_G: -0.1185 (0.1555) D(x): 0.5519 D(G(z)): 0.4630 / 0.4666 Acc: 35.9375 (30.5575)\n",
      "[9/25][112/782] Loss_D: -0.0751 (0.3073) Loss_G: 0.0081 (0.1555) D(x): 0.5995 D(G(z)): 0.5237 / 0.4011 Acc: 45.3125 (30.5595)\n",
      "[9/25][113/782] Loss_D: -0.2066 (0.3073) Loss_G: 0.0731 (0.1555) D(x): 0.5059 D(G(z)): 0.3757 / 0.3816 Acc: 43.7500 (30.5614)\n",
      "[9/25][114/782] Loss_D: -0.1144 (0.3072) Loss_G: -0.1086 (0.1554) D(x): 0.5789 D(G(z)): 0.4529 / 0.4663 Acc: 37.5000 (30.5624)\n",
      "[9/25][115/782] Loss_D: -0.0589 (0.3071) Loss_G: 0.1003 (0.1554) D(x): 0.5532 D(G(z)): 0.4475 / 0.3882 Acc: 34.3750 (30.5629)\n",
      "[9/25][116/782] Loss_D: -0.1646 (0.3071) Loss_G: 0.0561 (0.1554) D(x): 0.5458 D(G(z)): 0.4172 / 0.3779 Acc: 40.6250 (30.5643)\n",
      "[9/25][117/782] Loss_D: -0.2820 (0.3070) Loss_G: -0.0480 (0.1554) D(x): 0.5716 D(G(z)): 0.4725 / 0.4277 Acc: 59.3750 (30.5683)\n",
      "[9/25][118/782] Loss_D: -0.0629 (0.3069) Loss_G: -0.0139 (0.1554) D(x): 0.5652 D(G(z)): 0.4763 / 0.4063 Acc: 42.1875 (30.5699)\n",
      "[9/25][119/782] Loss_D: 0.0432 (0.3069) Loss_G: -0.2479 (0.1553) D(x): 0.4752 D(G(z)): 0.4483 / 0.5061 Acc: 46.8750 (30.5722)\n",
      "[9/25][120/782] Loss_D: 0.0012 (0.3069) Loss_G: -0.1172 (0.1553) D(x): 0.5797 D(G(z)): 0.5100 / 0.4468 Acc: 40.6250 (30.5736)\n",
      "[9/25][121/782] Loss_D: 0.1381 (0.3068) Loss_G: -0.2029 (0.1552) D(x): 0.4669 D(G(z)): 0.4664 / 0.4953 Acc: 37.5000 (30.5746)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/25][122/782] Loss_D: 0.2901 (0.3068) Loss_G: -0.2671 (0.1552) D(x): 0.5257 D(G(z)): 0.5553 / 0.5175 Acc: 32.8125 (30.5749)\n",
      "[9/25][123/782] Loss_D: -0.1766 (0.3068) Loss_G: -0.0960 (0.1551) D(x): 0.5775 D(G(z)): 0.4445 / 0.4505 Acc: 45.3125 (30.5770)\n",
      "[9/25][124/782] Loss_D: 0.2135 (0.3068) Loss_G: 0.0207 (0.1551) D(x): 0.4954 D(G(z)): 0.4831 / 0.3941 Acc: 32.8125 (30.5773)\n",
      "[9/25][125/782] Loss_D: 0.2006 (0.3067) Loss_G: -0.2434 (0.1550) D(x): 0.4276 D(G(z)): 0.4275 / 0.5023 Acc: 39.0625 (30.5785)\n",
      "[9/25][126/782] Loss_D: -0.0322 (0.3067) Loss_G: -0.1461 (0.1550) D(x): 0.5630 D(G(z)): 0.4727 / 0.4714 Acc: 34.3750 (30.5790)\n",
      "[9/25][127/782] Loss_D: -0.1494 (0.3066) Loss_G: 0.0073 (0.1550) D(x): 0.5864 D(G(z)): 0.4578 / 0.4008 Acc: 37.5000 (30.5800)\n",
      "[9/25][128/782] Loss_D: -0.0563 (0.3066) Loss_G: 0.0325 (0.1550) D(x): 0.5336 D(G(z)): 0.4803 / 0.4010 Acc: 45.3125 (30.5820)\n",
      "[9/25][129/782] Loss_D: -0.0111 (0.3065) Loss_G: -0.0809 (0.1549) D(x): 0.5270 D(G(z)): 0.4495 / 0.4430 Acc: 34.3750 (30.5825)\n",
      "[9/25][130/782] Loss_D: -0.1239 (0.3065) Loss_G: -0.0359 (0.1549) D(x): 0.5650 D(G(z)): 0.4541 / 0.4222 Acc: 42.1875 (30.5842)\n",
      "[9/25][131/782] Loss_D: -0.0455 (0.3064) Loss_G: -0.0123 (0.1549) D(x): 0.5791 D(G(z)): 0.4481 / 0.4049 Acc: 31.2500 (30.5842)\n",
      "[9/25][132/782] Loss_D: 0.0153 (0.3064) Loss_G: -0.1676 (0.1548) D(x): 0.4960 D(G(z)): 0.4348 / 0.4717 Acc: 35.9375 (30.5850)\n",
      "[9/25][133/782] Loss_D: 0.0392 (0.3064) Loss_G: -0.0718 (0.1548) D(x): 0.6147 D(G(z)): 0.5188 / 0.4170 Acc: 29.6875 (30.5849)\n",
      "[9/25][134/782] Loss_D: 0.0260 (0.3063) Loss_G: 0.0158 (0.1548) D(x): 0.5059 D(G(z)): 0.4319 / 0.3931 Acc: 32.8125 (30.5852)\n",
      "[9/25][135/782] Loss_D: 0.1014 (0.3063) Loss_G: -0.1757 (0.1547) D(x): 0.5414 D(G(z)): 0.4950 / 0.4681 Acc: 26.5625 (30.5846)\n",
      "[9/25][136/782] Loss_D: 0.0985 (0.3063) Loss_G: -0.1139 (0.1547) D(x): 0.5227 D(G(z)): 0.4952 / 0.4374 Acc: 32.8125 (30.5849)\n",
      "[9/25][137/782] Loss_D: 0.1043 (0.3062) Loss_G: -0.0319 (0.1547) D(x): 0.5038 D(G(z)): 0.4690 / 0.4174 Acc: 37.5000 (30.5859)\n",
      "[9/25][138/782] Loss_D: -0.0277 (0.3062) Loss_G: -0.0800 (0.1546) D(x): 0.4792 D(G(z)): 0.4025 / 0.4391 Acc: 39.0625 (30.5871)\n",
      "[9/25][139/782] Loss_D: -0.0867 (0.3061) Loss_G: -0.3239 (0.1546) D(x): 0.5393 D(G(z)): 0.4535 / 0.5319 Acc: 37.5000 (30.5880)\n",
      "[9/25][140/782] Loss_D: 0.0231 (0.3061) Loss_G: -0.0420 (0.1545) D(x): 0.6339 D(G(z)): 0.5677 / 0.4222 Acc: 39.0625 (30.5892)\n",
      "[9/25][141/782] Loss_D: -0.0365 (0.3060) Loss_G: 0.0632 (0.1545) D(x): 0.5174 D(G(z)): 0.4459 / 0.3719 Acc: 37.5000 (30.5902)\n",
      "[9/25][142/782] Loss_D: -0.0261 (0.3060) Loss_G: -0.0510 (0.1545) D(x): 0.4728 D(G(z)): 0.4288 / 0.4167 Acc: 43.7500 (30.5920)\n",
      "[9/25][143/782] Loss_D: 0.1997 (0.3060) Loss_G: -0.1633 (0.1545) D(x): 0.4811 D(G(z)): 0.4336 / 0.4856 Acc: 28.1250 (30.5917)\n",
      "[9/25][144/782] Loss_D: 0.1255 (0.3060) Loss_G: -0.2335 (0.1544) D(x): 0.5847 D(G(z)): 0.5547 / 0.4951 Acc: 34.3750 (30.5922)\n",
      "[9/25][145/782] Loss_D: 0.0305 (0.3059) Loss_G: -0.2091 (0.1544) D(x): 0.5551 D(G(z)): 0.5139 / 0.4988 Acc: 42.1875 (30.5938)\n",
      "[9/25][146/782] Loss_D: -0.0530 (0.3059) Loss_G: -0.0405 (0.1543) D(x): 0.5018 D(G(z)): 0.4121 / 0.4164 Acc: 34.3750 (30.5943)\n",
      "[9/25][147/782] Loss_D: 0.0876 (0.3058) Loss_G: -0.2408 (0.1543) D(x): 0.4735 D(G(z)): 0.4408 / 0.5060 Acc: 34.3750 (30.5949)\n",
      "[9/25][148/782] Loss_D: 0.0832 (0.3058) Loss_G: -0.2252 (0.1542) D(x): 0.5260 D(G(z)): 0.5119 / 0.5024 Acc: 40.6250 (30.5963)\n",
      "[9/25][149/782] Loss_D: -0.0639 (0.3058) Loss_G: 0.0093 (0.1542) D(x): 0.5846 D(G(z)): 0.4980 / 0.4051 Acc: 39.0625 (30.5974)\n",
      "[9/25][150/782] Loss_D: -0.0337 (0.3057) Loss_G: -0.0399 (0.1542) D(x): 0.5275 D(G(z)): 0.4260 / 0.4272 Acc: 35.9375 (30.5982)\n",
      "[9/25][151/782] Loss_D: -0.0309 (0.3057) Loss_G: -0.0392 (0.1541) D(x): 0.5292 D(G(z)): 0.4328 / 0.4096 Acc: 34.3750 (30.5987)\n",
      "[9/25][152/782] Loss_D: -0.0096 (0.3056) Loss_G: -0.2214 (0.1541) D(x): 0.5197 D(G(z)): 0.4756 / 0.4935 Acc: 40.6250 (30.6001)\n",
      "[9/25][153/782] Loss_D: 0.0998 (0.3056) Loss_G: 0.1845 (0.1541) D(x): 0.5524 D(G(z)): 0.5188 / 0.3452 Acc: 28.1250 (30.5998)\n",
      "[9/25][154/782] Loss_D: -0.0743 (0.3055) Loss_G: 0.0145 (0.1541) D(x): 0.5145 D(G(z)): 0.3756 / 0.4155 Acc: 35.9375 (30.6005)\n",
      "[9/25][155/782] Loss_D: 0.1132 (0.3055) Loss_G: -0.0726 (0.1540) D(x): 0.4902 D(G(z)): 0.4745 / 0.4393 Acc: 40.6250 (30.6019)\n",
      "[9/25][156/782] Loss_D: -0.1337 (0.3054) Loss_G: -0.0135 (0.1540) D(x): 0.5852 D(G(z)): 0.5005 / 0.4126 Acc: 50.0000 (30.6046)\n",
      "[9/25][157/782] Loss_D: -0.1194 (0.3054) Loss_G: 0.0377 (0.1540) D(x): 0.5681 D(G(z)): 0.4298 / 0.3995 Acc: 39.0625 (30.6058)\n",
      "[9/25][158/782] Loss_D: -0.0193 (0.3053) Loss_G: -0.0826 (0.1540) D(x): 0.5536 D(G(z)): 0.4411 / 0.4490 Acc: 35.9375 (30.6065)\n",
      "[9/25][159/782] Loss_D: -0.1397 (0.3053) Loss_G: -0.1104 (0.1539) D(x): 0.6075 D(G(z)): 0.4633 / 0.4595 Acc: 42.1875 (30.6081)\n",
      "[9/25][160/782] Loss_D: -0.1028 (0.3052) Loss_G: -0.0447 (0.1539) D(x): 0.5270 D(G(z)): 0.4320 / 0.4142 Acc: 43.7500 (30.6099)\n",
      "[9/25][161/782] Loss_D: -0.0303 (0.3052) Loss_G: -0.0622 (0.1539) D(x): 0.4598 D(G(z)): 0.3947 / 0.4401 Acc: 42.1875 (30.6115)\n",
      "[9/25][162/782] Loss_D: 0.0394 (0.3051) Loss_G: -0.2163 (0.1538) D(x): 0.5383 D(G(z)): 0.4831 / 0.5045 Acc: 40.6250 (30.6129)\n",
      "[9/25][163/782] Loss_D: -0.2641 (0.3051) Loss_G: -0.0936 (0.1538) D(x): 0.5970 D(G(z)): 0.4727 / 0.4610 Acc: 53.1250 (30.6161)\n",
      "[9/25][164/782] Loss_D: 0.0144 (0.3050) Loss_G: -0.1393 (0.1538) D(x): 0.5372 D(G(z)): 0.4972 / 0.4583 Acc: 40.6250 (30.6175)\n",
      "[9/25][165/782] Loss_D: -0.1514 (0.3050) Loss_G: -0.0053 (0.1537) D(x): 0.5310 D(G(z)): 0.4293 / 0.4049 Acc: 45.3125 (30.6195)\n",
      "[9/25][166/782] Loss_D: 0.0155 (0.3049) Loss_G: 0.0183 (0.1537) D(x): 0.5318 D(G(z)): 0.4309 / 0.4012 Acc: 26.5625 (30.6189)\n",
      "[9/25][167/782] Loss_D: -0.0728 (0.3049) Loss_G: -0.0504 (0.1537) D(x): 0.5555 D(G(z)): 0.4366 / 0.4338 Acc: 34.3750 (30.6194)\n",
      "[9/25][168/782] Loss_D: -0.0347 (0.3048) Loss_G: -0.0155 (0.1537) D(x): 0.5334 D(G(z)): 0.4841 / 0.4034 Acc: 43.7500 (30.6213)\n",
      "[9/25][169/782] Loss_D: 0.0255 (0.3048) Loss_G: 0.1215 (0.1537) D(x): 0.6531 D(G(z)): 0.5304 / 0.3656 Acc: 31.2500 (30.6214)\n",
      "[9/25][170/782] Loss_D: 0.1846 (0.3048) Loss_G: -0.1469 (0.1536) D(x): 0.4682 D(G(z)): 0.4598 / 0.4570 Acc: 28.1250 (30.6210)\n",
      "[9/25][171/782] Loss_D: -0.0725 (0.3047) Loss_G: -0.1476 (0.1536) D(x): 0.4606 D(G(z)): 0.3610 / 0.4639 Acc: 40.6250 (30.6224)\n",
      "[9/25][172/782] Loss_D: 0.0971 (0.3047) Loss_G: -0.2881 (0.1535) D(x): 0.5151 D(G(z)): 0.5176 / 0.5373 Acc: 40.6250 (30.6238)\n",
      "[9/25][173/782] Loss_D: 0.2266 (0.3047) Loss_G: -0.2940 (0.1535) D(x): 0.5167 D(G(z)): 0.5565 / 0.5288 Acc: 35.9375 (30.6245)\n",
      "[9/25][174/782] Loss_D: 0.1349 (0.3046) Loss_G: -0.1690 (0.1534) D(x): 0.5497 D(G(z)): 0.5115 / 0.4634 Acc: 32.8125 (30.6248)\n",
      "[9/25][175/782] Loss_D: -0.1486 (0.3046) Loss_G: -0.0894 (0.1534) D(x): 0.5485 D(G(z)): 0.4555 / 0.4501 Acc: 40.6250 (30.6262)\n",
      "[9/25][176/782] Loss_D: -0.0168 (0.3045) Loss_G: -0.0786 (0.1533) D(x): 0.5568 D(G(z)): 0.4949 / 0.4276 Acc: 35.9375 (30.6269)\n",
      "[9/25][177/782] Loss_D: -0.0640 (0.3045) Loss_G: -0.0899 (0.1533) D(x): 0.5168 D(G(z)): 0.4325 / 0.4356 Acc: 39.0625 (30.6281)\n",
      "[9/25][178/782] Loss_D: 0.1122 (0.3045) Loss_G: -0.1602 (0.1533) D(x): 0.5234 D(G(z)): 0.5036 / 0.4671 Acc: 39.0625 (30.6293)\n",
      "[9/25][179/782] Loss_D: 0.0084 (0.3044) Loss_G: -0.0572 (0.1532) D(x): 0.4665 D(G(z)): 0.4645 / 0.4195 Acc: 51.5625 (30.6322)\n",
      "[9/25][180/782] Loss_D: -0.0185 (0.3044) Loss_G: -0.1741 (0.1532) D(x): 0.5567 D(G(z)): 0.4809 / 0.4761 Acc: 37.5000 (30.6331)\n",
      "[9/25][181/782] Loss_D: -0.0889 (0.3043) Loss_G: -0.1429 (0.1531) D(x): 0.5693 D(G(z)): 0.4953 / 0.4552 Acc: 46.8750 (30.6354)\n",
      "[9/25][182/782] Loss_D: 0.0402 (0.3043) Loss_G: 0.0207 (0.1531) D(x): 0.5240 D(G(z)): 0.5031 / 0.4178 Acc: 43.7500 (30.6372)\n",
      "[9/25][183/782] Loss_D: 0.0727 (0.3043) Loss_G: -0.0967 (0.1531) D(x): 0.4820 D(G(z)): 0.4619 / 0.4581 Acc: 42.1875 (30.6388)\n",
      "[9/25][184/782] Loss_D: 0.1759 (0.3042) Loss_G: -0.0617 (0.1531) D(x): 0.4793 D(G(z)): 0.4914 / 0.4376 Acc: 37.5000 (30.6398)\n",
      "[9/25][185/782] Loss_D: 0.0891 (0.3042) Loss_G: -0.0670 (0.1530) D(x): 0.5114 D(G(z)): 0.4517 / 0.4328 Acc: 29.6875 (30.6396)\n",
      "[9/25][186/782] Loss_D: 0.0956 (0.3042) Loss_G: -0.0073 (0.1530) D(x): 0.5463 D(G(z)): 0.5319 / 0.4217 Acc: 42.1875 (30.6412)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/25][187/782] Loss_D: 0.0339 (0.3041) Loss_G: -0.0138 (0.1530) D(x): 0.4897 D(G(z)): 0.4415 / 0.4152 Acc: 39.0625 (30.6424)\n",
      "[9/25][188/782] Loss_D: 0.0183 (0.3041) Loss_G: -0.0105 (0.1530) D(x): 0.4946 D(G(z)): 0.4426 / 0.4097 Acc: 40.6250 (30.6438)\n",
      "[9/25][189/782] Loss_D: -0.0329 (0.3041) Loss_G: -0.0992 (0.1529) D(x): 0.5516 D(G(z)): 0.4812 / 0.4507 Acc: 42.1875 (30.6454)\n",
      "[9/25][190/782] Loss_D: -0.0201 (0.3040) Loss_G: 0.0060 (0.1529) D(x): 0.5671 D(G(z)): 0.4721 / 0.4239 Acc: 35.9375 (30.6461)\n",
      "[9/25][191/782] Loss_D: -0.0815 (0.3040) Loss_G: -0.0065 (0.1529) D(x): 0.4729 D(G(z)): 0.4309 / 0.4151 Acc: 54.6875 (30.6494)\n",
      "[9/25][192/782] Loss_D: -0.0337 (0.3039) Loss_G: -0.0429 (0.1529) D(x): 0.5359 D(G(z)): 0.4466 / 0.4151 Acc: 37.5000 (30.6504)\n",
      "[9/25][193/782] Loss_D: -0.0598 (0.3039) Loss_G: -0.0677 (0.1528) D(x): 0.5377 D(G(z)): 0.4535 / 0.4324 Acc: 39.0625 (30.6515)\n",
      "[9/25][194/782] Loss_D: -0.1302 (0.3038) Loss_G: -0.0034 (0.1528) D(x): 0.5592 D(G(z)): 0.4196 / 0.4165 Acc: 32.8125 (30.6518)\n",
      "[9/25][195/782] Loss_D: -0.2376 (0.3037) Loss_G: -0.0680 (0.1528) D(x): 0.5897 D(G(z)): 0.4741 / 0.4253 Acc: 51.5625 (30.6547)\n",
      "[9/25][196/782] Loss_D: -0.1692 (0.3037) Loss_G: -0.0124 (0.1528) D(x): 0.5645 D(G(z)): 0.4409 / 0.4197 Acc: 43.7500 (30.6565)\n",
      "[9/25][197/782] Loss_D: -0.0273 (0.3036) Loss_G: 0.0032 (0.1527) D(x): 0.5400 D(G(z)): 0.4785 / 0.3979 Acc: 37.5000 (30.6575)\n",
      "[9/25][198/782] Loss_D: -0.1205 (0.3036) Loss_G: 0.0637 (0.1527) D(x): 0.5637 D(G(z)): 0.4361 / 0.3733 Acc: 40.6250 (30.6589)\n",
      "[9/25][199/782] Loss_D: -0.1420 (0.3035) Loss_G: -0.0842 (0.1527) D(x): 0.5317 D(G(z)): 0.4133 / 0.4426 Acc: 37.5000 (30.6598)\n",
      "[9/25][200/782] Loss_D: 0.0431 (0.3035) Loss_G: -0.1867 (0.1526) D(x): 0.5480 D(G(z)): 0.4584 / 0.4938 Acc: 28.1250 (30.6594)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[9/25][201/782] Loss_D: 0.0673 (0.3034) Loss_G: -0.1239 (0.1526) D(x): 0.5338 D(G(z)): 0.5200 / 0.4441 Acc: 42.1875 (30.6610)\n",
      "[9/25][202/782] Loss_D: 0.0670 (0.3034) Loss_G: -0.0594 (0.1526) D(x): 0.5648 D(G(z)): 0.5393 / 0.4249 Acc: 40.6250 (30.6624)\n",
      "[9/25][203/782] Loss_D: 0.1281 (0.3034) Loss_G: -0.1785 (0.1525) D(x): 0.4616 D(G(z)): 0.4754 / 0.4647 Acc: 43.7500 (30.6642)\n",
      "[9/25][204/782] Loss_D: 0.0782 (0.3033) Loss_G: -0.0473 (0.1525) D(x): 0.4778 D(G(z)): 0.4421 / 0.4178 Acc: 37.5000 (30.6652)\n",
      "[9/25][205/782] Loss_D: 0.3333 (0.3033) Loss_G: -0.2359 (0.1524) D(x): 0.4685 D(G(z)): 0.4924 / 0.5072 Acc: 26.5625 (30.6646)\n",
      "[9/25][206/782] Loss_D: 0.2662 (0.3033) Loss_G: -0.2445 (0.1524) D(x): 0.5255 D(G(z)): 0.5630 / 0.5114 Acc: 35.9375 (30.6653)\n",
      "[9/25][207/782] Loss_D: 0.1517 (0.3033) Loss_G: -0.1275 (0.1524) D(x): 0.5307 D(G(z)): 0.5308 / 0.4432 Acc: 37.5000 (30.6663)\n",
      "[9/25][208/782] Loss_D: 0.0075 (0.3033) Loss_G: 0.0045 (0.1523) D(x): 0.5359 D(G(z)): 0.4592 / 0.3970 Acc: 32.8125 (30.6666)\n",
      "[9/25][209/782] Loss_D: -0.0211 (0.3032) Loss_G: 0.0512 (0.1523) D(x): 0.5071 D(G(z)): 0.4319 / 0.3937 Acc: 39.0625 (30.6677)\n",
      "[9/25][210/782] Loss_D: 0.0837 (0.3032) Loss_G: -0.0091 (0.1523) D(x): 0.5112 D(G(z)): 0.4912 / 0.4152 Acc: 42.1875 (30.6693)\n",
      "[9/25][211/782] Loss_D: 0.0102 (0.3032) Loss_G: 0.0190 (0.1523) D(x): 0.5470 D(G(z)): 0.4703 / 0.4257 Acc: 34.3750 (30.6698)\n",
      "[9/25][212/782] Loss_D: -0.0620 (0.3031) Loss_G: 0.0195 (0.1523) D(x): 0.5225 D(G(z)): 0.4347 / 0.3888 Acc: 46.8750 (30.6721)\n",
      "[9/25][213/782] Loss_D: 0.0922 (0.3031) Loss_G: -0.0792 (0.1522) D(x): 0.5491 D(G(z)): 0.4890 / 0.4401 Acc: 28.1250 (30.6717)\n",
      "[9/25][214/782] Loss_D: -0.0583 (0.3030) Loss_G: 0.0830 (0.1522) D(x): 0.5281 D(G(z)): 0.4816 / 0.3655 Acc: 43.7500 (30.6735)\n",
      "[9/25][215/782] Loss_D: 0.0269 (0.3030) Loss_G: -0.0528 (0.1522) D(x): 0.5137 D(G(z)): 0.4330 / 0.4256 Acc: 34.3750 (30.6740)\n",
      "[9/25][216/782] Loss_D: 0.0004 (0.3029) Loss_G: -0.1041 (0.1522) D(x): 0.5360 D(G(z)): 0.4496 / 0.4423 Acc: 34.3750 (30.6745)\n",
      "[9/25][217/782] Loss_D: 0.0001 (0.3029) Loss_G: -0.1345 (0.1521) D(x): 0.5240 D(G(z)): 0.5069 / 0.4602 Acc: 50.0000 (30.6772)\n",
      "[9/25][218/782] Loss_D: -0.0591 (0.3029) Loss_G: -0.0690 (0.1521) D(x): 0.5476 D(G(z)): 0.4505 / 0.4371 Acc: 40.6250 (30.6786)\n",
      "[9/25][219/782] Loss_D: -0.1839 (0.3028) Loss_G: -0.0175 (0.1521) D(x): 0.5502 D(G(z)): 0.4561 / 0.4048 Acc: 51.5625 (30.6814)\n",
      "[9/25][220/782] Loss_D: -0.0500 (0.3027) Loss_G: 0.0413 (0.1520) D(x): 0.4816 D(G(z)): 0.4500 / 0.3879 Acc: 50.0000 (30.6841)\n",
      "[9/25][221/782] Loss_D: -0.1057 (0.3027) Loss_G: 0.0341 (0.1520) D(x): 0.5510 D(G(z)): 0.4321 / 0.3941 Acc: 43.7500 (30.6859)\n",
      "[9/25][222/782] Loss_D: 0.0412 (0.3026) Loss_G: -0.0684 (0.1520) D(x): 0.5259 D(G(z)): 0.4927 / 0.4213 Acc: 40.6250 (30.6873)\n",
      "[9/25][223/782] Loss_D: 0.0299 (0.3026) Loss_G: 0.0677 (0.1520) D(x): 0.4665 D(G(z)): 0.4229 / 0.3983 Acc: 35.9375 (30.6880)\n",
      "[9/25][224/782] Loss_D: 0.1442 (0.3026) Loss_G: -0.1601 (0.1519) D(x): 0.5491 D(G(z)): 0.5314 / 0.4676 Acc: 34.3750 (30.6885)\n",
      "[9/25][225/782] Loss_D: -0.0474 (0.3025) Loss_G: 0.0869 (0.1519) D(x): 0.5297 D(G(z)): 0.4493 / 0.3718 Acc: 43.7500 (30.6903)\n",
      "[9/25][226/782] Loss_D: 0.0594 (0.3025) Loss_G: -0.0933 (0.1519) D(x): 0.5207 D(G(z)): 0.4581 / 0.4562 Acc: 37.5000 (30.6912)\n",
      "[9/25][227/782] Loss_D: 0.1196 (0.3025) Loss_G: -0.0156 (0.1519) D(x): 0.5017 D(G(z)): 0.4828 / 0.4145 Acc: 42.1875 (30.6928)\n",
      "[9/25][228/782] Loss_D: 0.0058 (0.3024) Loss_G: -0.0021 (0.1519) D(x): 0.5482 D(G(z)): 0.4666 / 0.4051 Acc: 32.8125 (30.6931)\n",
      "[9/25][229/782] Loss_D: 0.0539 (0.3024) Loss_G: -0.0373 (0.1518) D(x): 0.5293 D(G(z)): 0.5066 / 0.4150 Acc: 37.5000 (30.6941)\n",
      "[9/25][230/782] Loss_D: -0.0322 (0.3024) Loss_G: -0.0683 (0.1518) D(x): 0.4678 D(G(z)): 0.4120 / 0.4339 Acc: 40.6250 (30.6954)\n",
      "[9/25][231/782] Loss_D: -0.1011 (0.3023) Loss_G: -0.1251 (0.1518) D(x): 0.5275 D(G(z)): 0.4480 / 0.4492 Acc: 53.1250 (30.6985)\n",
      "[9/25][232/782] Loss_D: -0.1027 (0.3022) Loss_G: -0.1068 (0.1517) D(x): 0.5302 D(G(z)): 0.5052 / 0.4608 Acc: 54.6875 (30.7018)\n",
      "[9/25][233/782] Loss_D: -0.1195 (0.3022) Loss_G: -0.1717 (0.1517) D(x): 0.5804 D(G(z)): 0.4467 / 0.4812 Acc: 32.8125 (30.7021)\n",
      "[9/25][234/782] Loss_D: -0.1211 (0.3021) Loss_G: -0.0306 (0.1517) D(x): 0.5156 D(G(z)): 0.4198 / 0.4167 Acc: 45.3125 (30.7041)\n",
      "[9/25][235/782] Loss_D: -0.0364 (0.3021) Loss_G: -0.2091 (0.1516) D(x): 0.5789 D(G(z)): 0.5119 / 0.4867 Acc: 45.3125 (30.7061)\n",
      "[9/25][236/782] Loss_D: -0.0333 (0.3020) Loss_G: 0.1591 (0.1516) D(x): 0.5798 D(G(z)): 0.4979 / 0.3494 Acc: 37.5000 (30.7070)\n",
      "[9/25][237/782] Loss_D: 0.0620 (0.3020) Loss_G: 0.0777 (0.1516) D(x): 0.4956 D(G(z)): 0.4150 / 0.3753 Acc: 26.5625 (30.7065)\n",
      "[9/25][238/782] Loss_D: 0.0609 (0.3020) Loss_G: -0.1591 (0.1516) D(x): 0.4776 D(G(z)): 0.4226 / 0.4667 Acc: 31.2500 (30.7065)\n",
      "[9/25][239/782] Loss_D: 0.1072 (0.3019) Loss_G: -0.1550 (0.1515) D(x): 0.5248 D(G(z)): 0.5064 / 0.4797 Acc: 39.0625 (30.7077)\n",
      "[9/25][240/782] Loss_D: -0.0311 (0.3019) Loss_G: -0.1720 (0.1515) D(x): 0.5651 D(G(z)): 0.4962 / 0.4826 Acc: 34.3750 (30.7082)\n",
      "[9/25][241/782] Loss_D: 0.0377 (0.3019) Loss_G: -0.1162 (0.1514) D(x): 0.5985 D(G(z)): 0.5447 / 0.4563 Acc: 39.0625 (30.7093)\n",
      "[9/25][242/782] Loss_D: 0.0781 (0.3018) Loss_G: -0.0854 (0.1514) D(x): 0.4796 D(G(z)): 0.4379 / 0.4299 Acc: 29.6875 (30.7092)\n",
      "[9/25][243/782] Loss_D: 0.1468 (0.3018) Loss_G: -0.1047 (0.1514) D(x): 0.4581 D(G(z)): 0.4277 / 0.4534 Acc: 35.9375 (30.7099)\n",
      "[9/25][244/782] Loss_D: 0.1247 (0.3018) Loss_G: -0.1414 (0.1513) D(x): 0.5029 D(G(z)): 0.4898 / 0.4684 Acc: 35.9375 (30.7106)\n",
      "[9/25][245/782] Loss_D: -0.0080 (0.3017) Loss_G: -0.0595 (0.1513) D(x): 0.5675 D(G(z)): 0.4977 / 0.4314 Acc: 37.5000 (30.7116)\n",
      "[9/25][246/782] Loss_D: -0.2130 (0.3017) Loss_G: -0.0520 (0.1513) D(x): 0.5656 D(G(z)): 0.4438 / 0.4218 Acc: 46.8750 (30.7138)\n",
      "[9/25][247/782] Loss_D: 0.1232 (0.3017) Loss_G: 0.0103 (0.1513) D(x): 0.4611 D(G(z)): 0.4209 / 0.4137 Acc: 34.3750 (30.7143)\n",
      "[9/25][248/782] Loss_D: -0.0901 (0.3016) Loss_G: -0.1883 (0.1512) D(x): 0.5743 D(G(z)): 0.4849 / 0.4724 Acc: 40.6250 (30.7157)\n",
      "[9/25][249/782] Loss_D: -0.0331 (0.3016) Loss_G: -0.0603 (0.1512) D(x): 0.5412 D(G(z)): 0.4529 / 0.4196 Acc: 34.3750 (30.7162)\n",
      "[9/25][250/782] Loss_D: 0.0530 (0.3015) Loss_G: -0.0846 (0.1511) D(x): 0.5145 D(G(z)): 0.4907 / 0.4423 Acc: 42.1875 (30.7177)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/25][251/782] Loss_D: -0.0377 (0.3015) Loss_G: 0.0197 (0.1511) D(x): 0.5281 D(G(z)): 0.4368 / 0.3943 Acc: 35.9375 (30.7184)\n",
      "[9/25][252/782] Loss_D: -0.1575 (0.3014) Loss_G: -0.1171 (0.1511) D(x): 0.5473 D(G(z)): 0.4548 / 0.4630 Acc: 50.0000 (30.7211)\n",
      "[9/25][253/782] Loss_D: -0.0436 (0.3014) Loss_G: -0.0448 (0.1511) D(x): 0.5806 D(G(z)): 0.4699 / 0.4239 Acc: 31.2500 (30.7212)\n",
      "[9/25][254/782] Loss_D: -0.2184 (0.3013) Loss_G: -0.2361 (0.1510) D(x): 0.5165 D(G(z)): 0.4349 / 0.5071 Acc: 54.6875 (30.7245)\n",
      "[9/25][255/782] Loss_D: -0.0468 (0.3012) Loss_G: 0.0399 (0.1510) D(x): 0.5972 D(G(z)): 0.5076 / 0.4130 Acc: 40.6250 (30.7258)\n",
      "[9/25][256/782] Loss_D: 0.1448 (0.3012) Loss_G: -0.1459 (0.1510) D(x): 0.5225 D(G(z)): 0.4970 / 0.4562 Acc: 31.2500 (30.7259)\n",
      "[9/25][257/782] Loss_D: 0.0208 (0.3012) Loss_G: -0.1779 (0.1509) D(x): 0.4875 D(G(z)): 0.4784 / 0.4690 Acc: 48.4375 (30.7283)\n",
      "[9/25][258/782] Loss_D: -0.0060 (0.3011) Loss_G: -0.2180 (0.1509) D(x): 0.5344 D(G(z)): 0.5246 / 0.4855 Acc: 48.4375 (30.7307)\n",
      "[9/25][259/782] Loss_D: -0.0917 (0.3011) Loss_G: -0.1234 (0.1508) D(x): 0.5631 D(G(z)): 0.5015 / 0.4515 Acc: 48.4375 (30.7332)\n",
      "[9/25][260/782] Loss_D: 0.0866 (0.3011) Loss_G: -0.1970 (0.1508) D(x): 0.4788 D(G(z)): 0.4538 / 0.4735 Acc: 34.3750 (30.7337)\n",
      "[9/25][261/782] Loss_D: 0.2677 (0.3011) Loss_G: -0.1935 (0.1507) D(x): 0.4836 D(G(z)): 0.5593 / 0.4868 Acc: 43.7500 (30.7354)\n",
      "[9/25][262/782] Loss_D: 0.0814 (0.3010) Loss_G: -0.1749 (0.1507) D(x): 0.5054 D(G(z)): 0.4787 / 0.4822 Acc: 35.9375 (30.7362)\n",
      "[9/25][263/782] Loss_D: 0.0658 (0.3010) Loss_G: -0.0449 (0.1507) D(x): 0.5225 D(G(z)): 0.4970 / 0.4146 Acc: 37.5000 (30.7371)\n",
      "[9/25][264/782] Loss_D: -0.0421 (0.3009) Loss_G: 0.0277 (0.1506) D(x): 0.4769 D(G(z)): 0.3933 / 0.4114 Acc: 40.6250 (30.7384)\n",
      "[9/25][265/782] Loss_D: 0.1120 (0.3009) Loss_G: -0.1644 (0.1506) D(x): 0.5149 D(G(z)): 0.5124 / 0.4611 Acc: 39.0625 (30.7396)\n",
      "[9/25][266/782] Loss_D: -0.0361 (0.3009) Loss_G: -0.1893 (0.1505) D(x): 0.5117 D(G(z)): 0.4638 / 0.4769 Acc: 43.7500 (30.7414)\n",
      "[9/25][267/782] Loss_D: -0.1169 (0.3008) Loss_G: -0.0738 (0.1505) D(x): 0.5871 D(G(z)): 0.4522 / 0.4299 Acc: 35.9375 (30.7421)\n",
      "[9/25][268/782] Loss_D: 0.0351 (0.3008) Loss_G: -0.0507 (0.1505) D(x): 0.5197 D(G(z)): 0.4990 / 0.4164 Acc: 39.0625 (30.7432)\n",
      "[9/25][269/782] Loss_D: -0.0464 (0.3007) Loss_G: -0.1073 (0.1505) D(x): 0.5156 D(G(z)): 0.4631 / 0.4484 Acc: 42.1875 (30.7448)\n",
      "[9/25][270/782] Loss_D: -0.0193 (0.3007) Loss_G: -0.0377 (0.1504) D(x): 0.4997 D(G(z)): 0.4644 / 0.4116 Acc: 45.3125 (30.7468)\n",
      "[9/25][271/782] Loss_D: -0.0368 (0.3006) Loss_G: -0.0893 (0.1504) D(x): 0.5308 D(G(z)): 0.4790 / 0.4378 Acc: 42.1875 (30.7483)\n",
      "[9/25][272/782] Loss_D: -0.0356 (0.3006) Loss_G: -0.1042 (0.1504) D(x): 0.5198 D(G(z)): 0.4402 / 0.4382 Acc: 37.5000 (30.7493)\n",
      "[9/25][273/782] Loss_D: -0.0708 (0.3005) Loss_G: -0.0217 (0.1503) D(x): 0.5051 D(G(z)): 0.3932 / 0.4128 Acc: 39.0625 (30.7504)\n",
      "[9/25][274/782] Loss_D: -0.1585 (0.3005) Loss_G: -0.0407 (0.1503) D(x): 0.5677 D(G(z)): 0.4454 / 0.4121 Acc: 40.6250 (30.7517)\n",
      "[9/25][275/782] Loss_D: -0.1153 (0.3004) Loss_G: -0.0051 (0.1503) D(x): 0.6185 D(G(z)): 0.5148 / 0.3969 Acc: 39.0625 (30.7529)\n",
      "[9/25][276/782] Loss_D: -0.1697 (0.3004) Loss_G: 0.0739 (0.1503) D(x): 0.5734 D(G(z)): 0.4422 / 0.3885 Acc: 40.6250 (30.7542)\n",
      "[9/25][277/782] Loss_D: -0.1469 (0.3003) Loss_G: -0.0539 (0.1503) D(x): 0.5442 D(G(z)): 0.4047 / 0.4173 Acc: 34.3750 (30.7547)\n",
      "[9/25][278/782] Loss_D: -0.0970 (0.3002) Loss_G: -0.0191 (0.1502) D(x): 0.5309 D(G(z)): 0.4200 / 0.4084 Acc: 37.5000 (30.7556)\n",
      "[9/25][279/782] Loss_D: -0.2603 (0.3002) Loss_G: -0.1724 (0.1502) D(x): 0.5925 D(G(z)): 0.4698 / 0.4842 Acc: 53.1250 (30.7587)\n",
      "[9/25][280/782] Loss_D: -0.2404 (0.3001) Loss_G: 0.0409 (0.1502) D(x): 0.6466 D(G(z)): 0.4927 / 0.3958 Acc: 50.0000 (30.7613)\n",
      "[9/25][281/782] Loss_D: 0.0731 (0.3001) Loss_G: -0.0454 (0.1501) D(x): 0.4784 D(G(z)): 0.4284 / 0.4103 Acc: 34.3750 (30.7618)\n",
      "[9/25][282/782] Loss_D: -0.0562 (0.3000) Loss_G: -0.0898 (0.1501) D(x): 0.5125 D(G(z)): 0.4681 / 0.4301 Acc: 48.4375 (30.7642)\n",
      "[9/25][283/782] Loss_D: -0.0394 (0.3000) Loss_G: -0.1131 (0.1501) D(x): 0.5708 D(G(z)): 0.4471 / 0.4361 Acc: 31.2500 (30.7643)\n",
      "[9/25][284/782] Loss_D: 0.0398 (0.2999) Loss_G: -0.0563 (0.1500) D(x): 0.5316 D(G(z)): 0.4463 / 0.4349 Acc: 32.8125 (30.7646)\n",
      "[9/25][285/782] Loss_D: 0.1389 (0.2999) Loss_G: -0.1191 (0.1500) D(x): 0.5056 D(G(z)): 0.4853 / 0.4618 Acc: 32.8125 (30.7649)\n",
      "[9/25][286/782] Loss_D: 0.2500 (0.2999) Loss_G: -0.1592 (0.1500) D(x): 0.5055 D(G(z)): 0.5281 / 0.4779 Acc: 29.6875 (30.7647)\n",
      "[9/25][287/782] Loss_D: 0.2082 (0.2999) Loss_G: 0.1049 (0.1500) D(x): 0.5156 D(G(z)): 0.5665 / 0.3713 Acc: 40.6250 (30.7661)\n",
      "[9/25][288/782] Loss_D: 0.0702 (0.2999) Loss_G: 0.0560 (0.1499) D(x): 0.5127 D(G(z)): 0.4895 / 0.4000 Acc: 40.6250 (30.7674)\n",
      "[9/25][289/782] Loss_D: 0.0074 (0.2998) Loss_G: -0.0089 (0.1499) D(x): 0.4952 D(G(z)): 0.4446 / 0.4257 Acc: 43.7500 (30.7692)\n",
      "[9/25][290/782] Loss_D: -0.0085 (0.2998) Loss_G: -0.0842 (0.1499) D(x): 0.4808 D(G(z)): 0.4071 / 0.4413 Acc: 40.6250 (30.7705)\n",
      "[9/25][291/782] Loss_D: -0.1583 (0.2997) Loss_G: -0.1329 (0.1499) D(x): 0.5518 D(G(z)): 0.4445 / 0.4704 Acc: 42.1875 (30.7721)\n",
      "[9/25][292/782] Loss_D: 0.0256 (0.2997) Loss_G: -0.1167 (0.1498) D(x): 0.5813 D(G(z)): 0.4791 / 0.4567 Acc: 32.8125 (30.7724)\n",
      "[9/25][293/782] Loss_D: -0.1085 (0.2996) Loss_G: -0.0337 (0.1498) D(x): 0.5295 D(G(z)): 0.4471 / 0.4142 Acc: 43.7500 (30.7741)\n",
      "[9/25][294/782] Loss_D: -0.2551 (0.2995) Loss_G: 0.0238 (0.1498) D(x): 0.6137 D(G(z)): 0.4446 / 0.3829 Acc: 42.1875 (30.7757)\n",
      "[9/25][295/782] Loss_D: -0.2440 (0.2995) Loss_G: 0.0662 (0.1498) D(x): 0.5873 D(G(z)): 0.4392 / 0.3797 Acc: 40.6250 (30.7770)\n",
      "[9/25][296/782] Loss_D: -0.1655 (0.2994) Loss_G: 0.1961 (0.1498) D(x): 0.4855 D(G(z)): 0.3746 / 0.3352 Acc: 43.7500 (30.7788)\n",
      "[9/25][297/782] Loss_D: -0.0799 (0.2994) Loss_G: -0.1976 (0.1497) D(x): 0.5394 D(G(z)): 0.4400 / 0.4789 Acc: 37.5000 (30.7797)\n",
      "[9/25][298/782] Loss_D: 0.0175 (0.2993) Loss_G: -0.1347 (0.1497) D(x): 0.5217 D(G(z)): 0.4692 / 0.4683 Acc: 39.0625 (30.7808)\n",
      "[9/25][299/782] Loss_D: 0.0268 (0.2993) Loss_G: -0.1297 (0.1496) D(x): 0.5462 D(G(z)): 0.4729 / 0.4725 Acc: 39.0625 (30.7820)\n",
      "[9/25][300/782] Loss_D: 0.0745 (0.2993) Loss_G: -0.1328 (0.1496) D(x): 0.5259 D(G(z)): 0.4944 / 0.4565 Acc: 39.0625 (30.7831)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[9/25][301/782] Loss_D: 0.1286 (0.2992) Loss_G: -0.2133 (0.1496) D(x): 0.5252 D(G(z)): 0.5184 / 0.4784 Acc: 35.9375 (30.7838)\n",
      "[9/25][302/782] Loss_D: 0.1959 (0.2992) Loss_G: -0.2553 (0.1495) D(x): 0.4563 D(G(z)): 0.4685 / 0.5005 Acc: 28.1250 (30.7834)\n",
      "[9/25][303/782] Loss_D: 0.2117 (0.2992) Loss_G: -0.2879 (0.1494) D(x): 0.5159 D(G(z)): 0.5683 / 0.5202 Acc: 42.1875 (30.7850)\n",
      "[9/25][304/782] Loss_D: 0.1392 (0.2992) Loss_G: -0.1588 (0.1494) D(x): 0.5344 D(G(z)): 0.5609 / 0.4640 Acc: 37.5000 (30.7859)\n",
      "[9/25][305/782] Loss_D: 0.0743 (0.2991) Loss_G: -0.1339 (0.1494) D(x): 0.4670 D(G(z)): 0.4689 / 0.4730 Acc: 42.1875 (30.7875)\n",
      "[9/25][306/782] Loss_D: 0.1055 (0.2991) Loss_G: -0.2478 (0.1493) D(x): 0.5101 D(G(z)): 0.5082 / 0.5079 Acc: 42.1875 (30.7890)\n",
      "[9/25][307/782] Loss_D: -0.0062 (0.2991) Loss_G: -0.2143 (0.1493) D(x): 0.5136 D(G(z)): 0.4781 / 0.4829 Acc: 42.1875 (30.7906)\n",
      "[9/25][308/782] Loss_D: 0.0425 (0.2990) Loss_G: -0.0475 (0.1492) D(x): 0.5345 D(G(z)): 0.4924 / 0.4314 Acc: 42.1875 (30.7921)\n",
      "[9/25][309/782] Loss_D: 0.1199 (0.2990) Loss_G: -0.1012 (0.1492) D(x): 0.4911 D(G(z)): 0.4361 / 0.4464 Acc: 29.6875 (30.7920)\n",
      "[9/25][310/782] Loss_D: -0.0136 (0.2990) Loss_G: -0.0965 (0.1492) D(x): 0.5667 D(G(z)): 0.4802 / 0.4361 Acc: 35.9375 (30.7927)\n",
      "[9/25][311/782] Loss_D: -0.0975 (0.2989) Loss_G: -0.0321 (0.1491) D(x): 0.5417 D(G(z)): 0.4577 / 0.4170 Acc: 42.1875 (30.7942)\n",
      "[9/25][312/782] Loss_D: 0.0345 (0.2989) Loss_G: -0.1214 (0.1491) D(x): 0.5117 D(G(z)): 0.4458 / 0.4500 Acc: 32.8125 (30.7945)\n",
      "[9/25][313/782] Loss_D: -0.1760 (0.2988) Loss_G: -0.0886 (0.1491) D(x): 0.5727 D(G(z)): 0.4582 / 0.4408 Acc: 46.8750 (30.7967)\n",
      "[9/25][314/782] Loss_D: 0.0780 (0.2988) Loss_G: -0.0644 (0.1490) D(x): 0.4706 D(G(z)): 0.4458 / 0.4212 Acc: 40.6250 (30.7980)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/25][315/782] Loss_D: -0.0649 (0.2987) Loss_G: -0.0906 (0.1490) D(x): 0.5034 D(G(z)): 0.4516 / 0.4428 Acc: 43.7500 (30.7998)\n",
      "[9/25][316/782] Loss_D: -0.0573 (0.2987) Loss_G: -0.1665 (0.1490) D(x): 0.5559 D(G(z)): 0.4908 / 0.4867 Acc: 40.6250 (30.8011)\n",
      "[9/25][317/782] Loss_D: -0.1645 (0.2986) Loss_G: -0.0535 (0.1489) D(x): 0.6000 D(G(z)): 0.4629 / 0.4302 Acc: 48.4375 (30.8035)\n",
      "[9/25][318/782] Loss_D: 0.0061 (0.2986) Loss_G: -0.1102 (0.1489) D(x): 0.5635 D(G(z)): 0.4260 / 0.4407 Acc: 25.0000 (30.8027)\n",
      "[9/25][319/782] Loss_D: -0.0640 (0.2985) Loss_G: -0.1289 (0.1489) D(x): 0.5751 D(G(z)): 0.4479 / 0.4594 Acc: 32.8125 (30.8030)\n",
      "[9/25][320/782] Loss_D: -0.1245 (0.2985) Loss_G: -0.0252 (0.1488) D(x): 0.5398 D(G(z)): 0.4152 / 0.4101 Acc: 35.9375 (30.8037)\n",
      "[9/25][321/782] Loss_D: 0.0012 (0.2984) Loss_G: 0.0094 (0.1488) D(x): 0.5264 D(G(z)): 0.4574 / 0.4159 Acc: 39.0625 (30.8048)\n",
      "[9/25][322/782] Loss_D: -0.1114 (0.2984) Loss_G: -0.0979 (0.1488) D(x): 0.5699 D(G(z)): 0.4675 / 0.4335 Acc: 37.5000 (30.8057)\n",
      "[9/25][323/782] Loss_D: -0.0519 (0.2983) Loss_G: -0.0395 (0.1488) D(x): 0.5485 D(G(z)): 0.4910 / 0.4251 Acc: 42.1875 (30.8073)\n",
      "[9/25][324/782] Loss_D: 0.1220 (0.2983) Loss_G: -0.0604 (0.1487) D(x): 0.4981 D(G(z)): 0.5022 / 0.4327 Acc: 42.1875 (30.8088)\n",
      "[9/25][325/782] Loss_D: -0.1052 (0.2983) Loss_G: -0.1141 (0.1487) D(x): 0.5688 D(G(z)): 0.4391 / 0.4361 Acc: 34.3750 (30.8093)\n",
      "[9/25][326/782] Loss_D: 0.1063 (0.2982) Loss_G: -0.0138 (0.1487) D(x): 0.5163 D(G(z)): 0.4986 / 0.4319 Acc: 39.0625 (30.8104)\n",
      "[9/25][327/782] Loss_D: 0.0459 (0.2982) Loss_G: -0.0334 (0.1487) D(x): 0.4689 D(G(z)): 0.4540 / 0.4070 Acc: 39.0625 (30.8115)\n",
      "[9/25][328/782] Loss_D: 0.0373 (0.2982) Loss_G: -0.1888 (0.1486) D(x): 0.4558 D(G(z)): 0.4591 / 0.4737 Acc: 48.4375 (30.8139)\n",
      "[9/25][329/782] Loss_D: 0.0691 (0.2981) Loss_G: -0.1803 (0.1486) D(x): 0.5408 D(G(z)): 0.5012 / 0.4698 Acc: 34.3750 (30.8144)\n",
      "[9/25][330/782] Loss_D: 0.0864 (0.2981) Loss_G: -0.2637 (0.1485) D(x): 0.4953 D(G(z)): 0.5030 / 0.5276 Acc: 45.3125 (30.8164)\n",
      "[9/25][331/782] Loss_D: -0.0456 (0.2981) Loss_G: -0.1397 (0.1485) D(x): 0.5774 D(G(z)): 0.5168 / 0.4710 Acc: 46.8750 (30.8186)\n",
      "[9/25][332/782] Loss_D: 0.0791 (0.2980) Loss_G: -0.0958 (0.1484) D(x): 0.4989 D(G(z)): 0.4821 / 0.4401 Acc: 40.6250 (30.8199)\n",
      "[9/25][333/782] Loss_D: -0.0775 (0.2980) Loss_G: -0.0884 (0.1484) D(x): 0.5542 D(G(z)): 0.4532 / 0.4376 Acc: 37.5000 (30.8208)\n",
      "[9/25][334/782] Loss_D: -0.1468 (0.2979) Loss_G: -0.0340 (0.1484) D(x): 0.5117 D(G(z)): 0.3867 / 0.4225 Acc: 37.5000 (30.8217)\n",
      "[9/25][335/782] Loss_D: -0.0252 (0.2979) Loss_G: -0.0807 (0.1483) D(x): 0.6085 D(G(z)): 0.5135 / 0.4421 Acc: 39.0625 (30.8228)\n",
      "[9/25][336/782] Loss_D: -0.1310 (0.2978) Loss_G: 0.0033 (0.1483) D(x): 0.5758 D(G(z)): 0.4718 / 0.4004 Acc: 45.3125 (30.8248)\n",
      "[9/25][337/782] Loss_D: 0.0460 (0.2978) Loss_G: -0.1513 (0.1483) D(x): 0.4384 D(G(z)): 0.3693 / 0.4560 Acc: 34.3750 (30.8253)\n",
      "[9/25][338/782] Loss_D: -0.1010 (0.2977) Loss_G: -0.2811 (0.1482) D(x): 0.5923 D(G(z)): 0.4525 / 0.5112 Acc: 31.2500 (30.8253)\n",
      "[9/25][339/782] Loss_D: 0.0085 (0.2977) Loss_G: -0.1422 (0.1482) D(x): 0.4991 D(G(z)): 0.4789 / 0.4631 Acc: 43.7500 (30.8271)\n",
      "[9/25][340/782] Loss_D: 0.0589 (0.2977) Loss_G: -0.1566 (0.1482) D(x): 0.5326 D(G(z)): 0.4940 / 0.4572 Acc: 37.5000 (30.8280)\n",
      "[9/25][341/782] Loss_D: -0.0861 (0.2976) Loss_G: -0.0632 (0.1481) D(x): 0.5406 D(G(z)): 0.4639 / 0.4284 Acc: 42.1875 (30.8295)\n",
      "[9/25][342/782] Loss_D: 0.0278 (0.2976) Loss_G: -0.1611 (0.1481) D(x): 0.5224 D(G(z)): 0.4344 / 0.4771 Acc: 34.3750 (30.8300)\n",
      "[9/25][343/782] Loss_D: 0.0750 (0.2975) Loss_G: -0.0462 (0.1481) D(x): 0.5688 D(G(z)): 0.4875 / 0.4227 Acc: 26.5625 (30.8294)\n",
      "[9/25][344/782] Loss_D: 0.0272 (0.2975) Loss_G: -0.0521 (0.1480) D(x): 0.5332 D(G(z)): 0.4781 / 0.4330 Acc: 37.5000 (30.8303)\n",
      "[9/25][345/782] Loss_D: -0.0549 (0.2975) Loss_G: -0.0714 (0.1480) D(x): 0.4756 D(G(z)): 0.4172 / 0.4280 Acc: 42.1875 (30.8319)\n",
      "[9/25][346/782] Loss_D: -0.1064 (0.2974) Loss_G: -0.1689 (0.1480) D(x): 0.5392 D(G(z)): 0.4387 / 0.4601 Acc: 37.5000 (30.8328)\n",
      "[9/25][347/782] Loss_D: 0.0663 (0.2974) Loss_G: -0.1506 (0.1479) D(x): 0.5017 D(G(z)): 0.5055 / 0.4566 Acc: 39.0625 (30.8339)\n",
      "[9/25][348/782] Loss_D: 0.0050 (0.2973) Loss_G: -0.1325 (0.1479) D(x): 0.5558 D(G(z)): 0.4897 / 0.4437 Acc: 35.9375 (30.8346)\n",
      "[9/25][349/782] Loss_D: -0.1573 (0.2973) Loss_G: -0.0740 (0.1478) D(x): 0.5518 D(G(z)): 0.4372 / 0.4329 Acc: 39.0625 (30.8357)\n",
      "[9/25][350/782] Loss_D: -0.0455 (0.2972) Loss_G: -0.0279 (0.1478) D(x): 0.5690 D(G(z)): 0.4679 / 0.4198 Acc: 34.3750 (30.8362)\n",
      "[9/25][351/782] Loss_D: -0.0948 (0.2972) Loss_G: -0.0998 (0.1478) D(x): 0.5327 D(G(z)): 0.4004 / 0.4402 Acc: 37.5000 (30.8371)\n",
      "[9/25][352/782] Loss_D: -0.0955 (0.2971) Loss_G: 0.0130 (0.1478) D(x): 0.5442 D(G(z)): 0.4451 / 0.4002 Acc: 34.3750 (30.8375)\n",
      "[9/25][353/782] Loss_D: -0.0145 (0.2971) Loss_G: -0.1874 (0.1477) D(x): 0.5175 D(G(z)): 0.4869 / 0.4722 Acc: 46.8750 (30.8397)\n",
      "[9/25][354/782] Loss_D: 0.2419 (0.2971) Loss_G: -0.1988 (0.1477) D(x): 0.4793 D(G(z)): 0.5124 / 0.4807 Acc: 31.2500 (30.8398)\n",
      "[9/25][355/782] Loss_D: -0.1070 (0.2970) Loss_G: -0.1062 (0.1476) D(x): 0.5596 D(G(z)): 0.5351 / 0.4342 Acc: 54.6875 (30.8430)\n",
      "[9/25][356/782] Loss_D: -0.0230 (0.2970) Loss_G: -0.1713 (0.1476) D(x): 0.4831 D(G(z)): 0.4422 / 0.4742 Acc: 45.3125 (30.8450)\n",
      "[9/25][357/782] Loss_D: 0.1141 (0.2969) Loss_G: -0.1074 (0.1476) D(x): 0.5426 D(G(z)): 0.5237 / 0.4532 Acc: 37.5000 (30.8459)\n",
      "[9/25][358/782] Loss_D: -0.2180 (0.2969) Loss_G: -0.0348 (0.1475) D(x): 0.5591 D(G(z)): 0.3888 / 0.4254 Acc: 40.6250 (30.8472)\n",
      "[9/25][359/782] Loss_D: -0.1546 (0.2968) Loss_G: -0.0782 (0.1475) D(x): 0.5786 D(G(z)): 0.4652 / 0.4384 Acc: 45.3125 (30.8491)\n",
      "[9/25][360/782] Loss_D: 0.0238 (0.2968) Loss_G: -0.0835 (0.1475) D(x): 0.5673 D(G(z)): 0.4579 / 0.4455 Acc: 25.0000 (30.8483)\n",
      "[9/25][361/782] Loss_D: 0.0210 (0.2967) Loss_G: -0.0914 (0.1474) D(x): 0.5168 D(G(z)): 0.5041 / 0.4425 Acc: 42.1875 (30.8499)\n",
      "[9/25][362/782] Loss_D: 0.0780 (0.2967) Loss_G: -0.0025 (0.1474) D(x): 0.4912 D(G(z)): 0.4338 / 0.4031 Acc: 34.3750 (30.8503)\n",
      "[9/25][363/782] Loss_D: -0.1152 (0.2967) Loss_G: -0.0197 (0.1474) D(x): 0.5275 D(G(z)): 0.4923 / 0.4265 Acc: 51.5625 (30.8531)\n",
      "[9/25][364/782] Loss_D: -0.0619 (0.2966) Loss_G: -0.0380 (0.1474) D(x): 0.5623 D(G(z)): 0.4762 / 0.4347 Acc: 40.6250 (30.8545)\n",
      "[9/25][365/782] Loss_D: 0.0900 (0.2966) Loss_G: -0.1346 (0.1473) D(x): 0.5535 D(G(z)): 0.5071 / 0.4632 Acc: 31.2500 (30.8545)\n",
      "[9/25][366/782] Loss_D: 0.0296 (0.2965) Loss_G: -0.0999 (0.1473) D(x): 0.4806 D(G(z)): 0.4374 / 0.4528 Acc: 40.6250 (30.8558)\n",
      "[9/25][367/782] Loss_D: 0.0930 (0.2965) Loss_G: -0.2607 (0.1473) D(x): 0.5007 D(G(z)): 0.4793 / 0.4965 Acc: 31.2500 (30.8559)\n",
      "[9/25][368/782] Loss_D: 0.0912 (0.2965) Loss_G: -0.1772 (0.1472) D(x): 0.5276 D(G(z)): 0.5122 / 0.4756 Acc: 35.9375 (30.8566)\n",
      "[9/25][369/782] Loss_D: -0.0966 (0.2964) Loss_G: -0.1019 (0.1472) D(x): 0.5618 D(G(z)): 0.4976 / 0.4579 Acc: 50.0000 (30.8592)\n",
      "[9/25][370/782] Loss_D: 0.0966 (0.2964) Loss_G: -0.0728 (0.1471) D(x): 0.4947 D(G(z)): 0.4664 / 0.4273 Acc: 31.2500 (30.8592)\n",
      "[9/25][371/782] Loss_D: -0.1146 (0.2964) Loss_G: 0.0347 (0.1471) D(x): 0.5603 D(G(z)): 0.4415 / 0.3925 Acc: 37.5000 (30.8601)\n",
      "[9/25][372/782] Loss_D: -0.0264 (0.2963) Loss_G: -0.1273 (0.1471) D(x): 0.4883 D(G(z)): 0.4323 / 0.4580 Acc: 42.1875 (30.8616)\n",
      "[9/25][373/782] Loss_D: 0.0419 (0.2963) Loss_G: -0.1899 (0.1470) D(x): 0.4851 D(G(z)): 0.4542 / 0.4840 Acc: 39.0625 (30.8627)\n",
      "[9/25][374/782] Loss_D: -0.1931 (0.2962) Loss_G: -0.1854 (0.1470) D(x): 0.6451 D(G(z)): 0.4970 / 0.4669 Acc: 43.7500 (30.8645)\n",
      "[9/25][375/782] Loss_D: -0.0383 (0.2962) Loss_G: -0.1127 (0.1470) D(x): 0.4993 D(G(z)): 0.4527 / 0.4423 Acc: 43.7500 (30.8662)\n",
      "[9/25][376/782] Loss_D: 0.0235 (0.2961) Loss_G: -0.1446 (0.1469) D(x): 0.4935 D(G(z)): 0.4918 / 0.4658 Acc: 51.5625 (30.8690)\n",
      "[9/25][377/782] Loss_D: -0.0672 (0.2961) Loss_G: -0.0083 (0.1469) D(x): 0.5456 D(G(z)): 0.4461 / 0.4123 Acc: 34.3750 (30.8695)\n",
      "[9/25][378/782] Loss_D: 0.0033 (0.2960) Loss_G: -0.1355 (0.1469) D(x): 0.5254 D(G(z)): 0.4607 / 0.4525 Acc: 35.9375 (30.8702)\n",
      "[9/25][379/782] Loss_D: 0.2939 (0.2960) Loss_G: -0.1700 (0.1468) D(x): 0.4532 D(G(z)): 0.4950 / 0.4870 Acc: 35.9375 (30.8709)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/25][380/782] Loss_D: -0.1304 (0.2960) Loss_G: -0.2137 (0.1468) D(x): 0.5704 D(G(z)): 0.5001 / 0.4856 Acc: 48.4375 (30.8732)\n",
      "[9/25][381/782] Loss_D: 0.1548 (0.2960) Loss_G: -0.0508 (0.1468) D(x): 0.5190 D(G(z)): 0.5063 / 0.4234 Acc: 35.9375 (30.8739)\n",
      "[9/25][382/782] Loss_D: 0.0511 (0.2959) Loss_G: -0.1825 (0.1467) D(x): 0.5318 D(G(z)): 0.4603 / 0.4794 Acc: 31.2500 (30.8740)\n",
      "[9/25][383/782] Loss_D: 0.0724 (0.2959) Loss_G: -0.1425 (0.1467) D(x): 0.4789 D(G(z)): 0.4825 / 0.4455 Acc: 40.6250 (30.8753)\n",
      "[9/25][384/782] Loss_D: 0.1154 (0.2959) Loss_G: -0.2223 (0.1466) D(x): 0.4595 D(G(z)): 0.4743 / 0.4883 Acc: 39.0625 (30.8764)\n",
      "[9/25][385/782] Loss_D: -0.0435 (0.2958) Loss_G: -0.1677 (0.1466) D(x): 0.5260 D(G(z)): 0.4820 / 0.4738 Acc: 43.7500 (30.8781)\n",
      "[9/25][386/782] Loss_D: 0.0734 (0.2958) Loss_G: -0.1242 (0.1465) D(x): 0.5184 D(G(z)): 0.4638 / 0.4629 Acc: 35.9375 (30.8788)\n",
      "[9/25][387/782] Loss_D: -0.0292 (0.2958) Loss_G: -0.1542 (0.1465) D(x): 0.5971 D(G(z)): 0.4970 / 0.4574 Acc: 31.2500 (30.8788)\n",
      "[9/25][388/782] Loss_D: -0.0246 (0.2957) Loss_G: 0.0398 (0.1465) D(x): 0.5397 D(G(z)): 0.4916 / 0.3857 Acc: 45.3125 (30.8808)\n",
      "[9/25][389/782] Loss_D: -0.1040 (0.2957) Loss_G: 0.0360 (0.1465) D(x): 0.5303 D(G(z)): 0.3785 / 0.3884 Acc: 34.3750 (30.8813)\n",
      "[9/25][390/782] Loss_D: -0.1010 (0.2956) Loss_G: -0.2260 (0.1464) D(x): 0.4836 D(G(z)): 0.4099 / 0.4981 Acc: 45.3125 (30.8832)\n",
      "[9/25][391/782] Loss_D: 0.0190 (0.2956) Loss_G: -0.2387 (0.1464) D(x): 0.5307 D(G(z)): 0.4627 / 0.5046 Acc: 39.0625 (30.8843)\n",
      "[9/25][392/782] Loss_D: 0.0694 (0.2955) Loss_G: -0.1015 (0.1463) D(x): 0.5886 D(G(z)): 0.5125 / 0.4429 Acc: 29.6875 (30.8841)\n",
      "[9/25][393/782] Loss_D: -0.0604 (0.2955) Loss_G: -0.0691 (0.1463) D(x): 0.5505 D(G(z)): 0.4656 / 0.4328 Acc: 37.5000 (30.8850)\n",
      "[9/25][394/782] Loss_D: -0.0486 (0.2954) Loss_G: -0.0341 (0.1463) D(x): 0.5556 D(G(z)): 0.4875 / 0.4180 Acc: 40.6250 (30.8863)\n",
      "[9/25][395/782] Loss_D: -0.0698 (0.2954) Loss_G: 0.0410 (0.1463) D(x): 0.5168 D(G(z)): 0.4339 / 0.3947 Acc: 43.7500 (30.8881)\n",
      "[9/25][396/782] Loss_D: 0.1140 (0.2954) Loss_G: -0.0750 (0.1462) D(x): 0.4894 D(G(z)): 0.4319 / 0.4302 Acc: 31.2500 (30.8881)\n",
      "[9/25][397/782] Loss_D: -0.2511 (0.2953) Loss_G: -0.1731 (0.1462) D(x): 0.5489 D(G(z)): 0.3881 / 0.4772 Acc: 42.1875 (30.8896)\n",
      "[9/25][398/782] Loss_D: 0.0566 (0.2953) Loss_G: -0.1961 (0.1461) D(x): 0.5782 D(G(z)): 0.5206 / 0.4876 Acc: 37.5000 (30.8905)\n",
      "[9/25][399/782] Loss_D: -0.1333 (0.2952) Loss_G: 0.0032 (0.1461) D(x): 0.5714 D(G(z)): 0.4820 / 0.4006 Acc: 45.3125 (30.8925)\n",
      "[9/25][400/782] Loss_D: -0.0400 (0.2952) Loss_G: -0.0373 (0.1461) D(x): 0.5347 D(G(z)): 0.4693 / 0.4091 Acc: 40.6250 (30.8938)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[9/25][401/782] Loss_D: 0.0767 (0.2951) Loss_G: -0.0603 (0.1461) D(x): 0.5137 D(G(z)): 0.4917 / 0.4227 Acc: 35.9375 (30.8944)\n",
      "[9/25][402/782] Loss_D: -0.0328 (0.2951) Loss_G: -0.0257 (0.1461) D(x): 0.5069 D(G(z)): 0.4433 / 0.4029 Acc: 39.0625 (30.8955)\n",
      "[9/25][403/782] Loss_D: -0.0204 (0.2950) Loss_G: -0.1008 (0.1460) D(x): 0.5134 D(G(z)): 0.4759 / 0.4262 Acc: 43.7500 (30.8973)\n",
      "[9/25][404/782] Loss_D: -0.0134 (0.2950) Loss_G: -0.1216 (0.1460) D(x): 0.4987 D(G(z)): 0.4594 / 0.4414 Acc: 40.6250 (30.8986)\n",
      "[9/25][405/782] Loss_D: 0.0232 (0.2950) Loss_G: -0.1801 (0.1459) D(x): 0.5542 D(G(z)): 0.4736 / 0.4659 Acc: 28.1250 (30.8982)\n",
      "[9/25][406/782] Loss_D: -0.1537 (0.2949) Loss_G: -0.0240 (0.1459) D(x): 0.5962 D(G(z)): 0.4189 / 0.4183 Acc: 31.2500 (30.8983)\n",
      "[9/25][407/782] Loss_D: -0.2479 (0.2948) Loss_G: 0.0427 (0.1459) D(x): 0.5581 D(G(z)): 0.4074 / 0.3888 Acc: 45.3125 (30.9002)\n",
      "[9/25][408/782] Loss_D: -0.0864 (0.2948) Loss_G: -0.1671 (0.1459) D(x): 0.5297 D(G(z)): 0.4274 / 0.4598 Acc: 39.0625 (30.9013)\n",
      "[9/25][409/782] Loss_D: -0.0023 (0.2947) Loss_G: -0.2018 (0.1458) D(x): 0.5894 D(G(z)): 0.5082 / 0.4732 Acc: 34.3750 (30.9018)\n",
      "[9/25][410/782] Loss_D: 0.1007 (0.2947) Loss_G: 0.0986 (0.1458) D(x): 0.5440 D(G(z)): 0.5167 / 0.3772 Acc: 39.0625 (30.9028)\n",
      "[9/25][411/782] Loss_D: 0.0503 (0.2947) Loss_G: -0.0799 (0.1458) D(x): 0.5320 D(G(z)): 0.4829 / 0.4248 Acc: 34.3750 (30.9033)\n",
      "[9/25][412/782] Loss_D: -0.0322 (0.2946) Loss_G: -0.0492 (0.1458) D(x): 0.5011 D(G(z)): 0.4345 / 0.4186 Acc: 37.5000 (30.9042)\n",
      "[9/25][413/782] Loss_D: 0.0976 (0.2946) Loss_G: -0.1116 (0.1457) D(x): 0.5199 D(G(z)): 0.4438 / 0.4670 Acc: 25.0000 (30.9034)\n",
      "[9/25][414/782] Loss_D: 0.0577 (0.2946) Loss_G: -0.1604 (0.1457) D(x): 0.5402 D(G(z)): 0.4975 / 0.4822 Acc: 35.9375 (30.9041)\n",
      "[9/25][415/782] Loss_D: 0.0414 (0.2945) Loss_G: -0.0741 (0.1456) D(x): 0.5367 D(G(z)): 0.5146 / 0.4357 Acc: 42.1875 (30.9056)\n",
      "[9/25][416/782] Loss_D: 0.0668 (0.2945) Loss_G: -0.0325 (0.1456) D(x): 0.5039 D(G(z)): 0.4429 / 0.4223 Acc: 32.8125 (30.9059)\n",
      "[9/25][417/782] Loss_D: 0.1600 (0.2945) Loss_G: -0.1193 (0.1456) D(x): 0.5135 D(G(z)): 0.4878 / 0.4539 Acc: 29.6875 (30.9057)\n",
      "[9/25][418/782] Loss_D: 0.0016 (0.2945) Loss_G: -0.1275 (0.1456) D(x): 0.5549 D(G(z)): 0.4851 / 0.4449 Acc: 35.9375 (30.9064)\n",
      "[9/25][419/782] Loss_D: 0.1346 (0.2944) Loss_G: -0.0197 (0.1455) D(x): 0.5124 D(G(z)): 0.5045 / 0.4047 Acc: 37.5000 (30.9072)\n",
      "[9/25][420/782] Loss_D: 0.0227 (0.2944) Loss_G: -0.0225 (0.1455) D(x): 0.5125 D(G(z)): 0.4425 / 0.4044 Acc: 35.9375 (30.9079)\n",
      "[9/25][421/782] Loss_D: -0.2000 (0.2943) Loss_G: -0.1022 (0.1455) D(x): 0.5177 D(G(z)): 0.3812 / 0.4425 Acc: 43.7500 (30.9096)\n",
      "[9/25][422/782] Loss_D: -0.0822 (0.2943) Loss_G: -0.1159 (0.1454) D(x): 0.5441 D(G(z)): 0.4866 / 0.4467 Acc: 45.3125 (30.9116)\n",
      "[9/25][423/782] Loss_D: -0.1280 (0.2942) Loss_G: -0.1679 (0.1454) D(x): 0.5725 D(G(z)): 0.4698 / 0.4775 Acc: 42.1875 (30.9131)\n",
      "[9/25][424/782] Loss_D: 0.0303 (0.2942) Loss_G: -0.1291 (0.1454) D(x): 0.4962 D(G(z)): 0.4597 / 0.4586 Acc: 45.3125 (30.9150)\n",
      "[9/25][425/782] Loss_D: 0.1807 (0.2942) Loss_G: -0.0652 (0.1453) D(x): 0.5200 D(G(z)): 0.4778 / 0.4290 Acc: 28.1250 (30.9146)\n",
      "[9/25][426/782] Loss_D: -0.1126 (0.2941) Loss_G: -0.0955 (0.1453) D(x): 0.5950 D(G(z)): 0.4186 / 0.4480 Acc: 37.5000 (30.9155)\n",
      "[9/25][427/782] Loss_D: -0.0998 (0.2941) Loss_G: 0.0177 (0.1453) D(x): 0.5161 D(G(z)): 0.4262 / 0.4072 Acc: 42.1875 (30.9170)\n",
      "[9/25][428/782] Loss_D: -0.0503 (0.2940) Loss_G: -0.1052 (0.1452) D(x): 0.5718 D(G(z)): 0.4838 / 0.4567 Acc: 39.0625 (30.9181)\n",
      "[9/25][429/782] Loss_D: -0.0139 (0.2940) Loss_G: -0.0721 (0.1452) D(x): 0.5941 D(G(z)): 0.4501 / 0.4277 Acc: 21.8750 (30.9169)\n",
      "[9/25][430/782] Loss_D: -0.0017 (0.2939) Loss_G: 0.0041 (0.1452) D(x): 0.4979 D(G(z)): 0.4285 / 0.4233 Acc: 43.7500 (30.9186)\n",
      "[9/25][431/782] Loss_D: -0.1445 (0.2939) Loss_G: -0.0869 (0.1452) D(x): 0.5435 D(G(z)): 0.5018 / 0.4426 Acc: 56.2500 (30.9220)\n",
      "[9/25][432/782] Loss_D: 0.1422 (0.2939) Loss_G: -0.1042 (0.1451) D(x): 0.4808 D(G(z)): 0.4591 / 0.4597 Acc: 29.6875 (30.9219)\n",
      "[9/25][433/782] Loss_D: 0.0367 (0.2938) Loss_G: -0.1677 (0.1451) D(x): 0.5029 D(G(z)): 0.4479 / 0.4750 Acc: 35.9375 (30.9225)\n",
      "[9/25][434/782] Loss_D: 0.0348 (0.2938) Loss_G: -0.1579 (0.1451) D(x): 0.5735 D(G(z)): 0.5132 / 0.4897 Acc: 35.9375 (30.9232)\n",
      "[9/25][435/782] Loss_D: 0.0643 (0.2938) Loss_G: -0.0362 (0.1450) D(x): 0.5395 D(G(z)): 0.5318 / 0.4202 Acc: 43.7500 (30.9249)\n",
      "[9/25][436/782] Loss_D: -0.0198 (0.2937) Loss_G: 0.0454 (0.1450) D(x): 0.4806 D(G(z)): 0.4292 / 0.3874 Acc: 45.3125 (30.9268)\n",
      "[9/25][437/782] Loss_D: 0.0991 (0.2937) Loss_G: -0.0759 (0.1450) D(x): 0.5439 D(G(z)): 0.4920 / 0.4354 Acc: 32.8125 (30.9271)\n",
      "[9/25][438/782] Loss_D: -0.2132 (0.2936) Loss_G: 0.0917 (0.1450) D(x): 0.5678 D(G(z)): 0.4159 / 0.3792 Acc: 42.1875 (30.9286)\n",
      "[9/25][439/782] Loss_D: 0.0391 (0.2936) Loss_G: -0.1016 (0.1449) D(x): 0.5217 D(G(z)): 0.4518 / 0.4489 Acc: 32.8125 (30.9288)\n",
      "[9/25][440/782] Loss_D: 0.0320 (0.2936) Loss_G: 0.0029 (0.1449) D(x): 0.4993 D(G(z)): 0.4606 / 0.4038 Acc: 46.8750 (30.9310)\n",
      "[9/25][441/782] Loss_D: 0.0993 (0.2935) Loss_G: -0.1799 (0.1449) D(x): 0.4762 D(G(z)): 0.4266 / 0.4713 Acc: 29.6875 (30.9308)\n",
      "[9/25][442/782] Loss_D: 0.0770 (0.2935) Loss_G: -0.1184 (0.1448) D(x): 0.5549 D(G(z)): 0.5009 / 0.4480 Acc: 35.9375 (30.9315)\n",
      "[9/25][443/782] Loss_D: 0.1055 (0.2935) Loss_G: 0.0706 (0.1448) D(x): 0.5500 D(G(z)): 0.5132 / 0.4053 Acc: 40.6250 (30.9328)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/25][444/782] Loss_D: 0.0123 (0.2934) Loss_G: -0.0932 (0.1448) D(x): 0.5093 D(G(z)): 0.4062 / 0.4465 Acc: 29.6875 (30.9326)\n",
      "[9/25][445/782] Loss_D: 0.1475 (0.2934) Loss_G: -0.1329 (0.1448) D(x): 0.4809 D(G(z)): 0.4681 / 0.4746 Acc: 34.3750 (30.9331)\n",
      "[9/25][446/782] Loss_D: -0.0196 (0.2934) Loss_G: -0.2096 (0.1447) D(x): 0.5736 D(G(z)): 0.4902 / 0.4783 Acc: 32.8125 (30.9333)\n",
      "[9/25][447/782] Loss_D: 0.1406 (0.2934) Loss_G: -0.1041 (0.1447) D(x): 0.5340 D(G(z)): 0.4967 / 0.4364 Acc: 28.1250 (30.9329)\n",
      "[9/25][448/782] Loss_D: 0.0456 (0.2933) Loss_G: 0.0290 (0.1447) D(x): 0.5537 D(G(z)): 0.4693 / 0.3981 Acc: 28.1250 (30.9326)\n",
      "[9/25][449/782] Loss_D: -0.0196 (0.2933) Loss_G: -0.0590 (0.1446) D(x): 0.4896 D(G(z)): 0.4442 / 0.4123 Acc: 43.7500 (30.9343)\n",
      "[9/25][450/782] Loss_D: -0.2053 (0.2932) Loss_G: -0.2325 (0.1446) D(x): 0.5376 D(G(z)): 0.4108 / 0.4929 Acc: 43.7500 (30.9360)\n",
      "[9/25][451/782] Loss_D: 0.1461 (0.2932) Loss_G: -0.1732 (0.1446) D(x): 0.5697 D(G(z)): 0.5563 / 0.4660 Acc: 35.9375 (30.9367)\n",
      "[9/25][452/782] Loss_D: 0.0666 (0.2932) Loss_G: 0.0838 (0.1445) D(x): 0.5682 D(G(z)): 0.5172 / 0.3838 Acc: 34.3750 (30.9371)\n",
      "[9/25][453/782] Loss_D: -0.0643 (0.2931) Loss_G: -0.0171 (0.1445) D(x): 0.4455 D(G(z)): 0.3722 / 0.4172 Acc: 43.7500 (30.9388)\n",
      "[9/25][454/782] Loss_D: -0.0628 (0.2931) Loss_G: -0.2628 (0.1445) D(x): 0.5139 D(G(z)): 0.4563 / 0.5343 Acc: 46.8750 (30.9410)\n",
      "[9/25][455/782] Loss_D: 0.1578 (0.2931) Loss_G: -0.0797 (0.1444) D(x): 0.5323 D(G(z)): 0.4989 / 0.4427 Acc: 29.6875 (30.9408)\n",
      "[9/25][456/782] Loss_D: -0.1040 (0.2930) Loss_G: 0.0490 (0.1444) D(x): 0.5321 D(G(z)): 0.4574 / 0.3968 Acc: 48.4375 (30.9431)\n",
      "[9/25][457/782] Loss_D: 0.0978 (0.2930) Loss_G: -0.1365 (0.1444) D(x): 0.5056 D(G(z)): 0.4619 / 0.4502 Acc: 32.8125 (30.9434)\n",
      "[9/25][458/782] Loss_D: 0.1006 (0.2930) Loss_G: -0.1610 (0.1443) D(x): 0.4765 D(G(z)): 0.4373 / 0.4742 Acc: 28.1250 (30.9430)\n",
      "[9/25][459/782] Loss_D: -0.2417 (0.2929) Loss_G: -0.1351 (0.1443) D(x): 0.5823 D(G(z)): 0.4552 / 0.4523 Acc: 48.4375 (30.9453)\n",
      "[9/25][460/782] Loss_D: 0.0807 (0.2929) Loss_G: -0.1024 (0.1443) D(x): 0.5760 D(G(z)): 0.5399 / 0.4525 Acc: 37.5000 (30.9462)\n",
      "[9/25][461/782] Loss_D: -0.0521 (0.2928) Loss_G: -0.0090 (0.1443) D(x): 0.5242 D(G(z)): 0.4127 / 0.4174 Acc: 40.6250 (30.9475)\n",
      "[9/25][462/782] Loss_D: -0.1796 (0.2927) Loss_G: -0.1865 (0.1442) D(x): 0.5486 D(G(z)): 0.4585 / 0.4782 Acc: 54.6875 (30.9507)\n",
      "[9/25][463/782] Loss_D: 0.0399 (0.2927) Loss_G: -0.0800 (0.1442) D(x): 0.5143 D(G(z)): 0.4588 / 0.4368 Acc: 32.8125 (30.9509)\n",
      "[9/25][464/782] Loss_D: -0.0762 (0.2927) Loss_G: -0.1248 (0.1441) D(x): 0.5340 D(G(z)): 0.4265 / 0.4530 Acc: 34.3750 (30.9514)\n",
      "[9/25][465/782] Loss_D: -0.1339 (0.2926) Loss_G: -0.0902 (0.1441) D(x): 0.5706 D(G(z)): 0.4732 / 0.4447 Acc: 46.8750 (30.9535)\n",
      "[9/25][466/782] Loss_D: -0.0713 (0.2926) Loss_G: 0.1209 (0.1441) D(x): 0.6032 D(G(z)): 0.4999 / 0.3634 Acc: 39.0625 (30.9546)\n",
      "[9/25][467/782] Loss_D: -0.0161 (0.2925) Loss_G: -0.0953 (0.1441) D(x): 0.5263 D(G(z)): 0.4429 / 0.4356 Acc: 34.3750 (30.9550)\n",
      "[9/25][468/782] Loss_D: -0.0507 (0.2925) Loss_G: 0.0197 (0.1441) D(x): 0.5113 D(G(z)): 0.4732 / 0.3838 Acc: 46.8750 (30.9571)\n",
      "[9/25][469/782] Loss_D: -0.0333 (0.2924) Loss_G: 0.0151 (0.1440) D(x): 0.5017 D(G(z)): 0.4683 / 0.3884 Acc: 45.3125 (30.9591)\n",
      "[9/25][470/782] Loss_D: -0.1967 (0.2924) Loss_G: -0.0508 (0.1440) D(x): 0.5608 D(G(z)): 0.4618 / 0.4138 Acc: 50.0000 (30.9616)\n",
      "[9/25][471/782] Loss_D: 0.0405 (0.2923) Loss_G: -0.1429 (0.1440) D(x): 0.4845 D(G(z)): 0.4184 / 0.4582 Acc: 35.9375 (30.9623)\n",
      "[9/25][472/782] Loss_D: -0.1055 (0.2923) Loss_G: -0.1465 (0.1439) D(x): 0.5486 D(G(z)): 0.4392 / 0.4556 Acc: 39.0625 (30.9633)\n",
      "[9/25][473/782] Loss_D: 0.1088 (0.2922) Loss_G: -0.1246 (0.1439) D(x): 0.5341 D(G(z)): 0.5103 / 0.4305 Acc: 31.2500 (30.9634)\n",
      "[9/25][474/782] Loss_D: 0.0641 (0.2922) Loss_G: -0.0247 (0.1439) D(x): 0.4716 D(G(z)): 0.4283 / 0.4011 Acc: 34.3750 (30.9638)\n",
      "[9/25][475/782] Loss_D: -0.0335 (0.2922) Loss_G: -0.2495 (0.1438) D(x): 0.5534 D(G(z)): 0.4436 / 0.5013 Acc: 31.2500 (30.9639)\n",
      "[9/25][476/782] Loss_D: -0.0219 (0.2921) Loss_G: -0.0250 (0.1438) D(x): 0.5767 D(G(z)): 0.4923 / 0.4123 Acc: 37.5000 (30.9647)\n",
      "[9/25][477/782] Loss_D: 0.0084 (0.2921) Loss_G: -0.0283 (0.1438) D(x): 0.5069 D(G(z)): 0.4682 / 0.4154 Acc: 42.1875 (30.9662)\n",
      "[9/25][478/782] Loss_D: -0.0409 (0.2921) Loss_G: -0.0927 (0.1438) D(x): 0.5832 D(G(z)): 0.4528 / 0.4451 Acc: 31.2500 (30.9663)\n",
      "[9/25][479/782] Loss_D: -0.0044 (0.2920) Loss_G: -0.1729 (0.1437) D(x): 0.4957 D(G(z)): 0.4470 / 0.4810 Acc: 40.6250 (30.9676)\n",
      "[9/25][480/782] Loss_D: -0.1697 (0.2920) Loss_G: -0.0732 (0.1437) D(x): 0.5959 D(G(z)): 0.4781 / 0.4379 Acc: 42.1875 (30.9690)\n",
      "[9/25][481/782] Loss_D: -0.1592 (0.2919) Loss_G: 0.0545 (0.1437) D(x): 0.5590 D(G(z)): 0.4841 / 0.3755 Acc: 50.0000 (30.9716)\n",
      "[9/25][482/782] Loss_D: 0.0403 (0.2919) Loss_G: -0.1234 (0.1436) D(x): 0.5098 D(G(z)): 0.4984 / 0.4441 Acc: 43.7500 (30.9733)\n",
      "[9/25][483/782] Loss_D: 0.0703 (0.2918) Loss_G: -0.0647 (0.1436) D(x): 0.4931 D(G(z)): 0.4522 / 0.4569 Acc: 39.0625 (30.9744)\n",
      "[9/25][484/782] Loss_D: 0.0372 (0.2918) Loss_G: -0.0296 (0.1436) D(x): 0.5587 D(G(z)): 0.5138 / 0.4163 Acc: 35.9375 (30.9750)\n",
      "[9/25][485/782] Loss_D: 0.1898 (0.2918) Loss_G: -0.2650 (0.1435) D(x): 0.4491 D(G(z)): 0.4165 / 0.5078 Acc: 28.1250 (30.9746)\n",
      "[9/25][486/782] Loss_D: 0.3012 (0.2918) Loss_G: -0.2466 (0.1435) D(x): 0.4736 D(G(z)): 0.5098 / 0.5010 Acc: 29.6875 (30.9745)\n",
      "[9/25][487/782] Loss_D: 0.2524 (0.2918) Loss_G: -0.1896 (0.1434) D(x): 0.5067 D(G(z)): 0.5240 / 0.4950 Acc: 31.2500 (30.9745)\n",
      "[9/25][488/782] Loss_D: -0.0358 (0.2917) Loss_G: -0.1170 (0.1434) D(x): 0.5265 D(G(z)): 0.5034 / 0.4557 Acc: 50.0000 (30.9770)\n",
      "[9/25][489/782] Loss_D: 0.0483 (0.2917) Loss_G: -0.2018 (0.1434) D(x): 0.5332 D(G(z)): 0.4931 / 0.5012 Acc: 42.1875 (30.9785)\n",
      "[9/25][490/782] Loss_D: -0.1683 (0.2916) Loss_G: -0.0533 (0.1433) D(x): 0.5835 D(G(z)): 0.4325 / 0.4336 Acc: 40.6250 (30.9798)\n",
      "[9/25][491/782] Loss_D: 0.1222 (0.2916) Loss_G: 0.0060 (0.1433) D(x): 0.4782 D(G(z)): 0.4602 / 0.3942 Acc: 39.0625 (30.9809)\n",
      "[9/25][492/782] Loss_D: -0.0433 (0.2916) Loss_G: -0.0446 (0.1433) D(x): 0.5057 D(G(z)): 0.4551 / 0.4285 Acc: 46.8750 (30.9830)\n",
      "[9/25][493/782] Loss_D: 0.0693 (0.2915) Loss_G: -0.2051 (0.1432) D(x): 0.5004 D(G(z)): 0.5053 / 0.4978 Acc: 46.8750 (30.9851)\n",
      "[9/25][494/782] Loss_D: 0.1050 (0.2915) Loss_G: -0.1510 (0.1432) D(x): 0.5136 D(G(z)): 0.4735 / 0.4673 Acc: 35.9375 (30.9857)\n",
      "[9/25][495/782] Loss_D: 0.1065 (0.2915) Loss_G: -0.0924 (0.1432) D(x): 0.5317 D(G(z)): 0.4625 / 0.4580 Acc: 28.1250 (30.9854)\n",
      "[9/25][496/782] Loss_D: -0.0488 (0.2914) Loss_G: -0.1164 (0.1431) D(x): 0.5270 D(G(z)): 0.4662 / 0.4454 Acc: 39.0625 (30.9864)\n",
      "[9/25][497/782] Loss_D: -0.0404 (0.2914) Loss_G: -0.1461 (0.1431) D(x): 0.4938 D(G(z)): 0.4103 / 0.4543 Acc: 34.3750 (30.9869)\n",
      "[9/25][498/782] Loss_D: -0.0190 (0.2914) Loss_G: -0.1484 (0.1431) D(x): 0.5903 D(G(z)): 0.4866 / 0.4559 Acc: 32.8125 (30.9871)\n",
      "[9/25][499/782] Loss_D: 0.0733 (0.2913) Loss_G: -0.1981 (0.1430) D(x): 0.5626 D(G(z)): 0.5184 / 0.4864 Acc: 34.3750 (30.9876)\n",
      "[9/25][500/782] Loss_D: -0.1178 (0.2913) Loss_G: -0.0296 (0.1430) D(x): 0.5232 D(G(z)): 0.4229 / 0.4179 Acc: 43.7500 (30.9893)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[9/25][501/782] Loss_D: 0.0894 (0.2913) Loss_G: -0.2055 (0.1429) D(x): 0.4924 D(G(z)): 0.4484 / 0.5100 Acc: 35.9375 (30.9899)\n",
      "[9/25][502/782] Loss_D: -0.0912 (0.2912) Loss_G: -0.0899 (0.1429) D(x): 0.5623 D(G(z)): 0.4783 / 0.4317 Acc: 42.1875 (30.9914)\n",
      "[9/25][503/782] Loss_D: 0.0335 (0.2912) Loss_G: -0.1839 (0.1429) D(x): 0.5027 D(G(z)): 0.4649 / 0.4802 Acc: 42.1875 (30.9929)\n",
      "[9/25][504/782] Loss_D: -0.0755 (0.2911) Loss_G: -0.2558 (0.1428) D(x): 0.5372 D(G(z)): 0.4551 / 0.4970 Acc: 43.7500 (30.9946)\n",
      "[9/25][505/782] Loss_D: -0.0380 (0.2911) Loss_G: -0.1587 (0.1428) D(x): 0.5380 D(G(z)): 0.4479 / 0.4542 Acc: 37.5000 (30.9955)\n",
      "[9/25][506/782] Loss_D: -0.0902 (0.2910) Loss_G: -0.2575 (0.1427) D(x): 0.5581 D(G(z)): 0.4539 / 0.5056 Acc: 43.7500 (30.9971)\n",
      "[9/25][507/782] Loss_D: 0.1185 (0.2910) Loss_G: -0.1372 (0.1427) D(x): 0.5615 D(G(z)): 0.5160 / 0.4566 Acc: 29.6875 (30.9970)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/25][508/782] Loss_D: 0.2354 (0.2910) Loss_G: -0.2006 (0.1426) D(x): 0.4765 D(G(z)): 0.4972 / 0.4789 Acc: 34.3750 (30.9974)\n",
      "[9/25][509/782] Loss_D: -0.0370 (0.2910) Loss_G: -0.2037 (0.1426) D(x): 0.5152 D(G(z)): 0.4346 / 0.4804 Acc: 35.9375 (30.9981)\n",
      "[9/25][510/782] Loss_D: -0.1020 (0.2909) Loss_G: -0.1588 (0.1426) D(x): 0.5545 D(G(z)): 0.4367 / 0.4805 Acc: 37.5000 (30.9989)\n",
      "[9/25][511/782] Loss_D: -0.0978 (0.2908) Loss_G: -0.1010 (0.1425) D(x): 0.6142 D(G(z)): 0.5058 / 0.4422 Acc: 39.0625 (31.0000)\n",
      "[9/25][512/782] Loss_D: -0.1335 (0.2908) Loss_G: -0.0770 (0.1425) D(x): 0.5718 D(G(z)): 0.4681 / 0.4316 Acc: 40.6250 (31.0013)\n",
      "[9/25][513/782] Loss_D: 0.0631 (0.2908) Loss_G: -0.0634 (0.1425) D(x): 0.4649 D(G(z)): 0.4454 / 0.4180 Acc: 40.6250 (31.0025)\n",
      "[9/25][514/782] Loss_D: 0.1052 (0.2907) Loss_G: -0.1587 (0.1424) D(x): 0.4558 D(G(z)): 0.4842 / 0.4663 Acc: 51.5625 (31.0053)\n",
      "[9/25][515/782] Loss_D: 0.0657 (0.2907) Loss_G: -0.1668 (0.1424) D(x): 0.4978 D(G(z)): 0.4889 / 0.4654 Acc: 40.6250 (31.0065)\n",
      "[9/25][516/782] Loss_D: -0.0121 (0.2907) Loss_G: -0.1232 (0.1424) D(x): 0.5601 D(G(z)): 0.5063 / 0.4462 Acc: 43.7500 (31.0082)\n",
      "[9/25][517/782] Loss_D: -0.1814 (0.2906) Loss_G: 0.0108 (0.1423) D(x): 0.5501 D(G(z)): 0.4582 / 0.3864 Acc: 50.0000 (31.0107)\n",
      "[9/25][518/782] Loss_D: 0.0777 (0.2906) Loss_G: -0.1422 (0.1423) D(x): 0.4747 D(G(z)): 0.4274 / 0.4654 Acc: 34.3750 (31.0112)\n",
      "[9/25][519/782] Loss_D: -0.1397 (0.2905) Loss_G: -0.1382 (0.1423) D(x): 0.5706 D(G(z)): 0.4897 / 0.4553 Acc: 45.3125 (31.0131)\n",
      "[9/25][520/782] Loss_D: -0.0618 (0.2905) Loss_G: -0.1056 (0.1422) D(x): 0.5529 D(G(z)): 0.4822 / 0.4520 Acc: 45.3125 (31.0150)\n",
      "[9/25][521/782] Loss_D: 0.1072 (0.2904) Loss_G: 0.1923 (0.1422) D(x): 0.5609 D(G(z)): 0.5161 / 0.3367 Acc: 29.6875 (31.0148)\n",
      "[9/25][522/782] Loss_D: -0.0886 (0.2904) Loss_G: -0.0917 (0.1422) D(x): 0.4974 D(G(z)): 0.4251 / 0.4355 Acc: 45.3125 (31.0167)\n",
      "[9/25][523/782] Loss_D: 0.1054 (0.2904) Loss_G: -0.1708 (0.1422) D(x): 0.4561 D(G(z)): 0.5063 / 0.4856 Acc: 50.0000 (31.0192)\n",
      "[9/25][524/782] Loss_D: -0.1330 (0.2903) Loss_G: -0.2302 (0.1421) D(x): 0.5350 D(G(z)): 0.4240 / 0.4939 Acc: 42.1875 (31.0207)\n",
      "[9/25][525/782] Loss_D: -0.2944 (0.2902) Loss_G: -0.0907 (0.1421) D(x): 0.6109 D(G(z)): 0.4455 / 0.4328 Acc: 43.7500 (31.0224)\n",
      "[9/25][526/782] Loss_D: -0.1170 (0.2902) Loss_G: -0.1252 (0.1420) D(x): 0.5762 D(G(z)): 0.5060 / 0.4637 Acc: 48.4375 (31.0247)\n",
      "[9/25][527/782] Loss_D: -0.0975 (0.2901) Loss_G: -0.1356 (0.1420) D(x): 0.5570 D(G(z)): 0.4631 / 0.4601 Acc: 43.7500 (31.0263)\n",
      "[9/25][528/782] Loss_D: 0.0145 (0.2901) Loss_G: -0.0332 (0.1420) D(x): 0.4963 D(G(z)): 0.4463 / 0.4117 Acc: 42.1875 (31.0278)\n",
      "[9/25][529/782] Loss_D: 0.0815 (0.2901) Loss_G: -0.2659 (0.1419) D(x): 0.4650 D(G(z)): 0.4478 / 0.5065 Acc: 39.0625 (31.0289)\n",
      "[9/25][530/782] Loss_D: 0.0764 (0.2900) Loss_G: -0.1627 (0.1419) D(x): 0.5645 D(G(z)): 0.5320 / 0.4668 Acc: 35.9375 (31.0295)\n",
      "[9/25][531/782] Loss_D: 0.0741 (0.2900) Loss_G: -0.0816 (0.1419) D(x): 0.5651 D(G(z)): 0.5040 / 0.4495 Acc: 31.2500 (31.0296)\n",
      "[9/25][532/782] Loss_D: -0.0235 (0.2900) Loss_G: -0.1062 (0.1418) D(x): 0.5424 D(G(z)): 0.4781 / 0.4505 Acc: 37.5000 (31.0304)\n",
      "[9/25][533/782] Loss_D: 0.3227 (0.2900) Loss_G: -0.1046 (0.1418) D(x): 0.4511 D(G(z)): 0.4976 / 0.4555 Acc: 31.2500 (31.0304)\n",
      "[9/25][534/782] Loss_D: -0.0021 (0.2899) Loss_G: -0.2098 (0.1418) D(x): 0.4887 D(G(z)): 0.4214 / 0.4921 Acc: 40.6250 (31.0317)\n",
      "[9/25][535/782] Loss_D: -0.0807 (0.2899) Loss_G: 0.0149 (0.1417) D(x): 0.5981 D(G(z)): 0.5395 / 0.4008 Acc: 45.3125 (31.0336)\n",
      "[9/25][536/782] Loss_D: -0.2172 (0.2898) Loss_G: -0.0382 (0.1417) D(x): 0.5374 D(G(z)): 0.4359 / 0.4172 Acc: 53.1250 (31.0365)\n",
      "[9/25][537/782] Loss_D: 0.1049 (0.2898) Loss_G: -0.0877 (0.1417) D(x): 0.5418 D(G(z)): 0.5033 / 0.4355 Acc: 40.6250 (31.0378)\n",
      "[9/25][538/782] Loss_D: 0.0598 (0.2898) Loss_G: 0.0257 (0.1417) D(x): 0.4873 D(G(z)): 0.4742 / 0.3999 Acc: 43.7500 (31.0395)\n",
      "[9/25][539/782] Loss_D: -0.2378 (0.2897) Loss_G: 0.0686 (0.1417) D(x): 0.5619 D(G(z)): 0.4065 / 0.4004 Acc: 42.1875 (31.0409)\n",
      "[9/25][540/782] Loss_D: -0.0436 (0.2897) Loss_G: -0.0574 (0.1416) D(x): 0.5267 D(G(z)): 0.4697 / 0.4224 Acc: 46.8750 (31.0430)\n",
      "[9/25][541/782] Loss_D: -0.1426 (0.2896) Loss_G: -0.1397 (0.1416) D(x): 0.5577 D(G(z)): 0.4510 / 0.4524 Acc: 42.1875 (31.0445)\n",
      "[9/25][542/782] Loss_D: -0.1365 (0.2895) Loss_G: -0.1198 (0.1416) D(x): 0.5527 D(G(z)): 0.4553 / 0.4540 Acc: 42.1875 (31.0460)\n",
      "[9/25][543/782] Loss_D: -0.0869 (0.2895) Loss_G: -0.0150 (0.1415) D(x): 0.5490 D(G(z)): 0.4480 / 0.4074 Acc: 35.9375 (31.0466)\n",
      "[9/25][544/782] Loss_D: -0.0414 (0.2894) Loss_G: 0.0303 (0.1415) D(x): 0.5281 D(G(z)): 0.4688 / 0.4058 Acc: 48.4375 (31.0489)\n",
      "[9/25][545/782] Loss_D: 0.0724 (0.2894) Loss_G: -0.0694 (0.1415) D(x): 0.5115 D(G(z)): 0.4402 / 0.4412 Acc: 40.6250 (31.0502)\n",
      "[9/25][546/782] Loss_D: -0.0380 (0.2894) Loss_G: -0.1971 (0.1415) D(x): 0.5278 D(G(z)): 0.4752 / 0.4774 Acc: 45.3125 (31.0520)\n",
      "[9/25][547/782] Loss_D: 0.0273 (0.2893) Loss_G: -0.1256 (0.1414) D(x): 0.5377 D(G(z)): 0.4764 / 0.4480 Acc: 39.0625 (31.0531)\n",
      "[9/25][548/782] Loss_D: 0.0074 (0.2893) Loss_G: -0.0811 (0.1414) D(x): 0.5605 D(G(z)): 0.5112 / 0.4264 Acc: 39.0625 (31.0541)\n",
      "[9/25][549/782] Loss_D: 0.0048 (0.2893) Loss_G: -0.1019 (0.1414) D(x): 0.5324 D(G(z)): 0.4493 / 0.4538 Acc: 39.0625 (31.0552)\n",
      "[9/25][550/782] Loss_D: 0.0913 (0.2892) Loss_G: -0.0405 (0.1413) D(x): 0.4783 D(G(z)): 0.4933 / 0.4334 Acc: 45.3125 (31.0571)\n",
      "[9/25][551/782] Loss_D: -0.0312 (0.2892) Loss_G: -0.0385 (0.1413) D(x): 0.5099 D(G(z)): 0.4270 / 0.4289 Acc: 39.0625 (31.0581)\n",
      "[9/25][552/782] Loss_D: -0.2246 (0.2891) Loss_G: -0.1151 (0.1413) D(x): 0.5454 D(G(z)): 0.4401 / 0.4577 Acc: 53.1250 (31.0610)\n",
      "[9/25][553/782] Loss_D: -0.0670 (0.2891) Loss_G: -0.1485 (0.1412) D(x): 0.5764 D(G(z)): 0.4679 / 0.4646 Acc: 31.2500 (31.0611)\n",
      "[9/25][554/782] Loss_D: -0.0736 (0.2890) Loss_G: -0.0303 (0.1412) D(x): 0.5618 D(G(z)): 0.5013 / 0.4326 Acc: 43.7500 (31.0627)\n",
      "[9/25][555/782] Loss_D: 0.1516 (0.2890) Loss_G: -0.0082 (0.1412) D(x): 0.5276 D(G(z)): 0.5543 / 0.4198 Acc: 43.7500 (31.0644)\n",
      "[9/25][556/782] Loss_D: -0.0143 (0.2890) Loss_G: 0.0878 (0.1412) D(x): 0.5464 D(G(z)): 0.4134 / 0.3655 Acc: 29.6875 (31.0642)\n",
      "[9/25][557/782] Loss_D: 0.1625 (0.2890) Loss_G: -0.0825 (0.1412) D(x): 0.4706 D(G(z)): 0.4370 / 0.4597 Acc: 31.2500 (31.0643)\n",
      "[9/25][558/782] Loss_D: -0.0807 (0.2889) Loss_G: -0.0480 (0.1411) D(x): 0.4938 D(G(z)): 0.4530 / 0.4259 Acc: 56.2500 (31.0676)\n",
      "[9/25][559/782] Loss_D: -0.0761 (0.2889) Loss_G: -0.1706 (0.1411) D(x): 0.5326 D(G(z)): 0.4669 / 0.4738 Acc: 40.6250 (31.0688)\n",
      "[9/25][560/782] Loss_D: -0.2240 (0.2888) Loss_G: -0.0174 (0.1411) D(x): 0.6208 D(G(z)): 0.5033 / 0.4055 Acc: 48.4375 (31.0711)\n",
      "[9/25][561/782] Loss_D: 0.1311 (0.2888) Loss_G: -0.0489 (0.1410) D(x): 0.4546 D(G(z)): 0.4596 / 0.4310 Acc: 37.5000 (31.0720)\n",
      "[9/25][562/782] Loss_D: -0.0415 (0.2887) Loss_G: -0.1009 (0.1410) D(x): 0.5453 D(G(z)): 0.4630 / 0.4448 Acc: 40.6250 (31.0732)\n",
      "[9/25][563/782] Loss_D: 0.0372 (0.2887) Loss_G: -0.0831 (0.1410) D(x): 0.5637 D(G(z)): 0.4624 / 0.4365 Acc: 26.5625 (31.0726)\n",
      "[9/25][564/782] Loss_D: 0.1082 (0.2887) Loss_G: -0.1106 (0.1410) D(x): 0.4935 D(G(z)): 0.4359 / 0.4591 Acc: 32.8125 (31.0728)\n",
      "[9/25][565/782] Loss_D: 0.0773 (0.2886) Loss_G: -0.1526 (0.1409) D(x): 0.4901 D(G(z)): 0.4486 / 0.4861 Acc: 35.9375 (31.0735)\n",
      "[9/25][566/782] Loss_D: -0.0784 (0.2886) Loss_G: -0.0899 (0.1409) D(x): 0.6172 D(G(z)): 0.4947 / 0.4369 Acc: 35.9375 (31.0741)\n",
      "[9/25][567/782] Loss_D: 0.0159 (0.2886) Loss_G: -0.1099 (0.1408) D(x): 0.5157 D(G(z)): 0.4544 / 0.4565 Acc: 39.0625 (31.0752)\n",
      "[9/25][568/782] Loss_D: 0.0405 (0.2885) Loss_G: -0.1868 (0.1408) D(x): 0.5214 D(G(z)): 0.4584 / 0.4746 Acc: 31.2500 (31.0752)\n",
      "[9/25][569/782] Loss_D: -0.0423 (0.2885) Loss_G: -0.2103 (0.1408) D(x): 0.5908 D(G(z)): 0.4947 / 0.5070 Acc: 39.0625 (31.0763)\n",
      "[9/25][570/782] Loss_D: -0.0110 (0.2884) Loss_G: -0.0532 (0.1407) D(x): 0.5483 D(G(z)): 0.5067 / 0.4234 Acc: 43.7500 (31.0779)\n",
      "[9/25][571/782] Loss_D: 0.2291 (0.2884) Loss_G: -0.1101 (0.1407) D(x): 0.4728 D(G(z)): 0.5226 / 0.4348 Acc: 40.6250 (31.0792)\n",
      "[9/25][572/782] Loss_D: 0.0018 (0.2884) Loss_G: -0.1193 (0.1407) D(x): 0.5002 D(G(z)): 0.4057 / 0.4522 Acc: 39.0625 (31.0802)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/25][573/782] Loss_D: -0.1768 (0.2883) Loss_G: -0.0298 (0.1406) D(x): 0.5585 D(G(z)): 0.4958 / 0.4108 Acc: 53.1250 (31.0831)\n",
      "[9/25][574/782] Loss_D: -0.0431 (0.2883) Loss_G: -0.1499 (0.1406) D(x): 0.5151 D(G(z)): 0.4262 / 0.4593 Acc: 34.3750 (31.0835)\n",
      "[9/25][575/782] Loss_D: -0.0428 (0.2883) Loss_G: -0.2733 (0.1406) D(x): 0.6189 D(G(z)): 0.5187 / 0.5012 Acc: 35.9375 (31.0842)\n",
      "[9/25][576/782] Loss_D: 0.1341 (0.2882) Loss_G: -0.1191 (0.1405) D(x): 0.5137 D(G(z)): 0.4653 / 0.4378 Acc: 28.1250 (31.0838)\n",
      "[9/25][577/782] Loss_D: 0.2426 (0.2882) Loss_G: -0.0190 (0.1405) D(x): 0.5284 D(G(z)): 0.5478 / 0.4247 Acc: 31.2500 (31.0838)\n",
      "[9/25][578/782] Loss_D: 0.0137 (0.2882) Loss_G: -0.0955 (0.1405) D(x): 0.4718 D(G(z)): 0.3853 / 0.4488 Acc: 35.9375 (31.0845)\n",
      "[9/25][579/782] Loss_D: 0.0141 (0.2882) Loss_G: -0.2303 (0.1404) D(x): 0.5300 D(G(z)): 0.4471 / 0.4963 Acc: 32.8125 (31.0847)\n",
      "[9/25][580/782] Loss_D: 0.0616 (0.2881) Loss_G: -0.2587 (0.1404) D(x): 0.5371 D(G(z)): 0.5110 / 0.4917 Acc: 39.0625 (31.0857)\n",
      "[9/25][581/782] Loss_D: 0.0289 (0.2881) Loss_G: -0.0726 (0.1403) D(x): 0.5447 D(G(z)): 0.5228 / 0.4276 Acc: 45.3125 (31.0876)\n",
      "[9/25][582/782] Loss_D: -0.0840 (0.2880) Loss_G: -0.0080 (0.1403) D(x): 0.5979 D(G(z)): 0.4929 / 0.4037 Acc: 35.9375 (31.0882)\n",
      "[9/25][583/782] Loss_D: 0.0025 (0.2880) Loss_G: 0.0813 (0.1403) D(x): 0.4716 D(G(z)): 0.4386 / 0.3750 Acc: 46.8750 (31.0903)\n",
      "[9/25][584/782] Loss_D: -0.0585 (0.2880) Loss_G: -0.1453 (0.1403) D(x): 0.4683 D(G(z)): 0.4167 / 0.4577 Acc: 40.6250 (31.0916)\n",
      "[9/25][585/782] Loss_D: 0.1377 (0.2879) Loss_G: -0.1990 (0.1402) D(x): 0.5239 D(G(z)): 0.5001 / 0.4831 Acc: 34.3750 (31.0920)\n",
      "[9/25][586/782] Loss_D: -0.0465 (0.2879) Loss_G: -0.0851 (0.1402) D(x): 0.5962 D(G(z)): 0.5200 / 0.4422 Acc: 40.6250 (31.0932)\n",
      "[9/25][587/782] Loss_D: -0.0397 (0.2879) Loss_G: 0.1308 (0.1402) D(x): 0.5513 D(G(z)): 0.5237 / 0.3590 Acc: 46.8750 (31.0953)\n",
      "[9/25][588/782] Loss_D: -0.0628 (0.2878) Loss_G: 0.0095 (0.1402) D(x): 0.4950 D(G(z)): 0.3954 / 0.4009 Acc: 43.7500 (31.0970)\n",
      "[9/25][589/782] Loss_D: -0.0038 (0.2878) Loss_G: -0.1325 (0.1401) D(x): 0.4934 D(G(z)): 0.4585 / 0.4600 Acc: 42.1875 (31.0984)\n",
      "[9/25][590/782] Loss_D: 0.0014 (0.2877) Loss_G: -0.1112 (0.1401) D(x): 0.5411 D(G(z)): 0.4883 / 0.4421 Acc: 37.5000 (31.0993)\n",
      "[9/25][591/782] Loss_D: 0.1615 (0.2877) Loss_G: -0.1874 (0.1401) D(x): 0.4954 D(G(z)): 0.4935 / 0.4820 Acc: 34.3750 (31.0997)\n",
      "[9/25][592/782] Loss_D: 0.0609 (0.2877) Loss_G: -0.0262 (0.1400) D(x): 0.5864 D(G(z)): 0.5047 / 0.4260 Acc: 34.3750 (31.1001)\n",
      "[9/25][593/782] Loss_D: 0.0252 (0.2877) Loss_G: -0.2271 (0.1400) D(x): 0.4806 D(G(z)): 0.4660 / 0.4898 Acc: 51.5625 (31.1028)\n",
      "[9/25][594/782] Loss_D: -0.0543 (0.2876) Loss_G: -0.1276 (0.1400) D(x): 0.4991 D(G(z)): 0.4395 / 0.4444 Acc: 46.8750 (31.1049)\n",
      "[9/25][595/782] Loss_D: 0.1239 (0.2876) Loss_G: -0.2871 (0.1399) D(x): 0.4779 D(G(z)): 0.4668 / 0.5198 Acc: 34.3750 (31.1053)\n",
      "[9/25][596/782] Loss_D: 0.0729 (0.2876) Loss_G: -0.1033 (0.1399) D(x): 0.5883 D(G(z)): 0.5214 / 0.4511 Acc: 32.8125 (31.1055)\n",
      "[9/25][597/782] Loss_D: 0.0415 (0.2875) Loss_G: -0.0502 (0.1399) D(x): 0.5166 D(G(z)): 0.4562 / 0.4469 Acc: 39.0625 (31.1066)\n",
      "[9/25][598/782] Loss_D: -0.0836 (0.2875) Loss_G: -0.1399 (0.1398) D(x): 0.5603 D(G(z)): 0.4485 / 0.4569 Acc: 32.8125 (31.1068)\n",
      "[9/25][599/782] Loss_D: 0.0248 (0.2874) Loss_G: -0.0848 (0.1398) D(x): 0.5017 D(G(z)): 0.4848 / 0.4545 Acc: 45.3125 (31.1086)\n",
      "[9/25][600/782] Loss_D: -0.1238 (0.2874) Loss_G: -0.1154 (0.1398) D(x): 0.5633 D(G(z)): 0.4305 / 0.4672 Acc: 37.5000 (31.1095)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[9/25][601/782] Loss_D: 0.1635 (0.2874) Loss_G: -0.1358 (0.1397) D(x): 0.5160 D(G(z)): 0.4948 / 0.4682 Acc: 35.9375 (31.1101)\n",
      "[9/25][602/782] Loss_D: -0.1392 (0.2873) Loss_G: 0.0100 (0.1397) D(x): 0.5917 D(G(z)): 0.4650 / 0.4055 Acc: 43.7500 (31.1118)\n",
      "[9/25][603/782] Loss_D: -0.1285 (0.2873) Loss_G: -0.0275 (0.1397) D(x): 0.5207 D(G(z)): 0.4597 / 0.4205 Acc: 53.1250 (31.1146)\n",
      "[9/25][604/782] Loss_D: -0.0181 (0.2872) Loss_G: -0.1225 (0.1396) D(x): 0.5323 D(G(z)): 0.4210 / 0.4479 Acc: 29.6875 (31.1145)\n",
      "[9/25][605/782] Loss_D: -0.0684 (0.2872) Loss_G: -0.2098 (0.1396) D(x): 0.5264 D(G(z)): 0.4786 / 0.4756 Acc: 53.1250 (31.1173)\n",
      "[9/25][606/782] Loss_D: -0.1268 (0.2871) Loss_G: -0.1163 (0.1396) D(x): 0.5684 D(G(z)): 0.4876 / 0.4425 Acc: 46.8750 (31.1194)\n",
      "[9/25][607/782] Loss_D: 0.0796 (0.2871) Loss_G: 0.0324 (0.1395) D(x): 0.4794 D(G(z)): 0.4723 / 0.3893 Acc: 40.6250 (31.1206)\n",
      "[9/25][608/782] Loss_D: 0.0181 (0.2871) Loss_G: -0.1081 (0.1395) D(x): 0.5729 D(G(z)): 0.5078 / 0.4548 Acc: 39.0625 (31.1217)\n",
      "[9/25][609/782] Loss_D: -0.0996 (0.2870) Loss_G: -0.1203 (0.1395) D(x): 0.5232 D(G(z)): 0.4104 / 0.4426 Acc: 37.5000 (31.1225)\n",
      "[9/25][610/782] Loss_D: -0.1005 (0.2870) Loss_G: -0.1566 (0.1394) D(x): 0.5242 D(G(z)): 0.4331 / 0.4668 Acc: 39.0625 (31.1236)\n",
      "[9/25][611/782] Loss_D: 0.1022 (0.2869) Loss_G: -0.1237 (0.1394) D(x): 0.5265 D(G(z)): 0.4994 / 0.4515 Acc: 37.5000 (31.1244)\n",
      "[9/25][612/782] Loss_D: -0.2161 (0.2869) Loss_G: -0.1449 (0.1394) D(x): 0.5844 D(G(z)): 0.4836 / 0.4651 Acc: 48.4375 (31.1267)\n",
      "[9/25][613/782] Loss_D: -0.2104 (0.2868) Loss_G: -0.0891 (0.1393) D(x): 0.5500 D(G(z)): 0.4441 / 0.4322 Acc: 48.4375 (31.1289)\n",
      "[9/25][614/782] Loss_D: -0.1020 (0.2868) Loss_G: -0.1241 (0.1393) D(x): 0.5179 D(G(z)): 0.4349 / 0.4474 Acc: 40.6250 (31.1302)\n",
      "[9/25][615/782] Loss_D: 0.0988 (0.2867) Loss_G: -0.0441 (0.1393) D(x): 0.5009 D(G(z)): 0.5022 / 0.4187 Acc: 39.0625 (31.1312)\n",
      "[9/25][616/782] Loss_D: 0.0534 (0.2867) Loss_G: -0.0015 (0.1393) D(x): 0.5132 D(G(z)): 0.4955 / 0.4045 Acc: 45.3125 (31.1330)\n",
      "[9/25][617/782] Loss_D: -0.0353 (0.2867) Loss_G: -0.0596 (0.1392) D(x): 0.4951 D(G(z)): 0.4208 / 0.4353 Acc: 40.6250 (31.1343)\n",
      "[9/25][618/782] Loss_D: -0.0599 (0.2866) Loss_G: -0.1271 (0.1392) D(x): 0.5230 D(G(z)): 0.4520 / 0.4619 Acc: 45.3125 (31.1361)\n",
      "[9/25][619/782] Loss_D: -0.1387 (0.2866) Loss_G: -0.1722 (0.1392) D(x): 0.5731 D(G(z)): 0.4738 / 0.4751 Acc: 42.1875 (31.1376)\n",
      "[9/25][620/782] Loss_D: -0.3017 (0.2865) Loss_G: -0.0839 (0.1391) D(x): 0.5879 D(G(z)): 0.4483 / 0.4493 Acc: 51.5625 (31.1402)\n",
      "[9/25][621/782] Loss_D: -0.0653 (0.2864) Loss_G: -0.2278 (0.1391) D(x): 0.4764 D(G(z)): 0.4255 / 0.4969 Acc: 43.7500 (31.1419)\n",
      "[9/25][622/782] Loss_D: -0.0050 (0.2864) Loss_G: -0.1893 (0.1390) D(x): 0.5239 D(G(z)): 0.4770 / 0.4751 Acc: 39.0625 (31.1429)\n",
      "[9/25][623/782] Loss_D: -0.1025 (0.2863) Loss_G: -0.2358 (0.1390) D(x): 0.5526 D(G(z)): 0.4890 / 0.4957 Acc: 45.3125 (31.1448)\n",
      "[9/25][624/782] Loss_D: 0.0033 (0.2863) Loss_G: -0.2973 (0.1389) D(x): 0.5109 D(G(z)): 0.4874 / 0.5356 Acc: 48.4375 (31.1470)\n",
      "[9/25][625/782] Loss_D: -0.0790 (0.2863) Loss_G: -0.1040 (0.1389) D(x): 0.5501 D(G(z)): 0.4533 / 0.4418 Acc: 37.5000 (31.1479)\n",
      "[9/25][626/782] Loss_D: 0.0836 (0.2862) Loss_G: -0.0834 (0.1389) D(x): 0.5238 D(G(z)): 0.5086 / 0.4240 Acc: 42.1875 (31.1493)\n",
      "[9/25][627/782] Loss_D: 0.0092 (0.2862) Loss_G: -0.0733 (0.1388) D(x): 0.4722 D(G(z)): 0.4430 / 0.4475 Acc: 46.8750 (31.1514)\n",
      "[9/25][628/782] Loss_D: 0.1114 (0.2862) Loss_G: -0.2913 (0.1388) D(x): 0.4357 D(G(z)): 0.4215 / 0.5212 Acc: 35.9375 (31.1520)\n",
      "[9/25][629/782] Loss_D: 0.0136 (0.2861) Loss_G: -0.3104 (0.1387) D(x): 0.6116 D(G(z)): 0.5467 / 0.5450 Acc: 37.5000 (31.1528)\n",
      "[9/25][630/782] Loss_D: -0.0407 (0.2861) Loss_G: 0.0231 (0.1387) D(x): 0.5713 D(G(z)): 0.5297 / 0.3908 Acc: 50.0000 (31.1553)\n",
      "[9/25][631/782] Loss_D: -0.0411 (0.2861) Loss_G: 0.0598 (0.1387) D(x): 0.5064 D(G(z)): 0.4446 / 0.3824 Acc: 45.3125 (31.1571)\n",
      "[9/25][632/782] Loss_D: -0.0302 (0.2860) Loss_G: 0.0692 (0.1387) D(x): 0.4782 D(G(z)): 0.4152 / 0.4004 Acc: 40.6250 (31.1583)\n",
      "[9/25][633/782] Loss_D: 0.1503 (0.2860) Loss_G: -0.1495 (0.1387) D(x): 0.4945 D(G(z)): 0.5025 / 0.4566 Acc: 37.5000 (31.1592)\n",
      "[9/25][634/782] Loss_D: -0.2126 (0.2859) Loss_G: -0.1419 (0.1386) D(x): 0.5970 D(G(z)): 0.4614 / 0.4629 Acc: 43.7500 (31.1608)\n",
      "[9/25][635/782] Loss_D: -0.1920 (0.2859) Loss_G: 0.0581 (0.1386) D(x): 0.5679 D(G(z)): 0.4078 / 0.3948 Acc: 35.9375 (31.1614)\n",
      "[9/25][636/782] Loss_D: 0.0014 (0.2858) Loss_G: -0.1146 (0.1386) D(x): 0.5436 D(G(z)): 0.4720 / 0.4448 Acc: 35.9375 (31.1621)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/25][637/782] Loss_D: -0.0631 (0.2858) Loss_G: 0.0368 (0.1386) D(x): 0.5606 D(G(z)): 0.4827 / 0.3858 Acc: 42.1875 (31.1635)\n",
      "[9/25][638/782] Loss_D: -0.0791 (0.2857) Loss_G: 0.1222 (0.1386) D(x): 0.5603 D(G(z)): 0.4375 / 0.3670 Acc: 32.8125 (31.1637)\n",
      "[9/25][639/782] Loss_D: 0.0369 (0.2857) Loss_G: -0.0185 (0.1385) D(x): 0.5288 D(G(z)): 0.4541 / 0.4187 Acc: 35.9375 (31.1643)\n",
      "[9/25][640/782] Loss_D: -0.1073 (0.2857) Loss_G: -0.0160 (0.1385) D(x): 0.5239 D(G(z)): 0.4496 / 0.4040 Acc: 46.8750 (31.1664)\n",
      "[9/25][641/782] Loss_D: -0.1483 (0.2856) Loss_G: 0.0033 (0.1385) D(x): 0.6075 D(G(z)): 0.4605 / 0.4000 Acc: 34.3750 (31.1668)\n",
      "[9/25][642/782] Loss_D: -0.0400 (0.2856) Loss_G: 0.1907 (0.1385) D(x): 0.5200 D(G(z)): 0.4603 / 0.3401 Acc: 43.7500 (31.1684)\n",
      "[9/25][643/782] Loss_D: -0.1727 (0.2855) Loss_G: -0.0402 (0.1385) D(x): 0.5479 D(G(z)): 0.4349 / 0.4281 Acc: 46.8750 (31.1705)\n",
      "[9/25][644/782] Loss_D: -0.0113 (0.2855) Loss_G: -0.1946 (0.1384) D(x): 0.4784 D(G(z)): 0.4405 / 0.4860 Acc: 45.3125 (31.1723)\n",
      "[9/25][645/782] Loss_D: 0.2886 (0.2855) Loss_G: -0.1816 (0.1384) D(x): 0.5265 D(G(z)): 0.5604 / 0.4976 Acc: 29.6875 (31.1721)\n",
      "[9/25][646/782] Loss_D: 0.0684 (0.2854) Loss_G: -0.0364 (0.1384) D(x): 0.5458 D(G(z)): 0.5322 / 0.4284 Acc: 46.8750 (31.1742)\n",
      "[9/25][647/782] Loss_D: -0.0287 (0.2854) Loss_G: 0.0352 (0.1384) D(x): 0.5142 D(G(z)): 0.4498 / 0.3998 Acc: 43.7500 (31.1758)\n",
      "[9/25][648/782] Loss_D: -0.1238 (0.2853) Loss_G: 0.0111 (0.1384) D(x): 0.5264 D(G(z)): 0.4259 / 0.3919 Acc: 45.3125 (31.1776)\n",
      "[9/25][649/782] Loss_D: -0.2798 (0.2853) Loss_G: -0.0141 (0.1383) D(x): 0.5297 D(G(z)): 0.3942 / 0.4166 Acc: 53.1250 (31.1805)\n",
      "[9/25][650/782] Loss_D: -0.0606 (0.2852) Loss_G: -0.1201 (0.1383) D(x): 0.5304 D(G(z)): 0.4704 / 0.4701 Acc: 48.4375 (31.1827)\n",
      "[9/25][651/782] Loss_D: -0.0388 (0.2852) Loss_G: -0.0843 (0.1383) D(x): 0.5574 D(G(z)): 0.4591 / 0.4401 Acc: 40.6250 (31.1840)\n",
      "[9/25][652/782] Loss_D: -0.1296 (0.2851) Loss_G: -0.0850 (0.1382) D(x): 0.5347 D(G(z)): 0.4409 / 0.4361 Acc: 39.0625 (31.1850)\n",
      "[9/25][653/782] Loss_D: -0.1646 (0.2851) Loss_G: 0.0129 (0.1382) D(x): 0.5820 D(G(z)): 0.5127 / 0.3983 Acc: 53.1250 (31.1878)\n",
      "[9/25][654/782] Loss_D: 0.0403 (0.2850) Loss_G: 0.0347 (0.1382) D(x): 0.5267 D(G(z)): 0.4781 / 0.3995 Acc: 39.0625 (31.1889)\n",
      "[9/25][655/782] Loss_D: -0.0599 (0.2850) Loss_G: 0.0152 (0.1382) D(x): 0.4497 D(G(z)): 0.4249 / 0.4201 Acc: 50.0000 (31.1913)\n",
      "[9/25][656/782] Loss_D: 0.0218 (0.2850) Loss_G: -0.1037 (0.1382) D(x): 0.5277 D(G(z)): 0.4681 / 0.4738 Acc: 42.1875 (31.1927)\n",
      "[9/25][657/782] Loss_D: -0.1723 (0.2849) Loss_G: -0.1537 (0.1381) D(x): 0.5790 D(G(z)): 0.4508 / 0.4764 Acc: 40.6250 (31.1940)\n",
      "[9/25][658/782] Loss_D: -0.0678 (0.2848) Loss_G: -0.0113 (0.1381) D(x): 0.5730 D(G(z)): 0.4645 / 0.4189 Acc: 34.3750 (31.1944)\n",
      "[9/25][659/782] Loss_D: 0.1929 (0.2848) Loss_G: 0.0030 (0.1381) D(x): 0.5190 D(G(z)): 0.5289 / 0.4210 Acc: 39.0625 (31.1954)\n",
      "[9/25][660/782] Loss_D: -0.0551 (0.2848) Loss_G: -0.0748 (0.1381) D(x): 0.5102 D(G(z)): 0.4373 / 0.4368 Acc: 46.8750 (31.1974)\n",
      "[9/25][661/782] Loss_D: 0.1277 (0.2848) Loss_G: -0.0808 (0.1380) D(x): 0.5267 D(G(z)): 0.5176 / 0.4514 Acc: 42.1875 (31.1989)\n",
      "[9/25][662/782] Loss_D: -0.0093 (0.2847) Loss_G: -0.2380 (0.1380) D(x): 0.5403 D(G(z)): 0.4792 / 0.5012 Acc: 39.0625 (31.1999)\n",
      "[9/25][663/782] Loss_D: -0.1009 (0.2847) Loss_G: -0.1585 (0.1379) D(x): 0.5519 D(G(z)): 0.4355 / 0.4697 Acc: 39.0625 (31.2009)\n",
      "[9/25][664/782] Loss_D: -0.0046 (0.2846) Loss_G: -0.1713 (0.1379) D(x): 0.5410 D(G(z)): 0.5016 / 0.4817 Acc: 42.1875 (31.2023)\n",
      "[9/25][665/782] Loss_D: 0.1252 (0.2846) Loss_G: -0.1052 (0.1379) D(x): 0.5460 D(G(z)): 0.5260 / 0.4569 Acc: 39.0625 (31.2034)\n",
      "[9/25][666/782] Loss_D: 0.1023 (0.2846) Loss_G: -0.1705 (0.1378) D(x): 0.4685 D(G(z)): 0.4197 / 0.4648 Acc: 32.8125 (31.2036)\n",
      "[9/25][667/782] Loss_D: -0.0012 (0.2846) Loss_G: -0.1701 (0.1378) D(x): 0.5425 D(G(z)): 0.4849 / 0.4655 Acc: 42.1875 (31.2050)\n",
      "[9/25][668/782] Loss_D: -0.0236 (0.2845) Loss_G: -0.1072 (0.1378) D(x): 0.5219 D(G(z)): 0.4624 / 0.4621 Acc: 42.1875 (31.2064)\n",
      "[9/25][669/782] Loss_D: 0.0093 (0.2845) Loss_G: -0.0596 (0.1377) D(x): 0.5036 D(G(z)): 0.4755 / 0.4248 Acc: 46.8750 (31.2084)\n",
      "[9/25][670/782] Loss_D: -0.0998 (0.2844) Loss_G: -0.0796 (0.1377) D(x): 0.5405 D(G(z)): 0.4546 / 0.4361 Acc: 42.1875 (31.2099)\n",
      "[9/25][671/782] Loss_D: -0.0806 (0.2844) Loss_G: -0.1465 (0.1377) D(x): 0.5534 D(G(z)): 0.4517 / 0.4627 Acc: 45.3125 (31.2117)\n",
      "[9/25][672/782] Loss_D: 0.0607 (0.2844) Loss_G: -0.1682 (0.1376) D(x): 0.4929 D(G(z)): 0.4381 / 0.4809 Acc: 32.8125 (31.2119)\n",
      "[9/25][673/782] Loss_D: -0.1281 (0.2843) Loss_G: -0.0908 (0.1376) D(x): 0.6201 D(G(z)): 0.4882 / 0.4448 Acc: 42.1875 (31.2133)\n",
      "[9/25][674/782] Loss_D: -0.1257 (0.2843) Loss_G: 0.1162 (0.1376) D(x): 0.5600 D(G(z)): 0.4202 / 0.3817 Acc: 31.2500 (31.2133)\n",
      "[9/25][675/782] Loss_D: 0.0074 (0.2842) Loss_G: 0.0287 (0.1376) D(x): 0.5019 D(G(z)): 0.4226 / 0.4060 Acc: 39.0625 (31.2144)\n",
      "[9/25][676/782] Loss_D: 0.0458 (0.2842) Loss_G: -0.0143 (0.1376) D(x): 0.4913 D(G(z)): 0.4032 / 0.4278 Acc: 31.2500 (31.2144)\n",
      "[9/25][677/782] Loss_D: -0.1321 (0.2841) Loss_G: -0.1215 (0.1375) D(x): 0.5492 D(G(z)): 0.4916 / 0.4439 Acc: 51.5625 (31.2170)\n",
      "[9/25][678/782] Loss_D: 0.0459 (0.2841) Loss_G: -0.0297 (0.1375) D(x): 0.4938 D(G(z)): 0.4617 / 0.4303 Acc: 37.5000 (31.2178)\n",
      "[9/25][679/782] Loss_D: 0.0354 (0.2841) Loss_G: -0.0345 (0.1375) D(x): 0.5105 D(G(z)): 0.4790 / 0.4276 Acc: 45.3125 (31.2196)\n",
      "[9/25][680/782] Loss_D: -0.1142 (0.2840) Loss_G: 0.0777 (0.1375) D(x): 0.5830 D(G(z)): 0.4809 / 0.3852 Acc: 48.4375 (31.2219)\n",
      "[9/25][681/782] Loss_D: 0.0011 (0.2840) Loss_G: -0.0111 (0.1375) D(x): 0.5334 D(G(z)): 0.4893 / 0.4247 Acc: 40.6250 (31.2231)\n",
      "[9/25][682/782] Loss_D: 0.0358 (0.2839) Loss_G: -0.1470 (0.1374) D(x): 0.5248 D(G(z)): 0.4784 / 0.4714 Acc: 43.7500 (31.2247)\n",
      "[9/25][683/782] Loss_D: 0.0108 (0.2839) Loss_G: -0.1633 (0.1374) D(x): 0.4673 D(G(z)): 0.4730 / 0.4570 Acc: 50.0000 (31.2271)\n",
      "[9/25][684/782] Loss_D: -0.0587 (0.2839) Loss_G: -0.0859 (0.1374) D(x): 0.5002 D(G(z)): 0.4514 / 0.4572 Acc: 46.8750 (31.2292)\n",
      "[9/25][685/782] Loss_D: -0.0797 (0.2838) Loss_G: -0.1665 (0.1373) D(x): 0.5495 D(G(z)): 0.5259 / 0.4673 Acc: 56.2500 (31.2324)\n",
      "[9/25][686/782] Loss_D: 0.0986 (0.2838) Loss_G: -0.0464 (0.1373) D(x): 0.5068 D(G(z)): 0.5088 / 0.4098 Acc: 37.5000 (31.2332)\n",
      "[9/25][687/782] Loss_D: -0.2189 (0.2837) Loss_G: -0.0019 (0.1373) D(x): 0.5341 D(G(z)): 0.4535 / 0.4052 Acc: 53.1250 (31.2360)\n",
      "[9/25][688/782] Loss_D: 0.0872 (0.2837) Loss_G: -0.0678 (0.1373) D(x): 0.4644 D(G(z)): 0.4464 / 0.4240 Acc: 39.0625 (31.2371)\n",
      "[9/25][689/782] Loss_D: 0.0289 (0.2837) Loss_G: -0.1448 (0.1372) D(x): 0.5062 D(G(z)): 0.4502 / 0.4697 Acc: 43.7500 (31.2387)\n",
      "[9/25][690/782] Loss_D: 0.0610 (0.2836) Loss_G: -0.0435 (0.1372) D(x): 0.5495 D(G(z)): 0.5038 / 0.4247 Acc: 35.9375 (31.2393)\n",
      "[9/25][691/782] Loss_D: 0.0935 (0.2836) Loss_G: -0.1402 (0.1372) D(x): 0.5148 D(G(z)): 0.4925 / 0.4620 Acc: 42.1875 (31.2407)\n",
      "[9/25][692/782] Loss_D: -0.0921 (0.2836) Loss_G: -0.1622 (0.1371) D(x): 0.5543 D(G(z)): 0.4653 / 0.4665 Acc: 37.5000 (31.2415)\n",
      "[9/25][693/782] Loss_D: 0.0342 (0.2835) Loss_G: 0.0258 (0.1371) D(x): 0.5845 D(G(z)): 0.5261 / 0.3984 Acc: 39.0625 (31.2425)\n",
      "[9/25][694/782] Loss_D: -0.0287 (0.2835) Loss_G: 0.1658 (0.1371) D(x): 0.4860 D(G(z)): 0.4425 / 0.3474 Acc: 45.3125 (31.2443)\n",
      "[9/25][695/782] Loss_D: -0.0620 (0.2835) Loss_G: 0.0065 (0.1371) D(x): 0.4743 D(G(z)): 0.4261 / 0.4005 Acc: 46.8750 (31.2464)\n",
      "[9/25][696/782] Loss_D: -0.2656 (0.2834) Loss_G: -0.1336 (0.1371) D(x): 0.5709 D(G(z)): 0.4032 / 0.4459 Acc: 42.1875 (31.2478)\n",
      "[9/25][697/782] Loss_D: -0.0790 (0.2833) Loss_G: -0.2095 (0.1370) D(x): 0.5368 D(G(z)): 0.4897 / 0.4891 Acc: 48.4375 (31.2500)\n",
      "[9/25][698/782] Loss_D: -0.1073 (0.2833) Loss_G: -0.1220 (0.1370) D(x): 0.6115 D(G(z)): 0.4907 / 0.4479 Acc: 37.5000 (31.2508)\n",
      "[9/25][699/782] Loss_D: -0.0930 (0.2832) Loss_G: -0.0887 (0.1369) D(x): 0.5321 D(G(z)): 0.4499 / 0.4335 Acc: 42.1875 (31.2522)\n",
      "[9/25][700/782] Loss_D: -0.0014 (0.2832) Loss_G: -0.1322 (0.1369) D(x): 0.5558 D(G(z)): 0.5033 / 0.4557 Acc: 37.5000 (31.2530)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/25][701/782] Loss_D: 0.1071 (0.2832) Loss_G: -0.0957 (0.1369) D(x): 0.5152 D(G(z)): 0.4963 / 0.4524 Acc: 42.1875 (31.2544)\n",
      "[9/25][702/782] Loss_D: 0.0919 (0.2832) Loss_G: -0.0710 (0.1369) D(x): 0.5093 D(G(z)): 0.4679 / 0.4238 Acc: 28.1250 (31.2540)\n",
      "[9/25][703/782] Loss_D: 0.1621 (0.2831) Loss_G: -0.2966 (0.1368) D(x): 0.4373 D(G(z)): 0.4999 / 0.5303 Acc: 53.1250 (31.2569)\n",
      "[9/25][704/782] Loss_D: 0.0553 (0.2831) Loss_G: -0.1714 (0.1368) D(x): 0.5352 D(G(z)): 0.5111 / 0.4727 Acc: 46.8750 (31.2589)\n",
      "[9/25][705/782] Loss_D: -0.0032 (0.2831) Loss_G: -0.2067 (0.1367) D(x): 0.5480 D(G(z)): 0.4972 / 0.4854 Acc: 43.7500 (31.2605)\n",
      "[9/25][706/782] Loss_D: -0.0059 (0.2830) Loss_G: -0.1681 (0.1367) D(x): 0.5257 D(G(z)): 0.4718 / 0.4711 Acc: 40.6250 (31.2617)\n",
      "[9/25][707/782] Loss_D: 0.0262 (0.2830) Loss_G: -0.0233 (0.1367) D(x): 0.5780 D(G(z)): 0.5166 / 0.4239 Acc: 37.5000 (31.2625)\n",
      "[9/25][708/782] Loss_D: -0.0650 (0.2830) Loss_G: -0.0674 (0.1366) D(x): 0.4909 D(G(z)): 0.3955 / 0.4453 Acc: 40.6250 (31.2637)\n",
      "[9/25][709/782] Loss_D: 0.0343 (0.2829) Loss_G: -0.1035 (0.1366) D(x): 0.5058 D(G(z)): 0.4332 / 0.4506 Acc: 34.3750 (31.2641)\n",
      "[9/25][710/782] Loss_D: 0.1615 (0.2829) Loss_G: -0.1865 (0.1366) D(x): 0.4977 D(G(z)): 0.4804 / 0.4741 Acc: 34.3750 (31.2645)\n",
      "[9/25][711/782] Loss_D: -0.0127 (0.2829) Loss_G: -0.1467 (0.1365) D(x): 0.5403 D(G(z)): 0.4883 / 0.4646 Acc: 39.0625 (31.2655)\n",
      "[9/25][712/782] Loss_D: -0.2543 (0.2828) Loss_G: 0.0219 (0.1365) D(x): 0.6101 D(G(z)): 0.5239 / 0.3779 Acc: 60.9375 (31.2694)\n",
      "[9/25][713/782] Loss_D: -0.1853 (0.2827) Loss_G: 0.0209 (0.1365) D(x): 0.5324 D(G(z)): 0.4028 / 0.3945 Acc: 42.1875 (31.2708)\n",
      "[9/25][714/782] Loss_D: -0.1619 (0.2827) Loss_G: -0.0457 (0.1365) D(x): 0.5126 D(G(z)): 0.3662 / 0.4299 Acc: 40.6250 (31.2720)\n",
      "[9/25][715/782] Loss_D: -0.0824 (0.2826) Loss_G: -0.1803 (0.1364) D(x): 0.5222 D(G(z)): 0.4283 / 0.4717 Acc: 39.0625 (31.2730)\n",
      "[9/25][716/782] Loss_D: -0.1349 (0.2826) Loss_G: 0.0085 (0.1364) D(x): 0.5787 D(G(z)): 0.4602 / 0.4090 Acc: 43.7500 (31.2746)\n",
      "[9/25][717/782] Loss_D: -0.0281 (0.2825) Loss_G: 0.0990 (0.1364) D(x): 0.5642 D(G(z)): 0.4859 / 0.3800 Acc: 40.6250 (31.2758)\n",
      "[9/25][718/782] Loss_D: 0.0501 (0.2825) Loss_G: -0.1432 (0.1364) D(x): 0.5247 D(G(z)): 0.4407 / 0.4808 Acc: 37.5000 (31.2766)\n",
      "[9/25][719/782] Loss_D: 0.2980 (0.2825) Loss_G: -0.2327 (0.1363) D(x): 0.5003 D(G(z)): 0.5044 / 0.4919 Acc: 25.0000 (31.2758)\n",
      "[9/25][720/782] Loss_D: 0.0324 (0.2825) Loss_G: -0.1839 (0.1363) D(x): 0.5704 D(G(z)): 0.5104 / 0.4729 Acc: 40.6250 (31.2770)\n",
      "[9/25][721/782] Loss_D: -0.0104 (0.2824) Loss_G: -0.0705 (0.1363) D(x): 0.5080 D(G(z)): 0.4564 / 0.4226 Acc: 40.6250 (31.2782)\n",
      "[9/25][722/782] Loss_D: 0.0276 (0.2824) Loss_G: -0.1092 (0.1362) D(x): 0.5288 D(G(z)): 0.4969 / 0.4611 Acc: 46.8750 (31.2802)\n",
      "[9/25][723/782] Loss_D: 0.0238 (0.2824) Loss_G: -0.0230 (0.1362) D(x): 0.5050 D(G(z)): 0.4827 / 0.4269 Acc: 42.1875 (31.2816)\n",
      "[9/25][724/782] Loss_D: 0.1176 (0.2824) Loss_G: -0.0787 (0.1362) D(x): 0.5067 D(G(z)): 0.5160 / 0.4309 Acc: 40.6250 (31.2828)\n",
      "[9/25][725/782] Loss_D: 0.3282 (0.2824) Loss_G: -0.0895 (0.1361) D(x): 0.4325 D(G(z)): 0.4946 / 0.4393 Acc: 34.3750 (31.2832)\n",
      "[9/25][726/782] Loss_D: 0.1345 (0.2823) Loss_G: -0.0477 (0.1361) D(x): 0.5129 D(G(z)): 0.5166 / 0.4217 Acc: 42.1875 (31.2846)\n",
      "[9/25][727/782] Loss_D: 0.0578 (0.2823) Loss_G: -0.0442 (0.1361) D(x): 0.4833 D(G(z)): 0.4348 / 0.4488 Acc: 42.1875 (31.2860)\n",
      "[9/25][728/782] Loss_D: 0.1242 (0.2823) Loss_G: 0.0248 (0.1361) D(x): 0.5240 D(G(z)): 0.5354 / 0.4072 Acc: 46.8750 (31.2880)\n",
      "[9/25][729/782] Loss_D: -0.1692 (0.2822) Loss_G: 0.1401 (0.1361) D(x): 0.5191 D(G(z)): 0.3929 / 0.3784 Acc: 48.4375 (31.2902)\n",
      "[9/25][730/782] Loss_D: -0.0056 (0.2822) Loss_G: -0.0610 (0.1361) D(x): 0.5265 D(G(z)): 0.4549 / 0.4441 Acc: 42.1875 (31.2916)\n",
      "[9/25][731/782] Loss_D: 0.1472 (0.2822) Loss_G: -0.1780 (0.1360) D(x): 0.4745 D(G(z)): 0.4738 / 0.4781 Acc: 40.6250 (31.2928)\n",
      "[9/25][732/782] Loss_D: 0.1322 (0.2822) Loss_G: -0.1372 (0.1360) D(x): 0.5265 D(G(z)): 0.4980 / 0.4648 Acc: 32.8125 (31.2930)\n",
      "[9/25][733/782] Loss_D: -0.2321 (0.2821) Loss_G: -0.0489 (0.1360) D(x): 0.6175 D(G(z)): 0.5004 / 0.4238 Acc: 50.0000 (31.2954)\n",
      "[9/25][734/782] Loss_D: -0.1609 (0.2820) Loss_G: -0.1267 (0.1359) D(x): 0.5887 D(G(z)): 0.4620 / 0.4571 Acc: 40.6250 (31.2966)\n",
      "[9/25][735/782] Loss_D: -0.0596 (0.2820) Loss_G: -0.0849 (0.1359) D(x): 0.5231 D(G(z)): 0.4307 / 0.4387 Acc: 39.0625 (31.2976)\n",
      "[9/25][736/782] Loss_D: -0.0806 (0.2819) Loss_G: -0.1172 (0.1359) D(x): 0.5180 D(G(z)): 0.4669 / 0.4599 Acc: 48.4375 (31.2998)\n",
      "[9/25][737/782] Loss_D: 0.1112 (0.2819) Loss_G: -0.0922 (0.1358) D(x): 0.5676 D(G(z)): 0.5498 / 0.4332 Acc: 39.0625 (31.3008)\n",
      "[9/25][738/782] Loss_D: 0.0953 (0.2819) Loss_G: -0.1550 (0.1358) D(x): 0.4922 D(G(z)): 0.4518 / 0.4734 Acc: 37.5000 (31.3016)\n",
      "[9/25][739/782] Loss_D: 0.0614 (0.2819) Loss_G: -0.0140 (0.1358) D(x): 0.4938 D(G(z)): 0.4917 / 0.4151 Acc: 43.7500 (31.3032)\n",
      "[9/25][740/782] Loss_D: 0.2746 (0.2819) Loss_G: -0.1657 (0.1357) D(x): 0.4557 D(G(z)): 0.4637 / 0.4726 Acc: 35.9375 (31.3038)\n",
      "[9/25][741/782] Loss_D: 0.0448 (0.2818) Loss_G: -0.1337 (0.1357) D(x): 0.5316 D(G(z)): 0.4878 / 0.4627 Acc: 37.5000 (31.3046)\n",
      "[9/25][742/782] Loss_D: 0.0748 (0.2818) Loss_G: -0.2510 (0.1357) D(x): 0.5500 D(G(z)): 0.5028 / 0.5060 Acc: 31.2500 (31.3046)\n",
      "[9/25][743/782] Loss_D: -0.0231 (0.2818) Loss_G: -0.0487 (0.1356) D(x): 0.5114 D(G(z)): 0.4272 / 0.4183 Acc: 32.8125 (31.3048)\n",
      "[9/25][744/782] Loss_D: -0.0733 (0.2817) Loss_G: -0.1587 (0.1356) D(x): 0.5630 D(G(z)): 0.4994 / 0.4828 Acc: 45.3125 (31.3066)\n",
      "[9/25][745/782] Loss_D: -0.1862 (0.2817) Loss_G: 0.0874 (0.1356) D(x): 0.5569 D(G(z)): 0.4576 / 0.3818 Acc: 53.1250 (31.3094)\n",
      "[9/25][746/782] Loss_D: -0.0374 (0.2816) Loss_G: -0.0590 (0.1356) D(x): 0.5104 D(G(z)): 0.4203 / 0.4481 Acc: 35.9375 (31.3100)\n",
      "[9/25][747/782] Loss_D: -0.1580 (0.2816) Loss_G: 0.0318 (0.1355) D(x): 0.6000 D(G(z)): 0.4421 / 0.4163 Acc: 39.0625 (31.3110)\n",
      "[9/25][748/782] Loss_D: -0.0203 (0.2815) Loss_G: 0.0261 (0.1355) D(x): 0.5536 D(G(z)): 0.4699 / 0.3961 Acc: 39.0625 (31.3120)\n",
      "[9/25][749/782] Loss_D: -0.1993 (0.2815) Loss_G: 0.1709 (0.1355) D(x): 0.5254 D(G(z)): 0.3874 / 0.3621 Acc: 50.0000 (31.3144)\n",
      "[9/25][750/782] Loss_D: -0.0185 (0.2814) Loss_G: -0.0480 (0.1355) D(x): 0.5138 D(G(z)): 0.4232 / 0.4309 Acc: 37.5000 (31.3152)\n",
      "[9/25][751/782] Loss_D: -0.0798 (0.2814) Loss_G: 0.0843 (0.1355) D(x): 0.5637 D(G(z)): 0.4857 / 0.3814 Acc: 43.7500 (31.3168)\n",
      "[9/25][752/782] Loss_D: -0.0551 (0.2813) Loss_G: -0.0618 (0.1355) D(x): 0.5215 D(G(z)): 0.4526 / 0.4289 Acc: 43.7500 (31.3184)\n",
      "[9/25][753/782] Loss_D: -0.2084 (0.2813) Loss_G: 0.0785 (0.1355) D(x): 0.5976 D(G(z)): 0.4143 / 0.3891 Acc: 35.9375 (31.3190)\n",
      "[9/25][754/782] Loss_D: 0.1295 (0.2813) Loss_G: -0.0341 (0.1355) D(x): 0.5347 D(G(z)): 0.4924 / 0.4310 Acc: 34.3750 (31.3194)\n",
      "[9/25][755/782] Loss_D: -0.1096 (0.2812) Loss_G: -0.0776 (0.1354) D(x): 0.5156 D(G(z)): 0.4390 / 0.4256 Acc: 46.8750 (31.3214)\n",
      "[9/25][756/782] Loss_D: -0.1907 (0.2812) Loss_G: 0.0641 (0.1354) D(x): 0.5844 D(G(z)): 0.4896 / 0.3923 Acc: 51.5625 (31.3240)\n",
      "[9/25][757/782] Loss_D: 0.2253 (0.2811) Loss_G: 0.1420 (0.1354) D(x): 0.5159 D(G(z)): 0.5258 / 0.3677 Acc: 34.3750 (31.3244)\n",
      "[9/25][758/782] Loss_D: 0.0832 (0.2811) Loss_G: -0.1320 (0.1354) D(x): 0.4053 D(G(z)): 0.3756 / 0.4683 Acc: 42.1875 (31.3258)\n",
      "[9/25][759/782] Loss_D: -0.0602 (0.2811) Loss_G: -0.1593 (0.1353) D(x): 0.5492 D(G(z)): 0.5019 / 0.4678 Acc: 42.1875 (31.3271)\n",
      "[9/25][760/782] Loss_D: 0.2460 (0.2811) Loss_G: -0.0875 (0.1353) D(x): 0.4648 D(G(z)): 0.5211 / 0.4336 Acc: 37.5000 (31.3279)\n",
      "[9/25][761/782] Loss_D: 0.2154 (0.2811) Loss_G: -0.0885 (0.1353) D(x): 0.4592 D(G(z)): 0.4424 / 0.4368 Acc: 29.6875 (31.3277)\n",
      "[9/25][762/782] Loss_D: 0.0553 (0.2810) Loss_G: -0.2759 (0.1352) D(x): 0.5557 D(G(z)): 0.4888 / 0.5249 Acc: 31.2500 (31.3277)\n",
      "[9/25][763/782] Loss_D: -0.0374 (0.2810) Loss_G: -0.1185 (0.1352) D(x): 0.5502 D(G(z)): 0.4881 / 0.4467 Acc: 42.1875 (31.3291)\n",
      "[9/25][764/782] Loss_D: 0.0297 (0.2810) Loss_G: 0.0009 (0.1352) D(x): 0.5105 D(G(z)): 0.4713 / 0.4189 Acc: 40.6250 (31.3303)\n",
      "[9/25][765/782] Loss_D: -0.0682 (0.2809) Loss_G: 0.0876 (0.1352) D(x): 0.5500 D(G(z)): 0.4471 / 0.3852 Acc: 39.0625 (31.3313)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/25][766/782] Loss_D: -0.1722 (0.2809) Loss_G: -0.0851 (0.1352) D(x): 0.5291 D(G(z)): 0.3997 / 0.4464 Acc: 42.1875 (31.3327)\n",
      "[9/25][767/782] Loss_D: -0.0050 (0.2808) Loss_G: -0.0317 (0.1351) D(x): 0.5382 D(G(z)): 0.5013 / 0.4181 Acc: 45.3125 (31.3345)\n",
      "[9/25][768/782] Loss_D: -0.1124 (0.2808) Loss_G: 0.0014 (0.1351) D(x): 0.5511 D(G(z)): 0.4612 / 0.4020 Acc: 40.6250 (31.3357)\n",
      "[9/25][769/782] Loss_D: 0.1283 (0.2808) Loss_G: -0.1522 (0.1351) D(x): 0.4727 D(G(z)): 0.4653 / 0.4588 Acc: 39.0625 (31.3366)\n",
      "[9/25][770/782] Loss_D: 0.1373 (0.2807) Loss_G: -0.0212 (0.1351) D(x): 0.5951 D(G(z)): 0.5734 / 0.4236 Acc: 42.1875 (31.3380)\n",
      "[9/25][771/782] Loss_D: -0.1006 (0.2807) Loss_G: -0.0507 (0.1350) D(x): 0.4903 D(G(z)): 0.3772 / 0.4189 Acc: 39.0625 (31.3390)\n",
      "[9/25][772/782] Loss_D: 0.0855 (0.2807) Loss_G: -0.3173 (0.1350) D(x): 0.5028 D(G(z)): 0.4673 / 0.5290 Acc: 39.0625 (31.3400)\n",
      "[9/25][773/782] Loss_D: 0.0125 (0.2806) Loss_G: -0.2517 (0.1349) D(x): 0.5291 D(G(z)): 0.4834 / 0.5130 Acc: 39.0625 (31.3410)\n",
      "[9/25][774/782] Loss_D: 0.2120 (0.2806) Loss_G: -0.3043 (0.1349) D(x): 0.5356 D(G(z)): 0.5614 / 0.5400 Acc: 37.5000 (31.3418)\n",
      "[9/25][775/782] Loss_D: 0.0901 (0.2806) Loss_G: -0.1892 (0.1348) D(x): 0.5190 D(G(z)): 0.5054 / 0.4831 Acc: 32.8125 (31.3420)\n",
      "[9/25][776/782] Loss_D: 0.0612 (0.2806) Loss_G: -0.0792 (0.1348) D(x): 0.5405 D(G(z)): 0.5464 / 0.4454 Acc: 48.4375 (31.3442)\n",
      "[9/25][777/782] Loss_D: 0.0873 (0.2805) Loss_G: -0.1402 (0.1348) D(x): 0.4850 D(G(z)): 0.4304 / 0.4569 Acc: 32.8125 (31.3444)\n",
      "[9/25][778/782] Loss_D: 0.1053 (0.2805) Loss_G: -0.1462 (0.1347) D(x): 0.4833 D(G(z)): 0.4811 / 0.4592 Acc: 39.0625 (31.3453)\n",
      "[9/25][779/782] Loss_D: 0.1528 (0.2805) Loss_G: -0.0720 (0.1347) D(x): 0.5028 D(G(z)): 0.5010 / 0.4423 Acc: 37.5000 (31.3461)\n",
      "[9/25][780/782] Loss_D: -0.0074 (0.2805) Loss_G: -0.1818 (0.1347) D(x): 0.5529 D(G(z)): 0.4741 / 0.4704 Acc: 34.3750 (31.3465)\n",
      "[9/25][781/782] Loss_D: 0.3976 (0.2805) Loss_G: 0.0714 (0.1347) D(x): 0.4366 D(G(z)): 0.4886 / 0.3920 Acc: 25.0000 (31.3457)\n",
      "[10/25][0/782] Loss_D: 0.0605 (0.2805) Loss_G: -0.1422 (0.1346) D(x): 0.5263 D(G(z)): 0.5016 / 0.4659 Acc: 37.5000 (31.3465)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[10/25][1/782] Loss_D: -0.0974 (0.2804) Loss_G: -0.1493 (0.1346) D(x): 0.5695 D(G(z)): 0.4910 / 0.4546 Acc: 45.3125 (31.3483)\n",
      "[10/25][2/782] Loss_D: 0.0749 (0.2804) Loss_G: -0.1389 (0.1345) D(x): 0.5197 D(G(z)): 0.4558 / 0.4525 Acc: 31.2500 (31.3483)\n",
      "[10/25][3/782] Loss_D: 0.1116 (0.2804) Loss_G: -0.1773 (0.1345) D(x): 0.5035 D(G(z)): 0.5063 / 0.4620 Acc: 37.5000 (31.3491)\n",
      "[10/25][4/782] Loss_D: -0.0335 (0.2803) Loss_G: -0.0962 (0.1345) D(x): 0.5777 D(G(z)): 0.4615 / 0.4322 Acc: 32.8125 (31.3492)\n",
      "[10/25][5/782] Loss_D: 0.1501 (0.2803) Loss_G: -0.0949 (0.1344) D(x): 0.5246 D(G(z)): 0.4960 / 0.4482 Acc: 32.8125 (31.3494)\n",
      "[10/25][6/782] Loss_D: -0.1335 (0.2802) Loss_G: -0.2171 (0.1344) D(x): 0.5360 D(G(z)): 0.4345 / 0.4920 Acc: 42.1875 (31.3508)\n",
      "[10/25][7/782] Loss_D: -0.1326 (0.2802) Loss_G: -0.2566 (0.1344) D(x): 0.5697 D(G(z)): 0.4419 / 0.4961 Acc: 42.1875 (31.3522)\n",
      "[10/25][8/782] Loss_D: 0.0405 (0.2802) Loss_G: -0.0421 (0.1343) D(x): 0.5373 D(G(z)): 0.4726 / 0.4211 Acc: 34.3750 (31.3526)\n",
      "[10/25][9/782] Loss_D: -0.1039 (0.2801) Loss_G: -0.0944 (0.1343) D(x): 0.5841 D(G(z)): 0.4637 / 0.4419 Acc: 35.9375 (31.3532)\n",
      "[10/25][10/782] Loss_D: -0.0362 (0.2801) Loss_G: -0.1194 (0.1343) D(x): 0.4926 D(G(z)): 0.4460 / 0.4526 Acc: 40.6250 (31.3544)\n",
      "[10/25][11/782] Loss_D: -0.0316 (0.2800) Loss_G: -0.1617 (0.1342) D(x): 0.4951 D(G(z)): 0.4300 / 0.4944 Acc: 51.5625 (31.3569)\n",
      "[10/25][12/782] Loss_D: 0.0411 (0.2800) Loss_G: -0.1020 (0.1342) D(x): 0.5787 D(G(z)): 0.5266 / 0.4503 Acc: 37.5000 (31.3577)\n",
      "[10/25][13/782] Loss_D: -0.2041 (0.2799) Loss_G: -0.0170 (0.1342) D(x): 0.5400 D(G(z)): 0.4456 / 0.4220 Acc: 48.4375 (31.3599)\n",
      "[10/25][14/782] Loss_D: 0.0251 (0.2799) Loss_G: -0.1198 (0.1342) D(x): 0.5232 D(G(z)): 0.4571 / 0.4659 Acc: 37.5000 (31.3607)\n",
      "[10/25][15/782] Loss_D: -0.0016 (0.2799) Loss_G: -0.0963 (0.1341) D(x): 0.5111 D(G(z)): 0.4819 / 0.4545 Acc: 48.4375 (31.3629)\n",
      "[10/25][16/782] Loss_D: -0.1133 (0.2798) Loss_G: -0.0296 (0.1341) D(x): 0.5484 D(G(z)): 0.4642 / 0.4299 Acc: 50.0000 (31.3652)\n",
      "[10/25][17/782] Loss_D: 0.0347 (0.2798) Loss_G: -0.0443 (0.1341) D(x): 0.5114 D(G(z)): 0.4624 / 0.4217 Acc: 39.0625 (31.3662)\n",
      "[10/25][18/782] Loss_D: -0.0071 (0.2798) Loss_G: -0.0422 (0.1341) D(x): 0.5209 D(G(z)): 0.4399 / 0.4109 Acc: 35.9375 (31.3668)\n",
      "[10/25][19/782] Loss_D: -0.0288 (0.2797) Loss_G: -0.1399 (0.1340) D(x): 0.5583 D(G(z)): 0.5310 / 0.4511 Acc: 51.5625 (31.3694)\n",
      "[10/25][20/782] Loss_D: -0.0938 (0.2797) Loss_G: -0.0613 (0.1340) D(x): 0.5738 D(G(z)): 0.5114 / 0.4173 Acc: 48.4375 (31.3716)\n",
      "[10/25][21/782] Loss_D: -0.0694 (0.2796) Loss_G: 0.2045 (0.1340) D(x): 0.5407 D(G(z)): 0.4452 / 0.3438 Acc: 37.5000 (31.3723)\n",
      "[10/25][22/782] Loss_D: -0.0063 (0.2796) Loss_G: -0.1112 (0.1340) D(x): 0.5095 D(G(z)): 0.4194 / 0.4395 Acc: 32.8125 (31.3725)\n",
      "[10/25][23/782] Loss_D: -0.0607 (0.2795) Loss_G: -0.0596 (0.1339) D(x): 0.5644 D(G(z)): 0.4825 / 0.4450 Acc: 39.0625 (31.3735)\n",
      "[10/25][24/782] Loss_D: -0.2900 (0.2795) Loss_G: -0.1889 (0.1339) D(x): 0.5965 D(G(z)): 0.4096 / 0.4663 Acc: 40.6250 (31.3747)\n",
      "[10/25][25/782] Loss_D: -0.3447 (0.2794) Loss_G: -0.1187 (0.1339) D(x): 0.5865 D(G(z)): 0.3862 / 0.4475 Acc: 43.7500 (31.3763)\n",
      "[10/25][26/782] Loss_D: -0.1315 (0.2793) Loss_G: -0.0865 (0.1338) D(x): 0.5897 D(G(z)): 0.4739 / 0.4363 Acc: 42.1875 (31.3776)\n",
      "[10/25][27/782] Loss_D: -0.0956 (0.2793) Loss_G: -0.0258 (0.1338) D(x): 0.5008 D(G(z)): 0.4209 / 0.4081 Acc: 45.3125 (31.3794)\n",
      "[10/25][28/782] Loss_D: -0.0311 (0.2793) Loss_G: -0.2122 (0.1338) D(x): 0.5046 D(G(z)): 0.4325 / 0.4929 Acc: 37.5000 (31.3802)\n",
      "[10/25][29/782] Loss_D: 0.0098 (0.2792) Loss_G: -0.1082 (0.1338) D(x): 0.5971 D(G(z)): 0.5203 / 0.4529 Acc: 35.9375 (31.3808)\n",
      "[10/25][30/782] Loss_D: -0.0429 (0.2792) Loss_G: 0.0337 (0.1337) D(x): 0.5447 D(G(z)): 0.4798 / 0.3992 Acc: 42.1875 (31.3821)\n",
      "[10/25][31/782] Loss_D: -0.1284 (0.2791) Loss_G: -0.0931 (0.1337) D(x): 0.4880 D(G(z)): 0.4333 / 0.4301 Acc: 53.1250 (31.3849)\n",
      "[10/25][32/782] Loss_D: -0.0591 (0.2791) Loss_G: -0.1201 (0.1337) D(x): 0.5260 D(G(z)): 0.4304 / 0.4510 Acc: 39.0625 (31.3859)\n",
      "[10/25][33/782] Loss_D: -0.0046 (0.2790) Loss_G: -0.0587 (0.1337) D(x): 0.5458 D(G(z)): 0.4803 / 0.4288 Acc: 39.0625 (31.3869)\n",
      "[10/25][34/782] Loss_D: 0.0349 (0.2790) Loss_G: -0.1915 (0.1336) D(x): 0.5441 D(G(z)): 0.5188 / 0.4684 Acc: 45.3125 (31.3886)\n",
      "[10/25][35/782] Loss_D: -0.0118 (0.2790) Loss_G: 0.0583 (0.1336) D(x): 0.4895 D(G(z)): 0.4359 / 0.3989 Acc: 42.1875 (31.3900)\n",
      "[10/25][36/782] Loss_D: -0.0051 (0.2789) Loss_G: -0.0885 (0.1336) D(x): 0.5451 D(G(z)): 0.4664 / 0.4388 Acc: 37.5000 (31.3908)\n",
      "[10/25][37/782] Loss_D: 0.1961 (0.2789) Loss_G: -0.0852 (0.1335) D(x): 0.5224 D(G(z)): 0.5386 / 0.4321 Acc: 37.5000 (31.3916)\n",
      "[10/25][38/782] Loss_D: -0.0271 (0.2789) Loss_G: -0.0637 (0.1335) D(x): 0.4967 D(G(z)): 0.4665 / 0.4373 Acc: 45.3125 (31.3933)\n",
      "[10/25][39/782] Loss_D: 0.0534 (0.2789) Loss_G: -0.0513 (0.1335) D(x): 0.5168 D(G(z)): 0.4560 / 0.4148 Acc: 31.2500 (31.3933)\n",
      "[10/25][40/782] Loss_D: -0.0248 (0.2788) Loss_G: -0.1048 (0.1335) D(x): 0.5337 D(G(z)): 0.4886 / 0.4491 Acc: 42.1875 (31.3947)\n",
      "[10/25][41/782] Loss_D: -0.2326 (0.2788) Loss_G: -0.1094 (0.1334) D(x): 0.5827 D(G(z)): 0.4370 / 0.4445 Acc: 46.8750 (31.3967)\n",
      "[10/25][42/782] Loss_D: 0.0915 (0.2787) Loss_G: -0.1171 (0.1334) D(x): 0.4959 D(G(z)): 0.4683 / 0.4573 Acc: 34.3750 (31.3970)\n",
      "[10/25][43/782] Loss_D: -0.1791 (0.2787) Loss_G: -0.0210 (0.1334) D(x): 0.5324 D(G(z)): 0.3752 / 0.4140 Acc: 40.6250 (31.3982)\n",
      "[10/25][44/782] Loss_D: 0.0287 (0.2786) Loss_G: -0.0892 (0.1334) D(x): 0.5520 D(G(z)): 0.5047 / 0.4443 Acc: 40.6250 (31.3994)\n",
      "[10/25][45/782] Loss_D: 0.0276 (0.2786) Loss_G: -0.0665 (0.1333) D(x): 0.5047 D(G(z)): 0.4792 / 0.4312 Acc: 40.6250 (31.4006)\n",
      "[10/25][46/782] Loss_D: 0.0491 (0.2786) Loss_G: -0.0013 (0.1333) D(x): 0.5149 D(G(z)): 0.4688 / 0.4357 Acc: 34.3750 (31.4009)\n",
      "[10/25][47/782] Loss_D: -0.0725 (0.2785) Loss_G: -0.0940 (0.1333) D(x): 0.5300 D(G(z)): 0.4261 / 0.4675 Acc: 42.1875 (31.4023)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/25][48/782] Loss_D: -0.0166 (0.2785) Loss_G: -0.1658 (0.1332) D(x): 0.5779 D(G(z)): 0.5049 / 0.4571 Acc: 43.7500 (31.4039)\n",
      "[10/25][49/782] Loss_D: 0.0447 (0.2785) Loss_G: 0.0747 (0.1332) D(x): 0.5034 D(G(z)): 0.4430 / 0.3962 Acc: 32.8125 (31.4041)\n",
      "[10/25][50/782] Loss_D: 0.0987 (0.2784) Loss_G: -0.0738 (0.1332) D(x): 0.5276 D(G(z)): 0.4960 / 0.4293 Acc: 37.5000 (31.4048)\n",
      "[10/25][51/782] Loss_D: -0.0474 (0.2784) Loss_G: -0.1015 (0.1332) D(x): 0.5157 D(G(z)): 0.4535 / 0.4459 Acc: 43.7500 (31.4064)\n",
      "[10/25][52/782] Loss_D: -0.0694 (0.2784) Loss_G: -0.0595 (0.1332) D(x): 0.5314 D(G(z)): 0.4373 / 0.4344 Acc: 34.3750 (31.4068)\n",
      "[10/25][53/782] Loss_D: -0.0467 (0.2783) Loss_G: -0.1222 (0.1331) D(x): 0.5328 D(G(z)): 0.4816 / 0.4722 Acc: 50.0000 (31.4091)\n",
      "[10/25][54/782] Loss_D: -0.0248 (0.2783) Loss_G: -0.0617 (0.1331) D(x): 0.5304 D(G(z)): 0.4482 / 0.4254 Acc: 37.5000 (31.4099)\n",
      "[10/25][55/782] Loss_D: -0.2048 (0.2782) Loss_G: -0.1209 (0.1331) D(x): 0.5866 D(G(z)): 0.4734 / 0.4438 Acc: 46.8750 (31.4119)\n",
      "[10/25][56/782] Loss_D: 0.0527 (0.2782) Loss_G: -0.0651 (0.1330) D(x): 0.5291 D(G(z)): 0.4921 / 0.4254 Acc: 37.5000 (31.4127)\n",
      "[10/25][57/782] Loss_D: -0.0476 (0.2782) Loss_G: -0.1379 (0.1330) D(x): 0.5331 D(G(z)): 0.4781 / 0.4627 Acc: 39.0625 (31.4136)\n",
      "[10/25][58/782] Loss_D: -0.0164 (0.2781) Loss_G: -0.0547 (0.1330) D(x): 0.5519 D(G(z)): 0.4925 / 0.4116 Acc: 48.4375 (31.4158)\n",
      "[10/25][59/782] Loss_D: -0.1584 (0.2781) Loss_G: -0.0080 (0.1330) D(x): 0.5252 D(G(z)): 0.4174 / 0.4149 Acc: 43.7500 (31.4174)\n",
      "[10/25][60/782] Loss_D: 0.0367 (0.2780) Loss_G: -0.2381 (0.1329) D(x): 0.4901 D(G(z)): 0.4351 / 0.4956 Acc: 35.9375 (31.4179)\n",
      "[10/25][61/782] Loss_D: -0.1273 (0.2780) Loss_G: -0.1960 (0.1329) D(x): 0.5700 D(G(z)): 0.4807 / 0.4690 Acc: 43.7500 (31.4195)\n",
      "[10/25][62/782] Loss_D: -0.0830 (0.2779) Loss_G: -0.0999 (0.1328) D(x): 0.6025 D(G(z)): 0.5009 / 0.4437 Acc: 35.9375 (31.4201)\n",
      "[10/25][63/782] Loss_D: -0.0640 (0.2779) Loss_G: -0.0846 (0.1328) D(x): 0.5513 D(G(z)): 0.4856 / 0.4412 Acc: 40.6250 (31.4212)\n",
      "[10/25][64/782] Loss_D: -0.0524 (0.2778) Loss_G: -0.1443 (0.1328) D(x): 0.5179 D(G(z)): 0.4318 / 0.4634 Acc: 37.5000 (31.4220)\n",
      "[10/25][65/782] Loss_D: 0.0352 (0.2778) Loss_G: -0.0774 (0.1328) D(x): 0.5231 D(G(z)): 0.4912 / 0.4410 Acc: 43.7500 (31.4236)\n",
      "[10/25][66/782] Loss_D: -0.0330 (0.2778) Loss_G: -0.1156 (0.1327) D(x): 0.5395 D(G(z)): 0.4987 / 0.4622 Acc: 48.4375 (31.4257)\n",
      "[10/25][67/782] Loss_D: -0.0588 (0.2777) Loss_G: -0.0472 (0.1327) D(x): 0.5465 D(G(z)): 0.4760 / 0.4327 Acc: 45.3125 (31.4275)\n",
      "[10/25][68/782] Loss_D: -0.0874 (0.2777) Loss_G: -0.0884 (0.1327) D(x): 0.5169 D(G(z)): 0.4472 / 0.4208 Acc: 42.1875 (31.4288)\n",
      "[10/25][69/782] Loss_D: 0.0741 (0.2777) Loss_G: -0.2050 (0.1326) D(x): 0.5058 D(G(z)): 0.4848 / 0.4949 Acc: 39.0625 (31.4298)\n",
      "[10/25][70/782] Loss_D: -0.1202 (0.2776) Loss_G: -0.1200 (0.1326) D(x): 0.5734 D(G(z)): 0.4876 / 0.4590 Acc: 46.8750 (31.4318)\n",
      "[10/25][71/782] Loss_D: 0.0516 (0.2776) Loss_G: -0.0673 (0.1326) D(x): 0.4775 D(G(z)): 0.4559 / 0.4311 Acc: 39.0625 (31.4327)\n",
      "[10/25][72/782] Loss_D: 0.2248 (0.2776) Loss_G: 0.0030 (0.1326) D(x): 0.4997 D(G(z)): 0.5066 / 0.4197 Acc: 32.8125 (31.4329)\n",
      "[10/25][73/782] Loss_D: -0.0943 (0.2775) Loss_G: -0.0242 (0.1325) D(x): 0.5024 D(G(z)): 0.3886 / 0.4270 Acc: 37.5000 (31.4337)\n",
      "[10/25][74/782] Loss_D: -0.1001 (0.2775) Loss_G: -0.2910 (0.1325) D(x): 0.5245 D(G(z)): 0.4455 / 0.5324 Acc: 45.3125 (31.4354)\n",
      "[10/25][75/782] Loss_D: 0.0713 (0.2775) Loss_G: -0.2074 (0.1324) D(x): 0.6014 D(G(z)): 0.5397 / 0.4983 Acc: 32.8125 (31.4356)\n",
      "[10/25][76/782] Loss_D: 0.0085 (0.2774) Loss_G: -0.1019 (0.1324) D(x): 0.5118 D(G(z)): 0.4515 / 0.4372 Acc: 37.5000 (31.4364)\n",
      "[10/25][77/782] Loss_D: 0.0443 (0.2774) Loss_G: -0.0577 (0.1324) D(x): 0.5203 D(G(z)): 0.4696 / 0.4365 Acc: 37.5000 (31.4372)\n",
      "[10/25][78/782] Loss_D: -0.0512 (0.2773) Loss_G: -0.1297 (0.1324) D(x): 0.4864 D(G(z)): 0.4249 / 0.4541 Acc: 42.1875 (31.4385)\n",
      "[10/25][79/782] Loss_D: -0.0456 (0.2773) Loss_G: -0.2366 (0.1323) D(x): 0.5105 D(G(z)): 0.4865 / 0.5054 Acc: 48.4375 (31.4407)\n",
      "[10/25][80/782] Loss_D: 0.1248 (0.2773) Loss_G: -0.2020 (0.1323) D(x): 0.5291 D(G(z)): 0.5452 / 0.5047 Acc: 43.7500 (31.4422)\n",
      "[10/25][81/782] Loss_D: -0.2657 (0.2772) Loss_G: -0.0813 (0.1322) D(x): 0.6151 D(G(z)): 0.4799 / 0.4274 Acc: 50.0000 (31.4446)\n",
      "[10/25][82/782] Loss_D: 0.1922 (0.2772) Loss_G: -0.1486 (0.1322) D(x): 0.4898 D(G(z)): 0.5054 / 0.4557 Acc: 39.0625 (31.4455)\n",
      "[10/25][83/782] Loss_D: -0.0988 (0.2772) Loss_G: -0.1475 (0.1322) D(x): 0.4861 D(G(z)): 0.4335 / 0.4577 Acc: 48.4375 (31.4477)\n",
      "[10/25][84/782] Loss_D: 0.1208 (0.2771) Loss_G: -0.1738 (0.1321) D(x): 0.5138 D(G(z)): 0.4598 / 0.4875 Acc: 32.8125 (31.4479)\n",
      "[10/25][85/782] Loss_D: -0.0444 (0.2771) Loss_G: -0.0899 (0.1321) D(x): 0.5689 D(G(z)): 0.5048 / 0.4508 Acc: 46.8750 (31.4498)\n",
      "[10/25][86/782] Loss_D: 0.1932 (0.2771) Loss_G: -0.1782 (0.1321) D(x): 0.4903 D(G(z)): 0.4817 / 0.4787 Acc: 31.2500 (31.4498)\n",
      "[10/25][87/782] Loss_D: 0.0507 (0.2771) Loss_G: -0.0978 (0.1320) D(x): 0.5076 D(G(z)): 0.4384 / 0.4476 Acc: 32.8125 (31.4500)\n",
      "[10/25][88/782] Loss_D: -0.1157 (0.2770) Loss_G: -0.2269 (0.1320) D(x): 0.5274 D(G(z)): 0.4705 / 0.4896 Acc: 51.5625 (31.4525)\n",
      "[10/25][89/782] Loss_D: 0.2427 (0.2770) Loss_G: -0.1536 (0.1320) D(x): 0.5136 D(G(z)): 0.5382 / 0.4766 Acc: 32.8125 (31.4527)\n",
      "[10/25][90/782] Loss_D: -0.0070 (0.2770) Loss_G: -0.0404 (0.1319) D(x): 0.5434 D(G(z)): 0.4706 / 0.4242 Acc: 39.0625 (31.4536)\n",
      "[10/25][91/782] Loss_D: 0.0227 (0.2769) Loss_G: -0.1154 (0.1319) D(x): 0.5114 D(G(z)): 0.4968 / 0.4426 Acc: 46.8750 (31.4556)\n",
      "[10/25][92/782] Loss_D: 0.0142 (0.2769) Loss_G: -0.1632 (0.1319) D(x): 0.5248 D(G(z)): 0.4750 / 0.4796 Acc: 46.8750 (31.4575)\n",
      "[10/25][93/782] Loss_D: 0.1141 (0.2769) Loss_G: -0.2088 (0.1318) D(x): 0.5313 D(G(z)): 0.5077 / 0.4886 Acc: 34.3750 (31.4579)\n",
      "[10/25][94/782] Loss_D: -0.0686 (0.2768) Loss_G: 0.0012 (0.1318) D(x): 0.5512 D(G(z)): 0.4716 / 0.4332 Acc: 43.7500 (31.4595)\n",
      "[10/25][95/782] Loss_D: -0.0651 (0.2768) Loss_G: -0.0046 (0.1318) D(x): 0.5250 D(G(z)): 0.4546 / 0.4114 Acc: 43.7500 (31.4610)\n",
      "[10/25][96/782] Loss_D: -0.0114 (0.2768) Loss_G: -0.1191 (0.1318) D(x): 0.4891 D(G(z)): 0.4578 / 0.4622 Acc: 45.3125 (31.4628)\n",
      "[10/25][97/782] Loss_D: -0.1617 (0.2767) Loss_G: -0.1981 (0.1317) D(x): 0.5205 D(G(z)): 0.4518 / 0.4780 Acc: 53.1250 (31.4655)\n",
      "[10/25][98/782] Loss_D: -0.0267 (0.2767) Loss_G: -0.2866 (0.1317) D(x): 0.5240 D(G(z)): 0.4751 / 0.5232 Acc: 48.4375 (31.4676)\n",
      "[10/25][99/782] Loss_D: -0.1454 (0.2766) Loss_G: -0.0763 (0.1316) D(x): 0.5885 D(G(z)): 0.5219 / 0.4257 Acc: 48.4375 (31.4698)\n",
      "[10/25][100/782] Loss_D: 0.1221 (0.2766) Loss_G: -0.1179 (0.1316) D(x): 0.4985 D(G(z)): 0.4813 / 0.4392 Acc: 37.5000 (31.4705)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[10/25][101/782] Loss_D: -0.0148 (0.2766) Loss_G: -0.0191 (0.1316) D(x): 0.4839 D(G(z)): 0.4443 / 0.4245 Acc: 42.1875 (31.4719)\n",
      "[10/25][102/782] Loss_D: 0.1733 (0.2765) Loss_G: -0.0520 (0.1316) D(x): 0.5017 D(G(z)): 0.5193 / 0.4186 Acc: 39.0625 (31.4728)\n",
      "[10/25][103/782] Loss_D: -0.0431 (0.2765) Loss_G: -0.1105 (0.1315) D(x): 0.5212 D(G(z)): 0.4887 / 0.4430 Acc: 48.4375 (31.4750)\n",
      "[10/25][104/782] Loss_D: -0.0161 (0.2765) Loss_G: -0.0498 (0.1315) D(x): 0.4810 D(G(z)): 0.4617 / 0.4321 Acc: 50.0000 (31.4773)\n",
      "[10/25][105/782] Loss_D: -0.0451 (0.2764) Loss_G: -0.1669 (0.1315) D(x): 0.5098 D(G(z)): 0.4620 / 0.4733 Acc: 48.4375 (31.4795)\n",
      "[10/25][106/782] Loss_D: -0.1144 (0.2764) Loss_G: -0.1219 (0.1314) D(x): 0.5271 D(G(z)): 0.4684 / 0.4410 Acc: 53.1250 (31.4822)\n",
      "[10/25][107/782] Loss_D: -0.0499 (0.2763) Loss_G: -0.2131 (0.1314) D(x): 0.5697 D(G(z)): 0.5005 / 0.4850 Acc: 40.6250 (31.4834)\n",
      "[10/25][108/782] Loss_D: 0.0016 (0.2763) Loss_G: 0.0579 (0.1314) D(x): 0.5275 D(G(z)): 0.4895 / 0.3940 Acc: 40.6250 (31.4845)\n",
      "[10/25][109/782] Loss_D: -0.0251 (0.2763) Loss_G: -0.0990 (0.1314) D(x): 0.4814 D(G(z)): 0.4403 / 0.4461 Acc: 45.3125 (31.4862)\n",
      "[10/25][110/782] Loss_D: -0.1919 (0.2762) Loss_G: -0.0882 (0.1313) D(x): 0.5693 D(G(z)): 0.4096 / 0.4369 Acc: 42.1875 (31.4876)\n",
      "[10/25][111/782] Loss_D: -0.2230 (0.2761) Loss_G: -0.1408 (0.1313) D(x): 0.5351 D(G(z)): 0.4235 / 0.4553 Acc: 48.4375 (31.4897)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/25][112/782] Loss_D: -0.0069 (0.2761) Loss_G: -0.0837 (0.1313) D(x): 0.5331 D(G(z)): 0.4654 / 0.4355 Acc: 37.5000 (31.4905)\n",
      "[10/25][113/782] Loss_D: -0.1938 (0.2760) Loss_G: -0.1495 (0.1312) D(x): 0.5561 D(G(z)): 0.4416 / 0.4751 Acc: 51.5625 (31.4930)\n",
      "[10/25][114/782] Loss_D: -0.2071 (0.2760) Loss_G: -0.1138 (0.1312) D(x): 0.5456 D(G(z)): 0.4215 / 0.4517 Acc: 46.8750 (31.4950)\n",
      "[10/25][115/782] Loss_D: 0.0350 (0.2760) Loss_G: -0.1899 (0.1312) D(x): 0.5171 D(G(z)): 0.4701 / 0.4760 Acc: 34.3750 (31.4953)\n",
      "[10/25][116/782] Loss_D: 0.1626 (0.2759) Loss_G: -0.1040 (0.1311) D(x): 0.5460 D(G(z)): 0.5377 / 0.4433 Acc: 35.9375 (31.4959)\n",
      "[10/25][117/782] Loss_D: 0.0272 (0.2759) Loss_G: -0.0849 (0.1311) D(x): 0.5536 D(G(z)): 0.5343 / 0.4385 Acc: 42.1875 (31.4972)\n",
      "[10/25][118/782] Loss_D: -0.0118 (0.2759) Loss_G: 0.1030 (0.1311) D(x): 0.5141 D(G(z)): 0.4659 / 0.3818 Acc: 40.6250 (31.4984)\n",
      "[10/25][119/782] Loss_D: -0.1233 (0.2758) Loss_G: -0.0526 (0.1311) D(x): 0.4693 D(G(z)): 0.3905 / 0.4272 Acc: 50.0000 (31.5007)\n",
      "[10/25][120/782] Loss_D: -0.0221 (0.2758) Loss_G: -0.1512 (0.1310) D(x): 0.5201 D(G(z)): 0.4448 / 0.4632 Acc: 35.9375 (31.5013)\n",
      "[10/25][121/782] Loss_D: -0.0383 (0.2757) Loss_G: -0.1531 (0.1310) D(x): 0.5603 D(G(z)): 0.5154 / 0.4531 Acc: 46.8750 (31.5032)\n",
      "[10/25][122/782] Loss_D: -0.0174 (0.2757) Loss_G: -0.1046 (0.1310) D(x): 0.5241 D(G(z)): 0.4890 / 0.4446 Acc: 45.3125 (31.5049)\n",
      "[10/25][123/782] Loss_D: 0.3089 (0.2757) Loss_G: -0.1929 (0.1309) D(x): 0.4682 D(G(z)): 0.4968 / 0.4711 Acc: 26.5625 (31.5043)\n",
      "[10/25][124/782] Loss_D: 0.0340 (0.2757) Loss_G: -0.0614 (0.1309) D(x): 0.5420 D(G(z)): 0.4938 / 0.4615 Acc: 42.1875 (31.5057)\n",
      "[10/25][125/782] Loss_D: -0.3246 (0.2756) Loss_G: -0.1222 (0.1309) D(x): 0.5610 D(G(z)): 0.4765 / 0.4654 Acc: 65.6250 (31.5100)\n",
      "[10/25][126/782] Loss_D: 0.1327 (0.2756) Loss_G: -0.2127 (0.1308) D(x): 0.4696 D(G(z)): 0.4742 / 0.5011 Acc: 40.6250 (31.5111)\n",
      "[10/25][127/782] Loss_D: 0.0278 (0.2756) Loss_G: -0.1919 (0.1308) D(x): 0.4834 D(G(z)): 0.4647 / 0.4843 Acc: 46.8750 (31.5130)\n",
      "[10/25][128/782] Loss_D: -0.0503 (0.2755) Loss_G: -0.0490 (0.1308) D(x): 0.5766 D(G(z)): 0.4936 / 0.4364 Acc: 42.1875 (31.5144)\n",
      "[10/25][129/782] Loss_D: 0.0640 (0.2755) Loss_G: -0.2949 (0.1307) D(x): 0.4863 D(G(z)): 0.4558 / 0.5356 Acc: 40.6250 (31.5155)\n",
      "[10/25][130/782] Loss_D: 0.0888 (0.2755) Loss_G: -0.2636 (0.1307) D(x): 0.4735 D(G(z)): 0.4821 / 0.5251 Acc: 43.7500 (31.5171)\n",
      "[10/25][131/782] Loss_D: -0.1962 (0.2754) Loss_G: -0.1440 (0.1306) D(x): 0.6109 D(G(z)): 0.5035 / 0.4595 Acc: 48.4375 (31.5192)\n",
      "[10/25][132/782] Loss_D: -0.0791 (0.2754) Loss_G: -0.0361 (0.1306) D(x): 0.5534 D(G(z)): 0.4919 / 0.4428 Acc: 50.0000 (31.5215)\n",
      "[10/25][133/782] Loss_D: 0.0365 (0.2753) Loss_G: -0.0207 (0.1306) D(x): 0.5093 D(G(z)): 0.4372 / 0.4071 Acc: 32.8125 (31.5217)\n",
      "[10/25][134/782] Loss_D: -0.0595 (0.2753) Loss_G: -0.1920 (0.1306) D(x): 0.5306 D(G(z)): 0.4577 / 0.4934 Acc: 42.1875 (31.5230)\n",
      "[10/25][135/782] Loss_D: -0.1332 (0.2752) Loss_G: -0.1473 (0.1305) D(x): 0.5796 D(G(z)): 0.4807 / 0.4632 Acc: 46.8750 (31.5249)\n",
      "[10/25][136/782] Loss_D: -0.0466 (0.2752) Loss_G: -0.0682 (0.1305) D(x): 0.4998 D(G(z)): 0.4877 / 0.4176 Acc: 53.1250 (31.5277)\n",
      "[10/25][137/782] Loss_D: 0.0226 (0.2752) Loss_G: 0.0195 (0.1305) D(x): 0.5279 D(G(z)): 0.5032 / 0.4106 Acc: 48.4375 (31.5298)\n",
      "[10/25][138/782] Loss_D: -0.0568 (0.2751) Loss_G: -0.0873 (0.1305) D(x): 0.5649 D(G(z)): 0.5259 / 0.4346 Acc: 53.1250 (31.5325)\n",
      "[10/25][139/782] Loss_D: -0.0500 (0.2751) Loss_G: -0.0834 (0.1304) D(x): 0.4963 D(G(z)): 0.4460 / 0.4391 Acc: 46.8750 (31.5344)\n",
      "[10/25][140/782] Loss_D: -0.0582 (0.2750) Loss_G: -0.1913 (0.1304) D(x): 0.4778 D(G(z)): 0.4326 / 0.4899 Acc: 50.0000 (31.5367)\n",
      "[10/25][141/782] Loss_D: -0.1548 (0.2750) Loss_G: -0.0822 (0.1304) D(x): 0.5900 D(G(z)): 0.4395 / 0.4604 Acc: 35.9375 (31.5373)\n",
      "[10/25][142/782] Loss_D: -0.2532 (0.2749) Loss_G: -0.1057 (0.1303) D(x): 0.5485 D(G(z)): 0.4484 / 0.4555 Acc: 60.9375 (31.5410)\n",
      "[10/25][143/782] Loss_D: -0.0985 (0.2749) Loss_G: -0.1114 (0.1303) D(x): 0.5763 D(G(z)): 0.4692 / 0.4476 Acc: 42.1875 (31.5423)\n",
      "[10/25][144/782] Loss_D: 0.0147 (0.2748) Loss_G: 0.0712 (0.1303) D(x): 0.5381 D(G(z)): 0.4974 / 0.3983 Acc: 43.7500 (31.5439)\n",
      "[10/25][145/782] Loss_D: -0.1592 (0.2748) Loss_G: -0.0284 (0.1303) D(x): 0.5471 D(G(z)): 0.4369 / 0.4194 Acc: 43.7500 (31.5454)\n",
      "[10/25][146/782] Loss_D: -0.0570 (0.2747) Loss_G: 0.0541 (0.1303) D(x): 0.5274 D(G(z)): 0.4809 / 0.3856 Acc: 46.8750 (31.5473)\n",
      "[10/25][147/782] Loss_D: 0.0930 (0.2747) Loss_G: -0.1223 (0.1302) D(x): 0.4913 D(G(z)): 0.4598 / 0.4601 Acc: 34.3750 (31.5477)\n",
      "[10/25][148/782] Loss_D: -0.0453 (0.2747) Loss_G: -0.0863 (0.1302) D(x): 0.5421 D(G(z)): 0.4588 / 0.4569 Acc: 40.6250 (31.5488)\n",
      "[10/25][149/782] Loss_D: -0.2985 (0.2746) Loss_G: -0.0630 (0.1302) D(x): 0.6384 D(G(z)): 0.4392 / 0.4288 Acc: 42.1875 (31.5501)\n",
      "[10/25][150/782] Loss_D: -0.1970 (0.2746) Loss_G: -0.0742 (0.1302) D(x): 0.5673 D(G(z)): 0.4525 / 0.4313 Acc: 48.4375 (31.5523)\n",
      "[10/25][151/782] Loss_D: -0.2038 (0.2745) Loss_G: 0.0116 (0.1301) D(x): 0.5640 D(G(z)): 0.4209 / 0.4235 Acc: 40.6250 (31.5534)\n",
      "[10/25][152/782] Loss_D: 0.0645 (0.2745) Loss_G: -0.1575 (0.1301) D(x): 0.4787 D(G(z)): 0.4634 / 0.4775 Acc: 43.7500 (31.5549)\n",
      "[10/25][153/782] Loss_D: -0.0464 (0.2744) Loss_G: -0.2439 (0.1301) D(x): 0.5345 D(G(z)): 0.4828 / 0.5055 Acc: 43.7500 (31.5565)\n",
      "[10/25][154/782] Loss_D: -0.1628 (0.2744) Loss_G: -0.1705 (0.1300) D(x): 0.5116 D(G(z)): 0.4337 / 0.4631 Acc: 48.4375 (31.5586)\n",
      "[10/25][155/782] Loss_D: 0.2589 (0.2744) Loss_G: -0.1254 (0.1300) D(x): 0.5401 D(G(z)): 0.5481 / 0.4695 Acc: 31.2500 (31.5585)\n",
      "[10/25][156/782] Loss_D: -0.1465 (0.2743) Loss_G: -0.0800 (0.1300) D(x): 0.5499 D(G(z)): 0.4357 / 0.4293 Acc: 40.6250 (31.5597)\n",
      "[10/25][157/782] Loss_D: -0.0535 (0.2743) Loss_G: -0.1141 (0.1299) D(x): 0.5510 D(G(z)): 0.4754 / 0.4534 Acc: 42.1875 (31.5610)\n",
      "[10/25][158/782] Loss_D: -0.0429 (0.2742) Loss_G: -0.2145 (0.1299) D(x): 0.5505 D(G(z)): 0.4779 / 0.4913 Acc: 42.1875 (31.5623)\n",
      "[10/25][159/782] Loss_D: 0.1603 (0.2742) Loss_G: -0.0805 (0.1299) D(x): 0.5456 D(G(z)): 0.5169 / 0.4395 Acc: 29.6875 (31.5621)\n",
      "[10/25][160/782] Loss_D: -0.1042 (0.2742) Loss_G: -0.0616 (0.1298) D(x): 0.5044 D(G(z)): 0.3783 / 0.4212 Acc: 35.9375 (31.5627)\n",
      "[10/25][161/782] Loss_D: 0.1347 (0.2742) Loss_G: -0.0984 (0.1298) D(x): 0.4979 D(G(z)): 0.5149 / 0.4655 Acc: 45.3125 (31.5644)\n",
      "[10/25][162/782] Loss_D: 0.0110 (0.2741) Loss_G: -0.1446 (0.1298) D(x): 0.5053 D(G(z)): 0.4811 / 0.4722 Acc: 46.8750 (31.5663)\n",
      "[10/25][163/782] Loss_D: 0.0834 (0.2741) Loss_G: -0.1044 (0.1297) D(x): 0.5194 D(G(z)): 0.4804 / 0.4557 Acc: 34.3750 (31.5666)\n",
      "[10/25][164/782] Loss_D: -0.0913 (0.2741) Loss_G: -0.0468 (0.1297) D(x): 0.5404 D(G(z)): 0.4767 / 0.4457 Acc: 50.0000 (31.5690)\n",
      "[10/25][165/782] Loss_D: -0.1373 (0.2740) Loss_G: -0.1372 (0.1297) D(x): 0.4888 D(G(z)): 0.4466 / 0.4682 Acc: 59.3750 (31.5724)\n",
      "[10/25][166/782] Loss_D: 0.0527 (0.2740) Loss_G: -0.1764 (0.1296) D(x): 0.4637 D(G(z)): 0.4576 / 0.4756 Acc: 53.1250 (31.5751)\n",
      "[10/25][167/782] Loss_D: -0.0136 (0.2739) Loss_G: 0.0233 (0.1296) D(x): 0.5551 D(G(z)): 0.4785 / 0.4032 Acc: 37.5000 (31.5759)\n",
      "[10/25][168/782] Loss_D: 0.0699 (0.2739) Loss_G: -0.0197 (0.1296) D(x): 0.5092 D(G(z)): 0.5045 / 0.4206 Acc: 45.3125 (31.5776)\n",
      "[10/25][169/782] Loss_D: -0.1015 (0.2739) Loss_G: -0.2314 (0.1296) D(x): 0.4834 D(G(z)): 0.4293 / 0.5017 Acc: 50.0000 (31.5799)\n",
      "[10/25][170/782] Loss_D: -0.1828 (0.2738) Loss_G: -0.2671 (0.1295) D(x): 0.5727 D(G(z)): 0.4535 / 0.5093 Acc: 43.7500 (31.5814)\n",
      "[10/25][171/782] Loss_D: 0.0598 (0.2738) Loss_G: -0.2103 (0.1295) D(x): 0.5472 D(G(z)): 0.5048 / 0.4870 Acc: 37.5000 (31.5822)\n",
      "[10/25][172/782] Loss_D: -0.0957 (0.2737) Loss_G: -0.0937 (0.1295) D(x): 0.5112 D(G(z)): 0.4613 / 0.4700 Acc: 54.6875 (31.5851)\n",
      "[10/25][173/782] Loss_D: -0.0785 (0.2737) Loss_G: -0.0899 (0.1294) D(x): 0.4989 D(G(z)): 0.4514 / 0.4375 Acc: 48.4375 (31.5872)\n",
      "[10/25][174/782] Loss_D: -0.0561 (0.2737) Loss_G: -0.0487 (0.1294) D(x): 0.5311 D(G(z)): 0.4783 / 0.4310 Acc: 48.4375 (31.5893)\n",
      "[10/25][175/782] Loss_D: 0.0054 (0.2736) Loss_G: -0.1266 (0.1294) D(x): 0.5642 D(G(z)): 0.4917 / 0.4686 Acc: 37.5000 (31.5900)\n",
      "[10/25][176/782] Loss_D: -0.0893 (0.2736) Loss_G: -0.0184 (0.1294) D(x): 0.5841 D(G(z)): 0.5069 / 0.4080 Acc: 46.8750 (31.5919)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/25][177/782] Loss_D: -0.1737 (0.2735) Loss_G: 0.0596 (0.1293) D(x): 0.5221 D(G(z)): 0.4316 / 0.3857 Acc: 50.0000 (31.5942)\n",
      "[10/25][178/782] Loss_D: -0.1608 (0.2735) Loss_G: -0.1073 (0.1293) D(x): 0.4989 D(G(z)): 0.3910 / 0.4419 Acc: 48.4375 (31.5963)\n",
      "[10/25][179/782] Loss_D: 0.0076 (0.2734) Loss_G: -0.0737 (0.1293) D(x): 0.5332 D(G(z)): 0.4612 / 0.4369 Acc: 35.9375 (31.5969)\n",
      "[10/25][180/782] Loss_D: -0.1245 (0.2734) Loss_G: -0.0920 (0.1293) D(x): 0.5619 D(G(z)): 0.4409 / 0.4404 Acc: 37.5000 (31.5976)\n",
      "[10/25][181/782] Loss_D: 0.1957 (0.2734) Loss_G: -0.1205 (0.1292) D(x): 0.5102 D(G(z)): 0.5283 / 0.4477 Acc: 35.9375 (31.5982)\n",
      "[10/25][182/782] Loss_D: -0.1584 (0.2733) Loss_G: -0.0181 (0.1292) D(x): 0.5949 D(G(z)): 0.4806 / 0.4275 Acc: 42.1875 (31.5995)\n",
      "[10/25][183/782] Loss_D: -0.0650 (0.2733) Loss_G: -0.0722 (0.1292) D(x): 0.6037 D(G(z)): 0.4845 / 0.4311 Acc: 37.5000 (31.6002)\n",
      "[10/25][184/782] Loss_D: 0.0243 (0.2732) Loss_G: 0.0205 (0.1292) D(x): 0.5048 D(G(z)): 0.4203 / 0.4057 Acc: 37.5000 (31.6010)\n",
      "[10/25][185/782] Loss_D: -0.1128 (0.2732) Loss_G: -0.0326 (0.1292) D(x): 0.4897 D(G(z)): 0.3857 / 0.4278 Acc: 45.3125 (31.6027)\n",
      "[10/25][186/782] Loss_D: 0.1128 (0.2732) Loss_G: -0.1687 (0.1291) D(x): 0.4769 D(G(z)): 0.4785 / 0.4555 Acc: 35.9375 (31.6032)\n",
      "[10/25][187/782] Loss_D: -0.0652 (0.2731) Loss_G: -0.1123 (0.1291) D(x): 0.5648 D(G(z)): 0.5004 / 0.4427 Acc: 42.1875 (31.6045)\n",
      "[10/25][188/782] Loss_D: -0.1007 (0.2731) Loss_G: -0.0809 (0.1291) D(x): 0.6052 D(G(z)): 0.4739 / 0.4331 Acc: 31.2500 (31.6045)\n",
      "[10/25][189/782] Loss_D: 0.0352 (0.2731) Loss_G: -0.0863 (0.1290) D(x): 0.4973 D(G(z)): 0.4460 / 0.4222 Acc: 37.5000 (31.6052)\n",
      "[10/25][190/782] Loss_D: -0.0724 (0.2730) Loss_G: -0.1064 (0.1290) D(x): 0.5208 D(G(z)): 0.4355 / 0.4314 Acc: 39.0625 (31.6062)\n",
      "[10/25][191/782] Loss_D: -0.1134 (0.2730) Loss_G: -0.1471 (0.1290) D(x): 0.5347 D(G(z)): 0.4607 / 0.4610 Acc: 48.4375 (31.6083)\n",
      "[10/25][192/782] Loss_D: -0.0134 (0.2729) Loss_G: 0.0529 (0.1290) D(x): 0.5977 D(G(z)): 0.4904 / 0.3970 Acc: 32.8125 (31.6084)\n",
      "[10/25][193/782] Loss_D: -0.1235 (0.2729) Loss_G: -0.0666 (0.1289) D(x): 0.5414 D(G(z)): 0.4513 / 0.4208 Acc: 42.1875 (31.6097)\n",
      "[10/25][194/782] Loss_D: -0.1591 (0.2728) Loss_G: 0.0268 (0.1289) D(x): 0.5301 D(G(z)): 0.4072 / 0.3955 Acc: 37.5000 (31.6105)\n",
      "[10/25][195/782] Loss_D: -0.0601 (0.2728) Loss_G: -0.1809 (0.1289) D(x): 0.5207 D(G(z)): 0.4546 / 0.4711 Acc: 43.7500 (31.6120)\n",
      "[10/25][196/782] Loss_D: 0.0292 (0.2728) Loss_G: -0.0627 (0.1289) D(x): 0.5554 D(G(z)): 0.4627 / 0.4439 Acc: 31.2500 (31.6119)\n",
      "[10/25][197/782] Loss_D: -0.1859 (0.2727) Loss_G: -0.0916 (0.1288) D(x): 0.5926 D(G(z)): 0.4528 / 0.4485 Acc: 40.6250 (31.6131)\n",
      "[10/25][198/782] Loss_D: 0.2231 (0.2727) Loss_G: -0.1085 (0.1288) D(x): 0.5011 D(G(z)): 0.5265 / 0.4488 Acc: 35.9375 (31.6136)\n",
      "[10/25][199/782] Loss_D: 0.1169 (0.2727) Loss_G: -0.1602 (0.1288) D(x): 0.4926 D(G(z)): 0.4859 / 0.4600 Acc: 35.9375 (31.6141)\n",
      "[10/25][200/782] Loss_D: 0.1414 (0.2727) Loss_G: -0.1682 (0.1287) D(x): 0.4676 D(G(z)): 0.5070 / 0.4787 Acc: 45.3125 (31.6158)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[10/25][201/782] Loss_D: -0.0063 (0.2726) Loss_G: -0.1661 (0.1287) D(x): 0.5172 D(G(z)): 0.4948 / 0.4738 Acc: 43.7500 (31.6173)\n",
      "[10/25][202/782] Loss_D: 0.0124 (0.2726) Loss_G: -0.2012 (0.1287) D(x): 0.5157 D(G(z)): 0.4669 / 0.4776 Acc: 40.6250 (31.6185)\n",
      "[10/25][203/782] Loss_D: -0.0984 (0.2725) Loss_G: -0.2228 (0.1286) D(x): 0.5539 D(G(z)): 0.5142 / 0.4869 Acc: 51.5625 (31.6210)\n",
      "[10/25][204/782] Loss_D: 0.0781 (0.2725) Loss_G: -0.1204 (0.1286) D(x): 0.5079 D(G(z)): 0.5058 / 0.4420 Acc: 42.1875 (31.6223)\n",
      "[10/25][205/782] Loss_D: 0.0914 (0.2725) Loss_G: -0.1943 (0.1285) D(x): 0.5171 D(G(z)): 0.5287 / 0.4845 Acc: 43.7500 (31.6238)\n",
      "[10/25][206/782] Loss_D: -0.0587 (0.2725) Loss_G: -0.1056 (0.1285) D(x): 0.4908 D(G(z)): 0.4490 / 0.4402 Acc: 46.8750 (31.6257)\n",
      "[10/25][207/782] Loss_D: -0.0582 (0.2724) Loss_G: -0.1611 (0.1285) D(x): 0.4952 D(G(z)): 0.4523 / 0.4679 Acc: 51.5625 (31.6282)\n",
      "[10/25][208/782] Loss_D: -0.0818 (0.2724) Loss_G: -0.1460 (0.1284) D(x): 0.5365 D(G(z)): 0.4893 / 0.4442 Acc: 50.0000 (31.6305)\n",
      "[10/25][209/782] Loss_D: 0.0565 (0.2723) Loss_G: -0.0843 (0.1284) D(x): 0.5424 D(G(z)): 0.5020 / 0.4385 Acc: 34.3750 (31.6308)\n",
      "[10/25][210/782] Loss_D: -0.1022 (0.2723) Loss_G: -0.0544 (0.1284) D(x): 0.5657 D(G(z)): 0.4547 / 0.4148 Acc: 34.3750 (31.6311)\n",
      "[10/25][211/782] Loss_D: -0.1282 (0.2722) Loss_G: -0.2477 (0.1283) D(x): 0.5355 D(G(z)): 0.4194 / 0.4999 Acc: 39.0625 (31.6321)\n",
      "[10/25][212/782] Loss_D: -0.1221 (0.2722) Loss_G: -0.0458 (0.1283) D(x): 0.5166 D(G(z)): 0.4453 / 0.4206 Acc: 48.4375 (31.6342)\n",
      "[10/25][213/782] Loss_D: 0.0905 (0.2722) Loss_G: -0.2344 (0.1283) D(x): 0.5458 D(G(z)): 0.5343 / 0.5088 Acc: 42.1875 (31.6355)\n",
      "[10/25][214/782] Loss_D: -0.0131 (0.2721) Loss_G: -0.1256 (0.1282) D(x): 0.5396 D(G(z)): 0.4929 / 0.4467 Acc: 39.0625 (31.6364)\n",
      "[10/25][215/782] Loss_D: 0.0313 (0.2721) Loss_G: 0.0305 (0.1282) D(x): 0.4632 D(G(z)): 0.4121 / 0.3963 Acc: 40.6250 (31.6375)\n",
      "[10/25][216/782] Loss_D: 0.0770 (0.2721) Loss_G: -0.1330 (0.1282) D(x): 0.5164 D(G(z)): 0.5263 / 0.4497 Acc: 43.7500 (31.6390)\n",
      "[10/25][217/782] Loss_D: -0.2089 (0.2720) Loss_G: -0.1630 (0.1282) D(x): 0.5440 D(G(z)): 0.4327 / 0.4617 Acc: 46.8750 (31.6409)\n",
      "[10/25][218/782] Loss_D: -0.1976 (0.2720) Loss_G: -0.1786 (0.1281) D(x): 0.5624 D(G(z)): 0.4559 / 0.4640 Acc: 46.8750 (31.6428)\n",
      "[10/25][219/782] Loss_D: -0.0663 (0.2719) Loss_G: -0.0493 (0.1281) D(x): 0.5255 D(G(z)): 0.4718 / 0.4350 Acc: 46.8750 (31.6447)\n",
      "[10/25][220/782] Loss_D: 0.0164 (0.2719) Loss_G: -0.1616 (0.1281) D(x): 0.5000 D(G(z)): 0.4653 / 0.4625 Acc: 40.6250 (31.6458)\n",
      "[10/25][221/782] Loss_D: 0.0240 (0.2719) Loss_G: 0.0429 (0.1281) D(x): 0.5583 D(G(z)): 0.4766 / 0.4103 Acc: 34.3750 (31.6462)\n",
      "[10/25][222/782] Loss_D: -0.2144 (0.2718) Loss_G: -0.1694 (0.1280) D(x): 0.5522 D(G(z)): 0.4436 / 0.4727 Acc: 48.4375 (31.6483)\n",
      "[10/25][223/782] Loss_D: -0.0264 (0.2718) Loss_G: -0.0142 (0.1280) D(x): 0.5239 D(G(z)): 0.4735 / 0.4150 Acc: 42.1875 (31.6496)\n",
      "[10/25][224/782] Loss_D: -0.0438 (0.2717) Loss_G: -0.1568 (0.1280) D(x): 0.5228 D(G(z)): 0.4606 / 0.4627 Acc: 42.1875 (31.6509)\n",
      "[10/25][225/782] Loss_D: -0.2219 (0.2717) Loss_G: -0.1003 (0.1279) D(x): 0.5399 D(G(z)): 0.4230 / 0.4445 Acc: 48.4375 (31.6530)\n",
      "[10/25][226/782] Loss_D: -0.2086 (0.2716) Loss_G: -0.0808 (0.1279) D(x): 0.5370 D(G(z)): 0.4445 / 0.4328 Acc: 46.8750 (31.6548)\n",
      "[10/25][227/782] Loss_D: -0.2753 (0.2715) Loss_G: -0.1435 (0.1279) D(x): 0.5533 D(G(z)): 0.4645 / 0.4509 Acc: 62.5000 (31.6587)\n",
      "[10/25][228/782] Loss_D: -0.1812 (0.2715) Loss_G: -0.0631 (0.1279) D(x): 0.5350 D(G(z)): 0.4400 / 0.4296 Acc: 48.4375 (31.6608)\n",
      "[10/25][229/782] Loss_D: -0.1068 (0.2714) Loss_G: -0.1605 (0.1278) D(x): 0.5539 D(G(z)): 0.4422 / 0.4566 Acc: 37.5000 (31.6615)\n",
      "[10/25][230/782] Loss_D: -0.1126 (0.2714) Loss_G: -0.1621 (0.1278) D(x): 0.5423 D(G(z)): 0.4595 / 0.4666 Acc: 45.3125 (31.6632)\n",
      "[10/25][231/782] Loss_D: -0.1170 (0.2713) Loss_G: -0.0473 (0.1278) D(x): 0.5328 D(G(z)): 0.4214 / 0.4449 Acc: 40.6250 (31.6643)\n",
      "[10/25][232/782] Loss_D: -0.1113 (0.2713) Loss_G: -0.1476 (0.1277) D(x): 0.5162 D(G(z)): 0.4418 / 0.4603 Acc: 45.3125 (31.6660)\n",
      "[10/25][233/782] Loss_D: 0.0066 (0.2713) Loss_G: -0.1046 (0.1277) D(x): 0.6000 D(G(z)): 0.5237 / 0.4532 Acc: 34.3750 (31.6663)\n",
      "[10/25][234/782] Loss_D: -0.0717 (0.2712) Loss_G: -0.1497 (0.1277) D(x): 0.5292 D(G(z)): 0.3999 / 0.4742 Acc: 37.5000 (31.6671)\n",
      "[10/25][235/782] Loss_D: -0.1167 (0.2712) Loss_G: -0.0581 (0.1276) D(x): 0.5346 D(G(z)): 0.4432 / 0.4345 Acc: 40.6250 (31.6682)\n",
      "[10/25][236/782] Loss_D: -0.1611 (0.2711) Loss_G: -0.2632 (0.1276) D(x): 0.5250 D(G(z)): 0.4546 / 0.4969 Acc: 50.0000 (31.6704)\n",
      "[10/25][237/782] Loss_D: -0.0472 (0.2711) Loss_G: -0.2395 (0.1275) D(x): 0.5578 D(G(z)): 0.4973 / 0.5022 Acc: 39.0625 (31.6714)\n",
      "[10/25][238/782] Loss_D: -0.0620 (0.2710) Loss_G: -0.1240 (0.1275) D(x): 0.5425 D(G(z)): 0.4658 / 0.4520 Acc: 45.3125 (31.6731)\n",
      "[10/25][239/782] Loss_D: -0.1570 (0.2710) Loss_G: -0.0057 (0.1275) D(x): 0.5716 D(G(z)): 0.4490 / 0.4087 Acc: 35.9375 (31.6736)\n",
      "[10/25][240/782] Loss_D: 0.0921 (0.2710) Loss_G: -0.0315 (0.1275) D(x): 0.4726 D(G(z)): 0.4627 / 0.4132 Acc: 40.6250 (31.6747)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/25][241/782] Loss_D: 0.0366 (0.2709) Loss_G: -0.1945 (0.1274) D(x): 0.4769 D(G(z)): 0.4311 / 0.4789 Acc: 39.0625 (31.6756)\n",
      "[10/25][242/782] Loss_D: 0.0666 (0.2709) Loss_G: -0.2456 (0.1274) D(x): 0.5453 D(G(z)): 0.5110 / 0.5026 Acc: 37.5000 (31.6763)\n",
      "[10/25][243/782] Loss_D: -0.1065 (0.2709) Loss_G: -0.1686 (0.1274) D(x): 0.5613 D(G(z)): 0.4893 / 0.4586 Acc: 46.8750 (31.6782)\n",
      "[10/25][244/782] Loss_D: -0.2494 (0.2708) Loss_G: -0.1355 (0.1273) D(x): 0.5632 D(G(z)): 0.4120 / 0.4613 Acc: 43.7500 (31.6797)\n",
      "[10/25][245/782] Loss_D: -0.1443 (0.2707) Loss_G: -0.1476 (0.1273) D(x): 0.5236 D(G(z)): 0.4136 / 0.4509 Acc: 42.1875 (31.6810)\n",
      "[10/25][246/782] Loss_D: 0.1392 (0.2707) Loss_G: -0.2429 (0.1272) D(x): 0.4788 D(G(z)): 0.5152 / 0.4965 Acc: 43.7500 (31.6825)\n",
      "[10/25][247/782] Loss_D: -0.0350 (0.2707) Loss_G: -0.1429 (0.1272) D(x): 0.5299 D(G(z)): 0.4756 / 0.4501 Acc: 35.9375 (31.6830)\n",
      "[10/25][248/782] Loss_D: 0.0306 (0.2707) Loss_G: -0.1276 (0.1272) D(x): 0.5555 D(G(z)): 0.5083 / 0.4629 Acc: 40.6250 (31.6841)\n",
      "[10/25][249/782] Loss_D: 0.1013 (0.2706) Loss_G: -0.1222 (0.1271) D(x): 0.5167 D(G(z)): 0.5260 / 0.4578 Acc: 43.7500 (31.6856)\n",
      "[10/25][250/782] Loss_D: -0.1497 (0.2706) Loss_G: -0.1118 (0.1271) D(x): 0.5622 D(G(z)): 0.4942 / 0.4450 Acc: 53.1250 (31.6883)\n",
      "[10/25][251/782] Loss_D: -0.1324 (0.2705) Loss_G: -0.0074 (0.1271) D(x): 0.4933 D(G(z)): 0.4082 / 0.4084 Acc: 46.8750 (31.6902)\n",
      "[10/25][252/782] Loss_D: 0.0063 (0.2705) Loss_G: -0.1873 (0.1271) D(x): 0.4871 D(G(z)): 0.4335 / 0.4931 Acc: 42.1875 (31.6915)\n",
      "[10/25][253/782] Loss_D: -0.0995 (0.2705) Loss_G: -0.1919 (0.1270) D(x): 0.5337 D(G(z)): 0.4543 / 0.4751 Acc: 42.1875 (31.6928)\n",
      "[10/25][254/782] Loss_D: -0.0378 (0.2704) Loss_G: -0.1188 (0.1270) D(x): 0.6271 D(G(z)): 0.5134 / 0.4628 Acc: 37.5000 (31.6935)\n",
      "[10/25][255/782] Loss_D: -0.0977 (0.2704) Loss_G: -0.0984 (0.1270) D(x): 0.5469 D(G(z)): 0.4719 / 0.4491 Acc: 40.6250 (31.6946)\n",
      "[10/25][256/782] Loss_D: 0.0712 (0.2703) Loss_G: -0.1495 (0.1269) D(x): 0.5112 D(G(z)): 0.4528 / 0.4572 Acc: 34.3750 (31.6949)\n",
      "[10/25][257/782] Loss_D: -0.1122 (0.2703) Loss_G: -0.0743 (0.1269) D(x): 0.5128 D(G(z)): 0.4751 / 0.4317 Acc: 54.6875 (31.6978)\n",
      "[10/25][258/782] Loss_D: -0.0667 (0.2703) Loss_G: -0.0764 (0.1269) D(x): 0.5210 D(G(z)): 0.4890 / 0.4569 Acc: 51.5625 (31.7002)\n",
      "[10/25][259/782] Loss_D: 0.0607 (0.2702) Loss_G: -0.1161 (0.1268) D(x): 0.5034 D(G(z)): 0.4559 / 0.4445 Acc: 37.5000 (31.7010)\n",
      "[10/25][260/782] Loss_D: 0.1106 (0.2702) Loss_G: -0.2017 (0.1268) D(x): 0.4709 D(G(z)): 0.4846 / 0.4792 Acc: 43.7500 (31.7025)\n",
      "[10/25][261/782] Loss_D: -0.1287 (0.2702) Loss_G: -0.0173 (0.1268) D(x): 0.6222 D(G(z)): 0.4947 / 0.4098 Acc: 35.9375 (31.7030)\n",
      "[10/25][262/782] Loss_D: 0.2487 (0.2702) Loss_G: -0.0648 (0.1268) D(x): 0.4430 D(G(z)): 0.4698 / 0.4356 Acc: 35.9375 (31.7035)\n",
      "[10/25][263/782] Loss_D: -0.0799 (0.2701) Loss_G: -0.1832 (0.1267) D(x): 0.5317 D(G(z)): 0.4563 / 0.5019 Acc: 46.8750 (31.7054)\n",
      "[10/25][264/782] Loss_D: 0.0428 (0.2701) Loss_G: -0.1286 (0.1267) D(x): 0.4910 D(G(z)): 0.4639 / 0.4717 Acc: 40.6250 (31.7065)\n",
      "[10/25][265/782] Loss_D: -0.1028 (0.2700) Loss_G: -0.3095 (0.1266) D(x): 0.5725 D(G(z)): 0.5026 / 0.5330 Acc: 45.3125 (31.7082)\n",
      "[10/25][266/782] Loss_D: -0.1611 (0.2700) Loss_G: -0.0292 (0.1266) D(x): 0.5460 D(G(z)): 0.4561 / 0.4317 Acc: 53.1250 (31.7108)\n",
      "[10/25][267/782] Loss_D: 0.0384 (0.2700) Loss_G: -0.1983 (0.1266) D(x): 0.5296 D(G(z)): 0.4965 / 0.4809 Acc: 45.3125 (31.7125)\n",
      "[10/25][268/782] Loss_D: -0.0489 (0.2699) Loss_G: -0.1235 (0.1266) D(x): 0.5397 D(G(z)): 0.4519 / 0.4463 Acc: 40.6250 (31.7136)\n",
      "[10/25][269/782] Loss_D: 0.1749 (0.2699) Loss_G: -0.0905 (0.1265) D(x): 0.4736 D(G(z)): 0.4726 / 0.4321 Acc: 32.8125 (31.7137)\n",
      "[10/25][270/782] Loss_D: 0.0074 (0.2699) Loss_G: -0.2315 (0.1265) D(x): 0.4802 D(G(z)): 0.4860 / 0.4914 Acc: 53.1250 (31.7164)\n",
      "[10/25][271/782] Loss_D: 0.0759 (0.2699) Loss_G: -0.3245 (0.1264) D(x): 0.5069 D(G(z)): 0.5186 / 0.5461 Acc: 45.3125 (31.7181)\n",
      "[10/25][272/782] Loss_D: -0.0244 (0.2698) Loss_G: -0.2233 (0.1264) D(x): 0.5540 D(G(z)): 0.5085 / 0.4855 Acc: 40.6250 (31.7192)\n",
      "[10/25][273/782] Loss_D: -0.0582 (0.2698) Loss_G: -0.1243 (0.1264) D(x): 0.5240 D(G(z)): 0.4716 / 0.4330 Acc: 43.7500 (31.7206)\n",
      "[10/25][274/782] Loss_D: 0.0410 (0.2697) Loss_G: -0.2235 (0.1263) D(x): 0.5377 D(G(z)): 0.4629 / 0.4871 Acc: 35.9375 (31.7212)\n",
      "[10/25][275/782] Loss_D: -0.0768 (0.2697) Loss_G: -0.1339 (0.1263) D(x): 0.5001 D(G(z)): 0.4189 / 0.4484 Acc: 42.1875 (31.7225)\n",
      "[10/25][276/782] Loss_D: 0.0890 (0.2697) Loss_G: -0.2977 (0.1262) D(x): 0.4958 D(G(z)): 0.4811 / 0.5254 Acc: 39.0625 (31.7234)\n",
      "[10/25][277/782] Loss_D: -0.0190 (0.2696) Loss_G: -0.1649 (0.1262) D(x): 0.6013 D(G(z)): 0.5420 / 0.4487 Acc: 39.0625 (31.7243)\n",
      "[10/25][278/782] Loss_D: 0.0512 (0.2696) Loss_G: -0.1198 (0.1262) D(x): 0.4876 D(G(z)): 0.4678 / 0.4519 Acc: 42.1875 (31.7256)\n",
      "[10/25][279/782] Loss_D: 0.1150 (0.2696) Loss_G: -0.0743 (0.1261) D(x): 0.5004 D(G(z)): 0.4666 / 0.4459 Acc: 34.3750 (31.7259)\n",
      "[10/25][280/782] Loss_D: -0.1443 (0.2695) Loss_G: -0.1009 (0.1261) D(x): 0.5381 D(G(z)): 0.4239 / 0.4291 Acc: 37.5000 (31.7266)\n",
      "[10/25][281/782] Loss_D: -0.0299 (0.2695) Loss_G: -0.1479 (0.1261) D(x): 0.5092 D(G(z)): 0.4766 / 0.4604 Acc: 42.1875 (31.7279)\n",
      "[10/25][282/782] Loss_D: -0.0680 (0.2695) Loss_G: -0.1735 (0.1260) D(x): 0.5332 D(G(z)): 0.4771 / 0.4735 Acc: 46.8750 (31.7298)\n",
      "[10/25][283/782] Loss_D: -0.1066 (0.2694) Loss_G: -0.0352 (0.1260) D(x): 0.6019 D(G(z)): 0.5094 / 0.4174 Acc: 43.7500 (31.7312)\n",
      "[10/25][284/782] Loss_D: 0.0949 (0.2694) Loss_G: -0.0243 (0.1260) D(x): 0.5001 D(G(z)): 0.5073 / 0.4292 Acc: 46.8750 (31.7331)\n",
      "[10/25][285/782] Loss_D: -0.1804 (0.2693) Loss_G: -0.0813 (0.1260) D(x): 0.5416 D(G(z)): 0.4489 / 0.4245 Acc: 48.4375 (31.7352)\n",
      "[10/25][286/782] Loss_D: -0.0076 (0.2693) Loss_G: -0.0219 (0.1260) D(x): 0.4884 D(G(z)): 0.4443 / 0.4099 Acc: 42.1875 (31.7365)\n",
      "[10/25][287/782] Loss_D: -0.2613 (0.2692) Loss_G: -0.0868 (0.1259) D(x): 0.5521 D(G(z)): 0.4267 / 0.4442 Acc: 51.5625 (31.7389)\n",
      "[10/25][288/782] Loss_D: -0.0041 (0.2692) Loss_G: -0.0819 (0.1259) D(x): 0.5227 D(G(z)): 0.4819 / 0.4288 Acc: 43.7500 (31.7404)\n",
      "[10/25][289/782] Loss_D: 0.0131 (0.2692) Loss_G: -0.1855 (0.1259) D(x): 0.5497 D(G(z)): 0.4847 / 0.4718 Acc: 34.3750 (31.7407)\n",
      "[10/25][290/782] Loss_D: -0.0949 (0.2691) Loss_G: -0.1960 (0.1258) D(x): 0.5461 D(G(z)): 0.4828 / 0.4730 Acc: 45.3125 (31.7424)\n",
      "[10/25][291/782] Loss_D: 0.0104 (0.2691) Loss_G: -0.1047 (0.1258) D(x): 0.5397 D(G(z)): 0.5043 / 0.4480 Acc: 45.3125 (31.7441)\n",
      "[10/25][292/782] Loss_D: -0.1254 (0.2691) Loss_G: -0.0684 (0.1258) D(x): 0.5248 D(G(z)): 0.4877 / 0.4433 Acc: 56.2500 (31.7471)\n",
      "[10/25][293/782] Loss_D: 0.0908 (0.2690) Loss_G: -0.0517 (0.1257) D(x): 0.4709 D(G(z)): 0.4620 / 0.4310 Acc: 48.4375 (31.7491)\n",
      "[10/25][294/782] Loss_D: -0.1934 (0.2690) Loss_G: -0.1986 (0.1257) D(x): 0.5476 D(G(z)): 0.4307 / 0.4790 Acc: 45.3125 (31.7508)\n",
      "[10/25][295/782] Loss_D: 0.0745 (0.2690) Loss_G: -0.1196 (0.1257) D(x): 0.5454 D(G(z)): 0.5270 / 0.4646 Acc: 43.7500 (31.7523)\n",
      "[10/25][296/782] Loss_D: 0.1007 (0.2689) Loss_G: -0.0993 (0.1256) D(x): 0.5193 D(G(z)): 0.5041 / 0.4375 Acc: 35.9375 (31.7528)\n",
      "[10/25][297/782] Loss_D: -0.0621 (0.2689) Loss_G: -0.0339 (0.1256) D(x): 0.5035 D(G(z)): 0.4785 / 0.4133 Acc: 48.4375 (31.7549)\n",
      "[10/25][298/782] Loss_D: -0.0733 (0.2688) Loss_G: -0.1080 (0.1256) D(x): 0.4772 D(G(z)): 0.4318 / 0.4493 Acc: 51.5625 (31.7573)\n",
      "[10/25][299/782] Loss_D: 0.0055 (0.2688) Loss_G: -0.2596 (0.1256) D(x): 0.4973 D(G(z)): 0.4853 / 0.4993 Acc: 46.8750 (31.7592)\n",
      "[10/25][300/782] Loss_D: -0.0118 (0.2688) Loss_G: -0.1498 (0.1255) D(x): 0.5328 D(G(z)): 0.4948 / 0.4483 Acc: 40.6250 (31.7603)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[10/25][301/782] Loss_D: -0.1483 (0.2687) Loss_G: -0.0886 (0.1255) D(x): 0.5773 D(G(z)): 0.4583 / 0.4309 Acc: 39.0625 (31.7612)\n",
      "[10/25][302/782] Loss_D: -0.0338 (0.2687) Loss_G: -0.0531 (0.1255) D(x): 0.5234 D(G(z)): 0.4965 / 0.4248 Acc: 50.0000 (31.7634)\n",
      "[10/25][303/782] Loss_D: -0.0458 (0.2687) Loss_G: -0.1334 (0.1254) D(x): 0.5183 D(G(z)): 0.4166 / 0.4533 Acc: 37.5000 (31.7641)\n",
      "[10/25][304/782] Loss_D: 0.1273 (0.2686) Loss_G: -0.2345 (0.1254) D(x): 0.5027 D(G(z)): 0.4686 / 0.4970 Acc: 28.1250 (31.7637)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/25][305/782] Loss_D: 0.0144 (0.2686) Loss_G: -0.1295 (0.1254) D(x): 0.5259 D(G(z)): 0.4771 / 0.4471 Acc: 37.5000 (31.7644)\n",
      "[10/25][306/782] Loss_D: 0.0741 (0.2686) Loss_G: -0.1493 (0.1253) D(x): 0.5247 D(G(z)): 0.4902 / 0.4747 Acc: 37.5000 (31.7651)\n",
      "[10/25][307/782] Loss_D: 0.0071 (0.2685) Loss_G: -0.2386 (0.1253) D(x): 0.5196 D(G(z)): 0.4864 / 0.5060 Acc: 48.4375 (31.7671)\n",
      "[10/25][308/782] Loss_D: 0.0185 (0.2685) Loss_G: -0.0059 (0.1253) D(x): 0.5815 D(G(z)): 0.5384 / 0.4013 Acc: 39.0625 (31.7680)\n",
      "[10/25][309/782] Loss_D: -0.0998 (0.2685) Loss_G: -0.0520 (0.1252) D(x): 0.5113 D(G(z)): 0.4466 / 0.4365 Acc: 48.4375 (31.7701)\n",
      "[10/25][310/782] Loss_D: 0.0595 (0.2684) Loss_G: -0.0568 (0.1252) D(x): 0.4876 D(G(z)): 0.4493 / 0.4294 Acc: 34.3750 (31.7704)\n",
      "[10/25][311/782] Loss_D: 0.0423 (0.2684) Loss_G: -0.1142 (0.1252) D(x): 0.4898 D(G(z)): 0.4135 / 0.4552 Acc: 37.5000 (31.7711)\n",
      "[10/25][312/782] Loss_D: 0.1126 (0.2684) Loss_G: -0.2152 (0.1252) D(x): 0.5517 D(G(z)): 0.5328 / 0.4852 Acc: 35.9375 (31.7716)\n",
      "[10/25][313/782] Loss_D: 0.0516 (0.2684) Loss_G: -0.1587 (0.1251) D(x): 0.5237 D(G(z)): 0.4994 / 0.4702 Acc: 42.1875 (31.7729)\n",
      "[10/25][314/782] Loss_D: -0.0434 (0.2683) Loss_G: -0.0625 (0.1251) D(x): 0.5592 D(G(z)): 0.4765 / 0.4276 Acc: 39.0625 (31.7738)\n",
      "[10/25][315/782] Loss_D: -0.1498 (0.2683) Loss_G: -0.1506 (0.1251) D(x): 0.4939 D(G(z)): 0.4137 / 0.4553 Acc: 45.3125 (31.7754)\n",
      "[10/25][316/782] Loss_D: -0.1507 (0.2682) Loss_G: -0.2182 (0.1250) D(x): 0.5539 D(G(z)): 0.4598 / 0.4825 Acc: 43.7500 (31.7769)\n",
      "[10/25][317/782] Loss_D: -0.1394 (0.2682) Loss_G: -0.0511 (0.1250) D(x): 0.5651 D(G(z)): 0.4654 / 0.4247 Acc: 42.1875 (31.7782)\n",
      "[10/25][318/782] Loss_D: -0.3455 (0.2681) Loss_G: -0.1029 (0.1250) D(x): 0.5762 D(G(z)): 0.4123 / 0.4394 Acc: 50.0000 (31.7804)\n",
      "[10/25][319/782] Loss_D: -0.1915 (0.2681) Loss_G: -0.1178 (0.1249) D(x): 0.5392 D(G(z)): 0.4585 / 0.4433 Acc: 50.0000 (31.7827)\n",
      "[10/25][320/782] Loss_D: -0.0475 (0.2680) Loss_G: -0.0310 (0.1249) D(x): 0.5315 D(G(z)): 0.4472 / 0.4037 Acc: 37.5000 (31.7834)\n",
      "[10/25][321/782] Loss_D: -0.0482 (0.2680) Loss_G: -0.0719 (0.1249) D(x): 0.5063 D(G(z)): 0.4388 / 0.4375 Acc: 43.7500 (31.7848)\n",
      "[10/25][322/782] Loss_D: 0.1532 (0.2680) Loss_G: -0.2069 (0.1249) D(x): 0.4626 D(G(z)): 0.4772 / 0.5066 Acc: 35.9375 (31.7854)\n",
      "[10/25][323/782] Loss_D: -0.0231 (0.2679) Loss_G: -0.2489 (0.1248) D(x): 0.5492 D(G(z)): 0.5101 / 0.5046 Acc: 42.1875 (31.7866)\n",
      "[10/25][324/782] Loss_D: -0.1667 (0.2679) Loss_G: -0.1708 (0.1248) D(x): 0.5509 D(G(z)): 0.4532 / 0.4772 Acc: 46.8750 (31.7885)\n",
      "[10/25][325/782] Loss_D: -0.1968 (0.2678) Loss_G: -0.0243 (0.1248) D(x): 0.5808 D(G(z)): 0.4683 / 0.4241 Acc: 50.0000 (31.7907)\n",
      "[10/25][326/782] Loss_D: 0.0731 (0.2678) Loss_G: 0.0650 (0.1247) D(x): 0.4975 D(G(z)): 0.5035 / 0.3775 Acc: 42.1875 (31.7920)\n",
      "[10/25][327/782] Loss_D: -0.0183 (0.2678) Loss_G: -0.0133 (0.1247) D(x): 0.4833 D(G(z)): 0.4034 / 0.4260 Acc: 42.1875 (31.7933)\n",
      "[10/25][328/782] Loss_D: -0.0513 (0.2677) Loss_G: -0.2308 (0.1247) D(x): 0.5321 D(G(z)): 0.4959 / 0.4934 Acc: 46.8750 (31.7951)\n",
      "[10/25][329/782] Loss_D: -0.1355 (0.2677) Loss_G: -0.1320 (0.1247) D(x): 0.5786 D(G(z)): 0.5072 / 0.4476 Acc: 48.4375 (31.7972)\n",
      "[10/25][330/782] Loss_D: 0.0803 (0.2676) Loss_G: 0.0325 (0.1246) D(x): 0.5283 D(G(z)): 0.4723 / 0.3911 Acc: 32.8125 (31.7973)\n",
      "[10/25][331/782] Loss_D: -0.1071 (0.2676) Loss_G: -0.2046 (0.1246) D(x): 0.5307 D(G(z)): 0.4516 / 0.4782 Acc: 43.7500 (31.7988)\n",
      "[10/25][332/782] Loss_D: 0.1706 (0.2676) Loss_G: -0.0892 (0.1246) D(x): 0.4664 D(G(z)): 0.4650 / 0.4378 Acc: 35.9375 (31.7993)\n",
      "[10/25][333/782] Loss_D: -0.1506 (0.2675) Loss_G: -0.1969 (0.1245) D(x): 0.5286 D(G(z)): 0.4719 / 0.4744 Acc: 53.1250 (31.8019)\n",
      "[10/25][334/782] Loss_D: -0.0034 (0.2675) Loss_G: -0.1673 (0.1245) D(x): 0.5702 D(G(z)): 0.5318 / 0.4618 Acc: 43.7500 (31.8033)\n",
      "[10/25][335/782] Loss_D: -0.0103 (0.2675) Loss_G: -0.0064 (0.1245) D(x): 0.5224 D(G(z)): 0.5025 / 0.4158 Acc: 50.0000 (31.8056)\n",
      "[10/25][336/782] Loss_D: -0.0866 (0.2674) Loss_G: -0.1922 (0.1244) D(x): 0.4980 D(G(z)): 0.4443 / 0.4815 Acc: 51.5625 (31.8080)\n",
      "[10/25][337/782] Loss_D: 0.1301 (0.2674) Loss_G: -0.0911 (0.1244) D(x): 0.5217 D(G(z)): 0.4718 / 0.4336 Acc: 26.5625 (31.8074)\n",
      "[10/25][338/782] Loss_D: -0.1732 (0.2674) Loss_G: 0.0009 (0.1244) D(x): 0.5398 D(G(z)): 0.4668 / 0.4173 Acc: 54.6875 (31.8102)\n",
      "[10/25][339/782] Loss_D: -0.1464 (0.2673) Loss_G: -0.1811 (0.1244) D(x): 0.5384 D(G(z)): 0.4380 / 0.4676 Acc: 40.6250 (31.8112)\n",
      "[10/25][340/782] Loss_D: 0.1095 (0.2673) Loss_G: -0.3050 (0.1243) D(x): 0.4947 D(G(z)): 0.4975 / 0.5285 Acc: 42.1875 (31.8125)\n",
      "[10/25][341/782] Loss_D: -0.0607 (0.2672) Loss_G: -0.2329 (0.1243) D(x): 0.5579 D(G(z)): 0.4789 / 0.4839 Acc: 37.5000 (31.8132)\n",
      "[10/25][342/782] Loss_D: -0.0714 (0.2672) Loss_G: -0.1311 (0.1242) D(x): 0.5559 D(G(z)): 0.4939 / 0.4500 Acc: 50.0000 (31.8154)\n",
      "[10/25][343/782] Loss_D: -0.0942 (0.2672) Loss_G: -0.1561 (0.1242) D(x): 0.5266 D(G(z)): 0.4367 / 0.4608 Acc: 40.6250 (31.8165)\n",
      "[10/25][344/782] Loss_D: -0.1087 (0.2671) Loss_G: -0.0560 (0.1242) D(x): 0.5133 D(G(z)): 0.4599 / 0.4202 Acc: 48.4375 (31.8185)\n",
      "[10/25][345/782] Loss_D: -0.0408 (0.2671) Loss_G: -0.1873 (0.1241) D(x): 0.5722 D(G(z)): 0.4775 / 0.4702 Acc: 32.8125 (31.8187)\n",
      "[10/25][346/782] Loss_D: 0.1533 (0.2671) Loss_G: -0.1826 (0.1241) D(x): 0.4834 D(G(z)): 0.5097 / 0.4883 Acc: 40.6250 (31.8197)\n",
      "[10/25][347/782] Loss_D: -0.2876 (0.2670) Loss_G: -0.1184 (0.1241) D(x): 0.5481 D(G(z)): 0.4410 / 0.4493 Acc: 54.6875 (31.8225)\n",
      "[10/25][348/782] Loss_D: -0.0291 (0.2670) Loss_G: -0.1346 (0.1240) D(x): 0.5132 D(G(z)): 0.4702 / 0.4555 Acc: 45.3125 (31.8242)\n",
      "[10/25][349/782] Loss_D: -0.0211 (0.2669) Loss_G: -0.1871 (0.1240) D(x): 0.4972 D(G(z)): 0.4610 / 0.4670 Acc: 46.8750 (31.8260)\n",
      "[10/25][350/782] Loss_D: 0.0890 (0.2669) Loss_G: -0.1835 (0.1240) D(x): 0.5276 D(G(z)): 0.5031 / 0.4957 Acc: 34.3750 (31.8264)\n",
      "[10/25][351/782] Loss_D: -0.1288 (0.2668) Loss_G: -0.2152 (0.1239) D(x): 0.5621 D(G(z)): 0.5011 / 0.4853 Acc: 50.0000 (31.8286)\n",
      "[10/25][352/782] Loss_D: -0.0876 (0.2668) Loss_G: 0.0020 (0.1239) D(x): 0.5356 D(G(z)): 0.4711 / 0.4123 Acc: 45.3125 (31.8302)\n",
      "[10/25][353/782] Loss_D: -0.0389 (0.2668) Loss_G: -0.2400 (0.1239) D(x): 0.5068 D(G(z)): 0.4617 / 0.4948 Acc: 43.7500 (31.8317)\n",
      "[10/25][354/782] Loss_D: 0.0586 (0.2667) Loss_G: -0.2844 (0.1238) D(x): 0.4924 D(G(z)): 0.4546 / 0.5171 Acc: 32.8125 (31.8318)\n",
      "[10/25][355/782] Loss_D: 0.0521 (0.2667) Loss_G: -0.1915 (0.1238) D(x): 0.5386 D(G(z)): 0.5107 / 0.4768 Acc: 42.1875 (31.8331)\n",
      "[10/25][356/782] Loss_D: -0.0263 (0.2667) Loss_G: -0.0160 (0.1238) D(x): 0.5655 D(G(z)): 0.5211 / 0.3989 Acc: 40.6250 (31.8341)\n",
      "[10/25][357/782] Loss_D: -0.1137 (0.2666) Loss_G: -0.0305 (0.1237) D(x): 0.5387 D(G(z)): 0.4694 / 0.4037 Acc: 45.3125 (31.8358)\n",
      "[10/25][358/782] Loss_D: -0.1609 (0.2666) Loss_G: 0.1083 (0.1237) D(x): 0.4852 D(G(z)): 0.4005 / 0.3711 Acc: 50.0000 (31.8380)\n",
      "[10/25][359/782] Loss_D: -0.0241 (0.2665) Loss_G: -0.0356 (0.1237) D(x): 0.5344 D(G(z)): 0.4628 / 0.4258 Acc: 39.0625 (31.8389)\n",
      "[10/25][360/782] Loss_D: 0.0104 (0.2665) Loss_G: -0.0737 (0.1237) D(x): 0.4999 D(G(z)): 0.4630 / 0.4280 Acc: 39.0625 (31.8398)\n",
      "[10/25][361/782] Loss_D: -0.0276 (0.2665) Loss_G: -0.1883 (0.1237) D(x): 0.5568 D(G(z)): 0.5085 / 0.4769 Acc: 45.3125 (31.8414)\n",
      "[10/25][362/782] Loss_D: 0.0013 (0.2664) Loss_G: -0.0842 (0.1236) D(x): 0.4895 D(G(z)): 0.4576 / 0.4233 Acc: 43.7500 (31.8429)\n",
      "[10/25][363/782] Loss_D: -0.1519 (0.2664) Loss_G: -0.0562 (0.1236) D(x): 0.5312 D(G(z)): 0.4328 / 0.4468 Acc: 48.4375 (31.8449)\n",
      "[10/25][364/782] Loss_D: 0.0907 (0.2664) Loss_G: -0.1416 (0.1236) D(x): 0.5200 D(G(z)): 0.4775 / 0.4562 Acc: 34.3750 (31.8452)\n",
      "[10/25][365/782] Loss_D: 0.0268 (0.2663) Loss_G: -0.1101 (0.1236) D(x): 0.5669 D(G(z)): 0.5123 / 0.4557 Acc: 34.3750 (31.8455)\n",
      "[10/25][366/782] Loss_D: -0.0808 (0.2663) Loss_G: -0.0536 (0.1235) D(x): 0.5538 D(G(z)): 0.4365 / 0.4352 Acc: 35.9375 (31.8460)\n",
      "[10/25][367/782] Loss_D: -0.1389 (0.2663) Loss_G: -0.1531 (0.1235) D(x): 0.5332 D(G(z)): 0.4329 / 0.4597 Acc: 39.0625 (31.8469)\n",
      "[10/25][368/782] Loss_D: -0.1788 (0.2662) Loss_G: -0.0802 (0.1235) D(x): 0.5602 D(G(z)): 0.4358 / 0.4319 Acc: 45.3125 (31.8486)\n",
      "[10/25][369/782] Loss_D: -0.0055 (0.2662) Loss_G: -0.1483 (0.1234) D(x): 0.5543 D(G(z)): 0.4802 / 0.4521 Acc: 34.3750 (31.8489)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/25][370/782] Loss_D: -0.0178 (0.2661) Loss_G: -0.1306 (0.1234) D(x): 0.5434 D(G(z)): 0.4521 / 0.4445 Acc: 31.2500 (31.8488)\n",
      "[10/25][371/782] Loss_D: -0.1304 (0.2661) Loss_G: -0.1101 (0.1234) D(x): 0.4973 D(G(z)): 0.4251 / 0.4367 Acc: 46.8750 (31.8506)\n",
      "[10/25][372/782] Loss_D: -0.2575 (0.2660) Loss_G: -0.0360 (0.1234) D(x): 0.5855 D(G(z)): 0.4242 / 0.4117 Acc: 45.3125 (31.8523)\n",
      "[10/25][373/782] Loss_D: -0.0887 (0.2660) Loss_G: 0.0185 (0.1233) D(x): 0.5164 D(G(z)): 0.4163 / 0.4083 Acc: 43.7500 (31.8537)\n",
      "[10/25][374/782] Loss_D: -0.0321 (0.2659) Loss_G: -0.1120 (0.1233) D(x): 0.4883 D(G(z)): 0.4303 / 0.4594 Acc: 48.4375 (31.8557)\n",
      "[10/25][375/782] Loss_D: -0.3866 (0.2659) Loss_G: -0.1261 (0.1233) D(x): 0.6384 D(G(z)): 0.4270 / 0.4460 Acc: 51.5625 (31.8581)\n",
      "[10/25][376/782] Loss_D: -0.0210 (0.2658) Loss_G: 0.0677 (0.1233) D(x): 0.5477 D(G(z)): 0.5221 / 0.3724 Acc: 48.4375 (31.8602)\n",
      "[10/25][377/782] Loss_D: 0.0095 (0.2658) Loss_G: -0.0685 (0.1233) D(x): 0.5214 D(G(z)): 0.4313 / 0.4384 Acc: 34.3750 (31.8605)\n",
      "[10/25][378/782] Loss_D: -0.0886 (0.2657) Loss_G: -0.0405 (0.1232) D(x): 0.5077 D(G(z)): 0.4074 / 0.4200 Acc: 40.6250 (31.8615)\n",
      "[10/25][379/782] Loss_D: 0.0661 (0.2657) Loss_G: -0.1858 (0.1232) D(x): 0.5302 D(G(z)): 0.5197 / 0.4763 Acc: 43.7500 (31.8630)\n",
      "[10/25][380/782] Loss_D: 0.1354 (0.2657) Loss_G: -0.1273 (0.1232) D(x): 0.5226 D(G(z)): 0.5407 / 0.4435 Acc: 37.5000 (31.8637)\n",
      "[10/25][381/782] Loss_D: -0.1214 (0.2657) Loss_G: -0.0627 (0.1231) D(x): 0.5429 D(G(z)): 0.4333 / 0.4279 Acc: 42.1875 (31.8649)\n",
      "[10/25][382/782] Loss_D: -0.0854 (0.2656) Loss_G: -0.2235 (0.1231) D(x): 0.4899 D(G(z)): 0.4465 / 0.4884 Acc: 50.0000 (31.8672)\n",
      "[10/25][383/782] Loss_D: 0.1220 (0.2656) Loss_G: -0.1221 (0.1231) D(x): 0.5168 D(G(z)): 0.4940 / 0.4698 Acc: 35.9375 (31.8676)\n",
      "[10/25][384/782] Loss_D: 0.0546 (0.2656) Loss_G: -0.2793 (0.1230) D(x): 0.4959 D(G(z)): 0.5052 / 0.5095 Acc: 45.3125 (31.8693)\n",
      "[10/25][385/782] Loss_D: -0.0453 (0.2655) Loss_G: -0.2711 (0.1230) D(x): 0.5503 D(G(z)): 0.4534 / 0.5014 Acc: 32.8125 (31.8694)\n",
      "[10/25][386/782] Loss_D: 0.2416 (0.2655) Loss_G: -0.0589 (0.1230) D(x): 0.4447 D(G(z)): 0.5137 / 0.4258 Acc: 40.6250 (31.8705)\n",
      "[10/25][387/782] Loss_D: -0.1051 (0.2655) Loss_G: -0.1450 (0.1229) D(x): 0.5420 D(G(z)): 0.4785 / 0.4731 Acc: 48.4375 (31.8725)\n",
      "[10/25][388/782] Loss_D: -0.1467 (0.2654) Loss_G: -0.1285 (0.1229) D(x): 0.5711 D(G(z)): 0.4755 / 0.4613 Acc: 50.0000 (31.8747)\n",
      "[10/25][389/782] Loss_D: 0.0084 (0.2654) Loss_G: -0.1940 (0.1229) D(x): 0.5122 D(G(z)): 0.4456 / 0.4679 Acc: 39.0625 (31.8756)\n",
      "[10/25][390/782] Loss_D: -0.1690 (0.2654) Loss_G: -0.1584 (0.1228) D(x): 0.4846 D(G(z)): 0.4407 / 0.4692 Acc: 56.2500 (31.8785)\n",
      "[10/25][391/782] Loss_D: -0.0707 (0.2653) Loss_G: -0.1162 (0.1228) D(x): 0.5261 D(G(z)): 0.4931 / 0.4445 Acc: 50.0000 (31.8807)\n",
      "[10/25][392/782] Loss_D: 0.0268 (0.2653) Loss_G: -0.1861 (0.1228) D(x): 0.5301 D(G(z)): 0.4954 / 0.4805 Acc: 37.5000 (31.8814)\n",
      "[10/25][393/782] Loss_D: -0.1147 (0.2652) Loss_G: -0.1626 (0.1227) D(x): 0.5140 D(G(z)): 0.4416 / 0.4651 Acc: 46.8750 (31.8833)\n",
      "[10/25][394/782] Loss_D: 0.0063 (0.2652) Loss_G: -0.1922 (0.1227) D(x): 0.5453 D(G(z)): 0.4906 / 0.4821 Acc: 39.0625 (31.8841)\n",
      "[10/25][395/782] Loss_D: -0.1822 (0.2652) Loss_G: -0.0320 (0.1227) D(x): 0.5988 D(G(z)): 0.4502 / 0.4258 Acc: 40.6250 (31.8852)\n",
      "[10/25][396/782] Loss_D: -0.0060 (0.2651) Loss_G: -0.1719 (0.1226) D(x): 0.5058 D(G(z)): 0.4480 / 0.4782 Acc: 42.1875 (31.8864)\n",
      "[10/25][397/782] Loss_D: -0.1717 (0.2651) Loss_G: -0.1811 (0.1226) D(x): 0.5290 D(G(z)): 0.4326 / 0.4834 Acc: 50.0000 (31.8887)\n",
      "[10/25][398/782] Loss_D: -0.0818 (0.2650) Loss_G: -0.0693 (0.1226) D(x): 0.5621 D(G(z)): 0.4742 / 0.4346 Acc: 39.0625 (31.8895)\n",
      "[10/25][399/782] Loss_D: 0.0975 (0.2650) Loss_G: -0.0905 (0.1225) D(x): 0.5729 D(G(z)): 0.5083 / 0.4524 Acc: 32.8125 (31.8896)\n",
      "[10/25][400/782] Loss_D: -0.1137 (0.2650) Loss_G: -0.0221 (0.1225) D(x): 0.5172 D(G(z)): 0.3952 / 0.4261 Acc: 39.0625 (31.8905)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[10/25][401/782] Loss_D: -0.1606 (0.2649) Loss_G: -0.1463 (0.1225) D(x): 0.5150 D(G(z)): 0.4633 / 0.4816 Acc: 59.3750 (31.8939)\n",
      "[10/25][402/782] Loss_D: -0.0132 (0.2649) Loss_G: -0.1196 (0.1225) D(x): 0.5113 D(G(z)): 0.4640 / 0.4594 Acc: 48.4375 (31.8959)\n",
      "[10/25][403/782] Loss_D: -0.0592 (0.2648) Loss_G: -0.3022 (0.1224) D(x): 0.5681 D(G(z)): 0.4966 / 0.5329 Acc: 42.1875 (31.8971)\n",
      "[10/25][404/782] Loss_D: -0.0569 (0.2648) Loss_G: -0.1534 (0.1224) D(x): 0.5698 D(G(z)): 0.4822 / 0.4708 Acc: 45.3125 (31.8987)\n",
      "[10/25][405/782] Loss_D: -0.2471 (0.2647) Loss_G: -0.0372 (0.1224) D(x): 0.5371 D(G(z)): 0.4339 / 0.4266 Acc: 54.6875 (31.9015)\n",
      "[10/25][406/782] Loss_D: -0.0686 (0.2647) Loss_G: -0.0747 (0.1223) D(x): 0.5050 D(G(z)): 0.4800 / 0.4364 Acc: 54.6875 (31.9043)\n",
      "[10/25][407/782] Loss_D: -0.0967 (0.2646) Loss_G: -0.0577 (0.1223) D(x): 0.5260 D(G(z)): 0.4572 / 0.4250 Acc: 46.8750 (31.9061)\n",
      "[10/25][408/782] Loss_D: 0.2395 (0.2646) Loss_G: -0.1152 (0.1223) D(x): 0.4576 D(G(z)): 0.4461 / 0.4507 Acc: 28.1250 (31.9056)\n",
      "[10/25][409/782] Loss_D: -0.1392 (0.2646) Loss_G: -0.0318 (0.1223) D(x): 0.5205 D(G(z)): 0.4763 / 0.4089 Acc: 54.6875 (31.9084)\n",
      "[10/25][410/782] Loss_D: -0.0696 (0.2646) Loss_G: -0.0660 (0.1222) D(x): 0.5923 D(G(z)): 0.5032 / 0.4399 Acc: 42.1875 (31.9097)\n",
      "[10/25][411/782] Loss_D: -0.0555 (0.2645) Loss_G: -0.0358 (0.1222) D(x): 0.5487 D(G(z)): 0.4713 / 0.4295 Acc: 37.5000 (31.9103)\n",
      "[10/25][412/782] Loss_D: -0.2007 (0.2645) Loss_G: -0.1098 (0.1222) D(x): 0.5680 D(G(z)): 0.4119 / 0.4346 Acc: 40.6250 (31.9114)\n",
      "[10/25][413/782] Loss_D: -0.2213 (0.2644) Loss_G: -0.0767 (0.1222) D(x): 0.5173 D(G(z)): 0.3507 / 0.4288 Acc: 40.6250 (31.9125)\n",
      "[10/25][414/782] Loss_D: -0.1442 (0.2644) Loss_G: -0.2216 (0.1221) D(x): 0.5472 D(G(z)): 0.4476 / 0.5043 Acc: 48.4375 (31.9145)\n",
      "[10/25][415/782] Loss_D: -0.1420 (0.2643) Loss_G: -0.1552 (0.1221) D(x): 0.5830 D(G(z)): 0.4959 / 0.4782 Acc: 48.4375 (31.9165)\n",
      "[10/25][416/782] Loss_D: -0.2873 (0.2642) Loss_G: -0.1890 (0.1221) D(x): 0.5830 D(G(z)): 0.4659 / 0.4851 Acc: 56.2500 (31.9194)\n",
      "[10/25][417/782] Loss_D: 0.0076 (0.2642) Loss_G: -0.0053 (0.1220) D(x): 0.5495 D(G(z)): 0.4813 / 0.4247 Acc: 40.6250 (31.9205)\n",
      "[10/25][418/782] Loss_D: -0.2609 (0.2641) Loss_G: -0.0714 (0.1220) D(x): 0.5719 D(G(z)): 0.4677 / 0.4274 Acc: 59.3750 (31.9238)\n",
      "[10/25][419/782] Loss_D: -0.0440 (0.2641) Loss_G: 0.0040 (0.1220) D(x): 0.4970 D(G(z)): 0.4241 / 0.4013 Acc: 42.1875 (31.9251)\n",
      "[10/25][420/782] Loss_D: -0.1339 (0.2641) Loss_G: -0.1452 (0.1220) D(x): 0.5673 D(G(z)): 0.4607 / 0.4582 Acc: 42.1875 (31.9263)\n",
      "[10/25][421/782] Loss_D: 0.1045 (0.2640) Loss_G: -0.1405 (0.1219) D(x): 0.4421 D(G(z)): 0.4387 / 0.4661 Acc: 43.7500 (31.9277)\n",
      "[10/25][422/782] Loss_D: -0.0544 (0.2640) Loss_G: -0.1351 (0.1219) D(x): 0.5658 D(G(z)): 0.5354 / 0.4568 Acc: 50.0000 (31.9299)\n",
      "[10/25][423/782] Loss_D: -0.0601 (0.2640) Loss_G: -0.1641 (0.1219) D(x): 0.5109 D(G(z)): 0.4841 / 0.4637 Acc: 50.0000 (31.9321)\n",
      "[10/25][424/782] Loss_D: -0.0544 (0.2639) Loss_G: -0.0721 (0.1218) D(x): 0.5418 D(G(z)): 0.4807 / 0.4366 Acc: 42.1875 (31.9334)\n",
      "[10/25][425/782] Loss_D: -0.1502 (0.2639) Loss_G: 0.0194 (0.1218) D(x): 0.5443 D(G(z)): 0.4536 / 0.4161 Acc: 46.8750 (31.9352)\n",
      "[10/25][426/782] Loss_D: -0.1460 (0.2638) Loss_G: -0.0317 (0.1218) D(x): 0.5248 D(G(z)): 0.4299 / 0.4191 Acc: 48.4375 (31.9372)\n",
      "[10/25][427/782] Loss_D: -0.0097 (0.2638) Loss_G: -0.1435 (0.1218) D(x): 0.5254 D(G(z)): 0.4748 / 0.4826 Acc: 40.6250 (31.9382)\n",
      "[10/25][428/782] Loss_D: 0.0973 (0.2638) Loss_G: 0.0407 (0.1218) D(x): 0.5062 D(G(z)): 0.4589 / 0.3896 Acc: 31.2500 (31.9382)\n",
      "[10/25][429/782] Loss_D: -0.0097 (0.2637) Loss_G: -0.1700 (0.1217) D(x): 0.4977 D(G(z)): 0.4598 / 0.4585 Acc: 43.7500 (31.9396)\n",
      "[10/25][430/782] Loss_D: 0.0414 (0.2637) Loss_G: -0.2024 (0.1217) D(x): 0.4756 D(G(z)): 0.4653 / 0.5000 Acc: 42.1875 (31.9408)\n",
      "[10/25][431/782] Loss_D: -0.0662 (0.2637) Loss_G: -0.1924 (0.1217) D(x): 0.5808 D(G(z)): 0.5338 / 0.4929 Acc: 48.4375 (31.9428)\n",
      "[10/25][432/782] Loss_D: -0.0289 (0.2636) Loss_G: -0.0212 (0.1216) D(x): 0.5715 D(G(z)): 0.5085 / 0.4209 Acc: 43.7500 (31.9443)\n",
      "[10/25][433/782] Loss_D: 0.1472 (0.2636) Loss_G: 0.1647 (0.1216) D(x): 0.4955 D(G(z)): 0.4610 / 0.3527 Acc: 32.8125 (31.9444)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/25][434/782] Loss_D: -0.1098 (0.2636) Loss_G: -0.2209 (0.1216) D(x): 0.4689 D(G(z)): 0.4024 / 0.5035 Acc: 45.3125 (31.9460)\n",
      "[10/25][435/782] Loss_D: 0.0479 (0.2635) Loss_G: -0.2019 (0.1216) D(x): 0.5125 D(G(z)): 0.5065 / 0.4832 Acc: 46.8750 (31.9478)\n",
      "[10/25][436/782] Loss_D: -0.1983 (0.2635) Loss_G: -0.0676 (0.1215) D(x): 0.5518 D(G(z)): 0.4627 / 0.4217 Acc: 51.5625 (31.9502)\n",
      "[10/25][437/782] Loss_D: 0.0736 (0.2635) Loss_G: -0.1597 (0.1215) D(x): 0.5198 D(G(z)): 0.5170 / 0.4562 Acc: 39.0625 (31.9510)\n",
      "[10/25][438/782] Loss_D: -0.0726 (0.2634) Loss_G: -0.1099 (0.1215) D(x): 0.5536 D(G(z)): 0.4519 / 0.4502 Acc: 39.0625 (31.9519)\n",
      "[10/25][439/782] Loss_D: 0.0624 (0.2634) Loss_G: -0.2169 (0.1214) D(x): 0.4608 D(G(z)): 0.4767 / 0.4884 Acc: 45.3125 (31.9535)\n",
      "[10/25][440/782] Loss_D: -0.0147 (0.2634) Loss_G: -0.1131 (0.1214) D(x): 0.5457 D(G(z)): 0.5183 / 0.4513 Acc: 43.7500 (31.9549)\n",
      "[10/25][441/782] Loss_D: 0.0815 (0.2633) Loss_G: -0.1415 (0.1214) D(x): 0.4915 D(G(z)): 0.4870 / 0.4786 Acc: 42.1875 (31.9562)\n",
      "[10/25][442/782] Loss_D: -0.1454 (0.2633) Loss_G: -0.2194 (0.1213) D(x): 0.4996 D(G(z)): 0.3975 / 0.4840 Acc: 46.8750 (31.9580)\n",
      "[10/25][443/782] Loss_D: -0.0932 (0.2633) Loss_G: -0.2079 (0.1213) D(x): 0.5356 D(G(z)): 0.4589 / 0.4930 Acc: 46.8750 (31.9598)\n",
      "[10/25][444/782] Loss_D: -0.0058 (0.2632) Loss_G: -0.1778 (0.1213) D(x): 0.5584 D(G(z)): 0.5383 / 0.4694 Acc: 46.8750 (31.9616)\n",
      "[10/25][445/782] Loss_D: 0.0429 (0.2632) Loss_G: -0.0366 (0.1212) D(x): 0.5523 D(G(z)): 0.4595 / 0.4229 Acc: 35.9375 (31.9621)\n",
      "[10/25][446/782] Loss_D: -0.1381 (0.2631) Loss_G: -0.0569 (0.1212) D(x): 0.5150 D(G(z)): 0.4104 / 0.4295 Acc: 43.7500 (31.9635)\n",
      "[10/25][447/782] Loss_D: 0.1075 (0.2631) Loss_G: -0.1879 (0.1212) D(x): 0.5141 D(G(z)): 0.5112 / 0.4894 Acc: 40.6250 (31.9645)\n",
      "[10/25][448/782] Loss_D: -0.1078 (0.2631) Loss_G: -0.0472 (0.1212) D(x): 0.5961 D(G(z)): 0.4657 / 0.4235 Acc: 34.3750 (31.9648)\n",
      "[10/25][449/782] Loss_D: 0.0138 (0.2631) Loss_G: -0.2308 (0.1211) D(x): 0.5106 D(G(z)): 0.4499 / 0.4931 Acc: 37.5000 (31.9655)\n",
      "[10/25][450/782] Loss_D: -0.0692 (0.2630) Loss_G: -0.0735 (0.1211) D(x): 0.5213 D(G(z)): 0.4314 / 0.4315 Acc: 37.5000 (31.9662)\n",
      "[10/25][451/782] Loss_D: -0.1960 (0.2630) Loss_G: -0.0902 (0.1211) D(x): 0.5443 D(G(z)): 0.3883 / 0.4384 Acc: 39.0625 (31.9670)\n",
      "[10/25][452/782] Loss_D: 0.1463 (0.2629) Loss_G: 0.0181 (0.1211) D(x): 0.5462 D(G(z)): 0.5165 / 0.4093 Acc: 31.2500 (31.9669)\n",
      "[10/25][453/782] Loss_D: 0.0065 (0.2629) Loss_G: -0.0378 (0.1210) D(x): 0.5627 D(G(z)): 0.5060 / 0.4129 Acc: 37.5000 (31.9676)\n",
      "[10/25][454/782] Loss_D: -0.0809 (0.2629) Loss_G: -0.1349 (0.1210) D(x): 0.4827 D(G(z)): 0.4053 / 0.4610 Acc: 46.8750 (31.9694)\n",
      "[10/25][455/782] Loss_D: -0.0505 (0.2628) Loss_G: -0.1213 (0.1210) D(x): 0.5348 D(G(z)): 0.4254 / 0.4573 Acc: 34.3750 (31.9697)\n",
      "[10/25][456/782] Loss_D: -0.1790 (0.2628) Loss_G: -0.0722 (0.1210) D(x): 0.5918 D(G(z)): 0.4778 / 0.4264 Acc: 43.7500 (31.9711)\n",
      "[10/25][457/782] Loss_D: 0.0729 (0.2628) Loss_G: -0.0547 (0.1209) D(x): 0.5337 D(G(z)): 0.5064 / 0.4248 Acc: 40.6250 (31.9722)\n",
      "[10/25][458/782] Loss_D: -0.0376 (0.2627) Loss_G: -0.0322 (0.1209) D(x): 0.5096 D(G(z)): 0.4211 / 0.4251 Acc: 39.0625 (31.9730)\n",
      "[10/25][459/782] Loss_D: 0.0282 (0.2627) Loss_G: -0.0294 (0.1209) D(x): 0.5118 D(G(z)): 0.4429 / 0.4386 Acc: 37.5000 (31.9737)\n",
      "[10/25][460/782] Loss_D: -0.0154 (0.2627) Loss_G: -0.2260 (0.1209) D(x): 0.5645 D(G(z)): 0.4886 / 0.5020 Acc: 39.0625 (31.9746)\n",
      "[10/25][461/782] Loss_D: 0.1269 (0.2626) Loss_G: -0.1101 (0.1208) D(x): 0.5038 D(G(z)): 0.4875 / 0.4663 Acc: 32.8125 (31.9747)\n",
      "[10/25][462/782] Loss_D: -0.0986 (0.2626) Loss_G: -0.2629 (0.1208) D(x): 0.4994 D(G(z)): 0.4432 / 0.5100 Acc: 46.8750 (31.9765)\n",
      "[10/25][463/782] Loss_D: -0.0758 (0.2626) Loss_G: -0.1000 (0.1208) D(x): 0.5654 D(G(z)): 0.4787 / 0.4475 Acc: 42.1875 (31.9777)\n",
      "[10/25][464/782] Loss_D: -0.1035 (0.2625) Loss_G: -0.1413 (0.1207) D(x): 0.5819 D(G(z)): 0.5181 / 0.4763 Acc: 54.6875 (31.9804)\n",
      "[10/25][465/782] Loss_D: 0.0342 (0.2625) Loss_G: -0.0392 (0.1207) D(x): 0.4801 D(G(z)): 0.4750 / 0.4254 Acc: 48.4375 (31.9824)\n",
      "[10/25][466/782] Loss_D: 0.0763 (0.2625) Loss_G: -0.1285 (0.1207) D(x): 0.4731 D(G(z)): 0.4345 / 0.4643 Acc: 43.7500 (31.9838)\n",
      "[10/25][467/782] Loss_D: -0.0218 (0.2624) Loss_G: -0.1532 (0.1206) D(x): 0.4896 D(G(z)): 0.4632 / 0.4724 Acc: 46.8750 (31.9856)\n",
      "[10/25][468/782] Loss_D: 0.1978 (0.2624) Loss_G: -0.1536 (0.1206) D(x): 0.5312 D(G(z)): 0.5440 / 0.4631 Acc: 32.8125 (31.9857)\n",
      "[10/25][469/782] Loss_D: 0.2381 (0.2624) Loss_G: -0.1554 (0.1206) D(x): 0.4496 D(G(z)): 0.4888 / 0.4672 Acc: 39.0625 (31.9866)\n",
      "[10/25][470/782] Loss_D: -0.0566 (0.2624) Loss_G: -0.1369 (0.1205) D(x): 0.5581 D(G(z)): 0.4971 / 0.4662 Acc: 53.1250 (31.9891)\n",
      "[10/25][471/782] Loss_D: 0.0669 (0.2624) Loss_G: -0.0524 (0.1205) D(x): 0.5422 D(G(z)): 0.4926 / 0.4308 Acc: 39.0625 (31.9900)\n",
      "[10/25][472/782] Loss_D: -0.0109 (0.2623) Loss_G: -0.0265 (0.1205) D(x): 0.5583 D(G(z)): 0.4726 / 0.4063 Acc: 31.2500 (31.9899)\n",
      "[10/25][473/782] Loss_D: 0.0031 (0.2623) Loss_G: -0.1001 (0.1205) D(x): 0.4670 D(G(z)): 0.4509 / 0.4590 Acc: 48.4375 (31.9919)\n",
      "[10/25][474/782] Loss_D: -0.0657 (0.2622) Loss_G: -0.2048 (0.1204) D(x): 0.5232 D(G(z)): 0.4262 / 0.4924 Acc: 42.1875 (31.9931)\n",
      "[10/25][475/782] Loss_D: -0.0039 (0.2622) Loss_G: -0.1179 (0.1204) D(x): 0.5467 D(G(z)): 0.4678 / 0.4410 Acc: 32.8125 (31.9932)\n",
      "[10/25][476/782] Loss_D: -0.0039 (0.2622) Loss_G: -0.1491 (0.1204) D(x): 0.5849 D(G(z)): 0.5067 / 0.4637 Acc: 39.0625 (31.9941)\n",
      "[10/25][477/782] Loss_D: -0.2521 (0.2621) Loss_G: -0.0339 (0.1204) D(x): 0.5498 D(G(z)): 0.3918 / 0.4130 Acc: 43.7500 (31.9955)\n",
      "[10/25][478/782] Loss_D: -0.0605 (0.2621) Loss_G: -0.1335 (0.1203) D(x): 0.5131 D(G(z)): 0.4490 / 0.4430 Acc: 43.7500 (31.9969)\n",
      "[10/25][479/782] Loss_D: -0.1754 (0.2620) Loss_G: -0.1342 (0.1203) D(x): 0.5746 D(G(z)): 0.4743 / 0.4402 Acc: 45.3125 (31.9985)\n",
      "[10/25][480/782] Loss_D: 0.0340 (0.2620) Loss_G: -0.1599 (0.1203) D(x): 0.5442 D(G(z)): 0.5061 / 0.4589 Acc: 43.7500 (31.9999)\n",
      "[10/25][481/782] Loss_D: -0.1205 (0.2620) Loss_G: -0.1582 (0.1202) D(x): 0.5241 D(G(z)): 0.4629 / 0.4606 Acc: 54.6875 (32.0026)\n",
      "[10/25][482/782] Loss_D: -0.0960 (0.2619) Loss_G: -0.0412 (0.1202) D(x): 0.5513 D(G(z)): 0.4743 / 0.4072 Acc: 43.7500 (32.0041)\n",
      "[10/25][483/782] Loss_D: -0.1191 (0.2619) Loss_G: -0.0204 (0.1202) D(x): 0.5322 D(G(z)): 0.4624 / 0.4155 Acc: 48.4375 (32.0060)\n",
      "[10/25][484/782] Loss_D: 0.1017 (0.2619) Loss_G: -0.0123 (0.1202) D(x): 0.5031 D(G(z)): 0.4703 / 0.4089 Acc: 34.3750 (32.0063)\n",
      "[10/25][485/782] Loss_D: -0.0805 (0.2618) Loss_G: -0.1439 (0.1202) D(x): 0.4705 D(G(z)): 0.4074 / 0.4768 Acc: 46.8750 (32.0081)\n",
      "[10/25][486/782] Loss_D: -0.0575 (0.2618) Loss_G: -0.1011 (0.1201) D(x): 0.5615 D(G(z)): 0.4565 / 0.4384 Acc: 39.0625 (32.0090)\n",
      "[10/25][487/782] Loss_D: -0.0490 (0.2617) Loss_G: -0.1719 (0.1201) D(x): 0.5777 D(G(z)): 0.5206 / 0.4766 Acc: 39.0625 (32.0098)\n",
      "[10/25][488/782] Loss_D: 0.1143 (0.2617) Loss_G: -0.0747 (0.1201) D(x): 0.4997 D(G(z)): 0.4817 / 0.4351 Acc: 35.9375 (32.0103)\n",
      "[10/25][489/782] Loss_D: -0.1636 (0.2617) Loss_G: -0.0035 (0.1201) D(x): 0.5639 D(G(z)): 0.4649 / 0.4102 Acc: 43.7500 (32.0117)\n",
      "[10/25][490/782] Loss_D: 0.0374 (0.2616) Loss_G: -0.0641 (0.1200) D(x): 0.5106 D(G(z)): 0.4454 / 0.4250 Acc: 35.9375 (32.0122)\n",
      "[10/25][491/782] Loss_D: -0.0824 (0.2616) Loss_G: -0.1435 (0.1200) D(x): 0.4778 D(G(z)): 0.4254 / 0.4730 Acc: 46.8750 (32.0140)\n",
      "[10/25][492/782] Loss_D: -0.1797 (0.2615) Loss_G: -0.0292 (0.1200) D(x): 0.6184 D(G(z)): 0.5231 / 0.4157 Acc: 50.0000 (32.0161)\n",
      "[10/25][493/782] Loss_D: -0.0139 (0.2615) Loss_G: 0.0066 (0.1200) D(x): 0.5420 D(G(z)): 0.4706 / 0.4044 Acc: 40.6250 (32.0172)\n",
      "[10/25][494/782] Loss_D: -0.0292 (0.2615) Loss_G: -0.2341 (0.1199) D(x): 0.4751 D(G(z)): 0.4334 / 0.4850 Acc: 45.3125 (32.0188)\n",
      "[10/25][495/782] Loss_D: -0.0385 (0.2614) Loss_G: -0.1495 (0.1199) D(x): 0.5837 D(G(z)): 0.5168 / 0.4657 Acc: 39.0625 (32.0196)\n",
      "[10/25][496/782] Loss_D: -0.0836 (0.2614) Loss_G: -0.1310 (0.1199) D(x): 0.5419 D(G(z)): 0.4549 / 0.4614 Acc: 42.1875 (32.0208)\n",
      "[10/25][497/782] Loss_D: 0.0217 (0.2614) Loss_G: -0.0473 (0.1198) D(x): 0.5178 D(G(z)): 0.4510 / 0.4096 Acc: 34.3750 (32.0211)\n",
      "[10/25][498/782] Loss_D: 0.1089 (0.2613) Loss_G: -0.2170 (0.1198) D(x): 0.4802 D(G(z)): 0.4673 / 0.4855 Acc: 43.7500 (32.0225)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/25][499/782] Loss_D: -0.0058 (0.2613) Loss_G: -0.1034 (0.1198) D(x): 0.5428 D(G(z)): 0.5165 / 0.4424 Acc: 46.8750 (32.0243)\n",
      "[10/25][500/782] Loss_D: -0.2526 (0.2613) Loss_G: 0.0346 (0.1198) D(x): 0.5391 D(G(z)): 0.3933 / 0.3878 Acc: 51.5625 (32.0266)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[10/25][501/782] Loss_D: -0.0758 (0.2612) Loss_G: -0.0889 (0.1197) D(x): 0.5366 D(G(z)): 0.4146 / 0.4605 Acc: 37.5000 (32.0273)\n",
      "[10/25][502/782] Loss_D: 0.0187 (0.2612) Loss_G: -0.2062 (0.1197) D(x): 0.5605 D(G(z)): 0.4899 / 0.4820 Acc: 37.5000 (32.0280)\n",
      "[10/25][503/782] Loss_D: 0.0283 (0.2612) Loss_G: 0.2352 (0.1197) D(x): 0.5978 D(G(z)): 0.5029 / 0.3277 Acc: 31.2500 (32.0279)\n",
      "[10/25][504/782] Loss_D: -0.0966 (0.2611) Loss_G: -0.0635 (0.1197) D(x): 0.4798 D(G(z)): 0.3976 / 0.4277 Acc: 42.1875 (32.0291)\n",
      "[10/25][505/782] Loss_D: 0.0456 (0.2611) Loss_G: 0.0746 (0.1197) D(x): 0.5108 D(G(z)): 0.4611 / 0.3735 Acc: 35.9375 (32.0296)\n",
      "[10/25][506/782] Loss_D: -0.0538 (0.2611) Loss_G: -0.0793 (0.1197) D(x): 0.5344 D(G(z)): 0.4223 / 0.4425 Acc: 32.8125 (32.0297)\n",
      "[10/25][507/782] Loss_D: 0.1980 (0.2610) Loss_G: -0.0015 (0.1196) D(x): 0.4593 D(G(z)): 0.4481 / 0.4078 Acc: 31.2500 (32.0296)\n",
      "[10/25][508/782] Loss_D: 0.2058 (0.2610) Loss_G: -0.2410 (0.1196) D(x): 0.5054 D(G(z)): 0.5431 / 0.5118 Acc: 43.7500 (32.0310)\n",
      "[10/25][509/782] Loss_D: -0.0381 (0.2610) Loss_G: 0.0430 (0.1196) D(x): 0.5277 D(G(z)): 0.5027 / 0.3963 Acc: 53.1250 (32.0335)\n",
      "[10/25][510/782] Loss_D: -0.0462 (0.2610) Loss_G: 0.0337 (0.1196) D(x): 0.5372 D(G(z)): 0.4638 / 0.4103 Acc: 45.3125 (32.0351)\n",
      "[10/25][511/782] Loss_D: 0.1569 (0.2610) Loss_G: -0.2120 (0.1195) D(x): 0.5197 D(G(z)): 0.4810 / 0.4923 Acc: 34.3750 (32.0354)\n",
      "[10/25][512/782] Loss_D: -0.0131 (0.2609) Loss_G: -0.1773 (0.1195) D(x): 0.5177 D(G(z)): 0.4637 / 0.4765 Acc: 35.9375 (32.0358)\n",
      "[10/25][513/782] Loss_D: -0.0194 (0.2609) Loss_G: -0.0646 (0.1195) D(x): 0.5620 D(G(z)): 0.4934 / 0.4262 Acc: 39.0625 (32.0367)\n",
      "[10/25][514/782] Loss_D: 0.0553 (0.2609) Loss_G: -0.0609 (0.1195) D(x): 0.5128 D(G(z)): 0.4692 / 0.4411 Acc: 39.0625 (32.0375)\n",
      "[10/25][515/782] Loss_D: 0.0827 (0.2608) Loss_G: -0.0223 (0.1194) D(x): 0.4853 D(G(z)): 0.4477 / 0.4189 Acc: 37.5000 (32.0382)\n",
      "[10/25][516/782] Loss_D: -0.0871 (0.2608) Loss_G: -0.1337 (0.1194) D(x): 0.5183 D(G(z)): 0.3921 / 0.4736 Acc: 40.6250 (32.0392)\n",
      "[10/25][517/782] Loss_D: 0.0474 (0.2608) Loss_G: -0.1959 (0.1194) D(x): 0.5500 D(G(z)): 0.5084 / 0.4933 Acc: 43.7500 (32.0406)\n",
      "[10/25][518/782] Loss_D: -0.0032 (0.2607) Loss_G: -0.2217 (0.1193) D(x): 0.5430 D(G(z)): 0.4838 / 0.4809 Acc: 43.7500 (32.0420)\n",
      "[10/25][519/782] Loss_D: -0.0237 (0.2607) Loss_G: 0.0255 (0.1193) D(x): 0.4907 D(G(z)): 0.4427 / 0.3965 Acc: 42.1875 (32.0432)\n",
      "[10/25][520/782] Loss_D: 0.2389 (0.2607) Loss_G: -0.1232 (0.1193) D(x): 0.5179 D(G(z)): 0.5381 / 0.4626 Acc: 34.3750 (32.0435)\n",
      "[10/25][521/782] Loss_D: 0.0191 (0.2607) Loss_G: -0.0814 (0.1193) D(x): 0.5490 D(G(z)): 0.4768 / 0.4340 Acc: 34.3750 (32.0438)\n",
      "[10/25][522/782] Loss_D: 0.1103 (0.2607) Loss_G: 0.0404 (0.1193) D(x): 0.5204 D(G(z)): 0.5066 / 0.3968 Acc: 35.9375 (32.0443)\n",
      "[10/25][523/782] Loss_D: -0.0756 (0.2606) Loss_G: -0.0201 (0.1192) D(x): 0.5167 D(G(z)): 0.4395 / 0.4183 Acc: 42.1875 (32.0455)\n",
      "[10/25][524/782] Loss_D: -0.0313 (0.2606) Loss_G: 0.0331 (0.1192) D(x): 0.5515 D(G(z)): 0.4853 / 0.4191 Acc: 43.7500 (32.0469)\n",
      "[10/25][525/782] Loss_D: -0.1052 (0.2605) Loss_G: -0.0807 (0.1192) D(x): 0.5375 D(G(z)): 0.4490 / 0.4541 Acc: 46.8750 (32.0487)\n",
      "[10/25][526/782] Loss_D: 0.0855 (0.2605) Loss_G: -0.0707 (0.1192) D(x): 0.4784 D(G(z)): 0.4722 / 0.4376 Acc: 48.4375 (32.0506)\n",
      "[10/25][527/782] Loss_D: -0.2062 (0.2605) Loss_G: -0.1181 (0.1192) D(x): 0.5695 D(G(z)): 0.4570 / 0.4419 Acc: 50.0000 (32.0528)\n",
      "[10/25][528/782] Loss_D: 0.0316 (0.2604) Loss_G: -0.2221 (0.1191) D(x): 0.5018 D(G(z)): 0.4441 / 0.5008 Acc: 35.9375 (32.0532)\n",
      "[10/25][529/782] Loss_D: -0.0673 (0.2604) Loss_G: -0.1444 (0.1191) D(x): 0.5441 D(G(z)): 0.4751 / 0.4670 Acc: 48.4375 (32.0552)\n",
      "[10/25][530/782] Loss_D: 0.0079 (0.2604) Loss_G: -0.1078 (0.1191) D(x): 0.5968 D(G(z)): 0.5542 / 0.4494 Acc: 43.7500 (32.0566)\n",
      "[10/25][531/782] Loss_D: -0.0351 (0.2603) Loss_G: -0.0379 (0.1190) D(x): 0.5204 D(G(z)): 0.4788 / 0.4311 Acc: 46.8750 (32.0584)\n",
      "[10/25][532/782] Loss_D: -0.0142 (0.2603) Loss_G: -0.1270 (0.1190) D(x): 0.5011 D(G(z)): 0.4188 / 0.4493 Acc: 39.0625 (32.0592)\n",
      "[10/25][533/782] Loss_D: -0.0261 (0.2603) Loss_G: -0.1579 (0.1190) D(x): 0.5412 D(G(z)): 0.4742 / 0.4692 Acc: 37.5000 (32.0599)\n",
      "[10/25][534/782] Loss_D: -0.1228 (0.2602) Loss_G: -0.1520 (0.1189) D(x): 0.5669 D(G(z)): 0.5006 / 0.4592 Acc: 48.4375 (32.0618)\n",
      "[10/25][535/782] Loss_D: -0.0804 (0.2602) Loss_G: -0.1003 (0.1189) D(x): 0.5461 D(G(z)): 0.4767 / 0.4410 Acc: 46.8750 (32.0636)\n",
      "[10/25][536/782] Loss_D: -0.1812 (0.2601) Loss_G: -0.0662 (0.1189) D(x): 0.5716 D(G(z)): 0.4079 / 0.4255 Acc: 37.5000 (32.0643)\n",
      "[10/25][537/782] Loss_D: 0.1106 (0.2601) Loss_G: -0.0045 (0.1189) D(x): 0.5146 D(G(z)): 0.4750 / 0.4213 Acc: 32.8125 (32.0643)\n",
      "[10/25][538/782] Loss_D: -0.0422 (0.2601) Loss_G: 0.0081 (0.1189) D(x): 0.5090 D(G(z)): 0.4605 / 0.4019 Acc: 45.3125 (32.0659)\n",
      "[10/25][539/782] Loss_D: -0.2905 (0.2600) Loss_G: -0.0966 (0.1188) D(x): 0.5638 D(G(z)): 0.4139 / 0.4355 Acc: 51.5625 (32.0683)\n",
      "[10/25][540/782] Loss_D: -0.2626 (0.2599) Loss_G: -0.0362 (0.1188) D(x): 0.6028 D(G(z)): 0.4539 / 0.4322 Acc: 46.8750 (32.0700)\n",
      "[10/25][541/782] Loss_D: -0.0203 (0.2599) Loss_G: -0.0543 (0.1188) D(x): 0.5107 D(G(z)): 0.4307 / 0.4243 Acc: 39.0625 (32.0709)\n",
      "[10/25][542/782] Loss_D: -0.2012 (0.2599) Loss_G: -0.0051 (0.1188) D(x): 0.5446 D(G(z)): 0.4240 / 0.4068 Acc: 40.6250 (32.0719)\n",
      "[10/25][543/782] Loss_D: 0.0368 (0.2598) Loss_G: -0.0583 (0.1188) D(x): 0.5245 D(G(z)): 0.4671 / 0.4192 Acc: 35.9375 (32.0723)\n",
      "[10/25][544/782] Loss_D: -0.0007 (0.2598) Loss_G: 0.0619 (0.1188) D(x): 0.5448 D(G(z)): 0.4774 / 0.3973 Acc: 37.5000 (32.0730)\n",
      "[10/25][545/782] Loss_D: -0.0491 (0.2598) Loss_G: -0.1624 (0.1187) D(x): 0.4959 D(G(z)): 0.4074 / 0.4585 Acc: 40.6250 (32.0740)\n",
      "[10/25][546/782] Loss_D: 0.0233 (0.2597) Loss_G: -0.0405 (0.1187) D(x): 0.5569 D(G(z)): 0.5123 / 0.4371 Acc: 45.3125 (32.0756)\n",
      "[10/25][547/782] Loss_D: 0.0516 (0.2597) Loss_G: 0.0296 (0.1187) D(x): 0.5196 D(G(z)): 0.5087 / 0.3937 Acc: 42.1875 (32.0768)\n",
      "[10/25][548/782] Loss_D: 0.0318 (0.2597) Loss_G: -0.0336 (0.1187) D(x): 0.5327 D(G(z)): 0.4995 / 0.4176 Acc: 39.0625 (32.0776)\n",
      "[10/25][549/782] Loss_D: 0.0107 (0.2596) Loss_G: -0.0134 (0.1187) D(x): 0.5091 D(G(z)): 0.4276 / 0.4178 Acc: 34.3750 (32.0779)\n",
      "[10/25][550/782] Loss_D: 0.2252 (0.2596) Loss_G: -0.3033 (0.1186) D(x): 0.4174 D(G(z)): 0.4368 / 0.5288 Acc: 37.5000 (32.0786)\n",
      "[10/25][551/782] Loss_D: -0.1036 (0.2596) Loss_G: -0.1756 (0.1186) D(x): 0.5805 D(G(z)): 0.4799 / 0.4958 Acc: 42.1875 (32.0798)\n",
      "[10/25][552/782] Loss_D: 0.1493 (0.2596) Loss_G: -0.0642 (0.1186) D(x): 0.5274 D(G(z)): 0.5289 / 0.4285 Acc: 40.6250 (32.0808)\n",
      "[10/25][553/782] Loss_D: -0.0970 (0.2595) Loss_G: -0.1180 (0.1185) D(x): 0.5488 D(G(z)): 0.5175 / 0.4528 Acc: 56.2500 (32.0837)\n",
      "[10/25][554/782] Loss_D: -0.0631 (0.2595) Loss_G: -0.1138 (0.1185) D(x): 0.5047 D(G(z)): 0.4380 / 0.4367 Acc: 45.3125 (32.0853)\n",
      "[10/25][555/782] Loss_D: 0.0677 (0.2595) Loss_G: -0.0607 (0.1185) D(x): 0.4728 D(G(z)): 0.4662 / 0.4349 Acc: 39.0625 (32.0861)\n",
      "[10/25][556/782] Loss_D: 0.0000 (0.2595) Loss_G: -0.2639 (0.1184) D(x): 0.4991 D(G(z)): 0.4538 / 0.5152 Acc: 42.1875 (32.0873)\n",
      "[10/25][557/782] Loss_D: 0.1401 (0.2594) Loss_G: -0.1246 (0.1184) D(x): 0.5179 D(G(z)): 0.5128 / 0.4588 Acc: 35.9375 (32.0878)\n",
      "[10/25][558/782] Loss_D: 0.0629 (0.2594) Loss_G: -0.1610 (0.1184) D(x): 0.5040 D(G(z)): 0.4503 / 0.4731 Acc: 34.3750 (32.0880)\n",
      "[10/25][559/782] Loss_D: -0.0353 (0.2594) Loss_G: -0.0996 (0.1183) D(x): 0.5077 D(G(z)): 0.4486 / 0.4583 Acc: 45.3125 (32.0896)\n",
      "[10/25][560/782] Loss_D: -0.0210 (0.2593) Loss_G: -0.1369 (0.1183) D(x): 0.5620 D(G(z)): 0.4951 / 0.4517 Acc: 34.3750 (32.0899)\n",
      "[10/25][561/782] Loss_D: 0.0494 (0.2593) Loss_G: -0.0537 (0.1183) D(x): 0.5199 D(G(z)): 0.5385 / 0.4328 Acc: 51.5625 (32.0922)\n",
      "[10/25][562/782] Loss_D: -0.0637 (0.2593) Loss_G: -0.1129 (0.1183) D(x): 0.4789 D(G(z)): 0.4460 / 0.4414 Acc: 46.8750 (32.0940)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/25][563/782] Loss_D: -0.0558 (0.2592) Loss_G: -0.0619 (0.1182) D(x): 0.5638 D(G(z)): 0.5228 / 0.4312 Acc: 48.4375 (32.0959)\n",
      "[10/25][564/782] Loss_D: 0.0151 (0.2592) Loss_G: -0.1477 (0.1182) D(x): 0.4990 D(G(z)): 0.5050 / 0.4534 Acc: 51.5625 (32.0982)\n",
      "[10/25][565/782] Loss_D: -0.2530 (0.2592) Loss_G: -0.0794 (0.1182) D(x): 0.4981 D(G(z)): 0.3463 / 0.4293 Acc: 42.1875 (32.0994)\n",
      "[10/25][566/782] Loss_D: 0.0178 (0.2591) Loss_G: -0.1392 (0.1182) D(x): 0.5301 D(G(z)): 0.4532 / 0.4633 Acc: 29.6875 (32.0992)\n",
      "[10/25][567/782] Loss_D: -0.0256 (0.2591) Loss_G: -0.1375 (0.1181) D(x): 0.5643 D(G(z)): 0.5075 / 0.4478 Acc: 40.6250 (32.1002)\n",
      "[10/25][568/782] Loss_D: 0.0472 (0.2591) Loss_G: -0.2006 (0.1181) D(x): 0.5404 D(G(z)): 0.4754 / 0.4754 Acc: 32.8125 (32.1003)\n",
      "[10/25][569/782] Loss_D: -0.2248 (0.2590) Loss_G: -0.0718 (0.1181) D(x): 0.5864 D(G(z)): 0.4792 / 0.4207 Acc: 50.0000 (32.1024)\n",
      "[10/25][570/782] Loss_D: -0.1462 (0.2590) Loss_G: -0.1208 (0.1180) D(x): 0.5738 D(G(z)): 0.4641 / 0.4366 Acc: 42.1875 (32.1036)\n",
      "[10/25][571/782] Loss_D: -0.1137 (0.2589) Loss_G: -0.1676 (0.1180) D(x): 0.4847 D(G(z)): 0.4251 / 0.4710 Acc: 48.4375 (32.1055)\n",
      "[10/25][572/782] Loss_D: -0.1278 (0.2589) Loss_G: 0.0600 (0.1180) D(x): 0.5467 D(G(z)): 0.4447 / 0.3943 Acc: 45.3125 (32.1071)\n",
      "[10/25][573/782] Loss_D: 0.0097 (0.2588) Loss_G: -0.1548 (0.1180) D(x): 0.5839 D(G(z)): 0.5278 / 0.4618 Acc: 40.6250 (32.1081)\n",
      "[10/25][574/782] Loss_D: 0.0611 (0.2588) Loss_G: -0.0189 (0.1180) D(x): 0.5648 D(G(z)): 0.4867 / 0.4164 Acc: 28.1250 (32.1077)\n",
      "[10/25][575/782] Loss_D: -0.0346 (0.2588) Loss_G: 0.0159 (0.1179) D(x): 0.5144 D(G(z)): 0.4222 / 0.4115 Acc: 39.0625 (32.1085)\n",
      "[10/25][576/782] Loss_D: -0.0022 (0.2587) Loss_G: -0.0931 (0.1179) D(x): 0.5243 D(G(z)): 0.4712 / 0.4347 Acc: 43.7500 (32.1099)\n",
      "[10/25][577/782] Loss_D: -0.0434 (0.2587) Loss_G: -0.2253 (0.1179) D(x): 0.5089 D(G(z)): 0.4342 / 0.4945 Acc: 40.6250 (32.1109)\n",
      "[10/25][578/782] Loss_D: 0.0457 (0.2587) Loss_G: -0.0008 (0.1179) D(x): 0.5317 D(G(z)): 0.5030 / 0.4135 Acc: 42.1875 (32.1121)\n",
      "[10/25][579/782] Loss_D: -0.0604 (0.2586) Loss_G: -0.0797 (0.1178) D(x): 0.5269 D(G(z)): 0.4752 / 0.4334 Acc: 45.3125 (32.1137)\n",
      "[10/25][580/782] Loss_D: 0.0615 (0.2586) Loss_G: -0.0650 (0.1178) D(x): 0.5241 D(G(z)): 0.4922 / 0.4413 Acc: 37.5000 (32.1143)\n",
      "[10/25][581/782] Loss_D: 0.1864 (0.2586) Loss_G: -0.0697 (0.1178) D(x): 0.4751 D(G(z)): 0.5101 / 0.4296 Acc: 40.6250 (32.1153)\n",
      "[10/25][582/782] Loss_D: -0.0160 (0.2586) Loss_G: -0.1309 (0.1178) D(x): 0.5396 D(G(z)): 0.4982 / 0.4496 Acc: 45.3125 (32.1169)\n",
      "[10/25][583/782] Loss_D: -0.0938 (0.2585) Loss_G: -0.2150 (0.1177) D(x): 0.5375 D(G(z)): 0.4642 / 0.4795 Acc: 43.7500 (32.1183)\n",
      "[10/25][584/782] Loss_D: 0.1314 (0.2585) Loss_G: -0.1719 (0.1177) D(x): 0.5079 D(G(z)): 0.5012 / 0.4658 Acc: 37.5000 (32.1189)\n",
      "[10/25][585/782] Loss_D: -0.2228 (0.2585) Loss_G: -0.1562 (0.1177) D(x): 0.5461 D(G(z)): 0.4400 / 0.4608 Acc: 50.0000 (32.1210)\n",
      "[10/25][586/782] Loss_D: 0.0122 (0.2584) Loss_G: -0.0982 (0.1176) D(x): 0.4908 D(G(z)): 0.4996 / 0.4599 Acc: 53.1250 (32.1235)\n",
      "[10/25][587/782] Loss_D: -0.1445 (0.2584) Loss_G: -0.1874 (0.1176) D(x): 0.5026 D(G(z)): 0.4095 / 0.4847 Acc: 43.7500 (32.1249)\n",
      "[10/25][588/782] Loss_D: -0.0288 (0.2584) Loss_G: -0.1864 (0.1176) D(x): 0.5970 D(G(z)): 0.5589 / 0.4863 Acc: 46.8750 (32.1267)\n",
      "[10/25][589/782] Loss_D: -0.2071 (0.2583) Loss_G: -0.0032 (0.1175) D(x): 0.6033 D(G(z)): 0.4636 / 0.4004 Acc: 40.6250 (32.1277)\n",
      "[10/25][590/782] Loss_D: 0.0995 (0.2583) Loss_G: -0.0539 (0.1175) D(x): 0.4532 D(G(z)): 0.4359 / 0.4333 Acc: 39.0625 (32.1285)\n",
      "[10/25][591/782] Loss_D: -0.0940 (0.2582) Loss_G: -0.0757 (0.1175) D(x): 0.4884 D(G(z)): 0.3856 / 0.4318 Acc: 42.1875 (32.1297)\n",
      "[10/25][592/782] Loss_D: 0.0537 (0.2582) Loss_G: -0.1350 (0.1175) D(x): 0.5488 D(G(z)): 0.5072 / 0.4469 Acc: 35.9375 (32.1301)\n",
      "[10/25][593/782] Loss_D: -0.2279 (0.2582) Loss_G: -0.0680 (0.1174) D(x): 0.5819 D(G(z)): 0.4736 / 0.4280 Acc: 51.5625 (32.1325)\n",
      "[10/25][594/782] Loss_D: 0.0907 (0.2581) Loss_G: 0.1374 (0.1175) D(x): 0.5503 D(G(z)): 0.5386 / 0.3703 Acc: 40.6250 (32.1335)\n",
      "[10/25][595/782] Loss_D: -0.0094 (0.2581) Loss_G: -0.0690 (0.1174) D(x): 0.5056 D(G(z)): 0.4659 / 0.4227 Acc: 42.1875 (32.1347)\n",
      "[10/25][596/782] Loss_D: -0.0697 (0.2581) Loss_G: 0.0349 (0.1174) D(x): 0.5121 D(G(z)): 0.4180 / 0.4057 Acc: 37.5000 (32.1353)\n",
      "[10/25][597/782] Loss_D: 0.0956 (0.2581) Loss_G: -0.0571 (0.1174) D(x): 0.5352 D(G(z)): 0.4934 / 0.4329 Acc: 34.3750 (32.1356)\n",
      "[10/25][598/782] Loss_D: 0.0435 (0.2580) Loss_G: -0.1220 (0.1174) D(x): 0.5375 D(G(z)): 0.4561 / 0.4585 Acc: 31.2500 (32.1355)\n",
      "[10/25][599/782] Loss_D: 0.0165 (0.2580) Loss_G: -0.0973 (0.1173) D(x): 0.5353 D(G(z)): 0.4775 / 0.4448 Acc: 39.0625 (32.1363)\n",
      "[10/25][600/782] Loss_D: -0.1518 (0.2579) Loss_G: -0.0263 (0.1173) D(x): 0.5669 D(G(z)): 0.4318 / 0.4049 Acc: 40.6250 (32.1373)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[10/25][601/782] Loss_D: 0.0441 (0.2579) Loss_G: -0.1862 (0.1173) D(x): 0.4773 D(G(z)): 0.3952 / 0.4825 Acc: 31.2500 (32.1372)\n",
      "[10/25][602/782] Loss_D: -0.2358 (0.2579) Loss_G: -0.1543 (0.1173) D(x): 0.5931 D(G(z)): 0.4386 / 0.4652 Acc: 43.7500 (32.1386)\n",
      "[10/25][603/782] Loss_D: -0.0827 (0.2578) Loss_G: -0.0330 (0.1172) D(x): 0.5835 D(G(z)): 0.5076 / 0.4288 Acc: 45.3125 (32.1401)\n",
      "[10/25][604/782] Loss_D: 0.1184 (0.2578) Loss_G: -0.1335 (0.1172) D(x): 0.4991 D(G(z)): 0.4839 / 0.4446 Acc: 35.9375 (32.1406)\n",
      "[10/25][605/782] Loss_D: -0.0823 (0.2578) Loss_G: -0.0214 (0.1172) D(x): 0.5565 D(G(z)): 0.4774 / 0.4168 Acc: 42.1875 (32.1418)\n",
      "[10/25][606/782] Loss_D: -0.0862 (0.2577) Loss_G: -0.0451 (0.1172) D(x): 0.5148 D(G(z)): 0.4480 / 0.4236 Acc: 45.3125 (32.1433)\n",
      "[10/25][607/782] Loss_D: -0.0148 (0.2577) Loss_G: -0.1425 (0.1171) D(x): 0.4804 D(G(z)): 0.4313 / 0.4484 Acc: 43.7500 (32.1447)\n",
      "[10/25][608/782] Loss_D: -0.0358 (0.2577) Loss_G: -0.1193 (0.1171) D(x): 0.5443 D(G(z)): 0.4547 / 0.4503 Acc: 34.3750 (32.1450)\n",
      "[10/25][609/782] Loss_D: 0.0174 (0.2576) Loss_G: -0.1269 (0.1171) D(x): 0.5471 D(G(z)): 0.4962 / 0.4485 Acc: 40.6250 (32.1460)\n",
      "[10/25][610/782] Loss_D: 0.0187 (0.2576) Loss_G: -0.1272 (0.1171) D(x): 0.4960 D(G(z)): 0.4622 / 0.4523 Acc: 45.3125 (32.1475)\n",
      "[10/25][611/782] Loss_D: -0.0861 (0.2576) Loss_G: -0.1574 (0.1170) D(x): 0.6160 D(G(z)): 0.4901 / 0.4666 Acc: 39.0625 (32.1484)\n",
      "[10/25][612/782] Loss_D: -0.3001 (0.2575) Loss_G: -0.1611 (0.1170) D(x): 0.5417 D(G(z)): 0.4358 / 0.4780 Acc: 56.2500 (32.1512)\n",
      "[10/25][613/782] Loss_D: -0.1402 (0.2574) Loss_G: -0.1039 (0.1170) D(x): 0.5812 D(G(z)): 0.4752 / 0.4345 Acc: 40.6250 (32.1522)\n",
      "[10/25][614/782] Loss_D: -0.0089 (0.2574) Loss_G: 0.0157 (0.1170) D(x): 0.5413 D(G(z)): 0.5007 / 0.3975 Acc: 46.8750 (32.1540)\n",
      "[10/25][615/782] Loss_D: -0.0654 (0.2574) Loss_G: -0.1097 (0.1169) D(x): 0.4927 D(G(z)): 0.4055 / 0.4347 Acc: 39.0625 (32.1548)\n",
      "[10/25][616/782] Loss_D: -0.0678 (0.2573) Loss_G: -0.0429 (0.1169) D(x): 0.4972 D(G(z)): 0.4274 / 0.4183 Acc: 39.0625 (32.1556)\n",
      "[10/25][617/782] Loss_D: -0.0875 (0.2573) Loss_G: -0.1828 (0.1169) D(x): 0.5735 D(G(z)): 0.5059 / 0.4787 Acc: 51.5625 (32.1579)\n",
      "[10/25][618/782] Loss_D: -0.1532 (0.2573) Loss_G: -0.0510 (0.1169) D(x): 0.5791 D(G(z)): 0.4941 / 0.4335 Acc: 53.1250 (32.1604)\n",
      "[10/25][619/782] Loss_D: 0.1481 (0.2572) Loss_G: -0.0297 (0.1168) D(x): 0.4649 D(G(z)): 0.4879 / 0.4123 Acc: 35.9375 (32.1608)\n",
      "[10/25][620/782] Loss_D: -0.1884 (0.2572) Loss_G: -0.1310 (0.1168) D(x): 0.5451 D(G(z)): 0.4245 / 0.4450 Acc: 46.8750 (32.1626)\n",
      "[10/25][621/782] Loss_D: -0.0088 (0.2572) Loss_G: -0.0911 (0.1168) D(x): 0.5372 D(G(z)): 0.4910 / 0.4591 Acc: 42.1875 (32.1638)\n",
      "[10/25][622/782] Loss_D: -0.2013 (0.2571) Loss_G: -0.1553 (0.1168) D(x): 0.5455 D(G(z)): 0.4567 / 0.4644 Acc: 50.0000 (32.1659)\n",
      "[10/25][623/782] Loss_D: 0.0226 (0.2571) Loss_G: -0.1828 (0.1167) D(x): 0.5528 D(G(z)): 0.5168 / 0.4880 Acc: 39.0625 (32.1667)\n",
      "[10/25][624/782] Loss_D: -0.1733 (0.2570) Loss_G: -0.1850 (0.1167) D(x): 0.5568 D(G(z)): 0.4066 / 0.4679 Acc: 37.5000 (32.1673)\n",
      "[10/25][625/782] Loss_D: 0.0517 (0.2570) Loss_G: -0.1597 (0.1166) D(x): 0.4805 D(G(z)): 0.4766 / 0.4598 Acc: 48.4375 (32.1693)\n",
      "[10/25][626/782] Loss_D: -0.1230 (0.2570) Loss_G: -0.2401 (0.1166) D(x): 0.5773 D(G(z)): 0.4979 / 0.4890 Acc: 43.7500 (32.1706)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/25][627/782] Loss_D: -0.0638 (0.2569) Loss_G: -0.1140 (0.1166) D(x): 0.5713 D(G(z)): 0.5148 / 0.4395 Acc: 51.5625 (32.1729)\n",
      "[10/25][628/782] Loss_D: -0.0128 (0.2569) Loss_G: -0.0364 (0.1166) D(x): 0.4905 D(G(z)): 0.4861 / 0.4276 Acc: 51.5625 (32.1752)\n",
      "[10/25][629/782] Loss_D: -0.0023 (0.2569) Loss_G: -0.1079 (0.1165) D(x): 0.5168 D(G(z)): 0.5015 / 0.4462 Acc: 45.3125 (32.1768)\n",
      "[10/25][630/782] Loss_D: 0.0854 (0.2568) Loss_G: -0.1106 (0.1165) D(x): 0.5343 D(G(z)): 0.5330 / 0.4432 Acc: 40.6250 (32.1778)\n",
      "[10/25][631/782] Loss_D: 0.0612 (0.2568) Loss_G: -0.0758 (0.1165) D(x): 0.4814 D(G(z)): 0.4643 / 0.4431 Acc: 45.3125 (32.1793)\n",
      "[10/25][632/782] Loss_D: -0.2318 (0.2567) Loss_G: -0.0982 (0.1165) D(x): 0.5262 D(G(z)): 0.3795 / 0.4330 Acc: 43.7500 (32.1807)\n",
      "[10/25][633/782] Loss_D: -0.1354 (0.2567) Loss_G: -0.0964 (0.1164) D(x): 0.5902 D(G(z)): 0.4883 / 0.4425 Acc: 46.8750 (32.1824)\n",
      "[10/25][634/782] Loss_D: -0.0343 (0.2567) Loss_G: 0.0323 (0.1164) D(x): 0.5407 D(G(z)): 0.4683 / 0.3927 Acc: 37.5000 (32.1831)\n",
      "[10/25][635/782] Loss_D: -0.1124 (0.2566) Loss_G: -0.0954 (0.1164) D(x): 0.4898 D(G(z)): 0.4165 / 0.4327 Acc: 45.3125 (32.1846)\n",
      "[10/25][636/782] Loss_D: -0.1433 (0.2566) Loss_G: -0.0432 (0.1164) D(x): 0.5606 D(G(z)): 0.4449 / 0.4174 Acc: 37.5000 (32.1852)\n",
      "[10/25][637/782] Loss_D: -0.1097 (0.2565) Loss_G: -0.0058 (0.1164) D(x): 0.5731 D(G(z)): 0.4845 / 0.3951 Acc: 43.7500 (32.1866)\n",
      "[10/25][638/782] Loss_D: -0.2062 (0.2565) Loss_G: -0.1304 (0.1163) D(x): 0.5656 D(G(z)): 0.4455 / 0.4520 Acc: 45.3125 (32.1882)\n",
      "[10/25][639/782] Loss_D: -0.1418 (0.2564) Loss_G: -0.1319 (0.1163) D(x): 0.5207 D(G(z)): 0.4461 / 0.4456 Acc: 48.4375 (32.1901)\n",
      "[10/25][640/782] Loss_D: -0.1243 (0.2564) Loss_G: -0.1438 (0.1163) D(x): 0.5402 D(G(z)): 0.4512 / 0.4617 Acc: 48.4375 (32.1920)\n",
      "[10/25][641/782] Loss_D: -0.0993 (0.2563) Loss_G: -0.1460 (0.1162) D(x): 0.5307 D(G(z)): 0.4707 / 0.4681 Acc: 46.8750 (32.1937)\n",
      "[10/25][642/782] Loss_D: 0.0842 (0.2563) Loss_G: -0.1816 (0.1162) D(x): 0.4906 D(G(z)): 0.4858 / 0.4795 Acc: 39.0625 (32.1946)\n",
      "[10/25][643/782] Loss_D: 0.0133 (0.2563) Loss_G: -0.2145 (0.1162) D(x): 0.5718 D(G(z)): 0.5235 / 0.5027 Acc: 42.1875 (32.1957)\n",
      "[10/25][644/782] Loss_D: -0.0223 (0.2563) Loss_G: -0.1094 (0.1161) D(x): 0.5250 D(G(z)): 0.4807 / 0.4414 Acc: 43.7500 (32.1971)\n",
      "[10/25][645/782] Loss_D: -0.1316 (0.2562) Loss_G: -0.0306 (0.1161) D(x): 0.5194 D(G(z)): 0.4400 / 0.4278 Acc: 51.5625 (32.1994)\n",
      "[10/25][646/782] Loss_D: -0.1429 (0.2562) Loss_G: -0.1958 (0.1161) D(x): 0.5031 D(G(z)): 0.4562 / 0.5017 Acc: 54.6875 (32.2020)\n",
      "[10/25][647/782] Loss_D: -0.0748 (0.2561) Loss_G: -0.1147 (0.1161) D(x): 0.5311 D(G(z)): 0.4957 / 0.4532 Acc: 48.4375 (32.2040)\n",
      "[10/25][648/782] Loss_D: -0.1774 (0.2561) Loss_G: -0.1161 (0.1160) D(x): 0.5757 D(G(z)): 0.4520 / 0.4402 Acc: 43.7500 (32.2053)\n",
      "[10/25][649/782] Loss_D: 0.0136 (0.2561) Loss_G: -0.1524 (0.1160) D(x): 0.4816 D(G(z)): 0.4352 / 0.4574 Acc: 37.5000 (32.2059)\n",
      "[10/25][650/782] Loss_D: -0.0250 (0.2560) Loss_G: -0.1964 (0.1160) D(x): 0.5080 D(G(z)): 0.4842 / 0.4836 Acc: 51.5625 (32.2082)\n",
      "[10/25][651/782] Loss_D: -0.0382 (0.2560) Loss_G: -0.1615 (0.1159) D(x): 0.5750 D(G(z)): 0.5209 / 0.4682 Acc: 45.3125 (32.2098)\n",
      "[10/25][652/782] Loss_D: -0.1617 (0.2559) Loss_G: -0.0718 (0.1159) D(x): 0.5510 D(G(z)): 0.4823 / 0.4346 Acc: 50.0000 (32.2119)\n",
      "[10/25][653/782] Loss_D: -0.1030 (0.2559) Loss_G: -0.1277 (0.1159) D(x): 0.5205 D(G(z)): 0.4146 / 0.4445 Acc: 37.5000 (32.2125)\n",
      "[10/25][654/782] Loss_D: -0.0993 (0.2558) Loss_G: -0.2083 (0.1158) D(x): 0.5147 D(G(z)): 0.4494 / 0.4843 Acc: 45.3125 (32.2140)\n",
      "[10/25][655/782] Loss_D: -0.1263 (0.2558) Loss_G: -0.1206 (0.1158) D(x): 0.5531 D(G(z)): 0.4892 / 0.4439 Acc: 51.5625 (32.2163)\n",
      "[10/25][656/782] Loss_D: 0.0314 (0.2558) Loss_G: -0.2265 (0.1158) D(x): 0.5194 D(G(z)): 0.4682 / 0.4934 Acc: 37.5000 (32.2170)\n",
      "[10/25][657/782] Loss_D: -0.1428 (0.2557) Loss_G: -0.1432 (0.1157) D(x): 0.5842 D(G(z)): 0.4713 / 0.4471 Acc: 40.6250 (32.2179)\n",
      "[10/25][658/782] Loss_D: -0.1227 (0.2557) Loss_G: -0.0331 (0.1157) D(x): 0.5626 D(G(z)): 0.4754 / 0.4245 Acc: 50.0000 (32.2200)\n",
      "[10/25][659/782] Loss_D: 0.0797 (0.2557) Loss_G: -0.0816 (0.1157) D(x): 0.5100 D(G(z)): 0.4582 / 0.4389 Acc: 32.8125 (32.2201)\n",
      "[10/25][660/782] Loss_D: 0.0579 (0.2556) Loss_G: -0.0970 (0.1157) D(x): 0.4637 D(G(z)): 0.4297 / 0.4257 Acc: 39.0625 (32.2209)\n",
      "[10/25][661/782] Loss_D: 0.0008 (0.2556) Loss_G: -0.2814 (0.1156) D(x): 0.5277 D(G(z)): 0.4808 / 0.5180 Acc: 40.6250 (32.2219)\n",
      "[10/25][662/782] Loss_D: -0.0247 (0.2556) Loss_G: -0.1589 (0.1156) D(x): 0.5550 D(G(z)): 0.4850 / 0.4676 Acc: 42.1875 (32.2231)\n",
      "[10/25][663/782] Loss_D: -0.0787 (0.2555) Loss_G: 0.0038 (0.1156) D(x): 0.5933 D(G(z)): 0.5118 / 0.4113 Acc: 45.3125 (32.2246)\n",
      "[10/25][664/782] Loss_D: 0.0954 (0.2555) Loss_G: 0.2661 (0.1156) D(x): 0.4973 D(G(z)): 0.4196 / 0.3267 Acc: 32.8125 (32.2247)\n",
      "[10/25][665/782] Loss_D: -0.1340 (0.2555) Loss_G: -0.0107 (0.1156) D(x): 0.5229 D(G(z)): 0.3808 / 0.4192 Acc: 35.9375 (32.2251)\n",
      "[10/25][666/782] Loss_D: -0.1370 (0.2554) Loss_G: -0.0425 (0.1156) D(x): 0.5596 D(G(z)): 0.4276 / 0.4347 Acc: 34.3750 (32.2254)\n",
      "[10/25][667/782] Loss_D: -0.2649 (0.2554) Loss_G: 0.0599 (0.1156) D(x): 0.5753 D(G(z)): 0.4284 / 0.4022 Acc: 50.0000 (32.2275)\n",
      "[10/25][668/782] Loss_D: -0.1923 (0.2553) Loss_G: 0.0879 (0.1156) D(x): 0.5811 D(G(z)): 0.4441 / 0.3934 Acc: 43.7500 (32.2288)\n",
      "[10/25][669/782] Loss_D: -0.0210 (0.2553) Loss_G: -0.2475 (0.1155) D(x): 0.4813 D(G(z)): 0.4260 / 0.4857 Acc: 42.1875 (32.2300)\n",
      "[10/25][670/782] Loss_D: 0.0232 (0.2553) Loss_G: -0.1530 (0.1155) D(x): 0.4724 D(G(z)): 0.4454 / 0.4660 Acc: 42.1875 (32.2312)\n",
      "[10/25][671/782] Loss_D: -0.0802 (0.2552) Loss_G: -0.1633 (0.1155) D(x): 0.5529 D(G(z)): 0.4327 / 0.4685 Acc: 32.8125 (32.2313)\n",
      "[10/25][672/782] Loss_D: 0.0068 (0.2552) Loss_G: -0.1810 (0.1154) D(x): 0.5891 D(G(z)): 0.4945 / 0.4698 Acc: 29.6875 (32.2310)\n",
      "[10/25][673/782] Loss_D: -0.0750 (0.2551) Loss_G: -0.0927 (0.1154) D(x): 0.5984 D(G(z)): 0.5466 / 0.4419 Acc: 51.5625 (32.2332)\n",
      "[10/25][674/782] Loss_D: -0.0039 (0.2551) Loss_G: 0.0222 (0.1154) D(x): 0.5178 D(G(z)): 0.4406 / 0.4006 Acc: 37.5000 (32.2339)\n",
      "[10/25][675/782] Loss_D: -0.0103 (0.2551) Loss_G: 0.1041 (0.1154) D(x): 0.5083 D(G(z)): 0.3905 / 0.3721 Acc: 26.5625 (32.2332)\n",
      "[10/25][676/782] Loss_D: 0.0611 (0.2551) Loss_G: -0.1484 (0.1154) D(x): 0.4984 D(G(z)): 0.4770 / 0.4877 Acc: 42.1875 (32.2344)\n",
      "[10/25][677/782] Loss_D: 0.1146 (0.2550) Loss_G: -0.1696 (0.1153) D(x): 0.5018 D(G(z)): 0.5238 / 0.4863 Acc: 43.7500 (32.2357)\n",
      "[10/25][678/782] Loss_D: -0.0708 (0.2550) Loss_G: 0.0342 (0.1153) D(x): 0.5932 D(G(z)): 0.4938 / 0.4158 Acc: 40.6250 (32.2367)\n",
      "[10/25][679/782] Loss_D: 0.0516 (0.2550) Loss_G: -0.2065 (0.1153) D(x): 0.5204 D(G(z)): 0.4697 / 0.4950 Acc: 35.9375 (32.2371)\n",
      "[10/25][680/782] Loss_D: -0.0052 (0.2550) Loss_G: -0.1782 (0.1152) D(x): 0.4811 D(G(z)): 0.4067 / 0.4714 Acc: 35.9375 (32.2376)\n",
      "[10/25][681/782] Loss_D: 0.0629 (0.2549) Loss_G: -0.0550 (0.1152) D(x): 0.5245 D(G(z)): 0.5570 / 0.4502 Acc: 54.6875 (32.2402)\n",
      "[10/25][682/782] Loss_D: 0.1901 (0.2549) Loss_G: 0.0180 (0.1152) D(x): 0.5456 D(G(z)): 0.5497 / 0.4096 Acc: 39.0625 (32.2410)\n",
      "[10/25][683/782] Loss_D: 0.1261 (0.2549) Loss_G: -0.1113 (0.1152) D(x): 0.4510 D(G(z)): 0.4406 / 0.4361 Acc: 35.9375 (32.2414)\n",
      "[10/25][684/782] Loss_D: 0.1991 (0.2549) Loss_G: -0.1211 (0.1152) D(x): 0.4961 D(G(z)): 0.5163 / 0.4630 Acc: 34.3750 (32.2417)\n",
      "[10/25][685/782] Loss_D: 0.1768 (0.2549) Loss_G: -0.0526 (0.1151) D(x): 0.4365 D(G(z)): 0.4714 / 0.4217 Acc: 42.1875 (32.2429)\n",
      "[10/25][686/782] Loss_D: 0.1451 (0.2549) Loss_G: -0.1644 (0.1151) D(x): 0.5103 D(G(z)): 0.5086 / 0.4689 Acc: 40.6250 (32.2439)\n",
      "[10/25][687/782] Loss_D: 0.0196 (0.2549) Loss_G: -0.1021 (0.1151) D(x): 0.5227 D(G(z)): 0.4778 / 0.4643 Acc: 42.1875 (32.2450)\n",
      "[10/25][688/782] Loss_D: 0.0466 (0.2548) Loss_G: -0.1117 (0.1150) D(x): 0.5104 D(G(z)): 0.4893 / 0.4541 Acc: 39.0625 (32.2458)\n",
      "[10/25][689/782] Loss_D: 0.0933 (0.2548) Loss_G: -0.0988 (0.1150) D(x): 0.5206 D(G(z)): 0.4799 / 0.4618 Acc: 37.5000 (32.2464)\n",
      "[10/25][690/782] Loss_D: 0.0077 (0.2548) Loss_G: 0.0044 (0.1150) D(x): 0.5039 D(G(z)): 0.5156 / 0.4168 Acc: 51.5625 (32.2487)\n",
      "[10/25][691/782] Loss_D: 0.0284 (0.2548) Loss_G: -0.0054 (0.1150) D(x): 0.4845 D(G(z)): 0.4367 / 0.4082 Acc: 39.0625 (32.2495)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/25][692/782] Loss_D: -0.0279 (0.2547) Loss_G: -0.1736 (0.1150) D(x): 0.5205 D(G(z)): 0.4803 / 0.4763 Acc: 46.8750 (32.2512)\n",
      "[10/25][693/782] Loss_D: -0.2353 (0.2547) Loss_G: -0.1174 (0.1149) D(x): 0.5844 D(G(z)): 0.4821 / 0.4442 Acc: 50.0000 (32.2533)\n",
      "[10/25][694/782] Loss_D: 0.0680 (0.2546) Loss_G: -0.0995 (0.1149) D(x): 0.5330 D(G(z)): 0.4970 / 0.4368 Acc: 39.0625 (32.2541)\n",
      "[10/25][695/782] Loss_D: -0.0977 (0.2546) Loss_G: -0.0432 (0.1149) D(x): 0.5104 D(G(z)): 0.4048 / 0.4269 Acc: 42.1875 (32.2553)\n",
      "[10/25][696/782] Loss_D: -0.1032 (0.2546) Loss_G: -0.2042 (0.1149) D(x): 0.5274 D(G(z)): 0.4068 / 0.4798 Acc: 35.9375 (32.2557)\n",
      "[10/25][697/782] Loss_D: -0.1676 (0.2545) Loss_G: -0.1426 (0.1148) D(x): 0.5933 D(G(z)): 0.4719 / 0.4484 Acc: 39.0625 (32.2565)\n",
      "[10/25][698/782] Loss_D: -0.0184 (0.2545) Loss_G: -0.0923 (0.1148) D(x): 0.5911 D(G(z)): 0.5441 / 0.4345 Acc: 39.0625 (32.2573)\n",
      "[10/25][699/782] Loss_D: 0.0017 (0.2544) Loss_G: -0.0916 (0.1148) D(x): 0.4598 D(G(z)): 0.4568 / 0.4466 Acc: 50.0000 (32.2594)\n",
      "[10/25][700/782] Loss_D: -0.0074 (0.2544) Loss_G: -0.1078 (0.1147) D(x): 0.5531 D(G(z)): 0.5085 / 0.4350 Acc: 43.7500 (32.2607)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[10/25][701/782] Loss_D: -0.0751 (0.2544) Loss_G: -0.1111 (0.1147) D(x): 0.5095 D(G(z)): 0.4337 / 0.4394 Acc: 40.6250 (32.2617)\n",
      "[10/25][702/782] Loss_D: 0.0042 (0.2543) Loss_G: -0.1746 (0.1147) D(x): 0.5230 D(G(z)): 0.4663 / 0.4817 Acc: 39.0625 (32.2625)\n",
      "[10/25][703/782] Loss_D: -0.1433 (0.2543) Loss_G: -0.2218 (0.1146) D(x): 0.5862 D(G(z)): 0.4669 / 0.4875 Acc: 37.5000 (32.2631)\n",
      "[10/25][704/782] Loss_D: -0.2229 (0.2542) Loss_G: -0.0795 (0.1146) D(x): 0.5925 D(G(z)): 0.4497 / 0.4279 Acc: 42.1875 (32.2643)\n",
      "[10/25][705/782] Loss_D: -0.2328 (0.2542) Loss_G: 0.1209 (0.1146) D(x): 0.5624 D(G(z)): 0.4242 / 0.3619 Acc: 46.8750 (32.2660)\n",
      "[10/25][706/782] Loss_D: -0.3828 (0.2541) Loss_G: -0.0693 (0.1146) D(x): 0.5278 D(G(z)): 0.3593 / 0.4324 Acc: 56.2500 (32.2688)\n",
      "[10/25][707/782] Loss_D: -0.0878 (0.2541) Loss_G: -0.0525 (0.1146) D(x): 0.5676 D(G(z)): 0.4250 / 0.4400 Acc: 32.8125 (32.2689)\n",
      "[10/25][708/782] Loss_D: 0.0195 (0.2540) Loss_G: -0.1324 (0.1146) D(x): 0.5811 D(G(z)): 0.5251 / 0.4554 Acc: 40.6250 (32.2699)\n",
      "[10/25][709/782] Loss_D: -0.0740 (0.2540) Loss_G: 0.1344 (0.1146) D(x): 0.5749 D(G(z)): 0.4924 / 0.3564 Acc: 37.5000 (32.2705)\n",
      "[10/25][710/782] Loss_D: -0.1600 (0.2540) Loss_G: 0.0262 (0.1145) D(x): 0.5247 D(G(z)): 0.4005 / 0.4054 Acc: 45.3125 (32.2720)\n",
      "[10/25][711/782] Loss_D: -0.0550 (0.2539) Loss_G: 0.2191 (0.1146) D(x): 0.5626 D(G(z)): 0.4384 / 0.3327 Acc: 32.8125 (32.2721)\n",
      "[10/25][712/782] Loss_D: -0.1042 (0.2539) Loss_G: 0.0935 (0.1146) D(x): 0.5556 D(G(z)): 0.4794 / 0.3856 Acc: 45.3125 (32.2736)\n",
      "[10/25][713/782] Loss_D: -0.0093 (0.2538) Loss_G: 0.0213 (0.1145) D(x): 0.5122 D(G(z)): 0.4381 / 0.4053 Acc: 39.0625 (32.2744)\n",
      "[10/25][714/782] Loss_D: -0.2284 (0.2538) Loss_G: -0.1287 (0.1145) D(x): 0.5725 D(G(z)): 0.4324 / 0.4533 Acc: 40.6250 (32.2754)\n",
      "[10/25][715/782] Loss_D: -0.1978 (0.2537) Loss_G: -0.0619 (0.1145) D(x): 0.5821 D(G(z)): 0.4508 / 0.4366 Acc: 48.4375 (32.2773)\n",
      "[10/25][716/782] Loss_D: -0.0430 (0.2537) Loss_G: -0.0089 (0.1145) D(x): 0.5433 D(G(z)): 0.4504 / 0.4087 Acc: 35.9375 (32.2777)\n",
      "[10/25][717/782] Loss_D: -0.0566 (0.2537) Loss_G: -0.0459 (0.1145) D(x): 0.4881 D(G(z)): 0.4603 / 0.4228 Acc: 46.8750 (32.2794)\n",
      "[10/25][718/782] Loss_D: 0.1186 (0.2537) Loss_G: -0.1711 (0.1144) D(x): 0.5311 D(G(z)): 0.5264 / 0.4677 Acc: 35.9375 (32.2798)\n",
      "[10/25][719/782] Loss_D: 0.1215 (0.2536) Loss_G: -0.2113 (0.1144) D(x): 0.5201 D(G(z)): 0.5099 / 0.4808 Acc: 35.9375 (32.2803)\n",
      "[10/25][720/782] Loss_D: -0.0999 (0.2536) Loss_G: -0.1604 (0.1144) D(x): 0.5070 D(G(z)): 0.4330 / 0.4637 Acc: 50.0000 (32.2823)\n",
      "[10/25][721/782] Loss_D: 0.1050 (0.2536) Loss_G: -0.1543 (0.1143) D(x): 0.4351 D(G(z)): 0.4976 / 0.4687 Acc: 51.5625 (32.2846)\n",
      "[10/25][722/782] Loss_D: -0.0477 (0.2535) Loss_G: -0.1053 (0.1143) D(x): 0.5298 D(G(z)): 0.4420 / 0.4451 Acc: 34.3750 (32.2848)\n",
      "[10/25][723/782] Loss_D: -0.1153 (0.2535) Loss_G: -0.1093 (0.1143) D(x): 0.5546 D(G(z)): 0.4429 / 0.4560 Acc: 37.5000 (32.2854)\n",
      "[10/25][724/782] Loss_D: -0.0584 (0.2535) Loss_G: -0.0100 (0.1143) D(x): 0.5856 D(G(z)): 0.4501 / 0.4186 Acc: 32.8125 (32.2855)\n",
      "[10/25][725/782] Loss_D: -0.2113 (0.2534) Loss_G: -0.0736 (0.1142) D(x): 0.6051 D(G(z)): 0.4815 / 0.4352 Acc: 50.0000 (32.2876)\n",
      "[10/25][726/782] Loss_D: -0.0188 (0.2534) Loss_G: 0.1071 (0.1142) D(x): 0.5587 D(G(z)): 0.4950 / 0.3701 Acc: 39.0625 (32.2884)\n",
      "[10/25][727/782] Loss_D: 0.0117 (0.2533) Loss_G: -0.1256 (0.1142) D(x): 0.4626 D(G(z)): 0.4212 / 0.4560 Acc: 42.1875 (32.2895)\n",
      "[10/25][728/782] Loss_D: -0.0175 (0.2533) Loss_G: -0.0281 (0.1142) D(x): 0.5323 D(G(z)): 0.4719 / 0.4158 Acc: 43.7500 (32.2909)\n",
      "[10/25][729/782] Loss_D: 0.1380 (0.2533) Loss_G: -0.1915 (0.1142) D(x): 0.5034 D(G(z)): 0.4442 / 0.5063 Acc: 34.3750 (32.2911)\n",
      "[10/25][730/782] Loss_D: -0.0305 (0.2533) Loss_G: -0.1245 (0.1141) D(x): 0.5329 D(G(z)): 0.4962 / 0.4418 Acc: 46.8750 (32.2928)\n",
      "[10/25][731/782] Loss_D: 0.0524 (0.2532) Loss_G: -0.1816 (0.1141) D(x): 0.5648 D(G(z)): 0.5276 / 0.4785 Acc: 39.0625 (32.2936)\n",
      "[10/25][732/782] Loss_D: 0.0277 (0.2532) Loss_G: 0.0109 (0.1141) D(x): 0.5260 D(G(z)): 0.4887 / 0.3913 Acc: 40.6250 (32.2946)\n",
      "[10/25][733/782] Loss_D: -0.0998 (0.2532) Loss_G: -0.1566 (0.1141) D(x): 0.4852 D(G(z)): 0.4255 / 0.4531 Acc: 50.0000 (32.2967)\n",
      "[10/25][734/782] Loss_D: -0.0031 (0.2531) Loss_G: -0.0905 (0.1140) D(x): 0.5066 D(G(z)): 0.4266 / 0.4338 Acc: 39.0625 (32.2975)\n",
      "[10/25][735/782] Loss_D: 0.1630 (0.2531) Loss_G: -0.2102 (0.1140) D(x): 0.4630 D(G(z)): 0.5084 / 0.4868 Acc: 42.1875 (32.2986)\n",
      "[10/25][736/782] Loss_D: -0.1405 (0.2531) Loss_G: -0.2475 (0.1139) D(x): 0.5430 D(G(z)): 0.4395 / 0.5113 Acc: 45.3125 (32.3001)\n",
      "[10/25][737/782] Loss_D: 0.0339 (0.2531) Loss_G: -0.2188 (0.1139) D(x): 0.5737 D(G(z)): 0.5317 / 0.4946 Acc: 45.3125 (32.3016)\n",
      "[10/25][738/782] Loss_D: 0.2802 (0.2531) Loss_G: -0.2171 (0.1139) D(x): 0.5158 D(G(z)): 0.5571 / 0.4925 Acc: 35.9375 (32.3021)\n",
      "[10/25][739/782] Loss_D: -0.0373 (0.2530) Loss_G: -0.0342 (0.1139) D(x): 0.4854 D(G(z)): 0.3831 / 0.4144 Acc: 35.9375 (32.3025)\n",
      "[10/25][740/782] Loss_D: -0.2512 (0.2530) Loss_G: 0.0715 (0.1138) D(x): 0.5709 D(G(z)): 0.4440 / 0.3677 Acc: 46.8750 (32.3042)\n",
      "[10/25][741/782] Loss_D: -0.0963 (0.2529) Loss_G: -0.0285 (0.1138) D(x): 0.5346 D(G(z)): 0.4855 / 0.4127 Acc: 51.5625 (32.3064)\n",
      "[10/25][742/782] Loss_D: 0.0052 (0.2529) Loss_G: -0.0585 (0.1138) D(x): 0.5663 D(G(z)): 0.5052 / 0.4281 Acc: 37.5000 (32.3071)\n",
      "[10/25][743/782] Loss_D: -0.1202 (0.2529) Loss_G: 0.0607 (0.1138) D(x): 0.5406 D(G(z)): 0.4534 / 0.3917 Acc: 48.4375 (32.3089)\n",
      "[10/25][744/782] Loss_D: -0.2014 (0.2528) Loss_G: 0.0241 (0.1138) D(x): 0.5675 D(G(z)): 0.4440 / 0.4006 Acc: 48.4375 (32.3108)\n",
      "[10/25][745/782] Loss_D: 0.0027 (0.2528) Loss_G: -0.1092 (0.1138) D(x): 0.5289 D(G(z)): 0.5061 / 0.4461 Acc: 46.8750 (32.3125)\n",
      "[10/25][746/782] Loss_D: 0.1798 (0.2528) Loss_G: -0.1665 (0.1137) D(x): 0.4364 D(G(z)): 0.4971 / 0.4757 Acc: 53.1250 (32.3150)\n",
      "[10/25][747/782] Loss_D: 0.0631 (0.2528) Loss_G: -0.2189 (0.1137) D(x): 0.4676 D(G(z)): 0.4811 / 0.4956 Acc: 51.5625 (32.3172)\n",
      "[10/25][748/782] Loss_D: 0.1801 (0.2527) Loss_G: -0.1636 (0.1137) D(x): 0.5367 D(G(z)): 0.5397 / 0.4664 Acc: 34.3750 (32.3174)\n",
      "[10/25][749/782] Loss_D: 0.1921 (0.2527) Loss_G: -0.1460 (0.1136) D(x): 0.5323 D(G(z)): 0.5558 / 0.4880 Acc: 35.9375 (32.3179)\n",
      "[10/25][750/782] Loss_D: -0.1200 (0.2527) Loss_G: -0.0399 (0.1136) D(x): 0.5690 D(G(z)): 0.4489 / 0.4300 Acc: 35.9375 (32.3183)\n",
      "[10/25][751/782] Loss_D: 0.1225 (0.2527) Loss_G: -0.1763 (0.1136) D(x): 0.4741 D(G(z)): 0.4437 / 0.4734 Acc: 37.5000 (32.3189)\n",
      "[10/25][752/782] Loss_D: 0.0422 (0.2527) Loss_G: -0.1022 (0.1136) D(x): 0.4937 D(G(z)): 0.4285 / 0.4518 Acc: 34.3750 (32.3191)\n",
      "[10/25][753/782] Loss_D: -0.0869 (0.2526) Loss_G: 0.0140 (0.1135) D(x): 0.5372 D(G(z)): 0.4407 / 0.4048 Acc: 39.0625 (32.3199)\n",
      "[10/25][754/782] Loss_D: -0.0910 (0.2526) Loss_G: -0.1238 (0.1135) D(x): 0.5730 D(G(z)): 0.4849 / 0.4473 Acc: 42.1875 (32.3211)\n",
      "[10/25][755/782] Loss_D: 0.0197 (0.2525) Loss_G: 0.0094 (0.1135) D(x): 0.5654 D(G(z)): 0.5091 / 0.4120 Acc: 46.8750 (32.3228)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/25][756/782] Loss_D: -0.1122 (0.2525) Loss_G: 0.0652 (0.1135) D(x): 0.5198 D(G(z)): 0.4554 / 0.3945 Acc: 46.8750 (32.3245)\n",
      "[10/25][757/782] Loss_D: 0.0226 (0.2525) Loss_G: 0.0334 (0.1135) D(x): 0.5409 D(G(z)): 0.4449 / 0.3988 Acc: 35.9375 (32.3249)\n",
      "[10/25][758/782] Loss_D: -0.0509 (0.2524) Loss_G: -0.0390 (0.1135) D(x): 0.5328 D(G(z)): 0.4604 / 0.4269 Acc: 43.7500 (32.3262)\n",
      "[10/25][759/782] Loss_D: -0.0757 (0.2524) Loss_G: -0.0064 (0.1135) D(x): 0.5206 D(G(z)): 0.4334 / 0.4123 Acc: 40.6250 (32.3272)\n",
      "[10/25][760/782] Loss_D: -0.0898 (0.2524) Loss_G: -0.1057 (0.1134) D(x): 0.5222 D(G(z)): 0.4613 / 0.4535 Acc: 50.0000 (32.3292)\n",
      "[10/25][761/782] Loss_D: -0.0254 (0.2523) Loss_G: -0.1290 (0.1134) D(x): 0.5502 D(G(z)): 0.4647 / 0.4712 Acc: 35.9375 (32.3297)\n",
      "[10/25][762/782] Loss_D: -0.1917 (0.2523) Loss_G: -0.1593 (0.1134) D(x): 0.5489 D(G(z)): 0.4253 / 0.4610 Acc: 50.0000 (32.3317)\n",
      "[10/25][763/782] Loss_D: -0.0967 (0.2522) Loss_G: -0.1616 (0.1133) D(x): 0.5898 D(G(z)): 0.4845 / 0.4866 Acc: 39.0625 (32.3325)\n",
      "[10/25][764/782] Loss_D: -0.1419 (0.2522) Loss_G: -0.0635 (0.1133) D(x): 0.5545 D(G(z)): 0.4914 / 0.4278 Acc: 45.3125 (32.3340)\n",
      "[10/25][765/782] Loss_D: -0.1050 (0.2522) Loss_G: -0.0689 (0.1133) D(x): 0.5049 D(G(z)): 0.4195 / 0.4423 Acc: 46.8750 (32.3357)\n",
      "[10/25][766/782] Loss_D: -0.1703 (0.2521) Loss_G: 0.0235 (0.1133) D(x): 0.5562 D(G(z)): 0.4068 / 0.4008 Acc: 42.1875 (32.3369)\n",
      "[10/25][767/782] Loss_D: 0.0479 (0.2521) Loss_G: -0.0995 (0.1133) D(x): 0.5636 D(G(z)): 0.5480 / 0.4696 Acc: 50.0000 (32.3389)\n",
      "[10/25][768/782] Loss_D: 0.0445 (0.2521) Loss_G: -0.0554 (0.1132) D(x): 0.5134 D(G(z)): 0.4451 / 0.4233 Acc: 37.5000 (32.3395)\n",
      "[10/25][769/782] Loss_D: 0.0422 (0.2520) Loss_G: 0.0301 (0.1132) D(x): 0.4980 D(G(z)): 0.4759 / 0.3876 Acc: 45.3125 (32.3410)\n",
      "[10/25][770/782] Loss_D: -0.0613 (0.2520) Loss_G: -0.1195 (0.1132) D(x): 0.5501 D(G(z)): 0.4554 / 0.4490 Acc: 39.0625 (32.3418)\n",
      "[10/25][771/782] Loss_D: -0.1234 (0.2519) Loss_G: -0.1087 (0.1132) D(x): 0.5290 D(G(z)): 0.3939 / 0.4795 Acc: 39.0625 (32.3426)\n",
      "[10/25][772/782] Loss_D: 0.0903 (0.2519) Loss_G: -0.3215 (0.1131) D(x): 0.4607 D(G(z)): 0.4291 / 0.5345 Acc: 29.6875 (32.3423)\n",
      "[10/25][773/782] Loss_D: 0.0231 (0.2519) Loss_G: -0.2027 (0.1131) D(x): 0.5571 D(G(z)): 0.5125 / 0.4780 Acc: 37.5000 (32.3429)\n",
      "[10/25][774/782] Loss_D: 0.0856 (0.2519) Loss_G: -0.1132 (0.1131) D(x): 0.5478 D(G(z)): 0.5551 / 0.4547 Acc: 46.8750 (32.3446)\n",
      "[10/25][775/782] Loss_D: -0.1030 (0.2518) Loss_G: -0.0039 (0.1131) D(x): 0.5541 D(G(z)): 0.4573 / 0.4112 Acc: 40.6250 (32.3455)\n",
      "[10/25][776/782] Loss_D: -0.1947 (0.2518) Loss_G: -0.1076 (0.1130) D(x): 0.5017 D(G(z)): 0.3847 / 0.4369 Acc: 43.7500 (32.3469)\n",
      "[10/25][777/782] Loss_D: -0.0994 (0.2517) Loss_G: 0.0607 (0.1130) D(x): 0.5643 D(G(z)): 0.4550 / 0.3883 Acc: 39.0625 (32.3476)\n",
      "[10/25][778/782] Loss_D: -0.2738 (0.2517) Loss_G: -0.1403 (0.1130) D(x): 0.5410 D(G(z)): 0.4399 / 0.4616 Acc: 56.2500 (32.3504)\n",
      "[10/25][779/782] Loss_D: -0.0144 (0.2517) Loss_G: -0.0209 (0.1130) D(x): 0.5199 D(G(z)): 0.4640 / 0.4291 Acc: 43.7500 (32.3517)\n",
      "[10/25][780/782] Loss_D: -0.2106 (0.2516) Loss_G: -0.0065 (0.1130) D(x): 0.5659 D(G(z)): 0.4407 / 0.4039 Acc: 45.3125 (32.3533)\n",
      "[10/25][781/782] Loss_D: 0.2352 (0.2516) Loss_G: 0.0876 (0.1130) D(x): 0.5230 D(G(z)): 0.5305 / 0.4020 Acc: 37.5000 (32.3538)\n",
      "[11/25][0/782] Loss_D: -0.0990 (0.2516) Loss_G: -0.0202 (0.1129) D(x): 0.5544 D(G(z)): 0.4707 / 0.4109 Acc: 40.6250 (32.3548)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[11/25][1/782] Loss_D: -0.1569 (0.2515) Loss_G: 0.1284 (0.1129) D(x): 0.5471 D(G(z)): 0.4212 / 0.3697 Acc: 45.3125 (32.3563)\n",
      "[11/25][2/782] Loss_D: 0.1009 (0.2515) Loss_G: -0.1680 (0.1129) D(x): 0.5111 D(G(z)): 0.4533 / 0.4764 Acc: 34.3750 (32.3566)\n",
      "[11/25][3/782] Loss_D: 0.0858 (0.2515) Loss_G: -0.1087 (0.1129) D(x): 0.4658 D(G(z)): 0.4672 / 0.4510 Acc: 40.6250 (32.3575)\n",
      "[11/25][4/782] Loss_D: 0.0942 (0.2515) Loss_G: -0.1246 (0.1129) D(x): 0.5514 D(G(z)): 0.4948 / 0.4441 Acc: 32.8125 (32.3576)\n",
      "[11/25][5/782] Loss_D: -0.0854 (0.2514) Loss_G: -0.1533 (0.1128) D(x): 0.5744 D(G(z)): 0.5056 / 0.4635 Acc: 46.8750 (32.3593)\n",
      "[11/25][6/782] Loss_D: 0.0777 (0.2514) Loss_G: -0.0588 (0.1128) D(x): 0.5185 D(G(z)): 0.4812 / 0.4592 Acc: 43.7500 (32.3606)\n",
      "[11/25][7/782] Loss_D: 0.0529 (0.2514) Loss_G: -0.1098 (0.1128) D(x): 0.5190 D(G(z)): 0.5223 / 0.4501 Acc: 48.4375 (32.3624)\n",
      "[11/25][8/782] Loss_D: 0.0381 (0.2514) Loss_G: -0.0586 (0.1128) D(x): 0.4909 D(G(z)): 0.4330 / 0.4125 Acc: 37.5000 (32.3630)\n",
      "[11/25][9/782] Loss_D: 0.0304 (0.2513) Loss_G: -0.1661 (0.1127) D(x): 0.5454 D(G(z)): 0.4851 / 0.4806 Acc: 39.0625 (32.3638)\n",
      "[11/25][10/782] Loss_D: -0.0671 (0.2513) Loss_G: -0.0759 (0.1127) D(x): 0.5193 D(G(z)): 0.4857 / 0.4464 Acc: 48.4375 (32.3657)\n",
      "[11/25][11/782] Loss_D: 0.1244 (0.2513) Loss_G: -0.1504 (0.1127) D(x): 0.4486 D(G(z)): 0.4561 / 0.4783 Acc: 37.5000 (32.3663)\n",
      "[11/25][12/782] Loss_D: 0.1314 (0.2513) Loss_G: -0.0369 (0.1127) D(x): 0.5259 D(G(z)): 0.5031 / 0.4323 Acc: 35.9375 (32.3667)\n",
      "[11/25][13/782] Loss_D: 0.1022 (0.2512) Loss_G: -0.1212 (0.1126) D(x): 0.5260 D(G(z)): 0.4980 / 0.4684 Acc: 40.6250 (32.3677)\n",
      "[11/25][14/782] Loss_D: -0.0220 (0.2512) Loss_G: -0.1124 (0.1126) D(x): 0.5021 D(G(z)): 0.4578 / 0.4432 Acc: 48.4375 (32.3695)\n",
      "[11/25][15/782] Loss_D: -0.1811 (0.2512) Loss_G: -0.1647 (0.1126) D(x): 0.5572 D(G(z)): 0.4493 / 0.4756 Acc: 53.1250 (32.3719)\n",
      "[11/25][16/782] Loss_D: 0.0045 (0.2511) Loss_G: -0.0874 (0.1126) D(x): 0.5396 D(G(z)): 0.4816 / 0.4419 Acc: 42.1875 (32.3731)\n",
      "[11/25][17/782] Loss_D: -0.0768 (0.2511) Loss_G: -0.1156 (0.1125) D(x): 0.5185 D(G(z)): 0.4520 / 0.4464 Acc: 48.4375 (32.3749)\n",
      "[11/25][18/782] Loss_D: 0.0141 (0.2511) Loss_G: -0.1950 (0.1125) D(x): 0.5474 D(G(z)): 0.5041 / 0.4887 Acc: 45.3125 (32.3764)\n",
      "[11/25][19/782] Loss_D: 0.0265 (0.2510) Loss_G: -0.1020 (0.1125) D(x): 0.5395 D(G(z)): 0.4578 / 0.4601 Acc: 32.8125 (32.3765)\n",
      "[11/25][20/782] Loss_D: -0.0292 (0.2510) Loss_G: -0.1413 (0.1124) D(x): 0.5704 D(G(z)): 0.5137 / 0.4624 Acc: 40.6250 (32.3774)\n",
      "[11/25][21/782] Loss_D: -0.0740 (0.2510) Loss_G: 0.0376 (0.1124) D(x): 0.5561 D(G(z)): 0.4571 / 0.4026 Acc: 43.7500 (32.3788)\n",
      "[11/25][22/782] Loss_D: -0.0648 (0.2509) Loss_G: 0.0472 (0.1124) D(x): 0.5193 D(G(z)): 0.4138 / 0.4015 Acc: 37.5000 (32.3793)\n",
      "[11/25][23/782] Loss_D: 0.1230 (0.2509) Loss_G: -0.1417 (0.1124) D(x): 0.4758 D(G(z)): 0.4680 / 0.4693 Acc: 37.5000 (32.3799)\n",
      "[11/25][24/782] Loss_D: 0.1241 (0.2509) Loss_G: -0.2222 (0.1124) D(x): 0.4800 D(G(z)): 0.4672 / 0.5111 Acc: 43.7500 (32.3813)\n",
      "[11/25][25/782] Loss_D: 0.2740 (0.2509) Loss_G: -0.0023 (0.1123) D(x): 0.5088 D(G(z)): 0.5683 / 0.4235 Acc: 40.6250 (32.3822)\n",
      "[11/25][26/782] Loss_D: -0.2692 (0.2508) Loss_G: -0.0786 (0.1123) D(x): 0.5544 D(G(z)): 0.4664 / 0.4196 Acc: 56.2500 (32.3850)\n",
      "[11/25][27/782] Loss_D: 0.1167 (0.2508) Loss_G: -0.1053 (0.1123) D(x): 0.4598 D(G(z)): 0.4645 / 0.4640 Acc: 42.1875 (32.3861)\n",
      "[11/25][28/782] Loss_D: 0.0512 (0.2508) Loss_G: -0.1688 (0.1123) D(x): 0.5060 D(G(z)): 0.4362 / 0.4657 Acc: 32.8125 (32.3862)\n",
      "[11/25][29/782] Loss_D: -0.1073 (0.2508) Loss_G: -0.0849 (0.1122) D(x): 0.5764 D(G(z)): 0.4576 / 0.4512 Acc: 37.5000 (32.3868)\n",
      "[11/25][30/782] Loss_D: -0.0770 (0.2507) Loss_G: -0.1232 (0.1122) D(x): 0.5798 D(G(z)): 0.5166 / 0.4645 Acc: 46.8750 (32.3884)\n",
      "[11/25][31/782] Loss_D: -0.1863 (0.2507) Loss_G: 0.1126 (0.1122) D(x): 0.5421 D(G(z)): 0.4318 / 0.3740 Acc: 48.4375 (32.3903)\n",
      "[11/25][32/782] Loss_D: -0.0770 (0.2506) Loss_G: 0.0278 (0.1122) D(x): 0.5404 D(G(z)): 0.4836 / 0.4046 Acc: 48.4375 (32.3922)\n",
      "[11/25][33/782] Loss_D: -0.1096 (0.2506) Loss_G: 0.0125 (0.1122) D(x): 0.5744 D(G(z)): 0.4546 / 0.4054 Acc: 43.7500 (32.3935)\n",
      "[11/25][34/782] Loss_D: -0.0328 (0.2506) Loss_G: -0.0204 (0.1122) D(x): 0.5299 D(G(z)): 0.4557 / 0.4252 Acc: 46.8750 (32.3951)\n",
      "[11/25][35/782] Loss_D: 0.0621 (0.2505) Loss_G: 0.0657 (0.1122) D(x): 0.4941 D(G(z)): 0.4573 / 0.3981 Acc: 42.1875 (32.3963)\n",
      "[11/25][36/782] Loss_D: 0.1555 (0.2505) Loss_G: -0.1805 (0.1121) D(x): 0.4452 D(G(z)): 0.4543 / 0.4659 Acc: 42.1875 (32.3974)\n",
      "[11/25][37/782] Loss_D: 0.1293 (0.2505) Loss_G: -0.1782 (0.1121) D(x): 0.5652 D(G(z)): 0.5545 / 0.5057 Acc: 43.7500 (32.3987)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/25][38/782] Loss_D: -0.0032 (0.2505) Loss_G: -0.2307 (0.1121) D(x): 0.5431 D(G(z)): 0.4940 / 0.4978 Acc: 45.3125 (32.4002)\n",
      "[11/25][39/782] Loss_D: -0.0376 (0.2505) Loss_G: -0.1460 (0.1120) D(x): 0.4959 D(G(z)): 0.4407 / 0.4573 Acc: 48.4375 (32.4021)\n",
      "[11/25][40/782] Loss_D: 0.1854 (0.2504) Loss_G: -0.1067 (0.1120) D(x): 0.5369 D(G(z)): 0.5450 / 0.4417 Acc: 35.9375 (32.4025)\n",
      "[11/25][41/782] Loss_D: 0.0652 (0.2504) Loss_G: -0.0553 (0.1120) D(x): 0.4878 D(G(z)): 0.4353 / 0.4345 Acc: 37.5000 (32.4031)\n",
      "[11/25][42/782] Loss_D: 0.2422 (0.2504) Loss_G: -0.2333 (0.1119) D(x): 0.4595 D(G(z)): 0.4980 / 0.5201 Acc: 32.8125 (32.4031)\n",
      "[11/25][43/782] Loss_D: 0.0431 (0.2504) Loss_G: -0.0894 (0.1119) D(x): 0.5518 D(G(z)): 0.5279 / 0.4394 Acc: 40.6250 (32.4041)\n",
      "[11/25][44/782] Loss_D: -0.0468 (0.2504) Loss_G: -0.1457 (0.1119) D(x): 0.5052 D(G(z)): 0.4573 / 0.4618 Acc: 43.7500 (32.4054)\n",
      "[11/25][45/782] Loss_D: 0.0820 (0.2503) Loss_G: 0.1202 (0.1119) D(x): 0.5121 D(G(z)): 0.4575 / 0.3719 Acc: 39.0625 (32.4062)\n",
      "[11/25][46/782] Loss_D: 0.1149 (0.2503) Loss_G: 0.0301 (0.1119) D(x): 0.4540 D(G(z)): 0.4386 / 0.4076 Acc: 45.3125 (32.4076)\n",
      "[11/25][47/782] Loss_D: -0.1701 (0.2503) Loss_G: -0.0196 (0.1119) D(x): 0.5603 D(G(z)): 0.4865 / 0.4142 Acc: 57.8125 (32.4106)\n",
      "[11/25][48/782] Loss_D: -0.1007 (0.2502) Loss_G: -0.0344 (0.1119) D(x): 0.5228 D(G(z)): 0.4537 / 0.4264 Acc: 48.4375 (32.4124)\n",
      "[11/25][49/782] Loss_D: -0.1200 (0.2502) Loss_G: -0.0329 (0.1118) D(x): 0.5901 D(G(z)): 0.4754 / 0.4193 Acc: 37.5000 (32.4130)\n",
      "[11/25][50/782] Loss_D: -0.1343 (0.2502) Loss_G: 0.0450 (0.1118) D(x): 0.5188 D(G(z)): 0.4318 / 0.4031 Acc: 46.8750 (32.4147)\n",
      "[11/25][51/782] Loss_D: -0.0696 (0.2501) Loss_G: -0.1079 (0.1118) D(x): 0.5043 D(G(z)): 0.4330 / 0.4445 Acc: 46.8750 (32.4164)\n",
      "[11/25][52/782] Loss_D: -0.0301 (0.2501) Loss_G: -0.0363 (0.1118) D(x): 0.5562 D(G(z)): 0.4902 / 0.4317 Acc: 42.1875 (32.4175)\n",
      "[11/25][53/782] Loss_D: -0.1140 (0.2500) Loss_G: 0.0716 (0.1118) D(x): 0.5719 D(G(z)): 0.4915 / 0.3814 Acc: 46.8750 (32.4192)\n",
      "[11/25][54/782] Loss_D: -0.1655 (0.2500) Loss_G: -0.0784 (0.1118) D(x): 0.5344 D(G(z)): 0.4174 / 0.4210 Acc: 50.0000 (32.4212)\n",
      "[11/25][55/782] Loss_D: -0.2048 (0.2499) Loss_G: 0.0386 (0.1118) D(x): 0.5646 D(G(z)): 0.4230 / 0.3894 Acc: 43.7500 (32.4225)\n",
      "[11/25][56/782] Loss_D: -0.1293 (0.2499) Loss_G: -0.1102 (0.1117) D(x): 0.5280 D(G(z)): 0.4526 / 0.4505 Acc: 51.5625 (32.4247)\n",
      "[11/25][57/782] Loss_D: 0.0109 (0.2499) Loss_G: -0.0516 (0.1117) D(x): 0.5170 D(G(z)): 0.5061 / 0.4280 Acc: 46.8750 (32.4264)\n",
      "[11/25][58/782] Loss_D: -0.0565 (0.2498) Loss_G: -0.0479 (0.1117) D(x): 0.5211 D(G(z)): 0.4100 / 0.4274 Acc: 37.5000 (32.4270)\n",
      "[11/25][59/782] Loss_D: -0.1982 (0.2498) Loss_G: -0.2199 (0.1116) D(x): 0.5502 D(G(z)): 0.4217 / 0.4942 Acc: 43.7500 (32.4283)\n",
      "[11/25][60/782] Loss_D: -0.2009 (0.2497) Loss_G: -0.0867 (0.1116) D(x): 0.5462 D(G(z)): 0.4715 / 0.4371 Acc: 54.6875 (32.4308)\n",
      "[11/25][61/782] Loss_D: 0.0828 (0.2497) Loss_G: 0.0073 (0.1116) D(x): 0.5375 D(G(z)): 0.5080 / 0.4128 Acc: 39.0625 (32.4316)\n",
      "[11/25][62/782] Loss_D: -0.0587 (0.2497) Loss_G: -0.1376 (0.1116) D(x): 0.5569 D(G(z)): 0.4762 / 0.4539 Acc: 42.1875 (32.4327)\n",
      "[11/25][63/782] Loss_D: -0.0935 (0.2496) Loss_G: -0.0049 (0.1116) D(x): 0.5170 D(G(z)): 0.4092 / 0.4046 Acc: 42.1875 (32.4339)\n",
      "[11/25][64/782] Loss_D: -0.0867 (0.2496) Loss_G: -0.0767 (0.1116) D(x): 0.5243 D(G(z)): 0.4354 / 0.4289 Acc: 45.3125 (32.4354)\n",
      "[11/25][65/782] Loss_D: -0.1720 (0.2496) Loss_G: -0.0936 (0.1115) D(x): 0.5087 D(G(z)): 0.3960 / 0.4475 Acc: 45.3125 (32.4368)\n",
      "[11/25][66/782] Loss_D: 0.0483 (0.2495) Loss_G: -0.3117 (0.1115) D(x): 0.4713 D(G(z)): 0.4529 / 0.5427 Acc: 43.7500 (32.4381)\n",
      "[11/25][67/782] Loss_D: -0.0392 (0.2495) Loss_G: -0.1619 (0.1114) D(x): 0.5878 D(G(z)): 0.5467 / 0.4649 Acc: 51.5625 (32.4403)\n",
      "[11/25][68/782] Loss_D: -0.0802 (0.2495) Loss_G: -0.1578 (0.1114) D(x): 0.5125 D(G(z)): 0.4394 / 0.4766 Acc: 50.0000 (32.4424)\n",
      "[11/25][69/782] Loss_D: 0.1512 (0.2494) Loss_G: -0.1023 (0.1114) D(x): 0.5146 D(G(z)): 0.5148 / 0.4465 Acc: 32.8125 (32.4424)\n",
      "[11/25][70/782] Loss_D: -0.0408 (0.2494) Loss_G: -0.0879 (0.1114) D(x): 0.5080 D(G(z)): 0.4484 / 0.4251 Acc: 43.7500 (32.4437)\n",
      "[11/25][71/782] Loss_D: 0.1093 (0.2494) Loss_G: -0.2547 (0.1113) D(x): 0.4687 D(G(z)): 0.5106 / 0.5136 Acc: 51.5625 (32.4459)\n",
      "[11/25][72/782] Loss_D: 0.1508 (0.2494) Loss_G: -0.0605 (0.1113) D(x): 0.5177 D(G(z)): 0.5078 / 0.4336 Acc: 32.8125 (32.4460)\n",
      "[11/25][73/782] Loss_D: -0.0288 (0.2494) Loss_G: -0.0008 (0.1113) D(x): 0.5221 D(G(z)): 0.4733 / 0.4137 Acc: 46.8750 (32.4476)\n",
      "[11/25][74/782] Loss_D: 0.0029 (0.2493) Loss_G: -0.1214 (0.1113) D(x): 0.5161 D(G(z)): 0.4671 / 0.4526 Acc: 42.1875 (32.4488)\n",
      "[11/25][75/782] Loss_D: 0.0120 (0.2493) Loss_G: -0.0971 (0.1112) D(x): 0.5082 D(G(z)): 0.4837 / 0.4500 Acc: 42.1875 (32.4499)\n",
      "[11/25][76/782] Loss_D: -0.2413 (0.2492) Loss_G: -0.0507 (0.1112) D(x): 0.5756 D(G(z)): 0.4586 / 0.4143 Acc: 46.8750 (32.4515)\n",
      "[11/25][77/782] Loss_D: -0.0101 (0.2492) Loss_G: -0.1377 (0.1112) D(x): 0.4930 D(G(z)): 0.4875 / 0.4500 Acc: 51.5625 (32.4537)\n",
      "[11/25][78/782] Loss_D: 0.0110 (0.2492) Loss_G: -0.2478 (0.1112) D(x): 0.5124 D(G(z)): 0.4668 / 0.5040 Acc: 39.0625 (32.4545)\n",
      "[11/25][79/782] Loss_D: 0.1095 (0.2492) Loss_G: -0.1856 (0.1111) D(x): 0.5337 D(G(z)): 0.5209 / 0.4737 Acc: 32.8125 (32.4545)\n",
      "[11/25][80/782] Loss_D: -0.0074 (0.2491) Loss_G: -0.0626 (0.1111) D(x): 0.5342 D(G(z)): 0.4803 / 0.4242 Acc: 42.1875 (32.4557)\n",
      "[11/25][81/782] Loss_D: -0.1268 (0.2491) Loss_G: -0.0233 (0.1111) D(x): 0.5410 D(G(z)): 0.4602 / 0.4207 Acc: 48.4375 (32.4575)\n",
      "[11/25][82/782] Loss_D: -0.0496 (0.2491) Loss_G: -0.1086 (0.1111) D(x): 0.4808 D(G(z)): 0.4158 / 0.4386 Acc: 42.1875 (32.4586)\n",
      "[11/25][83/782] Loss_D: -0.0186 (0.2490) Loss_G: -0.1565 (0.1110) D(x): 0.5399 D(G(z)): 0.4836 / 0.4586 Acc: 40.6250 (32.4596)\n",
      "[11/25][84/782] Loss_D: -0.1668 (0.2490) Loss_G: -0.0787 (0.1110) D(x): 0.5466 D(G(z)): 0.4763 / 0.4191 Acc: 46.8750 (32.4612)\n",
      "[11/25][85/782] Loss_D: 0.0962 (0.2490) Loss_G: -0.0506 (0.1110) D(x): 0.4814 D(G(z)): 0.4582 / 0.4354 Acc: 34.3750 (32.4614)\n",
      "[11/25][86/782] Loss_D: -0.0107 (0.2489) Loss_G: -0.1438 (0.1110) D(x): 0.4890 D(G(z)): 0.4613 / 0.4549 Acc: 46.8750 (32.4631)\n",
      "[11/25][87/782] Loss_D: -0.1531 (0.2489) Loss_G: -0.2000 (0.1109) D(x): 0.5964 D(G(z)): 0.5184 / 0.5019 Acc: 51.5625 (32.4653)\n",
      "[11/25][88/782] Loss_D: -0.1736 (0.2488) Loss_G: -0.1039 (0.1109) D(x): 0.5698 D(G(z)): 0.4984 / 0.4354 Acc: 56.2500 (32.4680)\n",
      "[11/25][89/782] Loss_D: -0.1830 (0.2488) Loss_G: -0.0871 (0.1109) D(x): 0.5464 D(G(z)): 0.4613 / 0.4322 Acc: 48.4375 (32.4699)\n",
      "[11/25][90/782] Loss_D: -0.0629 (0.2488) Loss_G: -0.1612 (0.1108) D(x): 0.4955 D(G(z)): 0.4257 / 0.4734 Acc: 43.7500 (32.4712)\n",
      "[11/25][91/782] Loss_D: -0.1829 (0.2487) Loss_G: -0.0729 (0.1108) D(x): 0.5216 D(G(z)): 0.4102 / 0.4456 Acc: 50.0000 (32.4732)\n",
      "[11/25][92/782] Loss_D: -0.0191 (0.2487) Loss_G: -0.2404 (0.1108) D(x): 0.5338 D(G(z)): 0.4391 / 0.5062 Acc: 37.5000 (32.4738)\n",
      "[11/25][93/782] Loss_D: -0.0653 (0.2486) Loss_G: -0.1866 (0.1107) D(x): 0.5289 D(G(z)): 0.5030 / 0.4660 Acc: 50.0000 (32.4758)\n",
      "[11/25][94/782] Loss_D: 0.2407 (0.2486) Loss_G: -0.0479 (0.1107) D(x): 0.5482 D(G(z)): 0.5595 / 0.4348 Acc: 32.8125 (32.4758)\n",
      "[11/25][95/782] Loss_D: -0.1673 (0.2486) Loss_G: -0.1320 (0.1107) D(x): 0.4885 D(G(z)): 0.4155 / 0.4462 Acc: 53.1250 (32.4782)\n",
      "[11/25][96/782] Loss_D: -0.0939 (0.2485) Loss_G: -0.1248 (0.1107) D(x): 0.5166 D(G(z)): 0.4604 / 0.4616 Acc: 45.3125 (32.4797)\n",
      "[11/25][97/782] Loss_D: -0.1329 (0.2485) Loss_G: -0.1866 (0.1106) D(x): 0.5019 D(G(z)): 0.4248 / 0.5021 Acc: 48.4375 (32.4815)\n",
      "[11/25][98/782] Loss_D: -0.1920 (0.2485) Loss_G: -0.1217 (0.1106) D(x): 0.6254 D(G(z)): 0.5070 / 0.4644 Acc: 51.5625 (32.4837)\n",
      "[11/25][99/782] Loss_D: -0.0461 (0.2484) Loss_G: 0.0770 (0.1106) D(x): 0.5918 D(G(z)): 0.5195 / 0.3831 Acc: 42.1875 (32.4848)\n",
      "[11/25][100/782] Loss_D: -0.1526 (0.2484) Loss_G: -0.0504 (0.1106) D(x): 0.5223 D(G(z)): 0.4410 / 0.4316 Acc: 54.6875 (32.4874)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[11/25][101/782] Loss_D: -0.0672 (0.2483) Loss_G: -0.0754 (0.1106) D(x): 0.5232 D(G(z)): 0.4511 / 0.4335 Acc: 43.7500 (32.4887)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/25][102/782] Loss_D: 0.0062 (0.2483) Loss_G: -0.0759 (0.1105) D(x): 0.4903 D(G(z)): 0.4294 / 0.4482 Acc: 39.0625 (32.4894)\n",
      "[11/25][103/782] Loss_D: 0.0179 (0.2483) Loss_G: -0.0613 (0.1105) D(x): 0.5163 D(G(z)): 0.4537 / 0.4351 Acc: 34.3750 (32.4896)\n",
      "[11/25][104/782] Loss_D: -0.2051 (0.2482) Loss_G: -0.0754 (0.1105) D(x): 0.5705 D(G(z)): 0.4680 / 0.4413 Acc: 51.5625 (32.4918)\n",
      "[11/25][105/782] Loss_D: -0.1555 (0.2482) Loss_G: -0.0713 (0.1105) D(x): 0.5201 D(G(z)): 0.4391 / 0.4249 Acc: 46.8750 (32.4935)\n",
      "[11/25][106/782] Loss_D: -0.1713 (0.2481) Loss_G: -0.0965 (0.1105) D(x): 0.5732 D(G(z)): 0.4479 / 0.4446 Acc: 46.8750 (32.4951)\n",
      "[11/25][107/782] Loss_D: -0.1132 (0.2481) Loss_G: -0.0595 (0.1104) D(x): 0.5568 D(G(z)): 0.4552 / 0.4412 Acc: 50.0000 (32.4971)\n",
      "[11/25][108/782] Loss_D: -0.1727 (0.2480) Loss_G: 0.0795 (0.1104) D(x): 0.5573 D(G(z)): 0.4285 / 0.3884 Acc: 40.6250 (32.4981)\n",
      "[11/25][109/782] Loss_D: -0.3209 (0.2480) Loss_G: -0.0058 (0.1104) D(x): 0.5259 D(G(z)): 0.3709 / 0.4280 Acc: 53.1250 (32.5004)\n",
      "[11/25][110/782] Loss_D: 0.1270 (0.2480) Loss_G: -0.2432 (0.1104) D(x): 0.5122 D(G(z)): 0.5527 / 0.5161 Acc: 48.4375 (32.5023)\n",
      "[11/25][111/782] Loss_D: -0.2894 (0.2479) Loss_G: -0.1593 (0.1104) D(x): 0.5736 D(G(z)): 0.4463 / 0.4644 Acc: 54.6875 (32.5048)\n",
      "[11/25][112/782] Loss_D: -0.1546 (0.2479) Loss_G: -0.1224 (0.1103) D(x): 0.5304 D(G(z)): 0.4532 / 0.4498 Acc: 51.5625 (32.5070)\n",
      "[11/25][113/782] Loss_D: -0.1753 (0.2478) Loss_G: -0.0727 (0.1103) D(x): 0.5362 D(G(z)): 0.4206 / 0.4418 Acc: 48.4375 (32.5088)\n",
      "[11/25][114/782] Loss_D: -0.1191 (0.2478) Loss_G: -0.2178 (0.1103) D(x): 0.5453 D(G(z)): 0.4432 / 0.5035 Acc: 45.3125 (32.5103)\n",
      "[11/25][115/782] Loss_D: 0.0675 (0.2477) Loss_G: 0.0331 (0.1103) D(x): 0.5525 D(G(z)): 0.5014 / 0.4136 Acc: 32.8125 (32.5103)\n",
      "[11/25][116/782] Loss_D: -0.1849 (0.2477) Loss_G: 0.0759 (0.1103) D(x): 0.5540 D(G(z)): 0.4215 / 0.3908 Acc: 43.7500 (32.5116)\n",
      "[11/25][117/782] Loss_D: 0.0650 (0.2477) Loss_G: -0.1015 (0.1102) D(x): 0.5042 D(G(z)): 0.4753 / 0.4394 Acc: 37.5000 (32.5122)\n",
      "[11/25][118/782] Loss_D: -0.0099 (0.2476) Loss_G: -0.1281 (0.1102) D(x): 0.5331 D(G(z)): 0.5017 / 0.4721 Acc: 53.1250 (32.5145)\n",
      "[11/25][119/782] Loss_D: -0.0426 (0.2476) Loss_G: -0.1365 (0.1102) D(x): 0.5439 D(G(z)): 0.4724 / 0.4583 Acc: 45.3125 (32.5160)\n",
      "[11/25][120/782] Loss_D: 0.0329 (0.2476) Loss_G: -0.0025 (0.1102) D(x): 0.5605 D(G(z)): 0.5036 / 0.4046 Acc: 39.0625 (32.5168)\n",
      "[11/25][121/782] Loss_D: 0.0661 (0.2476) Loss_G: -0.0745 (0.1101) D(x): 0.4581 D(G(z)): 0.4483 / 0.4565 Acc: 48.4375 (32.5186)\n",
      "[11/25][122/782] Loss_D: -0.0393 (0.2475) Loss_G: -0.2253 (0.1101) D(x): 0.5181 D(G(z)): 0.4259 / 0.4959 Acc: 32.8125 (32.5186)\n",
      "[11/25][123/782] Loss_D: -0.0140 (0.2475) Loss_G: -0.0679 (0.1101) D(x): 0.5812 D(G(z)): 0.5129 / 0.4464 Acc: 48.4375 (32.5204)\n",
      "[11/25][124/782] Loss_D: 0.0564 (0.2475) Loss_G: -0.0362 (0.1101) D(x): 0.5405 D(G(z)): 0.5121 / 0.4332 Acc: 43.7500 (32.5217)\n",
      "[11/25][125/782] Loss_D: -0.2004 (0.2474) Loss_G: 0.0814 (0.1101) D(x): 0.5682 D(G(z)): 0.4305 / 0.3904 Acc: 46.8750 (32.5234)\n",
      "[11/25][126/782] Loss_D: 0.0065 (0.2474) Loss_G: -0.0957 (0.1100) D(x): 0.5531 D(G(z)): 0.4578 / 0.4505 Acc: 29.6875 (32.5231)\n",
      "[11/25][127/782] Loss_D: 0.0997 (0.2474) Loss_G: -0.1493 (0.1100) D(x): 0.4892 D(G(z)): 0.4937 / 0.4628 Acc: 46.8750 (32.5247)\n",
      "[11/25][128/782] Loss_D: 0.1279 (0.2474) Loss_G: -0.1172 (0.1100) D(x): 0.4798 D(G(z)): 0.4582 / 0.4484 Acc: 40.6250 (32.5256)\n",
      "[11/25][129/782] Loss_D: -0.0474 (0.2473) Loss_G: -0.0063 (0.1100) D(x): 0.5535 D(G(z)): 0.4843 / 0.4089 Acc: 39.0625 (32.5264)\n",
      "[11/25][130/782] Loss_D: -0.1628 (0.2473) Loss_G: -0.0655 (0.1100) D(x): 0.5770 D(G(z)): 0.4767 / 0.4214 Acc: 42.1875 (32.5275)\n",
      "[11/25][131/782] Loss_D: 0.1062 (0.2473) Loss_G: 0.0308 (0.1099) D(x): 0.5140 D(G(z)): 0.5009 / 0.4039 Acc: 37.5000 (32.5281)\n",
      "[11/25][132/782] Loss_D: -0.0616 (0.2472) Loss_G: -0.1412 (0.1099) D(x): 0.5318 D(G(z)): 0.4761 / 0.4670 Acc: 48.4375 (32.5299)\n",
      "[11/25][133/782] Loss_D: -0.0974 (0.2472) Loss_G: -0.1010 (0.1099) D(x): 0.4723 D(G(z)): 0.4105 / 0.4310 Acc: 46.8750 (32.5315)\n",
      "[11/25][134/782] Loss_D: -0.0781 (0.2472) Loss_G: -0.1371 (0.1099) D(x): 0.5993 D(G(z)): 0.5141 / 0.4618 Acc: 45.3125 (32.5330)\n",
      "[11/25][135/782] Loss_D: 0.0770 (0.2471) Loss_G: 0.0382 (0.1099) D(x): 0.4876 D(G(z)): 0.4824 / 0.4040 Acc: 42.1875 (32.5341)\n",
      "[11/25][136/782] Loss_D: 0.0178 (0.2471) Loss_G: -0.0022 (0.1098) D(x): 0.4991 D(G(z)): 0.4522 / 0.4150 Acc: 40.6250 (32.5350)\n",
      "[11/25][137/782] Loss_D: -0.1389 (0.2471) Loss_G: -0.0338 (0.1098) D(x): 0.5607 D(G(z)): 0.4477 / 0.4065 Acc: 39.0625 (32.5358)\n",
      "[11/25][138/782] Loss_D: -0.0959 (0.2470) Loss_G: -0.2064 (0.1098) D(x): 0.4961 D(G(z)): 0.4334 / 0.4914 Acc: 51.5625 (32.5379)\n",
      "[11/25][139/782] Loss_D: -0.1370 (0.2470) Loss_G: -0.0739 (0.1098) D(x): 0.5479 D(G(z)): 0.4296 / 0.4392 Acc: 39.0625 (32.5387)\n",
      "[11/25][140/782] Loss_D: -0.0868 (0.2470) Loss_G: -0.1516 (0.1097) D(x): 0.5814 D(G(z)): 0.4846 / 0.4581 Acc: 37.5000 (32.5392)\n",
      "[11/25][141/782] Loss_D: -0.0980 (0.2469) Loss_G: -0.0777 (0.1097) D(x): 0.5550 D(G(z)): 0.4534 / 0.4322 Acc: 42.1875 (32.5403)\n",
      "[11/25][142/782] Loss_D: 0.0019 (0.2469) Loss_G: -0.1554 (0.1097) D(x): 0.4762 D(G(z)): 0.4418 / 0.4608 Acc: 42.1875 (32.5415)\n",
      "[11/25][143/782] Loss_D: -0.1378 (0.2468) Loss_G: -0.2314 (0.1096) D(x): 0.5259 D(G(z)): 0.4707 / 0.4843 Acc: 50.0000 (32.5434)\n",
      "[11/25][144/782] Loss_D: -0.0036 (0.2468) Loss_G: -0.0129 (0.1096) D(x): 0.5269 D(G(z)): 0.4990 / 0.3961 Acc: 45.3125 (32.5449)\n",
      "[11/25][145/782] Loss_D: -0.0431 (0.2468) Loss_G: -0.2380 (0.1096) D(x): 0.5393 D(G(z)): 0.4978 / 0.4993 Acc: 45.3125 (32.5464)\n",
      "[11/25][146/782] Loss_D: -0.0172 (0.2468) Loss_G: 0.0135 (0.1096) D(x): 0.5429 D(G(z)): 0.4624 / 0.4072 Acc: 34.3750 (32.5466)\n",
      "[11/25][147/782] Loss_D: -0.0494 (0.2467) Loss_G: -0.2436 (0.1095) D(x): 0.5028 D(G(z)): 0.4261 / 0.4921 Acc: 42.1875 (32.5477)\n",
      "[11/25][148/782] Loss_D: -0.1581 (0.2467) Loss_G: -0.2464 (0.1095) D(x): 0.5559 D(G(z)): 0.4134 / 0.4998 Acc: 46.8750 (32.5493)\n",
      "[11/25][149/782] Loss_D: -0.0735 (0.2466) Loss_G: -0.0557 (0.1095) D(x): 0.5279 D(G(z)): 0.4563 / 0.4230 Acc: 40.6250 (32.5502)\n",
      "[11/25][150/782] Loss_D: -0.0635 (0.2466) Loss_G: -0.1879 (0.1094) D(x): 0.5820 D(G(z)): 0.5329 / 0.4809 Acc: 48.4375 (32.5521)\n",
      "[11/25][151/782] Loss_D: 0.0440 (0.2466) Loss_G: -0.1736 (0.1094) D(x): 0.5088 D(G(z)): 0.4823 / 0.4680 Acc: 39.0625 (32.5528)\n",
      "[11/25][152/782] Loss_D: -0.1431 (0.2465) Loss_G: 0.0124 (0.1094) D(x): 0.5413 D(G(z)): 0.4032 / 0.3996 Acc: 42.1875 (32.5539)\n",
      "[11/25][153/782] Loss_D: -0.2418 (0.2465) Loss_G: -0.1268 (0.1094) D(x): 0.5673 D(G(z)): 0.4250 / 0.4489 Acc: 45.3125 (32.5554)\n",
      "[11/25][154/782] Loss_D: 0.0211 (0.2465) Loss_G: -0.1230 (0.1093) D(x): 0.5302 D(G(z)): 0.4668 / 0.4449 Acc: 39.0625 (32.5561)\n",
      "[11/25][155/782] Loss_D: -0.1655 (0.2464) Loss_G: -0.1070 (0.1093) D(x): 0.5684 D(G(z)): 0.4228 / 0.4528 Acc: 42.1875 (32.5572)\n",
      "[11/25][156/782] Loss_D: -0.2315 (0.2464) Loss_G: 0.0260 (0.1093) D(x): 0.5803 D(G(z)): 0.4084 / 0.4028 Acc: 39.0625 (32.5579)\n",
      "[11/25][157/782] Loss_D: -0.2282 (0.2463) Loss_G: 0.0103 (0.1093) D(x): 0.5605 D(G(z)): 0.4747 / 0.4036 Acc: 53.1250 (32.5603)\n",
      "[11/25][158/782] Loss_D: 0.0570 (0.2463) Loss_G: -0.1197 (0.1093) D(x): 0.5000 D(G(z)): 0.4680 / 0.4608 Acc: 39.0625 (32.5610)\n",
      "[11/25][159/782] Loss_D: -0.1980 (0.2462) Loss_G: 0.0209 (0.1093) D(x): 0.6012 D(G(z)): 0.4863 / 0.3837 Acc: 48.4375 (32.5628)\n",
      "[11/25][160/782] Loss_D: -0.2343 (0.2462) Loss_G: -0.0052 (0.1093) D(x): 0.5390 D(G(z)): 0.4225 / 0.4028 Acc: 48.4375 (32.5647)\n",
      "[11/25][161/782] Loss_D: 0.0889 (0.2462) Loss_G: 0.0580 (0.1092) D(x): 0.4783 D(G(z)): 0.4707 / 0.3796 Acc: 43.7500 (32.5659)\n",
      "[11/25][162/782] Loss_D: -0.0157 (0.2461) Loss_G: -0.1146 (0.1092) D(x): 0.5022 D(G(z)): 0.4785 / 0.4600 Acc: 48.4375 (32.5677)\n",
      "[11/25][163/782] Loss_D: -0.1310 (0.2461) Loss_G: -0.0915 (0.1092) D(x): 0.5375 D(G(z)): 0.4645 / 0.4325 Acc: 46.8750 (32.5694)\n",
      "[11/25][164/782] Loss_D: -0.2091 (0.2460) Loss_G: -0.1964 (0.1092) D(x): 0.5420 D(G(z)): 0.4003 / 0.4830 Acc: 43.7500 (32.5706)\n",
      "[11/25][165/782] Loss_D: -0.0037 (0.2460) Loss_G: -0.2355 (0.1091) D(x): 0.5150 D(G(z)): 0.4772 / 0.5039 Acc: 48.4375 (32.5725)\n",
      "[11/25][166/782] Loss_D: 0.1536 (0.2460) Loss_G: -0.1902 (0.1091) D(x): 0.5265 D(G(z)): 0.5258 / 0.4851 Acc: 34.3750 (32.5727)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/25][167/782] Loss_D: -0.1512 (0.2459) Loss_G: -0.0466 (0.1091) D(x): 0.5913 D(G(z)): 0.4932 / 0.4181 Acc: 46.8750 (32.5743)\n",
      "[11/25][168/782] Loss_D: -0.0649 (0.2459) Loss_G: -0.0899 (0.1091) D(x): 0.4742 D(G(z)): 0.4085 / 0.4397 Acc: 45.3125 (32.5757)\n",
      "[11/25][169/782] Loss_D: 0.0841 (0.2459) Loss_G: -0.1578 (0.1090) D(x): 0.4959 D(G(z)): 0.4420 / 0.4671 Acc: 28.1250 (32.5752)\n",
      "[11/25][170/782] Loss_D: 0.0355 (0.2459) Loss_G: -0.1917 (0.1090) D(x): 0.5260 D(G(z)): 0.5087 / 0.4689 Acc: 42.1875 (32.5763)\n",
      "[11/25][171/782] Loss_D: 0.0355 (0.2458) Loss_G: -0.2166 (0.1090) D(x): 0.5238 D(G(z)): 0.5370 / 0.4807 Acc: 53.1250 (32.5787)\n",
      "[11/25][172/782] Loss_D: -0.0268 (0.2458) Loss_G: -0.1280 (0.1089) D(x): 0.5036 D(G(z)): 0.4126 / 0.4592 Acc: 40.6250 (32.5796)\n",
      "[11/25][173/782] Loss_D: 0.0149 (0.2458) Loss_G: -0.1647 (0.1089) D(x): 0.5032 D(G(z)): 0.4732 / 0.4788 Acc: 45.3125 (32.5810)\n",
      "[11/25][174/782] Loss_D: -0.0137 (0.2458) Loss_G: -0.1066 (0.1089) D(x): 0.5379 D(G(z)): 0.4481 / 0.4368 Acc: 39.0625 (32.5818)\n",
      "[11/25][175/782] Loss_D: -0.2034 (0.2457) Loss_G: -0.0308 (0.1089) D(x): 0.5514 D(G(z)): 0.4466 / 0.4032 Acc: 51.5625 (32.5839)\n",
      "[11/25][176/782] Loss_D: -0.1150 (0.2457) Loss_G: -0.0365 (0.1088) D(x): 0.5497 D(G(z)): 0.4780 / 0.4162 Acc: 48.4375 (32.5858)\n",
      "[11/25][177/782] Loss_D: -0.1399 (0.2456) Loss_G: -0.2818 (0.1088) D(x): 0.4875 D(G(z)): 0.4080 / 0.5193 Acc: 46.8750 (32.5874)\n",
      "[11/25][178/782] Loss_D: -0.0175 (0.2456) Loss_G: -0.0669 (0.1088) D(x): 0.5440 D(G(z)): 0.5003 / 0.4229 Acc: 42.1875 (32.5885)\n",
      "[11/25][179/782] Loss_D: 0.0683 (0.2456) Loss_G: -0.1567 (0.1087) D(x): 0.5318 D(G(z)): 0.5088 / 0.4631 Acc: 42.1875 (32.5896)\n",
      "[11/25][180/782] Loss_D: -0.0463 (0.2455) Loss_G: -0.0530 (0.1087) D(x): 0.5139 D(G(z)): 0.4442 / 0.4291 Acc: 40.6250 (32.5905)\n",
      "[11/25][181/782] Loss_D: 0.0140 (0.2455) Loss_G: -0.1397 (0.1087) D(x): 0.5405 D(G(z)): 0.4687 / 0.4958 Acc: 42.1875 (32.5916)\n",
      "[11/25][182/782] Loss_D: 0.0242 (0.2455) Loss_G: -0.2272 (0.1087) D(x): 0.5301 D(G(z)): 0.4878 / 0.4954 Acc: 40.6250 (32.5925)\n",
      "[11/25][183/782] Loss_D: 0.0158 (0.2455) Loss_G: -0.1403 (0.1086) D(x): 0.5670 D(G(z)): 0.5027 / 0.4582 Acc: 35.9375 (32.5929)\n",
      "[11/25][184/782] Loss_D: -0.0212 (0.2454) Loss_G: -0.0804 (0.1086) D(x): 0.4928 D(G(z)): 0.4471 / 0.4426 Acc: 45.3125 (32.5943)\n",
      "[11/25][185/782] Loss_D: -0.2318 (0.2454) Loss_G: -0.1358 (0.1086) D(x): 0.5673 D(G(z)): 0.4251 / 0.4559 Acc: 43.7500 (32.5956)\n",
      "[11/25][186/782] Loss_D: 0.2449 (0.2454) Loss_G: -0.1566 (0.1085) D(x): 0.5070 D(G(z)): 0.5420 / 0.4722 Acc: 35.9375 (32.5960)\n",
      "[11/25][187/782] Loss_D: -0.1204 (0.2453) Loss_G: -0.1008 (0.1085) D(x): 0.5366 D(G(z)): 0.4674 / 0.4382 Acc: 46.8750 (32.5976)\n",
      "[11/25][188/782] Loss_D: -0.1460 (0.2453) Loss_G: -0.0538 (0.1085) D(x): 0.5123 D(G(z)): 0.4368 / 0.4297 Acc: 48.4375 (32.5994)\n",
      "[11/25][189/782] Loss_D: -0.2312 (0.2452) Loss_G: -0.0228 (0.1085) D(x): 0.5706 D(G(z)): 0.4445 / 0.4096 Acc: 50.0000 (32.6014)\n",
      "[11/25][190/782] Loss_D: -0.1743 (0.2452) Loss_G: -0.0862 (0.1085) D(x): 0.5126 D(G(z)): 0.4266 / 0.4386 Acc: 46.8750 (32.6030)\n",
      "[11/25][191/782] Loss_D: 0.1972 (0.2452) Loss_G: -0.1440 (0.1084) D(x): 0.5280 D(G(z)): 0.5333 / 0.4845 Acc: 32.8125 (32.6030)\n",
      "[11/25][192/782] Loss_D: -0.0201 (0.2451) Loss_G: -0.0835 (0.1084) D(x): 0.5370 D(G(z)): 0.4571 / 0.4427 Acc: 34.3750 (32.6032)\n",
      "[11/25][193/782] Loss_D: -0.0378 (0.2451) Loss_G: -0.1532 (0.1084) D(x): 0.5486 D(G(z)): 0.4831 / 0.4640 Acc: 43.7500 (32.6045)\n",
      "[11/25][194/782] Loss_D: 0.1151 (0.2451) Loss_G: -0.2667 (0.1083) D(x): 0.4757 D(G(z)): 0.4680 / 0.5163 Acc: 37.5000 (32.6050)\n",
      "[11/25][195/782] Loss_D: 0.0110 (0.2451) Loss_G: -0.2495 (0.1083) D(x): 0.5062 D(G(z)): 0.4547 / 0.5147 Acc: 37.5000 (32.6056)\n",
      "[11/25][196/782] Loss_D: -0.1239 (0.2450) Loss_G: -0.1442 (0.1083) D(x): 0.5218 D(G(z)): 0.4632 / 0.4537 Acc: 51.5625 (32.6078)\n",
      "[11/25][197/782] Loss_D: 0.1671 (0.2450) Loss_G: -0.0991 (0.1083) D(x): 0.5739 D(G(z)): 0.5555 / 0.4472 Acc: 34.3750 (32.6080)\n",
      "[11/25][198/782] Loss_D: -0.0066 (0.2450) Loss_G: 0.0341 (0.1082) D(x): 0.5148 D(G(z)): 0.5042 / 0.4092 Acc: 51.5625 (32.6101)\n",
      "[11/25][199/782] Loss_D: -0.0299 (0.2450) Loss_G: -0.1494 (0.1082) D(x): 0.4824 D(G(z)): 0.4324 / 0.4709 Acc: 45.3125 (32.6116)\n",
      "[11/25][200/782] Loss_D: -0.1723 (0.2449) Loss_G: 0.0111 (0.1082) D(x): 0.6022 D(G(z)): 0.4366 / 0.4078 Acc: 39.0625 (32.6123)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[11/25][201/782] Loss_D: -0.1033 (0.2449) Loss_G: -0.1424 (0.1082) D(x): 0.5432 D(G(z)): 0.4192 / 0.4791 Acc: 37.5000 (32.6128)\n",
      "[11/25][202/782] Loss_D: 0.0539 (0.2449) Loss_G: -0.0727 (0.1082) D(x): 0.5085 D(G(z)): 0.4650 / 0.4567 Acc: 42.1875 (32.6139)\n",
      "[11/25][203/782] Loss_D: -0.0984 (0.2448) Loss_G: -0.2885 (0.1081) D(x): 0.5034 D(G(z)): 0.4457 / 0.5216 Acc: 43.7500 (32.6152)\n",
      "[11/25][204/782] Loss_D: 0.0769 (0.2448) Loss_G: -0.1501 (0.1081) D(x): 0.5521 D(G(z)): 0.5176 / 0.4675 Acc: 42.1875 (32.6163)\n",
      "[11/25][205/782] Loss_D: -0.2076 (0.2447) Loss_G: -0.0961 (0.1081) D(x): 0.5677 D(G(z)): 0.4478 / 0.4431 Acc: 45.3125 (32.6177)\n",
      "[11/25][206/782] Loss_D: -0.0727 (0.2447) Loss_G: 0.0263 (0.1080) D(x): 0.5845 D(G(z)): 0.5042 / 0.4015 Acc: 42.1875 (32.6188)\n",
      "[11/25][207/782] Loss_D: -0.2132 (0.2447) Loss_G: 0.0601 (0.1080) D(x): 0.5298 D(G(z)): 0.4069 / 0.3809 Acc: 48.4375 (32.6206)\n",
      "[11/25][208/782] Loss_D: 0.0508 (0.2446) Loss_G: -0.0232 (0.1080) D(x): 0.4612 D(G(z)): 0.4277 / 0.4205 Acc: 42.1875 (32.6217)\n",
      "[11/25][209/782] Loss_D: 0.0840 (0.2446) Loss_G: -0.2901 (0.1080) D(x): 0.4984 D(G(z)): 0.4560 / 0.5290 Acc: 34.3750 (32.6219)\n",
      "[11/25][210/782] Loss_D: 0.1004 (0.2446) Loss_G: -0.2149 (0.1079) D(x): 0.5649 D(G(z)): 0.5216 / 0.4971 Acc: 35.9375 (32.6223)\n",
      "[11/25][211/782] Loss_D: -0.1353 (0.2446) Loss_G: -0.0969 (0.1079) D(x): 0.5827 D(G(z)): 0.5059 / 0.4568 Acc: 51.5625 (32.6244)\n",
      "[11/25][212/782] Loss_D: 0.0211 (0.2445) Loss_G: -0.0718 (0.1079) D(x): 0.4871 D(G(z)): 0.4637 / 0.4414 Acc: 42.1875 (32.6255)\n",
      "[11/25][213/782] Loss_D: 0.0357 (0.2445) Loss_G: -0.0931 (0.1079) D(x): 0.4766 D(G(z)): 0.4991 / 0.4427 Acc: 50.0000 (32.6275)\n",
      "[11/25][214/782] Loss_D: 0.0287 (0.2445) Loss_G: -0.1257 (0.1079) D(x): 0.4706 D(G(z)): 0.4226 / 0.4561 Acc: 37.5000 (32.6280)\n",
      "[11/25][215/782] Loss_D: -0.1433 (0.2444) Loss_G: -0.1528 (0.1078) D(x): 0.5796 D(G(z)): 0.4702 / 0.4651 Acc: 45.3125 (32.6295)\n",
      "[11/25][216/782] Loss_D: -0.1002 (0.2444) Loss_G: -0.1903 (0.1078) D(x): 0.5080 D(G(z)): 0.4345 / 0.4899 Acc: 42.1875 (32.6305)\n",
      "[11/25][217/782] Loss_D: -0.0602 (0.2444) Loss_G: -0.2308 (0.1078) D(x): 0.5300 D(G(z)): 0.5186 / 0.5032 Acc: 50.0000 (32.6325)\n",
      "[11/25][218/782] Loss_D: -0.2756 (0.2443) Loss_G: 0.1127 (0.1078) D(x): 0.6176 D(G(z)): 0.4669 / 0.3590 Acc: 43.7500 (32.6338)\n",
      "[11/25][219/782] Loss_D: -0.2290 (0.2443) Loss_G: -0.1162 (0.1077) D(x): 0.4492 D(G(z)): 0.3644 / 0.4459 Acc: 57.8125 (32.6366)\n",
      "[11/25][220/782] Loss_D: 0.1080 (0.2442) Loss_G: -0.0092 (0.1077) D(x): 0.5003 D(G(z)): 0.4857 / 0.4006 Acc: 37.5000 (32.6372)\n",
      "[11/25][221/782] Loss_D: -0.0248 (0.2442) Loss_G: -0.0975 (0.1077) D(x): 0.5041 D(G(z)): 0.4933 / 0.4386 Acc: 51.5625 (32.6393)\n",
      "[11/25][222/782] Loss_D: 0.0294 (0.2442) Loss_G: -0.1626 (0.1077) D(x): 0.5696 D(G(z)): 0.5047 / 0.4612 Acc: 42.1875 (32.6404)\n",
      "[11/25][223/782] Loss_D: -0.0070 (0.2442) Loss_G: -0.0249 (0.1076) D(x): 0.5450 D(G(z)): 0.4736 / 0.4132 Acc: 40.6250 (32.6413)\n",
      "[11/25][224/782] Loss_D: -0.0823 (0.2441) Loss_G: 0.0056 (0.1076) D(x): 0.5329 D(G(z)): 0.4116 / 0.4083 Acc: 35.9375 (32.6417)\n",
      "[11/25][225/782] Loss_D: -0.0009 (0.2441) Loss_G: -0.0403 (0.1076) D(x): 0.5536 D(G(z)): 0.4772 / 0.4325 Acc: 32.8125 (32.6417)\n",
      "[11/25][226/782] Loss_D: -0.1440 (0.2440) Loss_G: 0.0496 (0.1076) D(x): 0.5238 D(G(z)): 0.3988 / 0.3886 Acc: 40.6250 (32.6426)\n",
      "[11/25][227/782] Loss_D: -0.1308 (0.2440) Loss_G: -0.2369 (0.1076) D(x): 0.5259 D(G(z)): 0.4424 / 0.5112 Acc: 46.8750 (32.6442)\n",
      "[11/25][228/782] Loss_D: 0.0324 (0.2440) Loss_G: -0.1224 (0.1075) D(x): 0.5827 D(G(z)): 0.5141 / 0.4416 Acc: 32.8125 (32.6442)\n",
      "[11/25][229/782] Loss_D: -0.0411 (0.2439) Loss_G: -0.2077 (0.1075) D(x): 0.5437 D(G(z)): 0.5201 / 0.4847 Acc: 46.8750 (32.6458)\n",
      "[11/25][230/782] Loss_D: 0.1064 (0.2439) Loss_G: -0.0753 (0.1075) D(x): 0.5270 D(G(z)): 0.5276 / 0.4408 Acc: 45.3125 (32.6473)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/25][231/782] Loss_D: -0.0235 (0.2439) Loss_G: -0.2105 (0.1075) D(x): 0.4861 D(G(z)): 0.4917 / 0.4724 Acc: 54.6875 (32.6498)\n",
      "[11/25][232/782] Loss_D: 0.3061 (0.2439) Loss_G: -0.0795 (0.1074) D(x): 0.4980 D(G(z)): 0.5558 / 0.4258 Acc: 31.2500 (32.6496)\n",
      "[11/25][233/782] Loss_D: 0.1302 (0.2439) Loss_G: -0.1315 (0.1074) D(x): 0.5029 D(G(z)): 0.4798 / 0.4742 Acc: 32.8125 (32.6496)\n",
      "[11/25][234/782] Loss_D: 0.0823 (0.2439) Loss_G: -0.1550 (0.1074) D(x): 0.4999 D(G(z)): 0.5195 / 0.4581 Acc: 50.0000 (32.6516)\n",
      "[11/25][235/782] Loss_D: -0.0249 (0.2438) Loss_G: -0.1669 (0.1073) D(x): 0.5398 D(G(z)): 0.4451 / 0.4796 Acc: 35.9375 (32.6520)\n",
      "[11/25][236/782] Loss_D: 0.0120 (0.2438) Loss_G: 0.0526 (0.1073) D(x): 0.5042 D(G(z)): 0.4450 / 0.3783 Acc: 35.9375 (32.6523)\n",
      "[11/25][237/782] Loss_D: -0.2111 (0.2438) Loss_G: -0.2219 (0.1073) D(x): 0.5021 D(G(z)): 0.4193 / 0.4998 Acc: 57.8125 (32.6552)\n",
      "[11/25][238/782] Loss_D: -0.2135 (0.2437) Loss_G: -0.2394 (0.1073) D(x): 0.5560 D(G(z)): 0.4682 / 0.4940 Acc: 51.5625 (32.6573)\n",
      "[11/25][239/782] Loss_D: -0.0769 (0.2437) Loss_G: -0.1266 (0.1072) D(x): 0.5565 D(G(z)): 0.4664 / 0.4619 Acc: 39.0625 (32.6581)\n",
      "[11/25][240/782] Loss_D: 0.0336 (0.2437) Loss_G: -0.0755 (0.1072) D(x): 0.5508 D(G(z)): 0.4502 / 0.4487 Acc: 31.2500 (32.6579)\n",
      "[11/25][241/782] Loss_D: 0.0544 (0.2436) Loss_G: -0.1500 (0.1072) D(x): 0.5318 D(G(z)): 0.5339 / 0.4773 Acc: 46.8750 (32.6595)\n",
      "[11/25][242/782] Loss_D: -0.2174 (0.2436) Loss_G: -0.0463 (0.1072) D(x): 0.5654 D(G(z)): 0.4704 / 0.4156 Acc: 54.6875 (32.6620)\n",
      "[11/25][243/782] Loss_D: -0.1984 (0.2435) Loss_G: -0.0611 (0.1071) D(x): 0.5223 D(G(z)): 0.4047 / 0.4165 Acc: 42.1875 (32.6631)\n",
      "[11/25][244/782] Loss_D: -0.0539 (0.2435) Loss_G: -0.1375 (0.1071) D(x): 0.5046 D(G(z)): 0.4401 / 0.4763 Acc: 43.7500 (32.6643)\n",
      "[11/25][245/782] Loss_D: 0.0719 (0.2435) Loss_G: -0.1024 (0.1071) D(x): 0.5530 D(G(z)): 0.5113 / 0.4400 Acc: 32.8125 (32.6643)\n",
      "[11/25][246/782] Loss_D: -0.0754 (0.2434) Loss_G: -0.0964 (0.1071) D(x): 0.5671 D(G(z)): 0.5005 / 0.4419 Acc: 46.8750 (32.6659)\n",
      "[11/25][247/782] Loss_D: -0.1594 (0.2434) Loss_G: -0.0417 (0.1071) D(x): 0.5387 D(G(z)): 0.4326 / 0.4112 Acc: 42.1875 (32.6670)\n",
      "[11/25][248/782] Loss_D: -0.0768 (0.2434) Loss_G: -0.0432 (0.1070) D(x): 0.5094 D(G(z)): 0.4526 / 0.4196 Acc: 40.6250 (32.6679)\n",
      "[11/25][249/782] Loss_D: 0.0689 (0.2433) Loss_G: -0.0636 (0.1070) D(x): 0.5213 D(G(z)): 0.4734 / 0.4301 Acc: 35.9375 (32.6683)\n",
      "[11/25][250/782] Loss_D: -0.1297 (0.2433) Loss_G: -0.0718 (0.1070) D(x): 0.5144 D(G(z)): 0.4366 / 0.4379 Acc: 42.1875 (32.6694)\n",
      "[11/25][251/782] Loss_D: -0.0574 (0.2433) Loss_G: -0.2354 (0.1070) D(x): 0.4970 D(G(z)): 0.4213 / 0.4887 Acc: 35.9375 (32.6697)\n",
      "[11/25][252/782] Loss_D: 0.0221 (0.2432) Loss_G: -0.1448 (0.1069) D(x): 0.5515 D(G(z)): 0.5153 / 0.4622 Acc: 40.6250 (32.6706)\n",
      "[11/25][253/782] Loss_D: 0.0126 (0.2432) Loss_G: -0.1049 (0.1069) D(x): 0.5431 D(G(z)): 0.5163 / 0.4386 Acc: 45.3125 (32.6721)\n",
      "[11/25][254/782] Loss_D: -0.0043 (0.2432) Loss_G: -0.0146 (0.1069) D(x): 0.5993 D(G(z)): 0.4866 / 0.4170 Acc: 34.3750 (32.6723)\n",
      "[11/25][255/782] Loss_D: -0.1620 (0.2431) Loss_G: -0.1098 (0.1069) D(x): 0.4885 D(G(z)): 0.4060 / 0.4316 Acc: 46.8750 (32.6739)\n",
      "[11/25][256/782] Loss_D: 0.0110 (0.2431) Loss_G: -0.2244 (0.1068) D(x): 0.4929 D(G(z)): 0.4584 / 0.4922 Acc: 40.6250 (32.6748)\n",
      "[11/25][257/782] Loss_D: 0.0205 (0.2431) Loss_G: -0.1712 (0.1068) D(x): 0.5803 D(G(z)): 0.5044 / 0.4701 Acc: 35.9375 (32.6751)\n",
      "[11/25][258/782] Loss_D: 0.0058 (0.2431) Loss_G: -0.1436 (0.1068) D(x): 0.5213 D(G(z)): 0.5008 / 0.4533 Acc: 42.1875 (32.6762)\n",
      "[11/25][259/782] Loss_D: -0.1537 (0.2430) Loss_G: -0.1306 (0.1067) D(x): 0.5256 D(G(z)): 0.4435 / 0.4533 Acc: 50.0000 (32.6781)\n",
      "[11/25][260/782] Loss_D: -0.0620 (0.2430) Loss_G: -0.0263 (0.1067) D(x): 0.5730 D(G(z)): 0.5031 / 0.4190 Acc: 43.7500 (32.6794)\n",
      "[11/25][261/782] Loss_D: -0.0544 (0.2430) Loss_G: -0.1360 (0.1067) D(x): 0.5282 D(G(z)): 0.4454 / 0.4731 Acc: 42.1875 (32.6805)\n",
      "[11/25][262/782] Loss_D: -0.1304 (0.2429) Loss_G: -0.2143 (0.1067) D(x): 0.4751 D(G(z)): 0.3833 / 0.5088 Acc: 51.5625 (32.6826)\n",
      "[11/25][263/782] Loss_D: -0.0146 (0.2429) Loss_G: -0.1580 (0.1066) D(x): 0.6036 D(G(z)): 0.5431 / 0.4736 Acc: 43.7500 (32.6838)\n",
      "[11/25][264/782] Loss_D: -0.1743 (0.2428) Loss_G: -0.1069 (0.1066) D(x): 0.5119 D(G(z)): 0.4248 / 0.4254 Acc: 53.1250 (32.6862)\n",
      "[11/25][265/782] Loss_D: -0.0569 (0.2428) Loss_G: -0.0743 (0.1066) D(x): 0.5392 D(G(z)): 0.4524 / 0.4348 Acc: 42.1875 (32.6872)\n",
      "[11/25][266/782] Loss_D: 0.0038 (0.2428) Loss_G: -0.1113 (0.1066) D(x): 0.5744 D(G(z)): 0.4842 / 0.4531 Acc: 31.2500 (32.6871)\n",
      "[11/25][267/782] Loss_D: -0.0132 (0.2427) Loss_G: -0.0294 (0.1066) D(x): 0.5226 D(G(z)): 0.4652 / 0.4102 Acc: 40.6250 (32.6880)\n",
      "[11/25][268/782] Loss_D: -0.1338 (0.2427) Loss_G: -0.1694 (0.1065) D(x): 0.4757 D(G(z)): 0.4340 / 0.4714 Acc: 53.1250 (32.6903)\n",
      "[11/25][269/782] Loss_D: -0.2229 (0.2426) Loss_G: -0.0305 (0.1065) D(x): 0.5781 D(G(z)): 0.4472 / 0.4335 Acc: 46.8750 (32.6919)\n",
      "[11/25][270/782] Loss_D: 0.1130 (0.2426) Loss_G: -0.1638 (0.1065) D(x): 0.4481 D(G(z)): 0.4985 / 0.4727 Acc: 56.2500 (32.6945)\n",
      "[11/25][271/782] Loss_D: -0.0182 (0.2426) Loss_G: -0.1679 (0.1064) D(x): 0.5342 D(G(z)): 0.4692 / 0.4874 Acc: 40.6250 (32.6954)\n",
      "[11/25][272/782] Loss_D: -0.0119 (0.2426) Loss_G: -0.1646 (0.1064) D(x): 0.5391 D(G(z)): 0.4971 / 0.4671 Acc: 39.0625 (32.6961)\n",
      "[11/25][273/782] Loss_D: 0.0069 (0.2426) Loss_G: -0.0780 (0.1064) D(x): 0.5394 D(G(z)): 0.4403 / 0.4319 Acc: 32.8125 (32.6961)\n",
      "[11/25][274/782] Loss_D: -0.1851 (0.2425) Loss_G: -0.1018 (0.1064) D(x): 0.5503 D(G(z)): 0.4272 / 0.4528 Acc: 45.3125 (32.6976)\n",
      "[11/25][275/782] Loss_D: -0.1332 (0.2425) Loss_G: -0.0498 (0.1064) D(x): 0.5471 D(G(z)): 0.4626 / 0.4183 Acc: 43.7500 (32.6988)\n",
      "[11/25][276/782] Loss_D: -0.1504 (0.2424) Loss_G: -0.1177 (0.1063) D(x): 0.4980 D(G(z)): 0.3915 / 0.4475 Acc: 46.8750 (32.7004)\n",
      "[11/25][277/782] Loss_D: -0.1880 (0.2424) Loss_G: -0.1344 (0.1063) D(x): 0.6204 D(G(z)): 0.4888 / 0.4523 Acc: 43.7500 (32.7016)\n",
      "[11/25][278/782] Loss_D: -0.2500 (0.2423) Loss_G: -0.1234 (0.1063) D(x): 0.5735 D(G(z)): 0.4714 / 0.4519 Acc: 54.6875 (32.7041)\n",
      "[11/25][279/782] Loss_D: -0.2101 (0.2423) Loss_G: 0.0123 (0.1063) D(x): 0.5806 D(G(z)): 0.4515 / 0.4019 Acc: 46.8750 (32.7057)\n",
      "[11/25][280/782] Loss_D: 0.0864 (0.2422) Loss_G: -0.0679 (0.1062) D(x): 0.5236 D(G(z)): 0.4910 / 0.4538 Acc: 42.1875 (32.7068)\n",
      "[11/25][281/782] Loss_D: -0.0308 (0.2422) Loss_G: -0.0280 (0.1062) D(x): 0.5194 D(G(z)): 0.4331 / 0.4164 Acc: 35.9375 (32.7071)\n",
      "[11/25][282/782] Loss_D: -0.2406 (0.2422) Loss_G: -0.0625 (0.1062) D(x): 0.5248 D(G(z)): 0.3952 / 0.4314 Acc: 53.1250 (32.7094)\n",
      "[11/25][283/782] Loss_D: -0.0911 (0.2421) Loss_G: -0.0637 (0.1062) D(x): 0.5474 D(G(z)): 0.4454 / 0.4282 Acc: 40.6250 (32.7103)\n",
      "[11/25][284/782] Loss_D: -0.1198 (0.2421) Loss_G: 0.0465 (0.1062) D(x): 0.6035 D(G(z)): 0.4401 / 0.4060 Acc: 32.8125 (32.7103)\n",
      "[11/25][285/782] Loss_D: -0.0983 (0.2420) Loss_G: -0.2106 (0.1061) D(x): 0.6054 D(G(z)): 0.5046 / 0.4965 Acc: 40.6250 (32.7112)\n",
      "[11/25][286/782] Loss_D: -0.0967 (0.2420) Loss_G: -0.1706 (0.1061) D(x): 0.5165 D(G(z)): 0.4051 / 0.4718 Acc: 40.6250 (32.7121)\n",
      "[11/25][287/782] Loss_D: -0.0550 (0.2420) Loss_G: -0.2653 (0.1061) D(x): 0.5279 D(G(z)): 0.4928 / 0.5269 Acc: 48.4375 (32.7139)\n",
      "[11/25][288/782] Loss_D: -0.0383 (0.2419) Loss_G: -0.0808 (0.1061) D(x): 0.5230 D(G(z)): 0.4806 / 0.4357 Acc: 50.0000 (32.7158)\n",
      "[11/25][289/782] Loss_D: 0.1089 (0.2419) Loss_G: -0.0593 (0.1060) D(x): 0.5420 D(G(z)): 0.4730 / 0.4362 Acc: 28.1250 (32.7153)\n",
      "[11/25][290/782] Loss_D: -0.0656 (0.2419) Loss_G: -0.1610 (0.1060) D(x): 0.5102 D(G(z)): 0.4758 / 0.4708 Acc: 50.0000 (32.7173)\n",
      "[11/25][291/782] Loss_D: 0.0060 (0.2419) Loss_G: -0.0126 (0.1060) D(x): 0.5700 D(G(z)): 0.5035 / 0.4170 Acc: 35.9375 (32.7176)\n",
      "[11/25][292/782] Loss_D: -0.0193 (0.2418) Loss_G: 0.0663 (0.1060) D(x): 0.5215 D(G(z)): 0.4620 / 0.3830 Acc: 42.1875 (32.7187)\n",
      "[11/25][293/782] Loss_D: -0.0182 (0.2418) Loss_G: -0.1921 (0.1060) D(x): 0.4843 D(G(z)): 0.4421 / 0.4883 Acc: 40.6250 (32.7196)\n",
      "[11/25][294/782] Loss_D: -0.0234 (0.2418) Loss_G: -0.1365 (0.1059) D(x): 0.5075 D(G(z)): 0.4716 / 0.4654 Acc: 42.1875 (32.7207)\n",
      "[11/25][295/782] Loss_D: 0.0232 (0.2417) Loss_G: -0.2402 (0.1059) D(x): 0.5507 D(G(z)): 0.5285 / 0.5039 Acc: 45.3125 (32.7221)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/25][296/782] Loss_D: -0.2705 (0.2417) Loss_G: -0.1425 (0.1059) D(x): 0.6160 D(G(z)): 0.5017 / 0.4727 Acc: 53.1250 (32.7244)\n",
      "[11/25][297/782] Loss_D: -0.0016 (0.2417) Loss_G: -0.1643 (0.1058) D(x): 0.4939 D(G(z)): 0.4565 / 0.4825 Acc: 46.8750 (32.7259)\n",
      "[11/25][298/782] Loss_D: 0.0084 (0.2416) Loss_G: -0.0822 (0.1058) D(x): 0.5184 D(G(z)): 0.4692 / 0.4363 Acc: 39.0625 (32.7267)\n",
      "[11/25][299/782] Loss_D: 0.0250 (0.2416) Loss_G: -0.1188 (0.1058) D(x): 0.5356 D(G(z)): 0.4759 / 0.4532 Acc: 39.0625 (32.7274)\n",
      "[11/25][300/782] Loss_D: 0.0028 (0.2416) Loss_G: -0.1581 (0.1058) D(x): 0.4876 D(G(z)): 0.4975 / 0.4638 Acc: 54.6875 (32.7298)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[11/25][301/782] Loss_D: 0.0591 (0.2416) Loss_G: -0.0941 (0.1057) D(x): 0.5572 D(G(z)): 0.5022 / 0.4705 Acc: 34.3750 (32.7300)\n",
      "[11/25][302/782] Loss_D: 0.1363 (0.2416) Loss_G: -0.0568 (0.1057) D(x): 0.4687 D(G(z)): 0.4943 / 0.4355 Acc: 42.1875 (32.7311)\n",
      "[11/25][303/782] Loss_D: 0.1710 (0.2415) Loss_G: -0.0768 (0.1057) D(x): 0.4751 D(G(z)): 0.5227 / 0.4473 Acc: 46.8750 (32.7327)\n",
      "[11/25][304/782] Loss_D: 0.2124 (0.2415) Loss_G: -0.1286 (0.1057) D(x): 0.4564 D(G(z)): 0.4821 / 0.4535 Acc: 35.9375 (32.7330)\n",
      "[11/25][305/782] Loss_D: -0.0293 (0.2415) Loss_G: -0.1711 (0.1056) D(x): 0.4690 D(G(z)): 0.4369 / 0.4787 Acc: 50.0000 (32.7350)\n",
      "[11/25][306/782] Loss_D: -0.0496 (0.2415) Loss_G: 0.0098 (0.1056) D(x): 0.5269 D(G(z)): 0.4725 / 0.4109 Acc: 46.8750 (32.7366)\n",
      "[11/25][307/782] Loss_D: -0.1000 (0.2414) Loss_G: -0.1297 (0.1056) D(x): 0.5551 D(G(z)): 0.4420 / 0.4665 Acc: 37.5000 (32.7371)\n",
      "[11/25][308/782] Loss_D: -0.0806 (0.2414) Loss_G: -0.0165 (0.1056) D(x): 0.5202 D(G(z)): 0.4259 / 0.4374 Acc: 50.0000 (32.7390)\n",
      "[11/25][309/782] Loss_D: -0.0593 (0.2414) Loss_G: -0.1206 (0.1056) D(x): 0.5554 D(G(z)): 0.4907 / 0.4550 Acc: 43.7500 (32.7403)\n",
      "[11/25][310/782] Loss_D: 0.1821 (0.2414) Loss_G: -0.0186 (0.1055) D(x): 0.5383 D(G(z)): 0.4688 / 0.3998 Acc: 21.8750 (32.7390)\n",
      "[11/25][311/782] Loss_D: -0.1478 (0.2413) Loss_G: 0.0463 (0.1055) D(x): 0.5280 D(G(z)): 0.4542 / 0.3887 Acc: 50.0000 (32.7410)\n",
      "[11/25][312/782] Loss_D: 0.0133 (0.2413) Loss_G: -0.0619 (0.1055) D(x): 0.4685 D(G(z)): 0.4332 / 0.4325 Acc: 42.1875 (32.7420)\n",
      "[11/25][313/782] Loss_D: -0.2435 (0.2412) Loss_G: -0.0438 (0.1055) D(x): 0.5574 D(G(z)): 0.4105 / 0.4253 Acc: 48.4375 (32.7438)\n",
      "[11/25][314/782] Loss_D: -0.1823 (0.2412) Loss_G: -0.0493 (0.1055) D(x): 0.5977 D(G(z)): 0.4589 / 0.4267 Acc: 46.8750 (32.7454)\n",
      "[11/25][315/782] Loss_D: -0.1560 (0.2412) Loss_G: 0.0200 (0.1055) D(x): 0.5550 D(G(z)): 0.4829 / 0.3898 Acc: 54.6875 (32.7478)\n",
      "[11/25][316/782] Loss_D: -0.1387 (0.2411) Loss_G: -0.0079 (0.1055) D(x): 0.5356 D(G(z)): 0.4507 / 0.4171 Acc: 50.0000 (32.7498)\n",
      "[11/25][317/782] Loss_D: -0.1300 (0.2411) Loss_G: -0.1965 (0.1054) D(x): 0.5279 D(G(z)): 0.4309 / 0.4739 Acc: 43.7500 (32.7510)\n",
      "[11/25][318/782] Loss_D: -0.0457 (0.2410) Loss_G: -0.1195 (0.1054) D(x): 0.4926 D(G(z)): 0.4295 / 0.4520 Acc: 40.6250 (32.7519)\n",
      "[11/25][319/782] Loss_D: -0.1009 (0.2410) Loss_G: -0.1629 (0.1054) D(x): 0.5278 D(G(z)): 0.4438 / 0.4656 Acc: 42.1875 (32.7530)\n",
      "[11/25][320/782] Loss_D: 0.0856 (0.2410) Loss_G: -0.1852 (0.1053) D(x): 0.5624 D(G(z)): 0.5493 / 0.4710 Acc: 39.0625 (32.7537)\n",
      "[11/25][321/782] Loss_D: -0.0664 (0.2409) Loss_G: -0.0693 (0.1053) D(x): 0.5735 D(G(z)): 0.5077 / 0.4324 Acc: 50.0000 (32.7556)\n",
      "[11/25][322/782] Loss_D: -0.0984 (0.2409) Loss_G: 0.0252 (0.1053) D(x): 0.5090 D(G(z)): 0.3876 / 0.4129 Acc: 35.9375 (32.7560)\n",
      "[11/25][323/782] Loss_D: 0.1217 (0.2409) Loss_G: -0.1571 (0.1053) D(x): 0.4652 D(G(z)): 0.4427 / 0.4729 Acc: 34.3750 (32.7561)\n",
      "[11/25][324/782] Loss_D: -0.0508 (0.2409) Loss_G: -0.1877 (0.1053) D(x): 0.5615 D(G(z)): 0.5102 / 0.4762 Acc: 43.7500 (32.7574)\n",
      "[11/25][325/782] Loss_D: 0.0447 (0.2408) Loss_G: -0.1393 (0.1052) D(x): 0.5471 D(G(z)): 0.4970 / 0.4635 Acc: 37.5000 (32.7579)\n",
      "[11/25][326/782] Loss_D: -0.0382 (0.2408) Loss_G: -0.0884 (0.1052) D(x): 0.5228 D(G(z)): 0.4808 / 0.4378 Acc: 42.1875 (32.7590)\n",
      "[11/25][327/782] Loss_D: -0.0393 (0.2408) Loss_G: -0.2839 (0.1052) D(x): 0.4935 D(G(z)): 0.4319 / 0.5353 Acc: 46.8750 (32.7605)\n",
      "[11/25][328/782] Loss_D: -0.0063 (0.2407) Loss_G: -0.1859 (0.1051) D(x): 0.5525 D(G(z)): 0.5117 / 0.4929 Acc: 50.0000 (32.7625)\n",
      "[11/25][329/782] Loss_D: -0.1425 (0.2407) Loss_G: -0.1514 (0.1051) D(x): 0.5659 D(G(z)): 0.4569 / 0.4722 Acc: 40.6250 (32.7633)\n",
      "[11/25][330/782] Loss_D: -0.1148 (0.2407) Loss_G: -0.0637 (0.1051) D(x): 0.5571 D(G(z)): 0.4604 / 0.4274 Acc: 43.7500 (32.7646)\n",
      "[11/25][331/782] Loss_D: -0.1920 (0.2406) Loss_G: -0.0976 (0.1051) D(x): 0.5298 D(G(z)): 0.4297 / 0.4350 Acc: 48.4375 (32.7663)\n",
      "[11/25][332/782] Loss_D: 0.0243 (0.2406) Loss_G: -0.1950 (0.1050) D(x): 0.4967 D(G(z)): 0.4549 / 0.4884 Acc: 45.3125 (32.7677)\n",
      "[11/25][333/782] Loss_D: 0.0571 (0.2406) Loss_G: -0.1760 (0.1050) D(x): 0.5220 D(G(z)): 0.4888 / 0.4657 Acc: 35.9375 (32.7681)\n",
      "[11/25][334/782] Loss_D: -0.0099 (0.2405) Loss_G: -0.0992 (0.1050) D(x): 0.5938 D(G(z)): 0.5335 / 0.4514 Acc: 42.1875 (32.7691)\n",
      "[11/25][335/782] Loss_D: -0.1380 (0.2405) Loss_G: -0.0743 (0.1049) D(x): 0.5435 D(G(z)): 0.4337 / 0.4348 Acc: 39.0625 (32.7698)\n",
      "[11/25][336/782] Loss_D: -0.0752 (0.2405) Loss_G: -0.0743 (0.1049) D(x): 0.4922 D(G(z)): 0.4626 / 0.4155 Acc: 48.4375 (32.7716)\n",
      "[11/25][337/782] Loss_D: -0.1397 (0.2404) Loss_G: -0.1040 (0.1049) D(x): 0.5119 D(G(z)): 0.4585 / 0.4403 Acc: 51.5625 (32.7737)\n",
      "[11/25][338/782] Loss_D: -0.0783 (0.2404) Loss_G: -0.1541 (0.1049) D(x): 0.5930 D(G(z)): 0.5259 / 0.4692 Acc: 43.7500 (32.7749)\n",
      "[11/25][339/782] Loss_D: 0.1479 (0.2404) Loss_G: -0.0365 (0.1049) D(x): 0.4639 D(G(z)): 0.4610 / 0.4198 Acc: 35.9375 (32.7753)\n",
      "[11/25][340/782] Loss_D: 0.0028 (0.2404) Loss_G: -0.1452 (0.1048) D(x): 0.5006 D(G(z)): 0.4651 / 0.4527 Acc: 43.7500 (32.7765)\n",
      "[11/25][341/782] Loss_D: -0.1648 (0.2403) Loss_G: -0.1306 (0.1048) D(x): 0.5472 D(G(z)): 0.4760 / 0.4547 Acc: 53.1250 (32.7788)\n",
      "[11/25][342/782] Loss_D: -0.0098 (0.2403) Loss_G: -0.2162 (0.1048) D(x): 0.4892 D(G(z)): 0.4802 / 0.4986 Acc: 50.0000 (32.7807)\n",
      "[11/25][343/782] Loss_D: -0.0913 (0.2402) Loss_G: -0.2195 (0.1047) D(x): 0.5514 D(G(z)): 0.4280 / 0.4865 Acc: 34.3750 (32.7809)\n",
      "[11/25][344/782] Loss_D: 0.0161 (0.2402) Loss_G: -0.2574 (0.1047) D(x): 0.5606 D(G(z)): 0.5356 / 0.5046 Acc: 43.7500 (32.7821)\n",
      "[11/25][345/782] Loss_D: 0.0453 (0.2402) Loss_G: -0.0727 (0.1047) D(x): 0.5596 D(G(z)): 0.5586 / 0.4191 Acc: 46.8750 (32.7837)\n",
      "[11/25][346/782] Loss_D: -0.0758 (0.2402) Loss_G: -0.0126 (0.1047) D(x): 0.6209 D(G(z)): 0.4897 / 0.4050 Acc: 32.8125 (32.7837)\n",
      "[11/25][347/782] Loss_D: -0.0223 (0.2401) Loss_G: 0.2165 (0.1047) D(x): 0.4787 D(G(z)): 0.3522 / 0.3375 Acc: 28.1250 (32.7832)\n",
      "[11/25][348/782] Loss_D: -0.1201 (0.2401) Loss_G: -0.0396 (0.1047) D(x): 0.5322 D(G(z)): 0.4309 / 0.4287 Acc: 40.6250 (32.7840)\n",
      "[11/25][349/782] Loss_D: 0.1036 (0.2401) Loss_G: -0.1708 (0.1046) D(x): 0.4844 D(G(z)): 0.4797 / 0.4852 Acc: 39.0625 (32.7847)\n",
      "[11/25][350/782] Loss_D: -0.1843 (0.2400) Loss_G: -0.2718 (0.1046) D(x): 0.5971 D(G(z)): 0.4969 / 0.5034 Acc: 50.0000 (32.7867)\n",
      "[11/25][351/782] Loss_D: 0.0293 (0.2400) Loss_G: -0.1318 (0.1046) D(x): 0.5398 D(G(z)): 0.5183 / 0.4572 Acc: 40.6250 (32.7875)\n",
      "[11/25][352/782] Loss_D: 0.0533 (0.2400) Loss_G: -0.0369 (0.1045) D(x): 0.4844 D(G(z)): 0.4331 / 0.4324 Acc: 39.0625 (32.7882)\n",
      "[11/25][353/782] Loss_D: 0.0176 (0.2400) Loss_G: -0.1254 (0.1045) D(x): 0.5541 D(G(z)): 0.4936 / 0.4642 Acc: 37.5000 (32.7888)\n",
      "[11/25][354/782] Loss_D: 0.0942 (0.2399) Loss_G: -0.1576 (0.1045) D(x): 0.4580 D(G(z)): 0.4656 / 0.4694 Acc: 43.7500 (32.7900)\n",
      "[11/25][355/782] Loss_D: -0.0167 (0.2399) Loss_G: -0.2444 (0.1044) D(x): 0.5015 D(G(z)): 0.4631 / 0.5111 Acc: 46.8750 (32.7916)\n",
      "[11/25][356/782] Loss_D: -0.0047 (0.2399) Loss_G: -0.0627 (0.1044) D(x): 0.5277 D(G(z)): 0.4994 / 0.4169 Acc: 46.8750 (32.7931)\n",
      "[11/25][357/782] Loss_D: 0.0850 (0.2399) Loss_G: 0.0395 (0.1044) D(x): 0.4990 D(G(z)): 0.4559 / 0.3890 Acc: 35.9375 (32.7935)\n",
      "[11/25][358/782] Loss_D: -0.2744 (0.2398) Loss_G: 0.0677 (0.1044) D(x): 0.5366 D(G(z)): 0.4049 / 0.3824 Acc: 50.0000 (32.7954)\n",
      "[11/25][359/782] Loss_D: -0.0383 (0.2398) Loss_G: -0.1046 (0.1044) D(x): 0.5265 D(G(z)): 0.4375 / 0.4540 Acc: 39.0625 (32.7961)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/25][360/782] Loss_D: -0.1369 (0.2397) Loss_G: -0.0766 (0.1044) D(x): 0.5660 D(G(z)): 0.4326 / 0.4222 Acc: 40.6250 (32.7970)\n",
      "[11/25][361/782] Loss_D: -0.0598 (0.2397) Loss_G: 0.0823 (0.1044) D(x): 0.6286 D(G(z)): 0.4818 / 0.3838 Acc: 29.6875 (32.7966)\n",
      "[11/25][362/782] Loss_D: -0.1652 (0.2397) Loss_G: 0.0179 (0.1044) D(x): 0.5291 D(G(z)): 0.4058 / 0.4066 Acc: 39.0625 (32.7973)\n",
      "[11/25][363/782] Loss_D: -0.0833 (0.2396) Loss_G: 0.0031 (0.1044) D(x): 0.5431 D(G(z)): 0.4483 / 0.4088 Acc: 37.5000 (32.7979)\n",
      "[11/25][364/782] Loss_D: -0.0537 (0.2396) Loss_G: -0.0969 (0.1043) D(x): 0.5645 D(G(z)): 0.4908 / 0.4559 Acc: 45.3125 (32.7993)\n",
      "[11/25][365/782] Loss_D: -0.1656 (0.2395) Loss_G: -0.0730 (0.1043) D(x): 0.5663 D(G(z)): 0.4667 / 0.4272 Acc: 45.3125 (32.8007)\n",
      "[11/25][366/782] Loss_D: -0.1514 (0.2395) Loss_G: -0.0672 (0.1043) D(x): 0.5599 D(G(z)): 0.4515 / 0.4399 Acc: 42.1875 (32.8017)\n",
      "[11/25][367/782] Loss_D: -0.0758 (0.2395) Loss_G: -0.2519 (0.1043) D(x): 0.4669 D(G(z)): 0.3967 / 0.5232 Acc: 48.4375 (32.8034)\n",
      "[11/25][368/782] Loss_D: 0.1236 (0.2395) Loss_G: -0.2000 (0.1042) D(x): 0.5633 D(G(z)): 0.5601 / 0.4745 Acc: 42.1875 (32.8045)\n",
      "[11/25][369/782] Loss_D: -0.1557 (0.2394) Loss_G: -0.1029 (0.1042) D(x): 0.5060 D(G(z)): 0.4380 / 0.4336 Acc: 56.2500 (32.8071)\n",
      "[11/25][370/782] Loss_D: -0.1827 (0.2394) Loss_G: -0.0954 (0.1042) D(x): 0.5551 D(G(z)): 0.4429 / 0.4306 Acc: 46.8750 (32.8087)\n",
      "[11/25][371/782] Loss_D: -0.1666 (0.2393) Loss_G: -0.0779 (0.1042) D(x): 0.5582 D(G(z)): 0.4623 / 0.4370 Acc: 46.8750 (32.8102)\n",
      "[11/25][372/782] Loss_D: 0.0973 (0.2393) Loss_G: -0.1482 (0.1041) D(x): 0.4892 D(G(z)): 0.4775 / 0.4616 Acc: 37.5000 (32.8108)\n",
      "[11/25][373/782] Loss_D: 0.0048 (0.2393) Loss_G: -0.1183 (0.1041) D(x): 0.4749 D(G(z)): 0.4255 / 0.4560 Acc: 43.7500 (32.8120)\n",
      "[11/25][374/782] Loss_D: 0.1006 (0.2393) Loss_G: -0.1663 (0.1041) D(x): 0.5488 D(G(z)): 0.5387 / 0.4755 Acc: 42.1875 (32.8130)\n",
      "[11/25][375/782] Loss_D: 0.0934 (0.2392) Loss_G: -0.1110 (0.1040) D(x): 0.4330 D(G(z)): 0.4582 / 0.4355 Acc: 46.8750 (32.8146)\n",
      "[11/25][376/782] Loss_D: -0.1417 (0.2392) Loss_G: 0.0080 (0.1040) D(x): 0.6182 D(G(z)): 0.4735 / 0.4048 Acc: 34.3750 (32.8148)\n",
      "[11/25][377/782] Loss_D: -0.3195 (0.2391) Loss_G: -0.0151 (0.1040) D(x): 0.5446 D(G(z)): 0.3900 / 0.4028 Acc: 50.0000 (32.8167)\n",
      "[11/25][378/782] Loss_D: 0.0372 (0.2391) Loss_G: -0.0224 (0.1040) D(x): 0.5474 D(G(z)): 0.4881 / 0.4115 Acc: 40.6250 (32.8175)\n",
      "[11/25][379/782] Loss_D: -0.0508 (0.2391) Loss_G: 0.0669 (0.1040) D(x): 0.5255 D(G(z)): 0.4105 / 0.3907 Acc: 34.3750 (32.8177)\n",
      "[11/25][380/782] Loss_D: -0.0812 (0.2390) Loss_G: -0.2523 (0.1040) D(x): 0.4966 D(G(z)): 0.4443 / 0.5051 Acc: 50.0000 (32.8196)\n",
      "[11/25][381/782] Loss_D: -0.0757 (0.2390) Loss_G: -0.2665 (0.1039) D(x): 0.5619 D(G(z)): 0.4816 / 0.5082 Acc: 39.0625 (32.8203)\n",
      "[11/25][382/782] Loss_D: -0.0184 (0.2390) Loss_G: -0.0023 (0.1039) D(x): 0.5707 D(G(z)): 0.4919 / 0.4004 Acc: 35.9375 (32.8207)\n",
      "[11/25][383/782] Loss_D: -0.0932 (0.2389) Loss_G: -0.0392 (0.1039) D(x): 0.4821 D(G(z)): 0.4068 / 0.4181 Acc: 42.1875 (32.8217)\n",
      "[11/25][384/782] Loss_D: -0.0440 (0.2389) Loss_G: -0.2157 (0.1039) D(x): 0.5328 D(G(z)): 0.4534 / 0.4881 Acc: 42.1875 (32.8228)\n",
      "[11/25][385/782] Loss_D: -0.1555 (0.2389) Loss_G: -0.2590 (0.1038) D(x): 0.5172 D(G(z)): 0.4327 / 0.5191 Acc: 46.8750 (32.8243)\n",
      "[11/25][386/782] Loss_D: -0.3129 (0.2388) Loss_G: -0.1823 (0.1038) D(x): 0.5939 D(G(z)): 0.4350 / 0.4679 Acc: 53.1250 (32.8266)\n",
      "[11/25][387/782] Loss_D: -0.1862 (0.2388) Loss_G: -0.1007 (0.1038) D(x): 0.5881 D(G(z)): 0.4708 / 0.4556 Acc: 46.8750 (32.8281)\n",
      "[11/25][388/782] Loss_D: -0.0129 (0.2387) Loss_G: -0.0349 (0.1037) D(x): 0.5491 D(G(z)): 0.4686 / 0.4253 Acc: 34.3750 (32.8283)\n",
      "[11/25][389/782] Loss_D: 0.0183 (0.2387) Loss_G: -0.1076 (0.1037) D(x): 0.4717 D(G(z)): 0.4441 / 0.4326 Acc: 45.3125 (32.8297)\n",
      "[11/25][390/782] Loss_D: 0.1315 (0.2387) Loss_G: -0.1001 (0.1037) D(x): 0.5517 D(G(z)): 0.5642 / 0.4592 Acc: 42.1875 (32.8307)\n",
      "[11/25][391/782] Loss_D: -0.1427 (0.2387) Loss_G: 0.0348 (0.1037) D(x): 0.5467 D(G(z)): 0.4516 / 0.3933 Acc: 46.8750 (32.8323)\n",
      "[11/25][392/782] Loss_D: -0.1121 (0.2386) Loss_G: -0.0294 (0.1037) D(x): 0.5342 D(G(z)): 0.3932 / 0.4129 Acc: 32.8125 (32.8323)\n",
      "[11/25][393/782] Loss_D: -0.0270 (0.2386) Loss_G: -0.0349 (0.1037) D(x): 0.5365 D(G(z)): 0.4493 / 0.4137 Acc: 35.9375 (32.8326)\n",
      "[11/25][394/782] Loss_D: -0.0264 (0.2386) Loss_G: 0.2212 (0.1037) D(x): 0.5838 D(G(z)): 0.4536 / 0.3353 Acc: 28.1250 (32.8321)\n",
      "[11/25][395/782] Loss_D: 0.0809 (0.2385) Loss_G: 0.0305 (0.1037) D(x): 0.5029 D(G(z)): 0.4686 / 0.4073 Acc: 39.0625 (32.8328)\n",
      "[11/25][396/782] Loss_D: 0.0128 (0.2385) Loss_G: -0.1065 (0.1036) D(x): 0.5229 D(G(z)): 0.4625 / 0.4467 Acc: 40.6250 (32.8337)\n",
      "[11/25][397/782] Loss_D: 0.0744 (0.2385) Loss_G: -0.1702 (0.1036) D(x): 0.5135 D(G(z)): 0.4525 / 0.4738 Acc: 34.3750 (32.8339)\n",
      "[11/25][398/782] Loss_D: 0.0397 (0.2385) Loss_G: -0.1787 (0.1036) D(x): 0.5309 D(G(z)): 0.5104 / 0.4714 Acc: 45.3125 (32.8352)\n",
      "[11/25][399/782] Loss_D: -0.0393 (0.2384) Loss_G: -0.0424 (0.1036) D(x): 0.5481 D(G(z)): 0.4881 / 0.4198 Acc: 37.5000 (32.8358)\n",
      "[11/25][400/782] Loss_D: 0.0393 (0.2384) Loss_G: -0.1769 (0.1035) D(x): 0.5201 D(G(z)): 0.5197 / 0.4717 Acc: 48.4375 (32.8375)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[11/25][401/782] Loss_D: 0.0062 (0.2384) Loss_G: -0.0063 (0.1035) D(x): 0.4855 D(G(z)): 0.4492 / 0.4194 Acc: 48.4375 (32.8392)\n",
      "[11/25][402/782] Loss_D: 0.0947 (0.2384) Loss_G: -0.2237 (0.1035) D(x): 0.5030 D(G(z)): 0.5032 / 0.4926 Acc: 39.0625 (32.8399)\n",
      "[11/25][403/782] Loss_D: 0.2196 (0.2384) Loss_G: -0.2915 (0.1034) D(x): 0.4607 D(G(z)): 0.5225 / 0.5286 Acc: 46.8750 (32.8415)\n",
      "[11/25][404/782] Loss_D: -0.0237 (0.2383) Loss_G: -0.2257 (0.1034) D(x): 0.5161 D(G(z)): 0.5335 / 0.5115 Acc: 54.6875 (32.8439)\n",
      "[11/25][405/782] Loss_D: 0.1889 (0.2383) Loss_G: -0.1682 (0.1034) D(x): 0.5033 D(G(z)): 0.5085 / 0.5027 Acc: 32.8125 (32.8439)\n",
      "[11/25][406/782] Loss_D: 0.0190 (0.2383) Loss_G: -0.1066 (0.1034) D(x): 0.5252 D(G(z)): 0.4958 / 0.4330 Acc: 43.7500 (32.8451)\n",
      "[11/25][407/782] Loss_D: 0.0619 (0.2383) Loss_G: -0.1074 (0.1033) D(x): 0.4742 D(G(z)): 0.4116 / 0.4466 Acc: 32.8125 (32.8451)\n",
      "[11/25][408/782] Loss_D: -0.0691 (0.2383) Loss_G: 0.1301 (0.1033) D(x): 0.5577 D(G(z)): 0.4512 / 0.3843 Acc: 40.6250 (32.8460)\n",
      "[11/25][409/782] Loss_D: -0.2511 (0.2382) Loss_G: -0.1028 (0.1033) D(x): 0.5705 D(G(z)): 0.4416 / 0.4423 Acc: 50.0000 (32.8479)\n",
      "[11/25][410/782] Loss_D: 0.0078 (0.2382) Loss_G: -0.1567 (0.1033) D(x): 0.5582 D(G(z)): 0.4809 / 0.4555 Acc: 34.3750 (32.8480)\n",
      "[11/25][411/782] Loss_D: -0.0890 (0.2381) Loss_G: -0.0559 (0.1033) D(x): 0.5517 D(G(z)): 0.4076 / 0.4358 Acc: 31.2500 (32.8479)\n",
      "[11/25][412/782] Loss_D: 0.1328 (0.2381) Loss_G: -0.1489 (0.1032) D(x): 0.4902 D(G(z)): 0.4469 / 0.4893 Acc: 35.9375 (32.8482)\n",
      "[11/25][413/782] Loss_D: -0.0955 (0.2381) Loss_G: -0.1105 (0.1032) D(x): 0.5968 D(G(z)): 0.5285 / 0.4629 Acc: 46.8750 (32.8498)\n",
      "[11/25][414/782] Loss_D: 0.0124 (0.2381) Loss_G: -0.0035 (0.1032) D(x): 0.6127 D(G(z)): 0.5515 / 0.4121 Acc: 43.7500 (32.8510)\n",
      "[11/25][415/782] Loss_D: -0.2055 (0.2380) Loss_G: 0.2153 (0.1032) D(x): 0.5754 D(G(z)): 0.4307 / 0.3463 Acc: 48.4375 (32.8527)\n",
      "[11/25][416/782] Loss_D: -0.2233 (0.2380) Loss_G: 0.2772 (0.1032) D(x): 0.4931 D(G(z)): 0.3211 / 0.3229 Acc: 39.0625 (32.8534)\n",
      "[11/25][417/782] Loss_D: -0.0327 (0.2379) Loss_G: -0.1359 (0.1032) D(x): 0.4982 D(G(z)): 0.4549 / 0.4699 Acc: 48.4375 (32.8551)\n",
      "[11/25][418/782] Loss_D: 0.0209 (0.2379) Loss_G: -0.0773 (0.1032) D(x): 0.5308 D(G(z)): 0.5053 / 0.4384 Acc: 42.1875 (32.8561)\n",
      "[11/25][419/782] Loss_D: -0.0634 (0.2379) Loss_G: -0.2459 (0.1031) D(x): 0.5457 D(G(z)): 0.4947 / 0.5088 Acc: 46.8750 (32.8577)\n",
      "[11/25][420/782] Loss_D: 0.1343 (0.2379) Loss_G: 0.0874 (0.1031) D(x): 0.5584 D(G(z)): 0.5573 / 0.3775 Acc: 39.0625 (32.8584)\n",
      "[11/25][421/782] Loss_D: -0.0581 (0.2378) Loss_G: -0.0333 (0.1031) D(x): 0.4864 D(G(z)): 0.4356 / 0.4167 Acc: 48.4375 (32.8601)\n",
      "[11/25][422/782] Loss_D: 0.0173 (0.2378) Loss_G: -0.1657 (0.1031) D(x): 0.4782 D(G(z)): 0.4296 / 0.4643 Acc: 43.7500 (32.8613)\n",
      "[11/25][423/782] Loss_D: -0.0915 (0.2378) Loss_G: -0.0933 (0.1031) D(x): 0.5276 D(G(z)): 0.4423 / 0.4506 Acc: 40.6250 (32.8622)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/25][424/782] Loss_D: -0.1895 (0.2377) Loss_G: -0.0104 (0.1031) D(x): 0.5419 D(G(z)): 0.4599 / 0.4250 Acc: 54.6875 (32.8646)\n",
      "[11/25][425/782] Loss_D: -0.1553 (0.2377) Loss_G: -0.0709 (0.1030) D(x): 0.5373 D(G(z)): 0.4697 / 0.4295 Acc: 48.4375 (32.8663)\n",
      "[11/25][426/782] Loss_D: -0.0551 (0.2377) Loss_G: -0.0091 (0.1030) D(x): 0.5794 D(G(z)): 0.4454 / 0.4068 Acc: 31.2500 (32.8661)\n",
      "[11/25][427/782] Loss_D: -0.0592 (0.2376) Loss_G: -0.0358 (0.1030) D(x): 0.5743 D(G(z)): 0.4864 / 0.4239 Acc: 39.0625 (32.8668)\n",
      "[11/25][428/782] Loss_D: -0.0780 (0.2376) Loss_G: 0.1481 (0.1030) D(x): 0.5466 D(G(z)): 0.4408 / 0.3615 Acc: 34.3750 (32.8670)\n",
      "[11/25][429/782] Loss_D: -0.1236 (0.2376) Loss_G: 0.0847 (0.1030) D(x): 0.5396 D(G(z)): 0.4257 / 0.3790 Acc: 39.0625 (32.8677)\n",
      "[11/25][430/782] Loss_D: -0.1459 (0.2375) Loss_G: 0.1453 (0.1030) D(x): 0.5950 D(G(z)): 0.4554 / 0.3806 Acc: 39.0625 (32.8684)\n",
      "[11/25][431/782] Loss_D: -0.2160 (0.2375) Loss_G: -0.1193 (0.1030) D(x): 0.5501 D(G(z)): 0.4116 / 0.4458 Acc: 51.5625 (32.8704)\n",
      "[11/25][432/782] Loss_D: -0.0830 (0.2374) Loss_G: -0.2007 (0.1030) D(x): 0.5218 D(G(z)): 0.4243 / 0.4780 Acc: 37.5000 (32.8710)\n",
      "[11/25][433/782] Loss_D: -0.1765 (0.2374) Loss_G: -0.1815 (0.1029) D(x): 0.5932 D(G(z)): 0.4716 / 0.4787 Acc: 42.1875 (32.8720)\n",
      "[11/25][434/782] Loss_D: -0.0498 (0.2373) Loss_G: -0.0564 (0.1029) D(x): 0.6203 D(G(z)): 0.4976 / 0.4352 Acc: 42.1875 (32.8730)\n",
      "[11/25][435/782] Loss_D: 0.0418 (0.2373) Loss_G: -0.1035 (0.1029) D(x): 0.4630 D(G(z)): 0.4387 / 0.4471 Acc: 43.7500 (32.8742)\n",
      "[11/25][436/782] Loss_D: 0.1991 (0.2373) Loss_G: -0.1516 (0.1029) D(x): 0.4563 D(G(z)): 0.5106 / 0.4883 Acc: 45.3125 (32.8756)\n",
      "[11/25][437/782] Loss_D: 0.1168 (0.2373) Loss_G: -0.2066 (0.1028) D(x): 0.5027 D(G(z)): 0.5418 / 0.4802 Acc: 48.4375 (32.8773)\n",
      "[11/25][438/782] Loss_D: -0.1045 (0.2373) Loss_G: -0.1054 (0.1028) D(x): 0.5678 D(G(z)): 0.4678 / 0.4390 Acc: 42.1875 (32.8783)\n",
      "[11/25][439/782] Loss_D: -0.0372 (0.2372) Loss_G: -0.1150 (0.1028) D(x): 0.5003 D(G(z)): 0.4390 / 0.4624 Acc: 43.7500 (32.8795)\n",
      "[11/25][440/782] Loss_D: 0.0143 (0.2372) Loss_G: -0.1602 (0.1028) D(x): 0.4979 D(G(z)): 0.4633 / 0.4779 Acc: 43.7500 (32.8808)\n",
      "[11/25][441/782] Loss_D: -0.1295 (0.2372) Loss_G: -0.1565 (0.1027) D(x): 0.5508 D(G(z)): 0.4605 / 0.4628 Acc: 43.7500 (32.8820)\n",
      "[11/25][442/782] Loss_D: 0.1132 (0.2372) Loss_G: -0.0529 (0.1027) D(x): 0.5513 D(G(z)): 0.5330 / 0.4530 Acc: 37.5000 (32.8825)\n",
      "[11/25][443/782] Loss_D: 0.0043 (0.2371) Loss_G: 0.0969 (0.1027) D(x): 0.5474 D(G(z)): 0.4848 / 0.3959 Acc: 37.5000 (32.8830)\n",
      "[11/25][444/782] Loss_D: 0.0145 (0.2371) Loss_G: -0.0834 (0.1027) D(x): 0.4769 D(G(z)): 0.4213 / 0.4387 Acc: 42.1875 (32.8840)\n",
      "[11/25][445/782] Loss_D: -0.1079 (0.2371) Loss_G: -0.1311 (0.1027) D(x): 0.5879 D(G(z)): 0.4678 / 0.4632 Acc: 40.6250 (32.8849)\n",
      "[11/25][446/782] Loss_D: 0.1323 (0.2371) Loss_G: -0.0998 (0.1026) D(x): 0.4809 D(G(z)): 0.4583 / 0.4704 Acc: 35.9375 (32.8852)\n",
      "[11/25][447/782] Loss_D: 0.0004 (0.2370) Loss_G: -0.0692 (0.1026) D(x): 0.5851 D(G(z)): 0.5118 / 0.4502 Acc: 45.3125 (32.8866)\n",
      "[11/25][448/782] Loss_D: -0.2043 (0.2370) Loss_G: -0.1031 (0.1026) D(x): 0.5640 D(G(z)): 0.4364 / 0.4556 Acc: 46.8750 (32.8881)\n",
      "[11/25][449/782] Loss_D: -0.0758 (0.2370) Loss_G: 0.0009 (0.1026) D(x): 0.5284 D(G(z)): 0.3954 / 0.4123 Acc: 40.6250 (32.8890)\n",
      "[11/25][450/782] Loss_D: -0.0698 (0.2369) Loss_G: -0.0351 (0.1026) D(x): 0.5231 D(G(z)): 0.4340 / 0.4236 Acc: 39.0625 (32.8896)\n",
      "[11/25][451/782] Loss_D: -0.2626 (0.2369) Loss_G: 0.0100 (0.1026) D(x): 0.6578 D(G(z)): 0.4937 / 0.3940 Acc: 46.8750 (32.8912)\n",
      "[11/25][452/782] Loss_D: -0.1683 (0.2368) Loss_G: 0.0319 (0.1026) D(x): 0.5469 D(G(z)): 0.4382 / 0.4028 Acc: 46.8750 (32.8927)\n",
      "[11/25][453/782] Loss_D: 0.1199 (0.2368) Loss_G: -0.1128 (0.1025) D(x): 0.4923 D(G(z)): 0.4428 / 0.4522 Acc: 35.9375 (32.8931)\n",
      "[11/25][454/782] Loss_D: -0.0768 (0.2368) Loss_G: -0.1026 (0.1025) D(x): 0.5691 D(G(z)): 0.4916 / 0.4613 Acc: 45.3125 (32.8944)\n",
      "[11/25][455/782] Loss_D: -0.1037 (0.2367) Loss_G: 0.0109 (0.1025) D(x): 0.5382 D(G(z)): 0.4417 / 0.4112 Acc: 39.0625 (32.8951)\n",
      "[11/25][456/782] Loss_D: -0.1779 (0.2367) Loss_G: -0.1327 (0.1025) D(x): 0.5314 D(G(z)): 0.4554 / 0.4731 Acc: 57.8125 (32.8979)\n",
      "[11/25][457/782] Loss_D: -0.0246 (0.2367) Loss_G: -0.1388 (0.1024) D(x): 0.5163 D(G(z)): 0.4627 / 0.4593 Acc: 42.1875 (32.8989)\n",
      "[11/25][458/782] Loss_D: 0.1085 (0.2366) Loss_G: -0.0952 (0.1024) D(x): 0.4645 D(G(z)): 0.4913 / 0.4488 Acc: 48.4375 (32.9006)\n",
      "[11/25][459/782] Loss_D: -0.0707 (0.2366) Loss_G: -0.0126 (0.1024) D(x): 0.5764 D(G(z)): 0.4641 / 0.4150 Acc: 32.8125 (32.9006)\n",
      "[11/25][460/782] Loss_D: -0.0308 (0.2366) Loss_G: -0.1761 (0.1024) D(x): 0.5295 D(G(z)): 0.4634 / 0.4660 Acc: 39.0625 (32.9013)\n",
      "[11/25][461/782] Loss_D: 0.2103 (0.2366) Loss_G: -0.0489 (0.1024) D(x): 0.4691 D(G(z)): 0.5359 / 0.4276 Acc: 53.1250 (32.9035)\n",
      "[11/25][462/782] Loss_D: 0.0978 (0.2366) Loss_G: -0.1409 (0.1023) D(x): 0.4587 D(G(z)): 0.4343 / 0.4586 Acc: 34.3750 (32.9037)\n",
      "[11/25][463/782] Loss_D: 0.0075 (0.2365) Loss_G: -0.1603 (0.1023) D(x): 0.5096 D(G(z)): 0.4440 / 0.4675 Acc: 35.9375 (32.9040)\n",
      "[11/25][464/782] Loss_D: -0.2397 (0.2365) Loss_G: -0.2138 (0.1023) D(x): 0.5972 D(G(z)): 0.4568 / 0.4838 Acc: 42.1875 (32.9050)\n",
      "[11/25][465/782] Loss_D: -0.3221 (0.2364) Loss_G: 0.0387 (0.1023) D(x): 0.5780 D(G(z)): 0.4243 / 0.3918 Acc: 51.5625 (32.9071)\n",
      "[11/25][466/782] Loss_D: -0.3069 (0.2364) Loss_G: -0.0799 (0.1022) D(x): 0.6167 D(G(z)): 0.4361 / 0.4371 Acc: 45.3125 (32.9085)\n",
      "[11/25][467/782] Loss_D: -0.2780 (0.2363) Loss_G: 0.0843 (0.1022) D(x): 0.6149 D(G(z)): 0.4232 / 0.3794 Acc: 45.3125 (32.9098)\n",
      "[11/25][468/782] Loss_D: -0.1611 (0.2363) Loss_G: 0.0077 (0.1022) D(x): 0.5684 D(G(z)): 0.4372 / 0.4008 Acc: 39.0625 (32.9105)\n",
      "[11/25][469/782] Loss_D: -0.1290 (0.2362) Loss_G: -0.1326 (0.1022) D(x): 0.5587 D(G(z)): 0.4140 / 0.4638 Acc: 34.3750 (32.9107)\n",
      "[11/25][470/782] Loss_D: -0.0799 (0.2362) Loss_G: -0.0076 (0.1022) D(x): 0.5718 D(G(z)): 0.4949 / 0.4338 Acc: 50.0000 (32.9126)\n",
      "[11/25][471/782] Loss_D: -0.0388 (0.2362) Loss_G: -0.0703 (0.1022) D(x): 0.5769 D(G(z)): 0.4887 / 0.4376 Acc: 43.7500 (32.9138)\n",
      "[11/25][472/782] Loss_D: -0.0343 (0.2361) Loss_G: 0.0948 (0.1022) D(x): 0.5257 D(G(z)): 0.4874 / 0.3698 Acc: 45.3125 (32.9151)\n",
      "[11/25][473/782] Loss_D: -0.1207 (0.2361) Loss_G: -0.1360 (0.1022) D(x): 0.4660 D(G(z)): 0.4088 / 0.4538 Acc: 54.6875 (32.9175)\n",
      "[11/25][474/782] Loss_D: -0.0593 (0.2361) Loss_G: -0.1657 (0.1021) D(x): 0.5527 D(G(z)): 0.4757 / 0.4748 Acc: 45.3125 (32.9189)\n",
      "[11/25][475/782] Loss_D: -0.2355 (0.2360) Loss_G: -0.2277 (0.1021) D(x): 0.5763 D(G(z)): 0.4343 / 0.4888 Acc: 48.4375 (32.9206)\n",
      "[11/25][476/782] Loss_D: -0.0497 (0.2360) Loss_G: -0.0419 (0.1021) D(x): 0.5283 D(G(z)): 0.5083 / 0.4160 Acc: 50.0000 (32.9225)\n",
      "[11/25][477/782] Loss_D: 0.1656 (0.2360) Loss_G: -0.0356 (0.1021) D(x): 0.4705 D(G(z)): 0.5078 / 0.4338 Acc: 48.4375 (32.9242)\n",
      "[11/25][478/782] Loss_D: 0.0184 (0.2359) Loss_G: -0.1431 (0.1020) D(x): 0.4668 D(G(z)): 0.4324 / 0.4581 Acc: 42.1875 (32.9252)\n",
      "[11/25][479/782] Loss_D: 0.0254 (0.2359) Loss_G: -0.2558 (0.1020) D(x): 0.5340 D(G(z)): 0.5081 / 0.5075 Acc: 45.3125 (32.9266)\n",
      "[11/25][480/782] Loss_D: -0.0093 (0.2359) Loss_G: -0.1485 (0.1020) D(x): 0.4975 D(G(z)): 0.4389 / 0.4647 Acc: 40.6250 (32.9274)\n",
      "[11/25][481/782] Loss_D: 0.0107 (0.2359) Loss_G: -0.0668 (0.1019) D(x): 0.5215 D(G(z)): 0.4937 / 0.4325 Acc: 40.6250 (32.9283)\n",
      "[11/25][482/782] Loss_D: 0.0006 (0.2358) Loss_G: -0.1532 (0.1019) D(x): 0.5214 D(G(z)): 0.4781 / 0.4685 Acc: 40.6250 (32.9291)\n",
      "[11/25][483/782] Loss_D: -0.3553 (0.2358) Loss_G: -0.1136 (0.1019) D(x): 0.6395 D(G(z)): 0.4584 / 0.4473 Acc: 46.8750 (32.9306)\n",
      "[11/25][484/782] Loss_D: -0.0350 (0.2357) Loss_G: 0.0248 (0.1019) D(x): 0.4938 D(G(z)): 0.4562 / 0.4286 Acc: 45.3125 (32.9320)\n",
      "[11/25][485/782] Loss_D: -0.1642 (0.2357) Loss_G: -0.0058 (0.1019) D(x): 0.5191 D(G(z)): 0.4087 / 0.4057 Acc: 42.1875 (32.9330)\n",
      "[11/25][486/782] Loss_D: -0.1109 (0.2357) Loss_G: -0.1600 (0.1018) D(x): 0.5365 D(G(z)): 0.4558 / 0.4625 Acc: 46.8750 (32.9346)\n",
      "[11/25][487/782] Loss_D: -0.2632 (0.2356) Loss_G: 0.0998 (0.1018) D(x): 0.5598 D(G(z)): 0.3917 / 0.3640 Acc: 50.0000 (32.9364)\n",
      "[11/25][488/782] Loss_D: -0.0697 (0.2356) Loss_G: -0.1347 (0.1018) D(x): 0.5464 D(G(z)): 0.4357 / 0.4810 Acc: 40.6250 (32.9373)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/25][489/782] Loss_D: -0.0724 (0.2355) Loss_G: -0.0852 (0.1018) D(x): 0.5581 D(G(z)): 0.4640 / 0.4469 Acc: 42.1875 (32.9383)\n",
      "[11/25][490/782] Loss_D: -0.1231 (0.2355) Loss_G: -0.0246 (0.1018) D(x): 0.5336 D(G(z)): 0.4597 / 0.4106 Acc: 43.7500 (32.9395)\n",
      "[11/25][491/782] Loss_D: -0.1376 (0.2355) Loss_G: -0.0802 (0.1018) D(x): 0.4960 D(G(z)): 0.4400 / 0.4240 Acc: 54.6875 (32.9419)\n",
      "[11/25][492/782] Loss_D: 0.0462 (0.2354) Loss_G: -0.1305 (0.1017) D(x): 0.5211 D(G(z)): 0.4875 / 0.4464 Acc: 39.0625 (32.9426)\n",
      "[11/25][493/782] Loss_D: -0.2547 (0.2354) Loss_G: -0.0498 (0.1017) D(x): 0.5811 D(G(z)): 0.4598 / 0.4234 Acc: 54.6875 (32.9449)\n",
      "[11/25][494/782] Loss_D: 0.1729 (0.2354) Loss_G: -0.1117 (0.1017) D(x): 0.4545 D(G(z)): 0.4629 / 0.4379 Acc: 35.9375 (32.9453)\n",
      "[11/25][495/782] Loss_D: 0.0240 (0.2354) Loss_G: -0.0224 (0.1017) D(x): 0.5285 D(G(z)): 0.5657 / 0.4183 Acc: 54.6875 (32.9477)\n",
      "[11/25][496/782] Loss_D: 0.1424 (0.2353) Loss_G: -0.1177 (0.1017) D(x): 0.4840 D(G(z)): 0.4529 / 0.4449 Acc: 32.8125 (32.9476)\n",
      "[11/25][497/782] Loss_D: -0.1351 (0.2353) Loss_G: -0.0418 (0.1016) D(x): 0.4862 D(G(z)): 0.3707 / 0.4356 Acc: 45.3125 (32.9490)\n",
      "[11/25][498/782] Loss_D: 0.0487 (0.2353) Loss_G: -0.1889 (0.1016) D(x): 0.5797 D(G(z)): 0.5007 / 0.4813 Acc: 34.3750 (32.9492)\n",
      "[11/25][499/782] Loss_D: 0.1299 (0.2353) Loss_G: -0.1363 (0.1016) D(x): 0.5502 D(G(z)): 0.5001 / 0.4550 Acc: 31.2500 (32.9490)\n",
      "[11/25][500/782] Loss_D: -0.2448 (0.2352) Loss_G: -0.2450 (0.1015) D(x): 0.5402 D(G(z)): 0.4636 / 0.5045 Acc: 59.3750 (32.9519)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[11/25][501/782] Loss_D: -0.0744 (0.2352) Loss_G: -0.1109 (0.1015) D(x): 0.5464 D(G(z)): 0.4693 / 0.4386 Acc: 42.1875 (32.9529)\n",
      "[11/25][502/782] Loss_D: -0.1023 (0.2351) Loss_G: -0.1509 (0.1015) D(x): 0.5936 D(G(z)): 0.5057 / 0.4758 Acc: 42.1875 (32.9539)\n",
      "[11/25][503/782] Loss_D: -0.0197 (0.2351) Loss_G: -0.0357 (0.1015) D(x): 0.5140 D(G(z)): 0.4352 / 0.4247 Acc: 37.5000 (32.9544)\n",
      "[11/25][504/782] Loss_D: -0.1475 (0.2351) Loss_G: -0.1226 (0.1015) D(x): 0.4780 D(G(z)): 0.3649 / 0.4688 Acc: 53.1250 (32.9566)\n",
      "[11/25][505/782] Loss_D: -0.1883 (0.2350) Loss_G: -0.1364 (0.1014) D(x): 0.5913 D(G(z)): 0.4691 / 0.4561 Acc: 45.3125 (32.9580)\n",
      "[11/25][506/782] Loss_D: 0.0570 (0.2350) Loss_G: -0.1073 (0.1014) D(x): 0.5192 D(G(z)): 0.5009 / 0.4491 Acc: 39.0625 (32.9586)\n",
      "[11/25][507/782] Loss_D: 0.0240 (0.2350) Loss_G: -0.0451 (0.1014) D(x): 0.5560 D(G(z)): 0.5248 / 0.4214 Acc: 45.3125 (32.9600)\n",
      "[11/25][508/782] Loss_D: -0.1872 (0.2349) Loss_G: 0.1739 (0.1014) D(x): 0.5534 D(G(z)): 0.4369 / 0.3441 Acc: 42.1875 (32.9610)\n",
      "[11/25][509/782] Loss_D: -0.0740 (0.2349) Loss_G: 0.0463 (0.1014) D(x): 0.5176 D(G(z)): 0.4427 / 0.3987 Acc: 42.1875 (32.9620)\n",
      "[11/25][510/782] Loss_D: -0.2821 (0.2349) Loss_G: -0.1290 (0.1014) D(x): 0.5213 D(G(z)): 0.4313 / 0.4671 Acc: 57.8125 (32.9648)\n",
      "[11/25][511/782] Loss_D: 0.0795 (0.2348) Loss_G: -0.2756 (0.1013) D(x): 0.5157 D(G(z)): 0.4926 / 0.5255 Acc: 43.7500 (32.9659)\n",
      "[11/25][512/782] Loss_D: 0.0671 (0.2348) Loss_G: -0.0812 (0.1013) D(x): 0.5069 D(G(z)): 0.5278 / 0.4410 Acc: 53.1250 (32.9682)\n",
      "[11/25][513/782] Loss_D: 0.2265 (0.2348) Loss_G: -0.2227 (0.1013) D(x): 0.4438 D(G(z)): 0.5165 / 0.4972 Acc: 40.6250 (32.9690)\n",
      "[11/25][514/782] Loss_D: -0.0822 (0.2348) Loss_G: -0.0552 (0.1013) D(x): 0.5616 D(G(z)): 0.5248 / 0.4345 Acc: 50.0000 (32.9709)\n",
      "[11/25][515/782] Loss_D: 0.0719 (0.2348) Loss_G: -0.0503 (0.1012) D(x): 0.4900 D(G(z)): 0.4588 / 0.4287 Acc: 40.6250 (32.9717)\n",
      "[11/25][516/782] Loss_D: 0.0452 (0.2347) Loss_G: -0.0893 (0.1012) D(x): 0.4904 D(G(z)): 0.4673 / 0.4350 Acc: 45.3125 (32.9731)\n",
      "[11/25][517/782] Loss_D: 0.1034 (0.2347) Loss_G: 0.0151 (0.1012) D(x): 0.5073 D(G(z)): 0.5135 / 0.4016 Acc: 45.3125 (32.9744)\n",
      "[11/25][518/782] Loss_D: -0.0094 (0.2347) Loss_G: -0.0681 (0.1012) D(x): 0.5095 D(G(z)): 0.4652 / 0.4326 Acc: 43.7500 (32.9756)\n",
      "[11/25][519/782] Loss_D: 0.0459 (0.2347) Loss_G: -0.0423 (0.1012) D(x): 0.5280 D(G(z)): 0.4831 / 0.4280 Acc: 39.0625 (32.9763)\n",
      "[11/25][520/782] Loss_D: -0.0440 (0.2346) Loss_G: -0.1669 (0.1011) D(x): 0.4913 D(G(z)): 0.4118 / 0.4670 Acc: 40.6250 (32.9771)\n",
      "[11/25][521/782] Loss_D: -0.2872 (0.2346) Loss_G: 0.0422 (0.1011) D(x): 0.5784 D(G(z)): 0.4163 / 0.3983 Acc: 46.8750 (32.9786)\n",
      "[11/25][522/782] Loss_D: -0.1572 (0.2345) Loss_G: -0.0574 (0.1011) D(x): 0.5608 D(G(z)): 0.4723 / 0.4210 Acc: 48.4375 (32.9803)\n",
      "[11/25][523/782] Loss_D: -0.0089 (0.2345) Loss_G: -0.2064 (0.1011) D(x): 0.4653 D(G(z)): 0.4344 / 0.4892 Acc: 48.4375 (32.9820)\n",
      "[11/25][524/782] Loss_D: -0.0713 (0.2345) Loss_G: -0.1523 (0.1011) D(x): 0.6075 D(G(z)): 0.4924 / 0.4748 Acc: 40.6250 (32.9828)\n",
      "[11/25][525/782] Loss_D: -0.0345 (0.2345) Loss_G: 0.0223 (0.1010) D(x): 0.5739 D(G(z)): 0.5091 / 0.4025 Acc: 46.8750 (32.9844)\n",
      "[11/25][526/782] Loss_D: -0.1515 (0.2344) Loss_G: 0.0848 (0.1010) D(x): 0.5404 D(G(z)): 0.4294 / 0.3697 Acc: 45.3125 (32.9857)\n",
      "[11/25][527/782] Loss_D: -0.2444 (0.2344) Loss_G: 0.0805 (0.1010) D(x): 0.5661 D(G(z)): 0.4201 / 0.3722 Acc: 46.8750 (32.9872)\n",
      "[11/25][528/782] Loss_D: -0.0871 (0.2343) Loss_G: 0.0005 (0.1010) D(x): 0.5260 D(G(z)): 0.4597 / 0.3992 Acc: 46.8750 (32.9888)\n",
      "[11/25][529/782] Loss_D: -0.1493 (0.2343) Loss_G: -0.1390 (0.1010) D(x): 0.5507 D(G(z)): 0.4614 / 0.4614 Acc: 46.8750 (32.9903)\n",
      "[11/25][530/782] Loss_D: -0.0897 (0.2343) Loss_G: 0.0105 (0.1010) D(x): 0.6248 D(G(z)): 0.5260 / 0.4015 Acc: 45.3125 (32.9916)\n",
      "[11/25][531/782] Loss_D: -0.0129 (0.2342) Loss_G: 0.0071 (0.1010) D(x): 0.4962 D(G(z)): 0.4803 / 0.4173 Acc: 50.0000 (32.9935)\n",
      "[11/25][532/782] Loss_D: 0.0226 (0.2342) Loss_G: -0.1138 (0.1010) D(x): 0.4778 D(G(z)): 0.4529 / 0.4638 Acc: 46.8750 (32.9950)\n",
      "[11/25][533/782] Loss_D: -0.0107 (0.2342) Loss_G: -0.0640 (0.1009) D(x): 0.4781 D(G(z)): 0.4485 / 0.4176 Acc: 50.0000 (32.9969)\n",
      "[11/25][534/782] Loss_D: 0.1102 (0.2342) Loss_G: -0.0707 (0.1009) D(x): 0.4832 D(G(z)): 0.4682 / 0.4464 Acc: 35.9375 (32.9972)\n",
      "[11/25][535/782] Loss_D: -0.0276 (0.2341) Loss_G: 0.1114 (0.1009) D(x): 0.5951 D(G(z)): 0.5245 / 0.3733 Acc: 46.8750 (32.9987)\n",
      "[11/25][536/782] Loss_D: -0.1984 (0.2341) Loss_G: 0.0741 (0.1009) D(x): 0.4892 D(G(z)): 0.4094 / 0.3853 Acc: 57.8125 (33.0014)\n",
      "[11/25][537/782] Loss_D: -0.1260 (0.2340) Loss_G: -0.0724 (0.1009) D(x): 0.5224 D(G(z)): 0.3990 / 0.4419 Acc: 40.6250 (33.0023)\n",
      "[11/25][538/782] Loss_D: 0.0856 (0.2340) Loss_G: -0.0754 (0.1009) D(x): 0.5706 D(G(z)): 0.4913 / 0.4499 Acc: 23.4375 (33.0012)\n",
      "[11/25][539/782] Loss_D: -0.0044 (0.2340) Loss_G: -0.0529 (0.1009) D(x): 0.5225 D(G(z)): 0.4754 / 0.4466 Acc: 42.1875 (33.0022)\n",
      "[11/25][540/782] Loss_D: -0.3480 (0.2339) Loss_G: 0.0271 (0.1009) D(x): 0.6507 D(G(z)): 0.4254 / 0.3959 Acc: 48.4375 (33.0039)\n",
      "[11/25][541/782] Loss_D: -0.0873 (0.2339) Loss_G: 0.0028 (0.1008) D(x): 0.5957 D(G(z)): 0.5073 / 0.4102 Acc: 45.3125 (33.0052)\n",
      "[11/25][542/782] Loss_D: -0.0312 (0.2339) Loss_G: 0.0882 (0.1008) D(x): 0.5545 D(G(z)): 0.4748 / 0.3955 Acc: 43.7500 (33.0064)\n",
      "[11/25][543/782] Loss_D: -0.2025 (0.2338) Loss_G: 0.1059 (0.1008) D(x): 0.5298 D(G(z)): 0.3595 / 0.3794 Acc: 43.7500 (33.0076)\n",
      "[11/25][544/782] Loss_D: -0.1990 (0.2338) Loss_G: -0.0834 (0.1008) D(x): 0.4778 D(G(z)): 0.3701 / 0.4475 Acc: 54.6875 (33.0100)\n",
      "[11/25][545/782] Loss_D: 0.0166 (0.2338) Loss_G: -0.0811 (0.1008) D(x): 0.6150 D(G(z)): 0.5242 / 0.4594 Acc: 34.3750 (33.0101)\n",
      "[11/25][546/782] Loss_D: -0.1482 (0.2337) Loss_G: -0.1367 (0.1008) D(x): 0.5755 D(G(z)): 0.4607 / 0.4634 Acc: 43.7500 (33.0113)\n",
      "[11/25][547/782] Loss_D: 0.2163 (0.2337) Loss_G: -0.1669 (0.1008) D(x): 0.4821 D(G(z)): 0.5017 / 0.4731 Acc: 35.9375 (33.0116)\n",
      "[11/25][548/782] Loss_D: 0.0087 (0.2337) Loss_G: -0.0357 (0.1007) D(x): 0.5287 D(G(z)): 0.5282 / 0.4125 Acc: 54.6875 (33.0140)\n",
      "[11/25][549/782] Loss_D: -0.0814 (0.2337) Loss_G: -0.2323 (0.1007) D(x): 0.5313 D(G(z)): 0.4529 / 0.4991 Acc: 40.6250 (33.0148)\n",
      "[11/25][550/782] Loss_D: 0.1564 (0.2336) Loss_G: -0.0785 (0.1007) D(x): 0.4730 D(G(z)): 0.5079 / 0.4652 Acc: 48.4375 (33.0165)\n",
      "[11/25][551/782] Loss_D: 0.0114 (0.2336) Loss_G: -0.1740 (0.1007) D(x): 0.5223 D(G(z)): 0.4978 / 0.5000 Acc: 51.5625 (33.0185)\n",
      "[11/25][552/782] Loss_D: 0.1475 (0.2336) Loss_G: -0.2558 (0.1006) D(x): 0.4980 D(G(z)): 0.5357 / 0.5161 Acc: 46.8750 (33.0200)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/25][553/782] Loss_D: 0.1683 (0.2336) Loss_G: -0.0003 (0.1006) D(x): 0.4643 D(G(z)): 0.4974 / 0.4063 Acc: 40.6250 (33.0209)\n",
      "[11/25][554/782] Loss_D: 0.0269 (0.2336) Loss_G: -0.1404 (0.1006) D(x): 0.5356 D(G(z)): 0.4660 / 0.4644 Acc: 35.9375 (33.0212)\n",
      "[11/25][555/782] Loss_D: -0.0668 (0.2335) Loss_G: -0.0464 (0.1006) D(x): 0.5501 D(G(z)): 0.5254 / 0.4234 Acc: 53.1250 (33.0234)\n",
      "[11/25][556/782] Loss_D: -0.2824 (0.2335) Loss_G: 0.0854 (0.1006) D(x): 0.5597 D(G(z)): 0.4057 / 0.3850 Acc: 48.4375 (33.0251)\n",
      "[11/25][557/782] Loss_D: -0.0074 (0.2335) Loss_G: -0.0078 (0.1005) D(x): 0.5062 D(G(z)): 0.4573 / 0.4074 Acc: 45.3125 (33.0264)\n",
      "[11/25][558/782] Loss_D: -0.0485 (0.2334) Loss_G: 0.0535 (0.1005) D(x): 0.5526 D(G(z)): 0.4518 / 0.3889 Acc: 42.1875 (33.0274)\n",
      "[11/25][559/782] Loss_D: -0.0169 (0.2334) Loss_G: -0.0890 (0.1005) D(x): 0.5103 D(G(z)): 0.4246 / 0.4447 Acc: 37.5000 (33.0279)\n",
      "[11/25][560/782] Loss_D: -0.1153 (0.2334) Loss_G: -0.0355 (0.1005) D(x): 0.5170 D(G(z)): 0.4210 / 0.4197 Acc: 48.4375 (33.0296)\n",
      "[11/25][561/782] Loss_D: -0.1062 (0.2333) Loss_G: -0.2066 (0.1005) D(x): 0.5659 D(G(z)): 0.4731 / 0.4898 Acc: 46.8750 (33.0311)\n",
      "[11/25][562/782] Loss_D: 0.0050 (0.2333) Loss_G: -0.0384 (0.1005) D(x): 0.5525 D(G(z)): 0.4899 / 0.4067 Acc: 39.0625 (33.0317)\n",
      "[11/25][563/782] Loss_D: -0.2378 (0.2333) Loss_G: -0.0692 (0.1004) D(x): 0.5904 D(G(z)): 0.4513 / 0.4264 Acc: 46.8750 (33.0333)\n",
      "[11/25][564/782] Loss_D: -0.0630 (0.2332) Loss_G: -0.0346 (0.1004) D(x): 0.5430 D(G(z)): 0.4143 / 0.4139 Acc: 31.2500 (33.0331)\n",
      "[11/25][565/782] Loss_D: -0.1918 (0.2332) Loss_G: -0.0583 (0.1004) D(x): 0.5444 D(G(z)): 0.4447 / 0.4239 Acc: 50.0000 (33.0349)\n",
      "[11/25][566/782] Loss_D: -0.1733 (0.2331) Loss_G: -0.0995 (0.1004) D(x): 0.5426 D(G(z)): 0.4133 / 0.4522 Acc: 42.1875 (33.0359)\n",
      "[11/25][567/782] Loss_D: -0.2903 (0.2331) Loss_G: 0.0076 (0.1004) D(x): 0.5820 D(G(z)): 0.4192 / 0.4141 Acc: 48.4375 (33.0376)\n",
      "[11/25][568/782] Loss_D: -0.1198 (0.2330) Loss_G: -0.0223 (0.1004) D(x): 0.5841 D(G(z)): 0.5310 / 0.4130 Acc: 56.2500 (33.0401)\n",
      "[11/25][569/782] Loss_D: -0.2295 (0.2330) Loss_G: -0.0101 (0.1003) D(x): 0.5831 D(G(z)): 0.4270 / 0.4030 Acc: 39.0625 (33.0408)\n",
      "[11/25][570/782] Loss_D: 0.0827 (0.2330) Loss_G: -0.0662 (0.1003) D(x): 0.5298 D(G(z)): 0.5050 / 0.4382 Acc: 39.0625 (33.0414)\n",
      "[11/25][571/782] Loss_D: 0.2008 (0.2330) Loss_G: -0.1187 (0.1003) D(x): 0.4629 D(G(z)): 0.4787 / 0.4597 Acc: 39.0625 (33.0421)\n",
      "[11/25][572/782] Loss_D: 0.0567 (0.2329) Loss_G: -0.1439 (0.1003) D(x): 0.4996 D(G(z)): 0.4640 / 0.4637 Acc: 48.4375 (33.0438)\n",
      "[11/25][573/782] Loss_D: 0.1094 (0.2329) Loss_G: -0.1798 (0.1002) D(x): 0.5151 D(G(z)): 0.5444 / 0.5114 Acc: 51.5625 (33.0458)\n",
      "[11/25][574/782] Loss_D: 0.0920 (0.2329) Loss_G: -0.1104 (0.1002) D(x): 0.5182 D(G(z)): 0.4616 / 0.4370 Acc: 32.8125 (33.0458)\n",
      "[11/25][575/782] Loss_D: -0.1122 (0.2329) Loss_G: -0.1132 (0.1002) D(x): 0.5185 D(G(z)): 0.4529 / 0.4657 Acc: 53.1250 (33.0479)\n",
      "[11/25][576/782] Loss_D: 0.0216 (0.2329) Loss_G: -0.1100 (0.1002) D(x): 0.5614 D(G(z)): 0.4883 / 0.4501 Acc: 35.9375 (33.0483)\n",
      "[11/25][577/782] Loss_D: -0.1590 (0.2328) Loss_G: -0.1842 (0.1001) D(x): 0.4792 D(G(z)): 0.4166 / 0.4807 Acc: 56.2500 (33.0508)\n",
      "[11/25][578/782] Loss_D: -0.0544 (0.2328) Loss_G: -0.2550 (0.1001) D(x): 0.5745 D(G(z)): 0.4933 / 0.5236 Acc: 40.6250 (33.0516)\n",
      "[11/25][579/782] Loss_D: -0.1940 (0.2327) Loss_G: 0.0475 (0.1001) D(x): 0.5805 D(G(z)): 0.4881 / 0.3797 Acc: 56.2500 (33.0541)\n",
      "[11/25][580/782] Loss_D: -0.0375 (0.2327) Loss_G: -0.0731 (0.1001) D(x): 0.4634 D(G(z)): 0.3784 / 0.4389 Acc: 50.0000 (33.0560)\n",
      "[11/25][581/782] Loss_D: -0.1258 (0.2327) Loss_G: -0.0810 (0.1001) D(x): 0.5609 D(G(z)): 0.4585 / 0.4331 Acc: 43.7500 (33.0572)\n",
      "[11/25][582/782] Loss_D: -0.1598 (0.2326) Loss_G: -0.1587 (0.1000) D(x): 0.5374 D(G(z)): 0.4731 / 0.4615 Acc: 51.5625 (33.0592)\n",
      "[11/25][583/782] Loss_D: -0.2149 (0.2326) Loss_G: -0.0228 (0.1000) D(x): 0.5180 D(G(z)): 0.4113 / 0.4070 Acc: 50.0000 (33.0610)\n",
      "[11/25][584/782] Loss_D: -0.0158 (0.2326) Loss_G: -0.0655 (0.1000) D(x): 0.5710 D(G(z)): 0.5312 / 0.4211 Acc: 43.7500 (33.0622)\n",
      "[11/25][585/782] Loss_D: -0.2097 (0.2325) Loss_G: 0.1018 (0.1000) D(x): 0.5411 D(G(z)): 0.4080 / 0.3850 Acc: 43.7500 (33.0633)\n",
      "[11/25][586/782] Loss_D: -0.0402 (0.2325) Loss_G: -0.2115 (0.1000) D(x): 0.5239 D(G(z)): 0.4632 / 0.4886 Acc: 42.1875 (33.0643)\n",
      "[11/25][587/782] Loss_D: -0.0635 (0.2324) Loss_G: -0.0211 (0.1000) D(x): 0.4552 D(G(z)): 0.4209 / 0.4082 Acc: 54.6875 (33.0667)\n",
      "[11/25][588/782] Loss_D: -0.1205 (0.2324) Loss_G: 0.0358 (0.1000) D(x): 0.5266 D(G(z)): 0.3969 / 0.4033 Acc: 40.6250 (33.0675)\n",
      "[11/25][589/782] Loss_D: 0.0164 (0.2324) Loss_G: -0.1902 (0.0999) D(x): 0.5277 D(G(z)): 0.4847 / 0.4993 Acc: 45.3125 (33.0688)\n",
      "[11/25][590/782] Loss_D: -0.1466 (0.2323) Loss_G: -0.1951 (0.0999) D(x): 0.6048 D(G(z)): 0.4729 / 0.4764 Acc: 39.0625 (33.0695)\n",
      "[11/25][591/782] Loss_D: -0.2509 (0.2323) Loss_G: -0.0724 (0.0999) D(x): 0.5641 D(G(z)): 0.4349 / 0.4182 Acc: 48.4375 (33.0712)\n",
      "[11/25][592/782] Loss_D: -0.2385 (0.2322) Loss_G: -0.1515 (0.0998) D(x): 0.5605 D(G(z)): 0.4448 / 0.4597 Acc: 46.8750 (33.0727)\n",
      "[11/25][593/782] Loss_D: -0.3050 (0.2322) Loss_G: 0.0684 (0.0998) D(x): 0.5719 D(G(z)): 0.4427 / 0.3768 Acc: 54.6875 (33.0750)\n",
      "[11/25][594/782] Loss_D: 0.1597 (0.2322) Loss_G: -0.2952 (0.0998) D(x): 0.4539 D(G(z)): 0.4746 / 0.5296 Acc: 45.3125 (33.0763)\n",
      "[11/25][595/782] Loss_D: -0.1259 (0.2321) Loss_G: -0.0606 (0.0998) D(x): 0.5641 D(G(z)): 0.4762 / 0.4434 Acc: 46.8750 (33.0778)\n",
      "[11/25][596/782] Loss_D: 0.1690 (0.2321) Loss_G: -0.0770 (0.0998) D(x): 0.5283 D(G(z)): 0.5662 / 0.4289 Acc: 42.1875 (33.0788)\n",
      "[11/25][597/782] Loss_D: -0.0203 (0.2321) Loss_G: 0.0446 (0.0998) D(x): 0.4941 D(G(z)): 0.4306 / 0.3797 Acc: 46.8750 (33.0803)\n",
      "[11/25][598/782] Loss_D: -0.1531 (0.2321) Loss_G: -0.1241 (0.0997) D(x): 0.5112 D(G(z)): 0.4126 / 0.4730 Acc: 45.3125 (33.0817)\n",
      "[11/25][599/782] Loss_D: -0.0989 (0.2320) Loss_G: -0.2553 (0.0997) D(x): 0.5859 D(G(z)): 0.5031 / 0.5028 Acc: 43.7500 (33.0828)\n",
      "[11/25][600/782] Loss_D: -0.2552 (0.2320) Loss_G: -0.0537 (0.0997) D(x): 0.5576 D(G(z)): 0.4377 / 0.4290 Acc: 48.4375 (33.0845)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[11/25][601/782] Loss_D: -0.2209 (0.2319) Loss_G: 0.0892 (0.0997) D(x): 0.5375 D(G(z)): 0.4046 / 0.3947 Acc: 50.0000 (33.0863)\n",
      "[11/25][602/782] Loss_D: 0.0335 (0.2319) Loss_G: -0.2142 (0.0996) D(x): 0.4699 D(G(z)): 0.4654 / 0.5039 Acc: 48.4375 (33.0880)\n",
      "[11/25][603/782] Loss_D: 0.0392 (0.2319) Loss_G: -0.1187 (0.0996) D(x): 0.5925 D(G(z)): 0.5568 / 0.4469 Acc: 40.6250 (33.0888)\n",
      "[11/25][604/782] Loss_D: -0.2286 (0.2318) Loss_G: -0.0877 (0.0996) D(x): 0.5227 D(G(z)): 0.3899 / 0.4395 Acc: 42.1875 (33.0898)\n",
      "[11/25][605/782] Loss_D: -0.1941 (0.2318) Loss_G: -0.0864 (0.0996) D(x): 0.5727 D(G(z)): 0.4682 / 0.4283 Acc: 48.4375 (33.0915)\n",
      "[11/25][606/782] Loss_D: -0.1737 (0.2317) Loss_G: -0.1246 (0.0996) D(x): 0.5923 D(G(z)): 0.4769 / 0.4484 Acc: 42.1875 (33.0925)\n",
      "[11/25][607/782] Loss_D: -0.0664 (0.2317) Loss_G: -0.1285 (0.0995) D(x): 0.4949 D(G(z)): 0.3997 / 0.4451 Acc: 35.9375 (33.0928)\n",
      "[11/25][608/782] Loss_D: -0.0952 (0.2317) Loss_G: -0.1045 (0.0995) D(x): 0.5491 D(G(z)): 0.5062 / 0.4432 Acc: 50.0000 (33.0946)\n",
      "[11/25][609/782] Loss_D: 0.0650 (0.2316) Loss_G: 0.1283 (0.0995) D(x): 0.5865 D(G(z)): 0.5409 / 0.3656 Acc: 40.6250 (33.0954)\n",
      "[11/25][610/782] Loss_D: -0.0774 (0.2316) Loss_G: -0.1534 (0.0995) D(x): 0.5033 D(G(z)): 0.4198 / 0.4628 Acc: 43.7500 (33.0966)\n",
      "[11/25][611/782] Loss_D: 0.1434 (0.2316) Loss_G: -0.0999 (0.0995) D(x): 0.4850 D(G(z)): 0.4993 / 0.4339 Acc: 39.0625 (33.0972)\n",
      "[11/25][612/782] Loss_D: 0.1177 (0.2316) Loss_G: -0.1120 (0.0994) D(x): 0.5083 D(G(z)): 0.5477 / 0.4474 Acc: 50.0000 (33.0991)\n",
      "[11/25][613/782] Loss_D: -0.1098 (0.2316) Loss_G: -0.0450 (0.0994) D(x): 0.5424 D(G(z)): 0.4706 / 0.4164 Acc: 48.4375 (33.1007)\n",
      "[11/25][614/782] Loss_D: 0.0707 (0.2315) Loss_G: -0.0730 (0.0994) D(x): 0.4240 D(G(z)): 0.4114 / 0.4331 Acc: 43.7500 (33.1019)\n",
      "[11/25][615/782] Loss_D: 0.2099 (0.2315) Loss_G: -0.2713 (0.0994) D(x): 0.4305 D(G(z)): 0.4964 / 0.5057 Acc: 48.4375 (33.1035)\n",
      "[11/25][616/782] Loss_D: -0.0123 (0.2315) Loss_G: -0.1446 (0.0993) D(x): 0.5887 D(G(z)): 0.5270 / 0.4521 Acc: 42.1875 (33.1045)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/25][617/782] Loss_D: 0.0103 (0.2315) Loss_G: -0.0199 (0.0993) D(x): 0.5478 D(G(z)): 0.4930 / 0.4166 Acc: 39.0625 (33.1052)\n",
      "[11/25][618/782] Loss_D: 0.0425 (0.2315) Loss_G: -0.0427 (0.0993) D(x): 0.4910 D(G(z)): 0.4323 / 0.4196 Acc: 32.8125 (33.1051)\n",
      "[11/25][619/782] Loss_D: -0.0112 (0.2314) Loss_G: -0.1596 (0.0993) D(x): 0.5135 D(G(z)): 0.4618 / 0.4643 Acc: 37.5000 (33.1056)\n",
      "[11/25][620/782] Loss_D: -0.1635 (0.2314) Loss_G: -0.2957 (0.0992) D(x): 0.5317 D(G(z)): 0.4444 / 0.5275 Acc: 48.4375 (33.1073)\n",
      "[11/25][621/782] Loss_D: -0.0754 (0.2314) Loss_G: -0.3218 (0.0992) D(x): 0.5291 D(G(z)): 0.4342 / 0.5380 Acc: 42.1875 (33.1083)\n",
      "[11/25][622/782] Loss_D: -0.1794 (0.2313) Loss_G: -0.2142 (0.0992) D(x): 0.6371 D(G(z)): 0.5459 / 0.4891 Acc: 56.2500 (33.1108)\n",
      "[11/25][623/782] Loss_D: -0.1098 (0.2313) Loss_G: 0.1405 (0.0992) D(x): 0.5785 D(G(z)): 0.4650 / 0.3445 Acc: 40.6250 (33.1116)\n",
      "[11/25][624/782] Loss_D: -0.2226 (0.2312) Loss_G: 0.0519 (0.0992) D(x): 0.4484 D(G(z)): 0.3864 / 0.3738 Acc: 60.9375 (33.1146)\n",
      "[11/25][625/782] Loss_D: 0.0618 (0.2312) Loss_G: -0.2403 (0.0991) D(x): 0.4537 D(G(z)): 0.4498 / 0.4965 Acc: 45.3125 (33.1159)\n",
      "[11/25][626/782] Loss_D: -0.2203 (0.2312) Loss_G: -0.1696 (0.0991) D(x): 0.5480 D(G(z)): 0.4565 / 0.4787 Acc: 53.1250 (33.1181)\n",
      "[11/25][627/782] Loss_D: -0.0757 (0.2311) Loss_G: -0.1727 (0.0991) D(x): 0.6306 D(G(z)): 0.5116 / 0.4720 Acc: 31.2500 (33.1179)\n",
      "[11/25][628/782] Loss_D: 0.0233 (0.2311) Loss_G: -0.0286 (0.0990) D(x): 0.4652 D(G(z)): 0.4936 / 0.4201 Acc: 53.1250 (33.1201)\n",
      "[11/25][629/782] Loss_D: -0.0529 (0.2311) Loss_G: -0.1734 (0.0990) D(x): 0.5205 D(G(z)): 0.4571 / 0.4756 Acc: 40.6250 (33.1209)\n",
      "[11/25][630/782] Loss_D: -0.0663 (0.2310) Loss_G: -0.0119 (0.0990) D(x): 0.5381 D(G(z)): 0.4768 / 0.4089 Acc: 43.7500 (33.1220)\n",
      "[11/25][631/782] Loss_D: 0.0768 (0.2310) Loss_G: 0.0711 (0.0990) D(x): 0.5316 D(G(z)): 0.4802 / 0.3838 Acc: 29.6875 (33.1216)\n",
      "[11/25][632/782] Loss_D: -0.2551 (0.2310) Loss_G: -0.1548 (0.0990) D(x): 0.5302 D(G(z)): 0.4098 / 0.4710 Acc: 50.0000 (33.1235)\n",
      "[11/25][633/782] Loss_D: 0.0088 (0.2310) Loss_G: -0.1814 (0.0989) D(x): 0.5493 D(G(z)): 0.5159 / 0.4792 Acc: 43.7500 (33.1246)\n",
      "[11/25][634/782] Loss_D: -0.2710 (0.2309) Loss_G: 0.0285 (0.0989) D(x): 0.5492 D(G(z)): 0.3867 / 0.3925 Acc: 43.7500 (33.1258)\n",
      "[11/25][635/782] Loss_D: -0.0456 (0.2309) Loss_G: -0.1734 (0.0989) D(x): 0.5256 D(G(z)): 0.4117 / 0.4878 Acc: 39.0625 (33.1264)\n",
      "[11/25][636/782] Loss_D: -0.1474 (0.2308) Loss_G: -0.1311 (0.0989) D(x): 0.5667 D(G(z)): 0.4929 / 0.4508 Acc: 53.1250 (33.1286)\n",
      "[11/25][637/782] Loss_D: -0.0047 (0.2308) Loss_G: -0.0704 (0.0989) D(x): 0.5472 D(G(z)): 0.4992 / 0.4537 Acc: 43.7500 (33.1297)\n",
      "[11/25][638/782] Loss_D: -0.1798 (0.2308) Loss_G: -0.0742 (0.0988) D(x): 0.5381 D(G(z)): 0.4161 / 0.4272 Acc: 50.0000 (33.1316)\n",
      "[11/25][639/782] Loss_D: -0.2019 (0.2307) Loss_G: -0.1225 (0.0988) D(x): 0.5667 D(G(z)): 0.4300 / 0.4647 Acc: 43.7500 (33.1327)\n",
      "[11/25][640/782] Loss_D: -0.0791 (0.2307) Loss_G: -0.1483 (0.0988) D(x): 0.5166 D(G(z)): 0.4785 / 0.4518 Acc: 48.4375 (33.1344)\n",
      "[11/25][641/782] Loss_D: -0.1925 (0.2306) Loss_G: 0.0078 (0.0988) D(x): 0.5829 D(G(z)): 0.4310 / 0.4070 Acc: 37.5000 (33.1348)\n",
      "[11/25][642/782] Loss_D: -0.1917 (0.2306) Loss_G: 0.0972 (0.0988) D(x): 0.5612 D(G(z)): 0.4644 / 0.3707 Acc: 48.4375 (33.1365)\n",
      "[11/25][643/782] Loss_D: -0.0924 (0.2305) Loss_G: 0.0673 (0.0988) D(x): 0.5051 D(G(z)): 0.4255 / 0.3955 Acc: 48.4375 (33.1381)\n",
      "[11/25][644/782] Loss_D: -0.0651 (0.2305) Loss_G: 0.0178 (0.0988) D(x): 0.5261 D(G(z)): 0.4563 / 0.3938 Acc: 45.3125 (33.1395)\n",
      "[11/25][645/782] Loss_D: -0.0955 (0.2305) Loss_G: -0.0651 (0.0988) D(x): 0.5879 D(G(z)): 0.4964 / 0.4451 Acc: 45.3125 (33.1408)\n",
      "[11/25][646/782] Loss_D: -0.0085 (0.2305) Loss_G: -0.0438 (0.0987) D(x): 0.5377 D(G(z)): 0.5058 / 0.4273 Acc: 45.3125 (33.1421)\n",
      "[11/25][647/782] Loss_D: 0.0133 (0.2304) Loss_G: -0.0891 (0.0987) D(x): 0.4331 D(G(z)): 0.3979 / 0.4395 Acc: 43.7500 (33.1432)\n",
      "[11/25][648/782] Loss_D: 0.0180 (0.2304) Loss_G: -0.1433 (0.0987) D(x): 0.4971 D(G(z)): 0.4776 / 0.4679 Acc: 46.8750 (33.1447)\n",
      "[11/25][649/782] Loss_D: -0.0903 (0.2304) Loss_G: -0.0822 (0.0987) D(x): 0.5981 D(G(z)): 0.4638 / 0.4367 Acc: 29.6875 (33.1444)\n",
      "[11/25][650/782] Loss_D: 0.0482 (0.2304) Loss_G: -0.0827 (0.0987) D(x): 0.5700 D(G(z)): 0.5325 / 0.4300 Acc: 40.6250 (33.1452)\n",
      "[11/25][651/782] Loss_D: 0.0374 (0.2303) Loss_G: -0.0578 (0.0986) D(x): 0.5028 D(G(z)): 0.4608 / 0.4277 Acc: 40.6250 (33.1460)\n",
      "[11/25][652/782] Loss_D: 0.0209 (0.2303) Loss_G: -0.0648 (0.0986) D(x): 0.5057 D(G(z)): 0.4759 / 0.4265 Acc: 42.1875 (33.1469)\n",
      "[11/25][653/782] Loss_D: -0.0861 (0.2303) Loss_G: -0.1353 (0.0986) D(x): 0.5503 D(G(z)): 0.4542 / 0.4630 Acc: 42.1875 (33.1479)\n",
      "[11/25][654/782] Loss_D: -0.1043 (0.2302) Loss_G: -0.1386 (0.0986) D(x): 0.5876 D(G(z)): 0.5235 / 0.4557 Acc: 50.0000 (33.1497)\n",
      "[11/25][655/782] Loss_D: -0.0923 (0.2302) Loss_G: 0.0725 (0.0986) D(x): 0.5560 D(G(z)): 0.4816 / 0.3779 Acc: 46.8750 (33.1512)\n",
      "[11/25][656/782] Loss_D: -0.0692 (0.2302) Loss_G: 0.0118 (0.0986) D(x): 0.4909 D(G(z)): 0.4213 / 0.3973 Acc: 46.8750 (33.1527)\n",
      "[11/25][657/782] Loss_D: -0.1677 (0.2301) Loss_G: -0.0984 (0.0985) D(x): 0.5474 D(G(z)): 0.4542 / 0.4488 Acc: 50.0000 (33.1545)\n",
      "[11/25][658/782] Loss_D: -0.0280 (0.2301) Loss_G: 0.0431 (0.0985) D(x): 0.5573 D(G(z)): 0.4823 / 0.4032 Acc: 43.7500 (33.1557)\n",
      "[11/25][659/782] Loss_D: -0.0310 (0.2301) Loss_G: 0.0121 (0.0985) D(x): 0.4972 D(G(z)): 0.4862 / 0.4175 Acc: 53.1250 (33.1578)\n",
      "[11/25][660/782] Loss_D: -0.0687 (0.2300) Loss_G: -0.0373 (0.0985) D(x): 0.5540 D(G(z)): 0.5130 / 0.4154 Acc: 51.5625 (33.1598)\n",
      "[11/25][661/782] Loss_D: -0.1520 (0.2300) Loss_G: -0.0577 (0.0985) D(x): 0.4652 D(G(z)): 0.3634 / 0.4238 Acc: 48.4375 (33.1615)\n",
      "[11/25][662/782] Loss_D: -0.0924 (0.2300) Loss_G: -0.1351 (0.0985) D(x): 0.5902 D(G(z)): 0.5013 / 0.4546 Acc: 45.3125 (33.1628)\n",
      "[11/25][663/782] Loss_D: 0.0608 (0.2299) Loss_G: -0.2460 (0.0984) D(x): 0.5282 D(G(z)): 0.5233 / 0.4965 Acc: 45.3125 (33.1641)\n",
      "[11/25][664/782] Loss_D: -0.2909 (0.2299) Loss_G: 0.0192 (0.0984) D(x): 0.6414 D(G(z)): 0.5111 / 0.4110 Acc: 54.6875 (33.1664)\n",
      "[11/25][665/782] Loss_D: 0.0482 (0.2299) Loss_G: -0.1720 (0.0984) D(x): 0.4316 D(G(z)): 0.4248 / 0.4653 Acc: 48.4375 (33.1681)\n",
      "[11/25][666/782] Loss_D: 0.0146 (0.2298) Loss_G: -0.2778 (0.0983) D(x): 0.4502 D(G(z)): 0.4505 / 0.5307 Acc: 51.5625 (33.1700)\n",
      "[11/25][667/782] Loss_D: -0.1015 (0.2298) Loss_G: -0.0396 (0.0983) D(x): 0.5933 D(G(z)): 0.5110 / 0.4161 Acc: 48.4375 (33.1717)\n",
      "[11/25][668/782] Loss_D: -0.0030 (0.2298) Loss_G: -0.1821 (0.0983) D(x): 0.5301 D(G(z)): 0.4500 / 0.4916 Acc: 32.8125 (33.1717)\n",
      "[11/25][669/782] Loss_D: 0.0780 (0.2298) Loss_G: -0.0387 (0.0983) D(x): 0.5300 D(G(z)): 0.5163 / 0.4203 Acc: 42.1875 (33.1726)\n",
      "[11/25][670/782] Loss_D: 0.2375 (0.2298) Loss_G: -0.1874 (0.0983) D(x): 0.4756 D(G(z)): 0.5033 / 0.4914 Acc: 37.5000 (33.1731)\n",
      "[11/25][671/782] Loss_D: 0.0878 (0.2298) Loss_G: -0.0798 (0.0982) D(x): 0.4896 D(G(z)): 0.4739 / 0.4354 Acc: 37.5000 (33.1736)\n",
      "[11/25][672/782] Loss_D: -0.0412 (0.2297) Loss_G: -0.3253 (0.0982) D(x): 0.5433 D(G(z)): 0.4692 / 0.5408 Acc: 37.5000 (33.1740)\n",
      "[11/25][673/782] Loss_D: -0.1643 (0.2297) Loss_G: -0.0524 (0.0982) D(x): 0.5206 D(G(z)): 0.4689 / 0.4355 Acc: 57.8125 (33.1767)\n",
      "[11/25][674/782] Loss_D: -0.0314 (0.2297) Loss_G: -0.2700 (0.0981) D(x): 0.5465 D(G(z)): 0.4963 / 0.5144 Acc: 42.1875 (33.1777)\n",
      "[11/25][675/782] Loss_D: -0.0294 (0.2296) Loss_G: -0.1142 (0.0981) D(x): 0.5578 D(G(z)): 0.4869 / 0.4406 Acc: 42.1875 (33.1786)\n",
      "[11/25][676/782] Loss_D: -0.0124 (0.2296) Loss_G: -0.1460 (0.0981) D(x): 0.5075 D(G(z)): 0.4133 / 0.4571 Acc: 31.2500 (33.1784)\n",
      "[11/25][677/782] Loss_D: -0.1620 (0.2296) Loss_G: -0.1047 (0.0981) D(x): 0.4988 D(G(z)): 0.3999 / 0.4482 Acc: 48.4375 (33.1801)\n",
      "[11/25][678/782] Loss_D: -0.2047 (0.2295) Loss_G: -0.3346 (0.0980) D(x): 0.5615 D(G(z)): 0.4630 / 0.5444 Acc: 48.4375 (33.1817)\n",
      "[11/25][679/782] Loss_D: -0.0813 (0.2295) Loss_G: -0.0205 (0.0980) D(x): 0.6458 D(G(z)): 0.5127 / 0.4139 Acc: 35.9375 (33.1820)\n",
      "[11/25][680/782] Loss_D: -0.0098 (0.2295) Loss_G: -0.0312 (0.0980) D(x): 0.5215 D(G(z)): 0.4827 / 0.4264 Acc: 46.8750 (33.1835)\n",
      "[11/25][681/782] Loss_D: -0.0026 (0.2294) Loss_G: 0.1122 (0.0980) D(x): 0.5089 D(G(z)): 0.4302 / 0.3570 Acc: 40.6250 (33.1843)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/25][682/782] Loss_D: -0.1381 (0.2294) Loss_G: -0.0381 (0.0980) D(x): 0.5237 D(G(z)): 0.4431 / 0.4198 Acc: 50.0000 (33.1861)\n",
      "[11/25][683/782] Loss_D: -0.1333 (0.2294) Loss_G: -0.1689 (0.0979) D(x): 0.5269 D(G(z)): 0.3863 / 0.4557 Acc: 37.5000 (33.1866)\n",
      "[11/25][684/782] Loss_D: -0.0341 (0.2293) Loss_G: -0.1471 (0.0979) D(x): 0.5606 D(G(z)): 0.5245 / 0.4764 Acc: 50.0000 (33.1884)\n",
      "[11/25][685/782] Loss_D: -0.0358 (0.2293) Loss_G: -0.2315 (0.0979) D(x): 0.5219 D(G(z)): 0.5048 / 0.4903 Acc: 50.0000 (33.1902)\n",
      "[11/25][686/782] Loss_D: 0.0600 (0.2293) Loss_G: -0.1202 (0.0979) D(x): 0.5519 D(G(z)): 0.5335 / 0.4542 Acc: 50.0000 (33.1920)\n",
      "[11/25][687/782] Loss_D: -0.0938 (0.2292) Loss_G: -0.0510 (0.0978) D(x): 0.5226 D(G(z)): 0.4656 / 0.4391 Acc: 53.1250 (33.1941)\n",
      "[11/25][688/782] Loss_D: -0.0387 (0.2292) Loss_G: 0.0170 (0.0978) D(x): 0.5738 D(G(z)): 0.5218 / 0.3912 Acc: 45.3125 (33.1954)\n",
      "[11/25][689/782] Loss_D: 0.0395 (0.2292) Loss_G: -0.1409 (0.0978) D(x): 0.4638 D(G(z)): 0.4449 / 0.4504 Acc: 39.0625 (33.1961)\n",
      "[11/25][690/782] Loss_D: -0.1350 (0.2292) Loss_G: -0.0949 (0.0978) D(x): 0.5559 D(G(z)): 0.4470 / 0.4330 Acc: 42.1875 (33.1970)\n",
      "[11/25][691/782] Loss_D: 0.1647 (0.2291) Loss_G: 0.0046 (0.0978) D(x): 0.4936 D(G(z)): 0.5213 / 0.4097 Acc: 43.7500 (33.1982)\n",
      "[11/25][692/782] Loss_D: 0.1411 (0.2291) Loss_G: -0.1785 (0.0978) D(x): 0.5066 D(G(z)): 0.4900 / 0.4838 Acc: 35.9375 (33.1985)\n",
      "[11/25][693/782] Loss_D: -0.0088 (0.2291) Loss_G: -0.0580 (0.0977) D(x): 0.5606 D(G(z)): 0.4933 / 0.4481 Acc: 39.0625 (33.1991)\n",
      "[11/25][694/782] Loss_D: 0.0384 (0.2291) Loss_G: 0.0272 (0.0977) D(x): 0.5275 D(G(z)): 0.4880 / 0.4077 Acc: 45.3125 (33.2004)\n",
      "[11/25][695/782] Loss_D: 0.0092 (0.2291) Loss_G: 0.0327 (0.0977) D(x): 0.5153 D(G(z)): 0.4611 / 0.3880 Acc: 39.0625 (33.2010)\n",
      "[11/25][696/782] Loss_D: -0.0817 (0.2290) Loss_G: -0.1071 (0.0977) D(x): 0.5254 D(G(z)): 0.4358 / 0.4516 Acc: 42.1875 (33.2020)\n",
      "[11/25][697/782] Loss_D: -0.2368 (0.2290) Loss_G: -0.1727 (0.0977) D(x): 0.6187 D(G(z)): 0.4815 / 0.4626 Acc: 46.8750 (33.2035)\n",
      "[11/25][698/782] Loss_D: -0.1641 (0.2289) Loss_G: -0.0146 (0.0977) D(x): 0.5310 D(G(z)): 0.4079 / 0.4033 Acc: 42.1875 (33.2044)\n",
      "[11/25][699/782] Loss_D: 0.0133 (0.2289) Loss_G: -0.0884 (0.0976) D(x): 0.5112 D(G(z)): 0.4388 / 0.4424 Acc: 35.9375 (33.2047)\n",
      "[11/25][700/782] Loss_D: -0.0610 (0.2289) Loss_G: 0.0798 (0.0976) D(x): 0.5259 D(G(z)): 0.4669 / 0.3846 Acc: 50.0000 (33.2065)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[11/25][701/782] Loss_D: -0.0297 (0.2289) Loss_G: -0.0718 (0.0976) D(x): 0.5531 D(G(z)): 0.4948 / 0.4219 Acc: 43.7500 (33.2077)\n",
      "[11/25][702/782] Loss_D: 0.2329 (0.2289) Loss_G: -0.0978 (0.0976) D(x): 0.4305 D(G(z)): 0.4448 / 0.4527 Acc: 37.5000 (33.2081)\n",
      "[11/25][703/782] Loss_D: 0.0791 (0.2288) Loss_G: -0.2755 (0.0976) D(x): 0.4772 D(G(z)): 0.4713 / 0.5200 Acc: 43.7500 (33.2093)\n",
      "[11/25][704/782] Loss_D: 0.1249 (0.2288) Loss_G: -0.0569 (0.0975) D(x): 0.5398 D(G(z)): 0.5329 / 0.4228 Acc: 35.9375 (33.2095)\n",
      "[11/25][705/782] Loss_D: -0.0170 (0.2288) Loss_G: -0.0414 (0.0975) D(x): 0.5264 D(G(z)): 0.5004 / 0.4201 Acc: 53.1250 (33.2117)\n",
      "[11/25][706/782] Loss_D: 0.1484 (0.2288) Loss_G: -0.0381 (0.0975) D(x): 0.5287 D(G(z)): 0.4838 / 0.4310 Acc: 29.6875 (33.2113)\n",
      "[11/25][707/782] Loss_D: 0.0246 (0.2288) Loss_G: -0.0405 (0.0975) D(x): 0.5031 D(G(z)): 0.4482 / 0.4333 Acc: 40.6250 (33.2121)\n",
      "[11/25][708/782] Loss_D: -0.0102 (0.2288) Loss_G: -0.1452 (0.0975) D(x): 0.4995 D(G(z)): 0.4448 / 0.4533 Acc: 42.1875 (33.2131)\n",
      "[11/25][709/782] Loss_D: -0.1401 (0.2287) Loss_G: -0.1692 (0.0974) D(x): 0.5641 D(G(z)): 0.4874 / 0.4661 Acc: 53.1250 (33.2152)\n",
      "[11/25][710/782] Loss_D: -0.1076 (0.2287) Loss_G: -0.1722 (0.0974) D(x): 0.5402 D(G(z)): 0.4658 / 0.4817 Acc: 51.5625 (33.2172)\n",
      "[11/25][711/782] Loss_D: -0.0015 (0.2286) Loss_G: -0.0935 (0.0974) D(x): 0.5006 D(G(z)): 0.4348 / 0.4429 Acc: 42.1875 (33.2181)\n",
      "[11/25][712/782] Loss_D: -0.1418 (0.2286) Loss_G: -0.0657 (0.0974) D(x): 0.5209 D(G(z)): 0.4369 / 0.4362 Acc: 53.1250 (33.2203)\n",
      "[11/25][713/782] Loss_D: 0.0105 (0.2286) Loss_G: -0.1690 (0.0973) D(x): 0.4900 D(G(z)): 0.4859 / 0.4768 Acc: 54.6875 (33.2226)\n",
      "[11/25][714/782] Loss_D: 0.0730 (0.2286) Loss_G: -0.1877 (0.0973) D(x): 0.4716 D(G(z)): 0.4893 / 0.5090 Acc: 50.0000 (33.2244)\n",
      "[11/25][715/782] Loss_D: -0.0019 (0.2285) Loss_G: -0.0640 (0.0973) D(x): 0.5607 D(G(z)): 0.5121 / 0.4323 Acc: 45.3125 (33.2257)\n",
      "[11/25][716/782] Loss_D: -0.0320 (0.2285) Loss_G: -0.1431 (0.0973) D(x): 0.5212 D(G(z)): 0.4577 / 0.4558 Acc: 37.5000 (33.2261)\n",
      "[11/25][717/782] Loss_D: 0.0005 (0.2285) Loss_G: 0.0961 (0.0973) D(x): 0.5370 D(G(z)): 0.4985 / 0.3600 Acc: 46.8750 (33.2276)\n",
      "[11/25][718/782] Loss_D: 0.0558 (0.2285) Loss_G: -0.0296 (0.0973) D(x): 0.4600 D(G(z)): 0.4414 / 0.4045 Acc: 45.3125 (33.2289)\n",
      "[11/25][719/782] Loss_D: 0.0403 (0.2285) Loss_G: -0.0220 (0.0972) D(x): 0.5419 D(G(z)): 0.5163 / 0.4212 Acc: 46.8750 (33.2304)\n",
      "[11/25][720/782] Loss_D: -0.1153 (0.2284) Loss_G: 0.0783 (0.0972) D(x): 0.5157 D(G(z)): 0.3987 / 0.3833 Acc: 45.3125 (33.2317)\n",
      "[11/25][721/782] Loss_D: -0.1317 (0.2284) Loss_G: -0.0469 (0.0972) D(x): 0.5458 D(G(z)): 0.4237 / 0.4191 Acc: 39.0625 (33.2323)\n",
      "[11/25][722/782] Loss_D: -0.0787 (0.2283) Loss_G: -0.1863 (0.0972) D(x): 0.5221 D(G(z)): 0.4328 / 0.4766 Acc: 43.7500 (33.2334)\n",
      "[11/25][723/782] Loss_D: -0.0740 (0.2283) Loss_G: -0.2276 (0.0972) D(x): 0.5716 D(G(z)): 0.4313 / 0.4857 Acc: 25.0000 (33.2325)\n",
      "[11/25][724/782] Loss_D: 0.0243 (0.2283) Loss_G: -0.2283 (0.0971) D(x): 0.5496 D(G(z)): 0.5437 / 0.5073 Acc: 45.3125 (33.2338)\n",
      "[11/25][725/782] Loss_D: 0.0466 (0.2283) Loss_G: -0.0958 (0.0971) D(x): 0.4917 D(G(z)): 0.5309 / 0.4395 Acc: 54.6875 (33.2361)\n",
      "[11/25][726/782] Loss_D: -0.1359 (0.2282) Loss_G: -0.0733 (0.0971) D(x): 0.4820 D(G(z)): 0.4238 / 0.4293 Acc: 46.8750 (33.2376)\n",
      "[11/25][727/782] Loss_D: -0.1188 (0.2282) Loss_G: -0.0048 (0.0971) D(x): 0.5192 D(G(z)): 0.4337 / 0.3974 Acc: 48.4375 (33.2392)\n",
      "[11/25][728/782] Loss_D: 0.0820 (0.2282) Loss_G: -0.1952 (0.0970) D(x): 0.5401 D(G(z)): 0.5363 / 0.5039 Acc: 45.3125 (33.2405)\n",
      "[11/25][729/782] Loss_D: -0.0799 (0.2281) Loss_G: -0.0839 (0.0970) D(x): 0.5269 D(G(z)): 0.4843 / 0.4513 Acc: 48.4375 (33.2421)\n",
      "[11/25][730/782] Loss_D: -0.0378 (0.2281) Loss_G: -0.1511 (0.0970) D(x): 0.5364 D(G(z)): 0.4921 / 0.4662 Acc: 40.6250 (33.2429)\n",
      "[11/25][731/782] Loss_D: 0.1983 (0.2281) Loss_G: -0.1400 (0.0970) D(x): 0.4628 D(G(z)): 0.4516 / 0.4492 Acc: 29.6875 (33.2425)\n",
      "[11/25][732/782] Loss_D: 0.0031 (0.2281) Loss_G: -0.0320 (0.0970) D(x): 0.5109 D(G(z)): 0.4904 / 0.4307 Acc: 48.4375 (33.2442)\n",
      "[11/25][733/782] Loss_D: -0.0123 (0.2281) Loss_G: -0.0001 (0.0970) D(x): 0.5479 D(G(z)): 0.4807 / 0.3958 Acc: 35.9375 (33.2445)\n",
      "[11/25][734/782] Loss_D: -0.1431 (0.2280) Loss_G: -0.0237 (0.0969) D(x): 0.5728 D(G(z)): 0.4620 / 0.4198 Acc: 37.5000 (33.2449)\n",
      "[11/25][735/782] Loss_D: 0.0278 (0.2280) Loss_G: -0.1349 (0.0969) D(x): 0.4794 D(G(z)): 0.4570 / 0.4593 Acc: 46.8750 (33.2464)\n",
      "[11/25][736/782] Loss_D: -0.0012 (0.2280) Loss_G: -0.1605 (0.0969) D(x): 0.5373 D(G(z)): 0.4935 / 0.4657 Acc: 40.6250 (33.2472)\n",
      "[11/25][737/782] Loss_D: -0.1846 (0.2279) Loss_G: -0.0122 (0.0969) D(x): 0.5476 D(G(z)): 0.4223 / 0.4132 Acc: 42.1875 (33.2481)\n",
      "[11/25][738/782] Loss_D: 0.0320 (0.2279) Loss_G: -0.1051 (0.0969) D(x): 0.4621 D(G(z)): 0.4682 / 0.4639 Acc: 48.4375 (33.2498)\n",
      "[11/25][739/782] Loss_D: -0.0390 (0.2279) Loss_G: -0.2783 (0.0968) D(x): 0.5345 D(G(z)): 0.4865 / 0.5038 Acc: 42.1875 (33.2507)\n",
      "[11/25][740/782] Loss_D: -0.1678 (0.2278) Loss_G: -0.0670 (0.0968) D(x): 0.5796 D(G(z)): 0.4896 / 0.4303 Acc: 53.1250 (33.2528)\n",
      "[11/25][741/782] Loss_D: -0.0320 (0.2278) Loss_G: -0.1507 (0.0968) D(x): 0.4807 D(G(z)): 0.4372 / 0.4714 Acc: 45.3125 (33.2541)\n",
      "[11/25][742/782] Loss_D: -0.0964 (0.2278) Loss_G: -0.1549 (0.0967) D(x): 0.5390 D(G(z)): 0.4678 / 0.4657 Acc: 43.7500 (33.2553)\n",
      "[11/25][743/782] Loss_D: -0.1459 (0.2277) Loss_G: -0.1981 (0.0967) D(x): 0.5919 D(G(z)): 0.5428 / 0.4903 Acc: 54.6875 (33.2575)\n",
      "[11/25][744/782] Loss_D: -0.0821 (0.2277) Loss_G: -0.1037 (0.0967) D(x): 0.5519 D(G(z)): 0.4688 / 0.4385 Acc: 45.3125 (33.2588)\n",
      "[11/25][745/782] Loss_D: -0.0661 (0.2277) Loss_G: 0.0123 (0.0967) D(x): 0.4755 D(G(z)): 0.4427 / 0.3948 Acc: 46.8750 (33.2603)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/25][746/782] Loss_D: -0.0708 (0.2276) Loss_G: -0.2471 (0.0966) D(x): 0.5270 D(G(z)): 0.5000 / 0.4998 Acc: 51.5625 (33.2622)\n",
      "[11/25][747/782] Loss_D: -0.0664 (0.2276) Loss_G: -0.1327 (0.0966) D(x): 0.5060 D(G(z)): 0.4630 / 0.4685 Acc: 46.8750 (33.2637)\n",
      "[11/25][748/782] Loss_D: -0.1964 (0.2276) Loss_G: -0.1743 (0.0966) D(x): 0.5676 D(G(z)): 0.4760 / 0.4714 Acc: 50.0000 (33.2655)\n",
      "[11/25][749/782] Loss_D: -0.2804 (0.2275) Loss_G: 0.0792 (0.0966) D(x): 0.6370 D(G(z)): 0.4746 / 0.3714 Acc: 45.3125 (33.2668)\n",
      "[11/25][750/782] Loss_D: -0.0268 (0.2275) Loss_G: -0.0747 (0.0966) D(x): 0.4826 D(G(z)): 0.4283 / 0.4247 Acc: 40.6250 (33.2676)\n",
      "[11/25][751/782] Loss_D: -0.1391 (0.2274) Loss_G: -0.0236 (0.0966) D(x): 0.4809 D(G(z)): 0.4200 / 0.4064 Acc: 48.4375 (33.2692)\n",
      "[11/25][752/782] Loss_D: -0.0184 (0.2274) Loss_G: -0.2754 (0.0965) D(x): 0.4882 D(G(z)): 0.4704 / 0.5250 Acc: 48.4375 (33.2708)\n",
      "[11/25][753/782] Loss_D: -0.0406 (0.2274) Loss_G: -0.2181 (0.0965) D(x): 0.5584 D(G(z)): 0.4849 / 0.5015 Acc: 42.1875 (33.2718)\n",
      "[11/25][754/782] Loss_D: 0.1512 (0.2274) Loss_G: -0.1364 (0.0965) D(x): 0.5170 D(G(z)): 0.5514 / 0.4547 Acc: 42.1875 (33.2727)\n",
      "[11/25][755/782] Loss_D: -0.0442 (0.2274) Loss_G: -0.1104 (0.0964) D(x): 0.5370 D(G(z)): 0.4700 / 0.4484 Acc: 39.0625 (33.2733)\n",
      "[11/25][756/782] Loss_D: -0.0572 (0.2273) Loss_G: -0.0844 (0.0964) D(x): 0.4852 D(G(z)): 0.4468 / 0.4485 Acc: 46.8750 (33.2748)\n",
      "[11/25][757/782] Loss_D: -0.1768 (0.2273) Loss_G: -0.0079 (0.0964) D(x): 0.5655 D(G(z)): 0.4753 / 0.4083 Acc: 53.1250 (33.2769)\n",
      "[11/25][758/782] Loss_D: -0.1431 (0.2272) Loss_G: -0.0192 (0.0964) D(x): 0.6000 D(G(z)): 0.4744 / 0.4298 Acc: 39.0625 (33.2775)\n",
      "[11/25][759/782] Loss_D: 0.0235 (0.2272) Loss_G: -0.1938 (0.0964) D(x): 0.5157 D(G(z)): 0.4910 / 0.4924 Acc: 45.3125 (33.2788)\n",
      "[11/25][760/782] Loss_D: -0.1889 (0.2272) Loss_G: 0.0404 (0.0964) D(x): 0.5224 D(G(z)): 0.4608 / 0.3828 Acc: 56.2500 (33.2813)\n",
      "[11/25][761/782] Loss_D: -0.1975 (0.2271) Loss_G: -0.0327 (0.0963) D(x): 0.5819 D(G(z)): 0.4686 / 0.4123 Acc: 48.4375 (33.2829)\n",
      "[11/25][762/782] Loss_D: -0.1419 (0.2271) Loss_G: 0.1295 (0.0963) D(x): 0.5726 D(G(z)): 0.4287 / 0.3726 Acc: 40.6250 (33.2837)\n",
      "[11/25][763/782] Loss_D: -0.0917 (0.2271) Loss_G: 0.0173 (0.0963) D(x): 0.5409 D(G(z)): 0.4263 / 0.4023 Acc: 37.5000 (33.2841)\n",
      "[11/25][764/782] Loss_D: 0.0247 (0.2270) Loss_G: -0.0800 (0.0963) D(x): 0.5395 D(G(z)): 0.5116 / 0.4496 Acc: 42.1875 (33.2851)\n",
      "[11/25][765/782] Loss_D: -0.0002 (0.2270) Loss_G: -0.2413 (0.0963) D(x): 0.4487 D(G(z)): 0.4756 / 0.4957 Acc: 57.8125 (33.2877)\n",
      "[11/25][766/782] Loss_D: 0.0824 (0.2270) Loss_G: -0.1258 (0.0963) D(x): 0.5135 D(G(z)): 0.5034 / 0.4639 Acc: 42.1875 (33.2886)\n",
      "[11/25][767/782] Loss_D: 0.1547 (0.2270) Loss_G: -0.1257 (0.0962) D(x): 0.4616 D(G(z)): 0.4693 / 0.4768 Acc: 40.6250 (33.2894)\n",
      "[11/25][768/782] Loss_D: 0.0093 (0.2270) Loss_G: -0.2267 (0.0962) D(x): 0.5920 D(G(z)): 0.5410 / 0.4994 Acc: 42.1875 (33.2904)\n",
      "[11/25][769/782] Loss_D: -0.0502 (0.2269) Loss_G: -0.0696 (0.0962) D(x): 0.6113 D(G(z)): 0.5360 / 0.4306 Acc: 40.6250 (33.2912)\n",
      "[11/25][770/782] Loss_D: -0.2628 (0.2269) Loss_G: -0.0561 (0.0962) D(x): 0.5174 D(G(z)): 0.3914 / 0.4152 Acc: 51.5625 (33.2931)\n",
      "[11/25][771/782] Loss_D: 0.0657 (0.2269) Loss_G: -0.2325 (0.0961) D(x): 0.4365 D(G(z)): 0.4137 / 0.5046 Acc: 39.0625 (33.2937)\n",
      "[11/25][772/782] Loss_D: -0.1198 (0.2268) Loss_G: -0.1819 (0.0961) D(x): 0.5945 D(G(z)): 0.5002 / 0.4677 Acc: 43.7500 (33.2948)\n",
      "[11/25][773/782] Loss_D: 0.0730 (0.2268) Loss_G: -0.1396 (0.0961) D(x): 0.4912 D(G(z)): 0.4748 / 0.4513 Acc: 39.0625 (33.2954)\n",
      "[11/25][774/782] Loss_D: -0.1473 (0.2268) Loss_G: -0.0090 (0.0961) D(x): 0.5706 D(G(z)): 0.4915 / 0.4107 Acc: 51.5625 (33.2974)\n",
      "[11/25][775/782] Loss_D: 0.0913 (0.2268) Loss_G: 0.0316 (0.0961) D(x): 0.4829 D(G(z)): 0.4772 / 0.4121 Acc: 40.6250 (33.2982)\n",
      "[11/25][776/782] Loss_D: -0.1104 (0.2267) Loss_G: -0.1744 (0.0960) D(x): 0.4848 D(G(z)): 0.4154 / 0.4682 Acc: 50.0000 (33.3000)\n",
      "[11/25][777/782] Loss_D: 0.0250 (0.2267) Loss_G: -0.0796 (0.0960) D(x): 0.4782 D(G(z)): 0.4469 / 0.4487 Acc: 46.8750 (33.3014)\n",
      "[11/25][778/782] Loss_D: 0.0683 (0.2267) Loss_G: -0.1859 (0.0960) D(x): 0.5185 D(G(z)): 0.5110 / 0.4660 Acc: 42.1875 (33.3024)\n",
      "[11/25][779/782] Loss_D: 0.1370 (0.2267) Loss_G: -0.0124 (0.0960) D(x): 0.5363 D(G(z)): 0.5280 / 0.4011 Acc: 35.9375 (33.3026)\n",
      "[11/25][780/782] Loss_D: 0.1284 (0.2267) Loss_G: 0.0215 (0.0960) D(x): 0.4573 D(G(z)): 0.4417 / 0.3934 Acc: 39.0625 (33.3032)\n",
      "[11/25][781/782] Loss_D: -0.2220 (0.2266) Loss_G: 0.1599 (0.0960) D(x): 0.5524 D(G(z)): 0.4265 / 0.3502 Acc: 50.0000 (33.3050)\n",
      "[12/25][0/782] Loss_D: -0.1587 (0.2266) Loss_G: -0.0822 (0.0959) D(x): 0.4988 D(G(z)): 0.3871 / 0.4339 Acc: 48.4375 (33.3066)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[12/25][1/782] Loss_D: -0.2829 (0.2265) Loss_G: -0.2290 (0.0959) D(x): 0.5557 D(G(z)): 0.4162 / 0.4987 Acc: 50.0000 (33.3084)\n",
      "[12/25][2/782] Loss_D: -0.0316 (0.2265) Loss_G: -0.1403 (0.0959) D(x): 0.5833 D(G(z)): 0.5159 / 0.4681 Acc: 43.7500 (33.3095)\n",
      "[12/25][3/782] Loss_D: -0.0105 (0.2265) Loss_G: -0.1333 (0.0959) D(x): 0.5584 D(G(z)): 0.5270 / 0.4386 Acc: 42.1875 (33.3105)\n",
      "[12/25][4/782] Loss_D: 0.0057 (0.2264) Loss_G: -0.0228 (0.0959) D(x): 0.5069 D(G(z)): 0.4938 / 0.4121 Acc: 46.8750 (33.3119)\n",
      "[12/25][5/782] Loss_D: -0.0500 (0.2264) Loss_G: -0.0556 (0.0958) D(x): 0.4661 D(G(z)): 0.4072 / 0.4365 Acc: 40.6250 (33.3127)\n",
      "[12/25][6/782] Loss_D: 0.1151 (0.2264) Loss_G: -0.0886 (0.0958) D(x): 0.4757 D(G(z)): 0.5103 / 0.4413 Acc: 48.4375 (33.3143)\n",
      "[12/25][7/782] Loss_D: 0.0433 (0.2264) Loss_G: -0.1285 (0.0958) D(x): 0.4999 D(G(z)): 0.4652 / 0.4770 Acc: 42.1875 (33.3153)\n",
      "[12/25][8/782] Loss_D: -0.1362 (0.2263) Loss_G: -0.0746 (0.0958) D(x): 0.5187 D(G(z)): 0.4549 / 0.4526 Acc: 51.5625 (33.3172)\n",
      "[12/25][9/782] Loss_D: 0.0512 (0.2263) Loss_G: -0.1176 (0.0958) D(x): 0.5335 D(G(z)): 0.4931 / 0.4530 Acc: 42.1875 (33.3181)\n",
      "[12/25][10/782] Loss_D: -0.0448 (0.2263) Loss_G: -0.2235 (0.0957) D(x): 0.5235 D(G(z)): 0.4597 / 0.5072 Acc: 40.6250 (33.3189)\n",
      "[12/25][11/782] Loss_D: -0.3799 (0.2262) Loss_G: -0.2205 (0.0957) D(x): 0.6264 D(G(z)): 0.4356 / 0.4785 Acc: 53.1250 (33.3210)\n",
      "[12/25][12/782] Loss_D: -0.1643 (0.2262) Loss_G: -0.0647 (0.0957) D(x): 0.6264 D(G(z)): 0.5408 / 0.4343 Acc: 54.6875 (33.3233)\n",
      "[12/25][13/782] Loss_D: -0.1819 (0.2261) Loss_G: 0.0938 (0.0957) D(x): 0.5691 D(G(z)): 0.4123 / 0.3677 Acc: 37.5000 (33.3237)\n",
      "[12/25][14/782] Loss_D: -0.1938 (0.2261) Loss_G: -0.0567 (0.0956) D(x): 0.4794 D(G(z)): 0.3577 / 0.4174 Acc: 45.3125 (33.3250)\n",
      "[12/25][15/782] Loss_D: -0.3223 (0.2260) Loss_G: -0.0534 (0.0956) D(x): 0.5978 D(G(z)): 0.4402 / 0.4202 Acc: 48.4375 (33.3266)\n",
      "[12/25][16/782] Loss_D: -0.1515 (0.2260) Loss_G: -0.1393 (0.0956) D(x): 0.5479 D(G(z)): 0.4649 / 0.4558 Acc: 50.0000 (33.3284)\n",
      "[12/25][17/782] Loss_D: -0.0206 (0.2260) Loss_G: -0.1315 (0.0956) D(x): 0.4842 D(G(z)): 0.4479 / 0.4680 Acc: 48.4375 (33.3300)\n",
      "[12/25][18/782] Loss_D: -0.1669 (0.2259) Loss_G: -0.0595 (0.0956) D(x): 0.5877 D(G(z)): 0.4574 / 0.4239 Acc: 40.6250 (33.3308)\n",
      "[12/25][19/782] Loss_D: -0.0464 (0.2259) Loss_G: -0.1370 (0.0955) D(x): 0.5358 D(G(z)): 0.4437 / 0.4618 Acc: 34.3750 (33.3309)\n",
      "[12/25][20/782] Loss_D: -0.1675 (0.2259) Loss_G: -0.1541 (0.0955) D(x): 0.5207 D(G(z)): 0.4418 / 0.4688 Acc: 51.5625 (33.3328)\n",
      "[12/25][21/782] Loss_D: -0.1346 (0.2258) Loss_G: -0.1248 (0.0955) D(x): 0.5761 D(G(z)): 0.4953 / 0.4562 Acc: 46.8750 (33.3343)\n",
      "[12/25][22/782] Loss_D: -0.3023 (0.2258) Loss_G: -0.1248 (0.0955) D(x): 0.5670 D(G(z)): 0.4109 / 0.4509 Acc: 50.0000 (33.3360)\n",
      "[12/25][23/782] Loss_D: -0.0671 (0.2257) Loss_G: -0.1994 (0.0954) D(x): 0.5036 D(G(z)): 0.4525 / 0.4863 Acc: 46.8750 (33.3375)\n",
      "[12/25][24/782] Loss_D: -0.0124 (0.2257) Loss_G: -0.0475 (0.0954) D(x): 0.5603 D(G(z)): 0.5274 / 0.4219 Acc: 48.4375 (33.3391)\n",
      "[12/25][25/782] Loss_D: -0.0407 (0.2257) Loss_G: -0.0036 (0.0954) D(x): 0.5317 D(G(z)): 0.4189 / 0.4160 Acc: 35.9375 (33.3394)\n",
      "[12/25][26/782] Loss_D: -0.0955 (0.2257) Loss_G: -0.1805 (0.0954) D(x): 0.5080 D(G(z)): 0.4326 / 0.4796 Acc: 51.5625 (33.3413)\n",
      "[12/25][27/782] Loss_D: -0.0483 (0.2256) Loss_G: -0.1147 (0.0954) D(x): 0.5690 D(G(z)): 0.5335 / 0.4454 Acc: 43.7500 (33.3424)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/25][28/782] Loss_D: -0.0552 (0.2256) Loss_G: -0.0126 (0.0954) D(x): 0.5157 D(G(z)): 0.5029 / 0.4118 Acc: 54.6875 (33.3447)\n",
      "[12/25][29/782] Loss_D: -0.0343 (0.2256) Loss_G: 0.0161 (0.0953) D(x): 0.5073 D(G(z)): 0.4479 / 0.4033 Acc: 45.3125 (33.3459)\n",
      "[12/25][30/782] Loss_D: 0.0606 (0.2255) Loss_G: -0.0858 (0.0953) D(x): 0.5602 D(G(z)): 0.4761 / 0.4331 Acc: 29.6875 (33.3456)\n",
      "[12/25][31/782] Loss_D: -0.2411 (0.2255) Loss_G: 0.0111 (0.0953) D(x): 0.6284 D(G(z)): 0.4554 / 0.3992 Acc: 42.1875 (33.3465)\n",
      "[12/25][32/782] Loss_D: 0.0041 (0.2255) Loss_G: -0.0041 (0.0953) D(x): 0.4728 D(G(z)): 0.4175 / 0.3966 Acc: 39.0625 (33.3471)\n",
      "[12/25][33/782] Loss_D: 0.0335 (0.2255) Loss_G: -0.0343 (0.0953) D(x): 0.5016 D(G(z)): 0.5021 / 0.4103 Acc: 48.4375 (33.3487)\n",
      "[12/25][34/782] Loss_D: -0.1748 (0.2254) Loss_G: -0.1732 (0.0953) D(x): 0.5451 D(G(z)): 0.4030 / 0.4659 Acc: 42.1875 (33.3496)\n",
      "[12/25][35/782] Loss_D: -0.2043 (0.2254) Loss_G: -0.0533 (0.0952) D(x): 0.6086 D(G(z)): 0.5074 / 0.4339 Acc: 51.5625 (33.3516)\n",
      "[12/25][36/782] Loss_D: 0.0118 (0.2253) Loss_G: -0.0370 (0.0952) D(x): 0.5459 D(G(z)): 0.4891 / 0.4199 Acc: 42.1875 (33.3525)\n",
      "[12/25][37/782] Loss_D: -0.1733 (0.2253) Loss_G: -0.0845 (0.0952) D(x): 0.4914 D(G(z)): 0.4282 / 0.4293 Acc: 53.1250 (33.3546)\n",
      "[12/25][38/782] Loss_D: -0.0732 (0.2253) Loss_G: -0.0255 (0.0952) D(x): 0.5533 D(G(z)): 0.4995 / 0.4201 Acc: 48.4375 (33.3562)\n",
      "[12/25][39/782] Loss_D: -0.3052 (0.2252) Loss_G: -0.0380 (0.0952) D(x): 0.5800 D(G(z)): 0.3988 / 0.4300 Acc: 50.0000 (33.3580)\n",
      "[12/25][40/782] Loss_D: -0.0512 (0.2252) Loss_G: -0.0968 (0.0952) D(x): 0.5912 D(G(z)): 0.5002 / 0.4630 Acc: 45.3125 (33.3593)\n",
      "[12/25][41/782] Loss_D: -0.1847 (0.2251) Loss_G: -0.2206 (0.0951) D(x): 0.5165 D(G(z)): 0.4177 / 0.4887 Acc: 48.4375 (33.3609)\n",
      "[12/25][42/782] Loss_D: 0.1137 (0.2251) Loss_G: -0.1398 (0.0951) D(x): 0.5417 D(G(z)): 0.5182 / 0.4696 Acc: 35.9375 (33.3611)\n",
      "[12/25][43/782] Loss_D: -0.0554 (0.2251) Loss_G: -0.1930 (0.0951) D(x): 0.5107 D(G(z)): 0.4811 / 0.4909 Acc: 54.6875 (33.3634)\n",
      "[12/25][44/782] Loss_D: 0.0438 (0.2251) Loss_G: -0.1443 (0.0951) D(x): 0.5315 D(G(z)): 0.4613 / 0.4755 Acc: 40.6250 (33.3642)\n",
      "[12/25][45/782] Loss_D: 0.0084 (0.2251) Loss_G: -0.0365 (0.0950) D(x): 0.5395 D(G(z)): 0.4703 / 0.4260 Acc: 34.3750 (33.3643)\n",
      "[12/25][46/782] Loss_D: -0.0707 (0.2250) Loss_G: -0.0380 (0.0950) D(x): 0.5516 D(G(z)): 0.4802 / 0.4225 Acc: 45.3125 (33.3655)\n",
      "[12/25][47/782] Loss_D: 0.2299 (0.2250) Loss_G: -0.0972 (0.0950) D(x): 0.4616 D(G(z)): 0.4784 / 0.4512 Acc: 34.3750 (33.3656)\n",
      "[12/25][48/782] Loss_D: -0.0602 (0.2250) Loss_G: -0.1723 (0.0950) D(x): 0.4888 D(G(z)): 0.4128 / 0.4571 Acc: 42.1875 (33.3666)\n",
      "[12/25][49/782] Loss_D: 0.0669 (0.2250) Loss_G: -0.1934 (0.0949) D(x): 0.5085 D(G(z)): 0.4830 / 0.4855 Acc: 37.5000 (33.3670)\n",
      "[12/25][50/782] Loss_D: 0.1037 (0.2250) Loss_G: -0.0921 (0.0949) D(x): 0.5381 D(G(z)): 0.5391 / 0.4406 Acc: 37.5000 (33.3674)\n",
      "[12/25][51/782] Loss_D: -0.0184 (0.2249) Loss_G: -0.0986 (0.0949) D(x): 0.5226 D(G(z)): 0.4800 / 0.4518 Acc: 48.4375 (33.3690)\n",
      "[12/25][52/782] Loss_D: 0.0219 (0.2249) Loss_G: -0.1376 (0.0949) D(x): 0.4836 D(G(z)): 0.4470 / 0.4650 Acc: 43.7500 (33.3701)\n",
      "[12/25][53/782] Loss_D: 0.0720 (0.2249) Loss_G: -0.0932 (0.0949) D(x): 0.5239 D(G(z)): 0.4734 / 0.4429 Acc: 34.3750 (33.3703)\n",
      "[12/25][54/782] Loss_D: -0.0947 (0.2249) Loss_G: -0.1520 (0.0948) D(x): 0.5595 D(G(z)): 0.4876 / 0.4667 Acc: 48.4375 (33.3718)\n",
      "[12/25][55/782] Loss_D: -0.1644 (0.2248) Loss_G: -0.0579 (0.0948) D(x): 0.5293 D(G(z)): 0.4510 / 0.4279 Acc: 48.4375 (33.3734)\n",
      "[12/25][56/782] Loss_D: -0.0556 (0.2248) Loss_G: -0.1489 (0.0948) D(x): 0.5728 D(G(z)): 0.5052 / 0.4729 Acc: 50.0000 (33.3752)\n",
      "[12/25][57/782] Loss_D: -0.0839 (0.2248) Loss_G: -0.0973 (0.0948) D(x): 0.5203 D(G(z)): 0.4506 / 0.4412 Acc: 45.3125 (33.3765)\n",
      "[12/25][58/782] Loss_D: -0.1068 (0.2247) Loss_G: 0.0081 (0.0948) D(x): 0.5747 D(G(z)): 0.4512 / 0.3998 Acc: 40.6250 (33.3772)\n",
      "[12/25][59/782] Loss_D: 0.0134 (0.2247) Loss_G: -0.0429 (0.0947) D(x): 0.4818 D(G(z)): 0.4215 / 0.4068 Acc: 32.8125 (33.3772)\n",
      "[12/25][60/782] Loss_D: -0.0984 (0.2247) Loss_G: -0.1753 (0.0947) D(x): 0.5745 D(G(z)): 0.4927 / 0.4826 Acc: 46.8750 (33.3786)\n",
      "[12/25][61/782] Loss_D: -0.2067 (0.2246) Loss_G: 0.0176 (0.0947) D(x): 0.5675 D(G(z)): 0.4933 / 0.4013 Acc: 53.1250 (33.3807)\n",
      "[12/25][62/782] Loss_D: -0.0206 (0.2246) Loss_G: 0.0403 (0.0947) D(x): 0.4570 D(G(z)): 0.4366 / 0.4020 Acc: 48.4375 (33.3823)\n",
      "[12/25][63/782] Loss_D: -0.2540 (0.2246) Loss_G: -0.1755 (0.0947) D(x): 0.5104 D(G(z)): 0.4070 / 0.4690 Acc: 56.2500 (33.3847)\n",
      "[12/25][64/782] Loss_D: -0.1684 (0.2245) Loss_G: -0.1979 (0.0946) D(x): 0.5451 D(G(z)): 0.4549 / 0.4735 Acc: 46.8750 (33.3861)\n",
      "[12/25][65/782] Loss_D: 0.1008 (0.2245) Loss_G: -0.1900 (0.0946) D(x): 0.6045 D(G(z)): 0.5705 / 0.4886 Acc: 39.0625 (33.3867)\n",
      "[12/25][66/782] Loss_D: -0.0159 (0.2245) Loss_G: -0.1574 (0.0946) D(x): 0.5299 D(G(z)): 0.4980 / 0.4596 Acc: 39.0625 (33.3873)\n",
      "[12/25][67/782] Loss_D: 0.0474 (0.2245) Loss_G: -0.0499 (0.0946) D(x): 0.4522 D(G(z)): 0.4186 / 0.4208 Acc: 46.8750 (33.3888)\n",
      "[12/25][68/782] Loss_D: 0.0279 (0.2244) Loss_G: -0.0928 (0.0946) D(x): 0.5292 D(G(z)): 0.4877 / 0.4404 Acc: 37.5000 (33.3892)\n",
      "[12/25][69/782] Loss_D: 0.1013 (0.2244) Loss_G: -0.2392 (0.0945) D(x): 0.4712 D(G(z)): 0.4727 / 0.5035 Acc: 45.3125 (33.3905)\n",
      "[12/25][70/782] Loss_D: 0.1785 (0.2244) Loss_G: -0.1156 (0.0945) D(x): 0.5271 D(G(z)): 0.5380 / 0.4538 Acc: 37.5000 (33.3909)\n",
      "[12/25][71/782] Loss_D: -0.0115 (0.2244) Loss_G: -0.1049 (0.0945) D(x): 0.5465 D(G(z)): 0.4361 / 0.4545 Acc: 35.9375 (33.3912)\n",
      "[12/25][72/782] Loss_D: 0.0386 (0.2244) Loss_G: -0.1803 (0.0944) D(x): 0.4729 D(G(z)): 0.4565 / 0.4867 Acc: 42.1875 (33.3921)\n",
      "[12/25][73/782] Loss_D: 0.0833 (0.2244) Loss_G: -0.2168 (0.0944) D(x): 0.4891 D(G(z)): 0.4731 / 0.5088 Acc: 35.9375 (33.3924)\n",
      "[12/25][74/782] Loss_D: 0.0504 (0.2243) Loss_G: -0.1763 (0.0944) D(x): 0.6091 D(G(z)): 0.5637 / 0.4708 Acc: 40.6250 (33.3931)\n",
      "[12/25][75/782] Loss_D: -0.0613 (0.2243) Loss_G: 0.0603 (0.0944) D(x): 0.5026 D(G(z)): 0.4737 / 0.3858 Acc: 53.1250 (33.3952)\n",
      "[12/25][76/782] Loss_D: -0.0694 (0.2243) Loss_G: -0.1091 (0.0944) D(x): 0.4943 D(G(z)): 0.4336 / 0.4415 Acc: 45.3125 (33.3965)\n",
      "[12/25][77/782] Loss_D: -0.0970 (0.2242) Loss_G: -0.1257 (0.0943) D(x): 0.5193 D(G(z)): 0.4456 / 0.4455 Acc: 46.8750 (33.3979)\n",
      "[12/25][78/782] Loss_D: 0.0141 (0.2242) Loss_G: -0.2774 (0.0943) D(x): 0.5039 D(G(z)): 0.4800 / 0.5063 Acc: 42.1875 (33.3988)\n",
      "[12/25][79/782] Loss_D: 0.1610 (0.2242) Loss_G: -0.1971 (0.0943) D(x): 0.5737 D(G(z)): 0.5653 / 0.4836 Acc: 35.9375 (33.3991)\n",
      "[12/25][80/782] Loss_D: -0.3354 (0.2242) Loss_G: -0.0727 (0.0942) D(x): 0.5651 D(G(z)): 0.4287 / 0.4313 Acc: 56.2500 (33.4015)\n",
      "[12/25][81/782] Loss_D: -0.1994 (0.2241) Loss_G: -0.0630 (0.0942) D(x): 0.5638 D(G(z)): 0.4170 / 0.4285 Acc: 39.0625 (33.4021)\n",
      "[12/25][82/782] Loss_D: 0.0345 (0.2241) Loss_G: -0.1621 (0.0942) D(x): 0.5114 D(G(z)): 0.4339 / 0.4620 Acc: 28.1250 (33.4016)\n",
      "[12/25][83/782] Loss_D: -0.2358 (0.2240) Loss_G: -0.0723 (0.0942) D(x): 0.5578 D(G(z)): 0.4333 / 0.4279 Acc: 46.8750 (33.4030)\n",
      "[12/25][84/782] Loss_D: -0.0937 (0.2240) Loss_G: -0.1322 (0.0942) D(x): 0.5406 D(G(z)): 0.4446 / 0.4647 Acc: 39.0625 (33.4036)\n",
      "[12/25][85/782] Loss_D: -0.2536 (0.2240) Loss_G: -0.1031 (0.0941) D(x): 0.5903 D(G(z)): 0.4132 / 0.4448 Acc: 42.1875 (33.4045)\n",
      "[12/25][86/782] Loss_D: -0.0351 (0.2239) Loss_G: -0.1916 (0.0941) D(x): 0.5200 D(G(z)): 0.4763 / 0.4816 Acc: 45.3125 (33.4058)\n",
      "[12/25][87/782] Loss_D: 0.0646 (0.2239) Loss_G: -0.0752 (0.0941) D(x): 0.5471 D(G(z)): 0.5355 / 0.4307 Acc: 46.8750 (33.4072)\n",
      "[12/25][88/782] Loss_D: -0.0094 (0.2239) Loss_G: -0.0117 (0.0941) D(x): 0.4904 D(G(z)): 0.4731 / 0.4024 Acc: 50.0000 (33.4089)\n",
      "[12/25][89/782] Loss_D: -0.0504 (0.2239) Loss_G: -0.1201 (0.0941) D(x): 0.5272 D(G(z)): 0.4809 / 0.4441 Acc: 48.4375 (33.4105)\n",
      "[12/25][90/782] Loss_D: -0.0827 (0.2238) Loss_G: -0.0581 (0.0940) D(x): 0.5630 D(G(z)): 0.4811 / 0.4215 Acc: 46.8750 (33.4119)\n",
      "[12/25][91/782] Loss_D: -0.1206 (0.2238) Loss_G: -0.0368 (0.0940) D(x): 0.5242 D(G(z)): 0.4270 / 0.4213 Acc: 42.1875 (33.4129)\n",
      "[12/25][92/782] Loss_D: 0.0536 (0.2238) Loss_G: -0.0029 (0.0940) D(x): 0.4936 D(G(z)): 0.4968 / 0.4045 Acc: 45.3125 (33.4141)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/25][93/782] Loss_D: -0.0794 (0.2237) Loss_G: -0.0990 (0.0940) D(x): 0.4945 D(G(z)): 0.4401 / 0.4392 Acc: 48.4375 (33.4157)\n",
      "[12/25][94/782] Loss_D: -0.0426 (0.2237) Loss_G: -0.1342 (0.0940) D(x): 0.5178 D(G(z)): 0.4710 / 0.4491 Acc: 46.8750 (33.4171)\n",
      "[12/25][95/782] Loss_D: -0.0907 (0.2237) Loss_G: -0.2164 (0.0939) D(x): 0.5320 D(G(z)): 0.4584 / 0.4867 Acc: 46.8750 (33.4185)\n",
      "[12/25][96/782] Loss_D: -0.0336 (0.2237) Loss_G: -0.1285 (0.0939) D(x): 0.5845 D(G(z)): 0.5562 / 0.4539 Acc: 50.0000 (33.4203)\n",
      "[12/25][97/782] Loss_D: -0.3145 (0.2236) Loss_G: -0.0246 (0.0939) D(x): 0.5934 D(G(z)): 0.4586 / 0.4138 Acc: 54.6875 (33.4225)\n",
      "[12/25][98/782] Loss_D: 0.1273 (0.2236) Loss_G: -0.2584 (0.0939) D(x): 0.4462 D(G(z)): 0.4056 / 0.5091 Acc: 31.2500 (33.4223)\n",
      "[12/25][99/782] Loss_D: -0.0713 (0.2236) Loss_G: 0.0417 (0.0939) D(x): 0.5589 D(G(z)): 0.4696 / 0.3917 Acc: 40.6250 (33.4231)\n",
      "[12/25][100/782] Loss_D: 0.0560 (0.2235) Loss_G: -0.1096 (0.0938) D(x): 0.5154 D(G(z)): 0.4850 / 0.4466 Acc: 40.6250 (33.4238)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[12/25][101/782] Loss_D: -0.0244 (0.2235) Loss_G: -0.0550 (0.0938) D(x): 0.5260 D(G(z)): 0.4708 / 0.4423 Acc: 43.7500 (33.4249)\n",
      "[12/25][102/782] Loss_D: -0.0804 (0.2235) Loss_G: 0.0022 (0.0938) D(x): 0.5751 D(G(z)): 0.4565 / 0.4297 Acc: 43.7500 (33.4260)\n",
      "[12/25][103/782] Loss_D: 0.1600 (0.2235) Loss_G: -0.2220 (0.0938) D(x): 0.5100 D(G(z)): 0.5176 / 0.5065 Acc: 34.3750 (33.4261)\n",
      "[12/25][104/782] Loss_D: -0.1490 (0.2234) Loss_G: -0.1908 (0.0938) D(x): 0.5161 D(G(z)): 0.4070 / 0.4744 Acc: 42.1875 (33.4270)\n",
      "[12/25][105/782] Loss_D: -0.0158 (0.2234) Loss_G: -0.1454 (0.0937) D(x): 0.5206 D(G(z)): 0.4750 / 0.4583 Acc: 46.8750 (33.4284)\n",
      "[12/25][106/782] Loss_D: 0.0534 (0.2234) Loss_G: -0.1367 (0.0937) D(x): 0.5698 D(G(z)): 0.4801 / 0.4676 Acc: 29.6875 (33.4281)\n",
      "[12/25][107/782] Loss_D: -0.0821 (0.2234) Loss_G: -0.0496 (0.0937) D(x): 0.5550 D(G(z)): 0.4797 / 0.4454 Acc: 42.1875 (33.4290)\n",
      "[12/25][108/782] Loss_D: 0.1448 (0.2233) Loss_G: -0.0581 (0.0937) D(x): 0.4818 D(G(z)): 0.4684 / 0.4387 Acc: 35.9375 (33.4292)\n",
      "[12/25][109/782] Loss_D: 0.1042 (0.2233) Loss_G: -0.0801 (0.0937) D(x): 0.5175 D(G(z)): 0.5045 / 0.4275 Acc: 35.9375 (33.4295)\n",
      "[12/25][110/782] Loss_D: 0.0069 (0.2233) Loss_G: -0.0022 (0.0936) D(x): 0.5189 D(G(z)): 0.4737 / 0.4106 Acc: 42.1875 (33.4304)\n",
      "[12/25][111/782] Loss_D: 0.0663 (0.2233) Loss_G: -0.1608 (0.0936) D(x): 0.4927 D(G(z)): 0.4703 / 0.4780 Acc: 42.1875 (33.4313)\n",
      "[12/25][112/782] Loss_D: -0.0214 (0.2233) Loss_G: -0.1557 (0.0936) D(x): 0.5587 D(G(z)): 0.4704 / 0.4626 Acc: 35.9375 (33.4316)\n",
      "[12/25][113/782] Loss_D: -0.0723 (0.2232) Loss_G: -0.1299 (0.0936) D(x): 0.5391 D(G(z)): 0.4837 / 0.4486 Acc: 45.3125 (33.4329)\n",
      "[12/25][114/782] Loss_D: -0.1683 (0.2232) Loss_G: -0.1278 (0.0935) D(x): 0.5252 D(G(z)): 0.4474 / 0.4638 Acc: 53.1250 (33.4349)\n",
      "[12/25][115/782] Loss_D: -0.0881 (0.2232) Loss_G: -0.2137 (0.0935) D(x): 0.5406 D(G(z)): 0.4869 / 0.4992 Acc: 48.4375 (33.4365)\n",
      "[12/25][116/782] Loss_D: -0.0235 (0.2231) Loss_G: -0.2182 (0.0935) D(x): 0.5117 D(G(z)): 0.4807 / 0.4941 Acc: 46.8750 (33.4379)\n",
      "[12/25][117/782] Loss_D: -0.0666 (0.2231) Loss_G: -0.1083 (0.0935) D(x): 0.5231 D(G(z)): 0.4981 / 0.4324 Acc: 51.5625 (33.4398)\n",
      "[12/25][118/782] Loss_D: -0.1455 (0.2231) Loss_G: -0.0171 (0.0934) D(x): 0.5445 D(G(z)): 0.4631 / 0.3967 Acc: 46.8750 (33.4412)\n",
      "[12/25][119/782] Loss_D: -0.0549 (0.2230) Loss_G: -0.1867 (0.0934) D(x): 0.5491 D(G(z)): 0.4823 / 0.4760 Acc: 42.1875 (33.4422)\n",
      "[12/25][120/782] Loss_D: -0.2181 (0.2230) Loss_G: -0.1556 (0.0934) D(x): 0.5573 D(G(z)): 0.4683 / 0.4595 Acc: 53.1250 (33.4442)\n",
      "[12/25][121/782] Loss_D: 0.0424 (0.2230) Loss_G: -0.0989 (0.0934) D(x): 0.5097 D(G(z)): 0.4655 / 0.4540 Acc: 40.6250 (33.4450)\n",
      "[12/25][122/782] Loss_D: -0.0943 (0.2229) Loss_G: -0.1079 (0.0933) D(x): 0.5151 D(G(z)): 0.4852 / 0.4557 Acc: 54.6875 (33.4472)\n",
      "[12/25][123/782] Loss_D: -0.1597 (0.2229) Loss_G: -0.0900 (0.0933) D(x): 0.5692 D(G(z)): 0.5056 / 0.4555 Acc: 51.5625 (33.4491)\n",
      "[12/25][124/782] Loss_D: -0.0322 (0.2229) Loss_G: -0.0183 (0.0933) D(x): 0.4964 D(G(z)): 0.4101 / 0.4113 Acc: 40.6250 (33.4499)\n",
      "[12/25][125/782] Loss_D: 0.1264 (0.2229) Loss_G: -0.0014 (0.0933) D(x): 0.4957 D(G(z)): 0.4743 / 0.3919 Acc: 32.8125 (33.4498)\n",
      "[12/25][126/782] Loss_D: 0.1256 (0.2229) Loss_G: -0.2558 (0.0933) D(x): 0.4582 D(G(z)): 0.4453 / 0.4999 Acc: 39.0625 (33.4504)\n",
      "[12/25][127/782] Loss_D: -0.2240 (0.2228) Loss_G: -0.2357 (0.0932) D(x): 0.5849 D(G(z)): 0.4333 / 0.5002 Acc: 45.3125 (33.4517)\n",
      "[12/25][128/782] Loss_D: -0.0185 (0.2228) Loss_G: -0.0947 (0.0932) D(x): 0.5378 D(G(z)): 0.5403 / 0.4369 Acc: 51.5625 (33.4536)\n",
      "[12/25][129/782] Loss_D: -0.0917 (0.2227) Loss_G: 0.1008 (0.0932) D(x): 0.5616 D(G(z)): 0.5217 / 0.3674 Acc: 48.4375 (33.4551)\n",
      "[12/25][130/782] Loss_D: -0.0013 (0.2227) Loss_G: 0.0619 (0.0932) D(x): 0.4597 D(G(z)): 0.4282 / 0.3895 Acc: 42.1875 (33.4561)\n",
      "[12/25][131/782] Loss_D: -0.1526 (0.2227) Loss_G: -0.0501 (0.0932) D(x): 0.5207 D(G(z)): 0.4335 / 0.4144 Acc: 46.8750 (33.4575)\n",
      "[12/25][132/782] Loss_D: -0.1056 (0.2227) Loss_G: -0.1433 (0.0932) D(x): 0.5393 D(G(z)): 0.4318 / 0.4531 Acc: 39.0625 (33.4581)\n",
      "[12/25][133/782] Loss_D: -0.0550 (0.2226) Loss_G: -0.0260 (0.0932) D(x): 0.5412 D(G(z)): 0.4526 / 0.4081 Acc: 35.9375 (33.4583)\n",
      "[12/25][134/782] Loss_D: -0.1618 (0.2226) Loss_G: -0.2137 (0.0931) D(x): 0.4927 D(G(z)): 0.4317 / 0.5014 Acc: 57.8125 (33.4609)\n",
      "[12/25][135/782] Loss_D: -0.0825 (0.2225) Loss_G: -0.1602 (0.0931) D(x): 0.5668 D(G(z)): 0.5047 / 0.4615 Acc: 50.0000 (33.4626)\n",
      "[12/25][136/782] Loss_D: -0.0558 (0.2225) Loss_G: -0.0795 (0.0931) D(x): 0.5244 D(G(z)): 0.4611 / 0.4394 Acc: 45.3125 (33.4639)\n",
      "[12/25][137/782] Loss_D: 0.0247 (0.2225) Loss_G: -0.1431 (0.0931) D(x): 0.5429 D(G(z)): 0.4774 / 0.4440 Acc: 35.9375 (33.4641)\n",
      "[12/25][138/782] Loss_D: 0.1373 (0.2225) Loss_G: -0.2691 (0.0930) D(x): 0.4771 D(G(z)): 0.4915 / 0.5017 Acc: 37.5000 (33.4645)\n",
      "[12/25][139/782] Loss_D: 0.0593 (0.2225) Loss_G: -0.1773 (0.0930) D(x): 0.5234 D(G(z)): 0.5121 / 0.4817 Acc: 48.4375 (33.4661)\n",
      "[12/25][140/782] Loss_D: -0.1641 (0.2224) Loss_G: -0.1731 (0.0930) D(x): 0.5345 D(G(z)): 0.4767 / 0.4750 Acc: 57.8125 (33.4687)\n",
      "[12/25][141/782] Loss_D: 0.0663 (0.2224) Loss_G: -0.1887 (0.0929) D(x): 0.5024 D(G(z)): 0.5047 / 0.4808 Acc: 45.3125 (33.4699)\n",
      "[12/25][142/782] Loss_D: -0.0840 (0.2224) Loss_G: -0.2445 (0.0929) D(x): 0.4996 D(G(z)): 0.4324 / 0.5007 Acc: 48.4375 (33.4715)\n",
      "[12/25][143/782] Loss_D: -0.2187 (0.2223) Loss_G: -0.2296 (0.0929) D(x): 0.5583 D(G(z)): 0.4538 / 0.4961 Acc: 50.0000 (33.4732)\n",
      "[12/25][144/782] Loss_D: -0.0872 (0.2223) Loss_G: -0.2403 (0.0928) D(x): 0.5497 D(G(z)): 0.5302 / 0.4975 Acc: 57.8125 (33.4758)\n",
      "[12/25][145/782] Loss_D: -0.0817 (0.2223) Loss_G: 0.0007 (0.0928) D(x): 0.5331 D(G(z)): 0.4910 / 0.3961 Acc: 45.3125 (33.4770)\n",
      "[12/25][146/782] Loss_D: 0.0011 (0.2223) Loss_G: -0.0565 (0.0928) D(x): 0.4926 D(G(z)): 0.4335 / 0.4353 Acc: 37.5000 (33.4774)\n",
      "[12/25][147/782] Loss_D: -0.0310 (0.2222) Loss_G: 0.0244 (0.0928) D(x): 0.5439 D(G(z)): 0.5032 / 0.4050 Acc: 48.4375 (33.4790)\n",
      "[12/25][148/782] Loss_D: -0.0053 (0.2222) Loss_G: -0.1272 (0.0928) D(x): 0.5012 D(G(z)): 0.4505 / 0.4614 Acc: 46.8750 (33.4804)\n",
      "[12/25][149/782] Loss_D: -0.2097 (0.2222) Loss_G: -0.1001 (0.0928) D(x): 0.5198 D(G(z)): 0.4185 / 0.4363 Acc: 48.4375 (33.4820)\n",
      "[12/25][150/782] Loss_D: -0.2057 (0.2221) Loss_G: -0.1729 (0.0927) D(x): 0.5246 D(G(z)): 0.4467 / 0.4775 Acc: 54.6875 (33.4842)\n",
      "[12/25][151/782] Loss_D: 0.0132 (0.2221) Loss_G: -0.3226 (0.0927) D(x): 0.5093 D(G(z)): 0.4607 / 0.5505 Acc: 40.6250 (33.4850)\n",
      "[12/25][152/782] Loss_D: -0.1259 (0.2221) Loss_G: -0.0840 (0.0927) D(x): 0.6189 D(G(z)): 0.5334 / 0.4289 Acc: 46.8750 (33.4864)\n",
      "[12/25][153/782] Loss_D: -0.0669 (0.2220) Loss_G: -0.0476 (0.0927) D(x): 0.5034 D(G(z)): 0.4741 / 0.4139 Acc: 53.1250 (33.4884)\n",
      "[12/25][154/782] Loss_D: 0.0115 (0.2220) Loss_G: -0.0971 (0.0926) D(x): 0.4260 D(G(z)): 0.3623 / 0.4347 Acc: 39.0625 (33.4890)\n",
      "[12/25][155/782] Loss_D: -0.0156 (0.2220) Loss_G: -0.1742 (0.0926) D(x): 0.5440 D(G(z)): 0.5083 / 0.4794 Acc: 43.7500 (33.4901)\n",
      "[12/25][156/782] Loss_D: -0.0808 (0.2219) Loss_G: -0.2533 (0.0926) D(x): 0.5834 D(G(z)): 0.5240 / 0.5099 Acc: 43.7500 (33.4912)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/25][157/782] Loss_D: -0.1615 (0.2219) Loss_G: -0.0247 (0.0926) D(x): 0.5714 D(G(z)): 0.4516 / 0.4047 Acc: 39.0625 (33.4917)\n",
      "[12/25][158/782] Loss_D: -0.0408 (0.2219) Loss_G: -0.1449 (0.0925) D(x): 0.4970 D(G(z)): 0.4574 / 0.4482 Acc: 45.3125 (33.4930)\n",
      "[12/25][159/782] Loss_D: -0.2015 (0.2218) Loss_G: -0.0743 (0.0925) D(x): 0.5526 D(G(z)): 0.4399 / 0.4249 Acc: 48.4375 (33.4945)\n",
      "[12/25][160/782] Loss_D: -0.2504 (0.2218) Loss_G: -0.1577 (0.0925) D(x): 0.5950 D(G(z)): 0.4520 / 0.4563 Acc: 42.1875 (33.4954)\n",
      "[12/25][161/782] Loss_D: -0.0094 (0.2218) Loss_G: 0.0143 (0.0925) D(x): 0.5070 D(G(z)): 0.4374 / 0.3884 Acc: 35.9375 (33.4957)\n",
      "[12/25][162/782] Loss_D: -0.2222 (0.2217) Loss_G: 0.0074 (0.0925) D(x): 0.5058 D(G(z)): 0.4156 / 0.3978 Acc: 50.0000 (33.4974)\n",
      "[12/25][163/782] Loss_D: -0.2744 (0.2217) Loss_G: -0.0862 (0.0925) D(x): 0.5318 D(G(z)): 0.4185 / 0.4475 Acc: 56.2500 (33.4998)\n",
      "[12/25][164/782] Loss_D: -0.2368 (0.2216) Loss_G: -0.0463 (0.0924) D(x): 0.5899 D(G(z)): 0.4915 / 0.4322 Acc: 51.5625 (33.5017)\n",
      "[12/25][165/782] Loss_D: -0.0192 (0.2216) Loss_G: -0.0066 (0.0924) D(x): 0.5572 D(G(z)): 0.4799 / 0.4141 Acc: 40.6250 (33.5025)\n",
      "[12/25][166/782] Loss_D: -0.1190 (0.2215) Loss_G: -0.1321 (0.0924) D(x): 0.5084 D(G(z)): 0.3756 / 0.4460 Acc: 42.1875 (33.5034)\n",
      "[12/25][167/782] Loss_D: 0.0240 (0.2215) Loss_G: -0.2448 (0.0924) D(x): 0.4802 D(G(z)): 0.4818 / 0.5030 Acc: 48.4375 (33.5049)\n",
      "[12/25][168/782] Loss_D: -0.1391 (0.2215) Loss_G: -0.2672 (0.0923) D(x): 0.5805 D(G(z)): 0.4727 / 0.5168 Acc: 43.7500 (33.5060)\n",
      "[12/25][169/782] Loss_D: -0.0519 (0.2215) Loss_G: -0.1399 (0.0923) D(x): 0.5924 D(G(z)): 0.5407 / 0.4528 Acc: 45.3125 (33.5072)\n",
      "[12/25][170/782] Loss_D: -0.0702 (0.2214) Loss_G: -0.0630 (0.0923) D(x): 0.5594 D(G(z)): 0.5212 / 0.4430 Acc: 51.5625 (33.5091)\n",
      "[12/25][171/782] Loss_D: 0.1902 (0.2214) Loss_G: -0.1982 (0.0923) D(x): 0.3696 D(G(z)): 0.4031 / 0.4786 Acc: 46.8750 (33.5105)\n",
      "[12/25][172/782] Loss_D: 0.0013 (0.2214) Loss_G: -0.1029 (0.0922) D(x): 0.5059 D(G(z)): 0.4641 / 0.4575 Acc: 45.3125 (33.5118)\n",
      "[12/25][173/782] Loss_D: 0.0807 (0.2214) Loss_G: -0.1119 (0.0922) D(x): 0.5437 D(G(z)): 0.5006 / 0.4430 Acc: 34.3750 (33.5118)\n",
      "[12/25][174/782] Loss_D: -0.0089 (0.2214) Loss_G: -0.1482 (0.0922) D(x): 0.5255 D(G(z)): 0.4738 / 0.4655 Acc: 42.1875 (33.5128)\n",
      "[12/25][175/782] Loss_D: 0.0538 (0.2213) Loss_G: -0.1810 (0.0922) D(x): 0.5270 D(G(z)): 0.4915 / 0.4707 Acc: 40.6250 (33.5135)\n",
      "[12/25][176/782] Loss_D: -0.1143 (0.2213) Loss_G: -0.0810 (0.0921) D(x): 0.5333 D(G(z)): 0.4708 / 0.4321 Acc: 45.3125 (33.5147)\n",
      "[12/25][177/782] Loss_D: -0.0474 (0.2213) Loss_G: -0.1935 (0.0921) D(x): 0.5198 D(G(z)): 0.4654 / 0.4781 Acc: 42.1875 (33.5156)\n",
      "[12/25][178/782] Loss_D: -0.1068 (0.2213) Loss_G: -0.1366 (0.0921) D(x): 0.5494 D(G(z)): 0.4815 / 0.4565 Acc: 45.3125 (33.5169)\n",
      "[12/25][179/782] Loss_D: 0.0741 (0.2212) Loss_G: -0.1004 (0.0921) D(x): 0.4660 D(G(z)): 0.4782 / 0.4615 Acc: 48.4375 (33.5184)\n",
      "[12/25][180/782] Loss_D: -0.1163 (0.2212) Loss_G: -0.0351 (0.0921) D(x): 0.5271 D(G(z)): 0.4358 / 0.4162 Acc: 40.6250 (33.5192)\n",
      "[12/25][181/782] Loss_D: -0.0679 (0.2212) Loss_G: -0.1435 (0.0920) D(x): 0.5383 D(G(z)): 0.4799 / 0.4636 Acc: 43.7500 (33.5202)\n",
      "[12/25][182/782] Loss_D: -0.0140 (0.2211) Loss_G: -0.1639 (0.0920) D(x): 0.5120 D(G(z)): 0.4491 / 0.4771 Acc: 42.1875 (33.5212)\n",
      "[12/25][183/782] Loss_D: -0.0246 (0.2211) Loss_G: -0.0897 (0.0920) D(x): 0.5162 D(G(z)): 0.4630 / 0.4338 Acc: 40.6250 (33.5219)\n",
      "[12/25][184/782] Loss_D: -0.1993 (0.2211) Loss_G: -0.1472 (0.0920) D(x): 0.5590 D(G(z)): 0.4642 / 0.4671 Acc: 48.4375 (33.5235)\n",
      "[12/25][185/782] Loss_D: -0.2663 (0.2210) Loss_G: -0.1342 (0.0919) D(x): 0.5863 D(G(z)): 0.4791 / 0.4579 Acc: 54.6875 (33.5257)\n",
      "[12/25][186/782] Loss_D: -0.1217 (0.2210) Loss_G: -0.1477 (0.0919) D(x): 0.4848 D(G(z)): 0.4257 / 0.4490 Acc: 50.0000 (33.5274)\n",
      "[12/25][187/782] Loss_D: -0.2188 (0.2209) Loss_G: -0.0967 (0.0919) D(x): 0.5319 D(G(z)): 0.4512 / 0.4531 Acc: 56.2500 (33.5298)\n",
      "[12/25][188/782] Loss_D: 0.0488 (0.2209) Loss_G: -0.1294 (0.0919) D(x): 0.5492 D(G(z)): 0.4942 / 0.4576 Acc: 34.3750 (33.5298)\n",
      "[12/25][189/782] Loss_D: -0.1712 (0.2209) Loss_G: -0.0972 (0.0919) D(x): 0.5530 D(G(z)): 0.4405 / 0.4330 Acc: 42.1875 (33.5308)\n",
      "[12/25][190/782] Loss_D: -0.0588 (0.2209) Loss_G: -0.0454 (0.0918) D(x): 0.4995 D(G(z)): 0.4517 / 0.4101 Acc: 45.3125 (33.5320)\n",
      "[12/25][191/782] Loss_D: -0.0326 (0.2208) Loss_G: -0.1947 (0.0918) D(x): 0.4833 D(G(z)): 0.4506 / 0.4897 Acc: 43.7500 (33.5331)\n",
      "[12/25][192/782] Loss_D: -0.0586 (0.2208) Loss_G: -0.0918 (0.0918) D(x): 0.5804 D(G(z)): 0.5245 / 0.4472 Acc: 48.4375 (33.5346)\n",
      "[12/25][193/782] Loss_D: -0.2214 (0.2208) Loss_G: -0.1549 (0.0918) D(x): 0.5855 D(G(z)): 0.4691 / 0.4493 Acc: 50.0000 (33.5363)\n",
      "[12/25][194/782] Loss_D: 0.0401 (0.2207) Loss_G: -0.1194 (0.0917) D(x): 0.5279 D(G(z)): 0.4840 / 0.4402 Acc: 37.5000 (33.5367)\n",
      "[12/25][195/782] Loss_D: 0.0319 (0.2207) Loss_G: -0.2177 (0.0917) D(x): 0.4899 D(G(z)): 0.4406 / 0.4923 Acc: 35.9375 (33.5370)\n",
      "[12/25][196/782] Loss_D: -0.0944 (0.2207) Loss_G: -0.0820 (0.0917) D(x): 0.5455 D(G(z)): 0.4425 / 0.4448 Acc: 45.3125 (33.5382)\n",
      "[12/25][197/782] Loss_D: -0.0241 (0.2207) Loss_G: -0.1576 (0.0917) D(x): 0.4889 D(G(z)): 0.4680 / 0.4638 Acc: 46.8750 (33.5396)\n",
      "[12/25][198/782] Loss_D: 0.0218 (0.2206) Loss_G: -0.1775 (0.0916) D(x): 0.5911 D(G(z)): 0.5119 / 0.4875 Acc: 34.3750 (33.5397)\n",
      "[12/25][199/782] Loss_D: 0.0663 (0.2206) Loss_G: -0.2081 (0.0916) D(x): 0.5645 D(G(z)): 0.5090 / 0.4839 Acc: 35.9375 (33.5399)\n",
      "[12/25][200/782] Loss_D: -0.0641 (0.2206) Loss_G: 0.0132 (0.0916) D(x): 0.5284 D(G(z)): 0.4511 / 0.3996 Acc: 48.4375 (33.5415)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[12/25][201/782] Loss_D: 0.0938 (0.2206) Loss_G: -0.2471 (0.0916) D(x): 0.4269 D(G(z)): 0.4207 / 0.5050 Acc: 43.7500 (33.5426)\n",
      "[12/25][202/782] Loss_D: 0.0895 (0.2206) Loss_G: -0.2713 (0.0915) D(x): 0.5303 D(G(z)): 0.5325 / 0.4998 Acc: 42.1875 (33.5435)\n",
      "[12/25][203/782] Loss_D: 0.0667 (0.2205) Loss_G: -0.2045 (0.0915) D(x): 0.5299 D(G(z)): 0.5029 / 0.4829 Acc: 43.7500 (33.5445)\n",
      "[12/25][204/782] Loss_D: 0.0009 (0.2205) Loss_G: -0.1101 (0.0915) D(x): 0.4883 D(G(z)): 0.4487 / 0.4543 Acc: 39.0625 (33.5451)\n",
      "[12/25][205/782] Loss_D: 0.1186 (0.2205) Loss_G: -0.1619 (0.0914) D(x): 0.5588 D(G(z)): 0.5745 / 0.4699 Acc: 48.4375 (33.5467)\n",
      "[12/25][206/782] Loss_D: -0.3230 (0.2205) Loss_G: 0.0231 (0.0914) D(x): 0.5693 D(G(z)): 0.4161 / 0.3857 Acc: 51.5625 (33.5485)\n",
      "[12/25][207/782] Loss_D: 0.1042 (0.2204) Loss_G: -0.1333 (0.0914) D(x): 0.5150 D(G(z)): 0.5050 / 0.4528 Acc: 39.0625 (33.5491)\n",
      "[12/25][208/782] Loss_D: -0.3099 (0.2204) Loss_G: -0.1259 (0.0914) D(x): 0.5646 D(G(z)): 0.4189 / 0.4449 Acc: 51.5625 (33.5510)\n",
      "[12/25][209/782] Loss_D: -0.2213 (0.2203) Loss_G: -0.0403 (0.0914) D(x): 0.5330 D(G(z)): 0.4083 / 0.4263 Acc: 48.4375 (33.5525)\n",
      "[12/25][210/782] Loss_D: -0.0496 (0.2203) Loss_G: 0.0130 (0.0914) D(x): 0.5987 D(G(z)): 0.5332 / 0.4030 Acc: 46.8750 (33.5539)\n",
      "[12/25][211/782] Loss_D: -0.1131 (0.2203) Loss_G: 0.0059 (0.0914) D(x): 0.5055 D(G(z)): 0.4258 / 0.4092 Acc: 48.4375 (33.5555)\n",
      "[12/25][212/782] Loss_D: -0.0808 (0.2202) Loss_G: -0.0616 (0.0913) D(x): 0.5292 D(G(z)): 0.4843 / 0.4435 Acc: 51.5625 (33.5574)\n",
      "[12/25][213/782] Loss_D: -0.0178 (0.2202) Loss_G: -0.2203 (0.0913) D(x): 0.5271 D(G(z)): 0.4966 / 0.4848 Acc: 46.8750 (33.5587)\n",
      "[12/25][214/782] Loss_D: -0.1016 (0.2202) Loss_G: -0.0899 (0.0913) D(x): 0.5174 D(G(z)): 0.4186 / 0.4401 Acc: 40.6250 (33.5595)\n",
      "[12/25][215/782] Loss_D: -0.0782 (0.2202) Loss_G: -0.2606 (0.0913) D(x): 0.5158 D(G(z)): 0.4840 / 0.5143 Acc: 54.6875 (33.5617)\n",
      "[12/25][216/782] Loss_D: 0.1757 (0.2202) Loss_G: -0.1938 (0.0912) D(x): 0.5544 D(G(z)): 0.5575 / 0.4782 Acc: 32.8125 (33.5616)\n",
      "[12/25][217/782] Loss_D: 0.0314 (0.2201) Loss_G: 0.0727 (0.0912) D(x): 0.5250 D(G(z)): 0.4998 / 0.4057 Acc: 48.4375 (33.5632)\n",
      "[12/25][218/782] Loss_D: 0.0719 (0.2201) Loss_G: -0.0365 (0.0912) D(x): 0.5187 D(G(z)): 0.4857 / 0.4203 Acc: 39.0625 (33.5637)\n",
      "[12/25][219/782] Loss_D: -0.0624 (0.2201) Loss_G: -0.0848 (0.0912) D(x): 0.5222 D(G(z)): 0.4149 / 0.4242 Acc: 35.9375 (33.5640)\n",
      "[12/25][220/782] Loss_D: -0.0583 (0.2201) Loss_G: -0.1298 (0.0912) D(x): 0.5428 D(G(z)): 0.4934 / 0.4506 Acc: 43.7500 (33.5650)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/25][221/782] Loss_D: -0.0494 (0.2200) Loss_G: -0.0329 (0.0912) D(x): 0.5534 D(G(z)): 0.4939 / 0.4092 Acc: 42.1875 (33.5659)\n",
      "[12/25][222/782] Loss_D: -0.0096 (0.2200) Loss_G: -0.0994 (0.0911) D(x): 0.5029 D(G(z)): 0.4541 / 0.4507 Acc: 37.5000 (33.5663)\n",
      "[12/25][223/782] Loss_D: 0.1167 (0.2200) Loss_G: -0.1757 (0.0911) D(x): 0.4462 D(G(z)): 0.4617 / 0.4908 Acc: 46.8750 (33.5677)\n",
      "[12/25][224/782] Loss_D: -0.0656 (0.2200) Loss_G: -0.1790 (0.0911) D(x): 0.5379 D(G(z)): 0.4382 / 0.4789 Acc: 39.0625 (33.5683)\n",
      "[12/25][225/782] Loss_D: -0.0131 (0.2199) Loss_G: -0.3218 (0.0910) D(x): 0.4762 D(G(z)): 0.4501 / 0.5466 Acc: 46.8750 (33.5697)\n",
      "[12/25][226/782] Loss_D: -0.0144 (0.2199) Loss_G: -0.1687 (0.0910) D(x): 0.6047 D(G(z)): 0.5485 / 0.4905 Acc: 43.7500 (33.5707)\n",
      "[12/25][227/782] Loss_D: -0.0405 (0.2199) Loss_G: -0.0165 (0.0910) D(x): 0.5253 D(G(z)): 0.4510 / 0.4258 Acc: 45.3125 (33.5720)\n",
      "[12/25][228/782] Loss_D: -0.1771 (0.2199) Loss_G: -0.1640 (0.0910) D(x): 0.5182 D(G(z)): 0.4461 / 0.4757 Acc: 51.5625 (33.5738)\n",
      "[12/25][229/782] Loss_D: -0.1589 (0.2198) Loss_G: -0.3056 (0.0909) D(x): 0.5035 D(G(z)): 0.4429 / 0.5311 Acc: 56.2500 (33.5762)\n",
      "[12/25][230/782] Loss_D: -0.1807 (0.2198) Loss_G: -0.2989 (0.0909) D(x): 0.5548 D(G(z)): 0.5355 / 0.5118 Acc: 60.9375 (33.5790)\n",
      "[12/25][231/782] Loss_D: -0.0771 (0.2197) Loss_G: -0.1954 (0.0909) D(x): 0.5552 D(G(z)): 0.4758 / 0.4800 Acc: 42.1875 (33.5799)\n",
      "[12/25][232/782] Loss_D: -0.1195 (0.2197) Loss_G: -0.0964 (0.0908) D(x): 0.5220 D(G(z)): 0.4783 / 0.4450 Acc: 54.6875 (33.5821)\n",
      "[12/25][233/782] Loss_D: -0.0909 (0.2197) Loss_G: -0.1600 (0.0908) D(x): 0.4994 D(G(z)): 0.4552 / 0.4437 Acc: 53.1250 (33.5842)\n",
      "[12/25][234/782] Loss_D: -0.1510 (0.2196) Loss_G: -0.0437 (0.0908) D(x): 0.5418 D(G(z)): 0.4305 / 0.4195 Acc: 43.7500 (33.5852)\n",
      "[12/25][235/782] Loss_D: -0.0150 (0.2196) Loss_G: -0.1148 (0.0908) D(x): 0.5037 D(G(z)): 0.4581 / 0.4570 Acc: 42.1875 (33.5861)\n",
      "[12/25][236/782] Loss_D: -0.2116 (0.2196) Loss_G: -0.1748 (0.0908) D(x): 0.5399 D(G(z)): 0.4276 / 0.4690 Acc: 46.8750 (33.5875)\n",
      "[12/25][237/782] Loss_D: -0.2458 (0.2195) Loss_G: -0.0520 (0.0907) D(x): 0.6050 D(G(z)): 0.4677 / 0.4252 Acc: 43.7500 (33.5886)\n",
      "[12/25][238/782] Loss_D: -0.1263 (0.2195) Loss_G: -0.1490 (0.0907) D(x): 0.5462 D(G(z)): 0.4615 / 0.4624 Acc: 45.3125 (33.5898)\n",
      "[12/25][239/782] Loss_D: 0.0441 (0.2195) Loss_G: 0.0024 (0.0907) D(x): 0.5289 D(G(z)): 0.4822 / 0.4047 Acc: 37.5000 (33.5902)\n",
      "[12/25][240/782] Loss_D: -0.0645 (0.2194) Loss_G: 0.0182 (0.0907) D(x): 0.5452 D(G(z)): 0.4556 / 0.3979 Acc: 35.9375 (33.5904)\n",
      "[12/25][241/782] Loss_D: -0.1462 (0.2194) Loss_G: -0.0785 (0.0907) D(x): 0.4903 D(G(z)): 0.4108 / 0.4329 Acc: 51.5625 (33.5923)\n",
      "[12/25][242/782] Loss_D: 0.0352 (0.2194) Loss_G: -0.0650 (0.0907) D(x): 0.4676 D(G(z)): 0.4673 / 0.4363 Acc: 45.3125 (33.5935)\n",
      "[12/25][243/782] Loss_D: -0.1216 (0.2193) Loss_G: -0.2540 (0.0906) D(x): 0.5779 D(G(z)): 0.4686 / 0.5336 Acc: 46.8750 (33.5949)\n",
      "[12/25][244/782] Loss_D: -0.2331 (0.2193) Loss_G: -0.1426 (0.0906) D(x): 0.5980 D(G(z)): 0.4400 / 0.4543 Acc: 43.7500 (33.5959)\n",
      "[12/25][245/782] Loss_D: -0.1340 (0.2193) Loss_G: 0.0018 (0.0906) D(x): 0.5293 D(G(z)): 0.4281 / 0.4135 Acc: 43.7500 (33.5970)\n",
      "[12/25][246/782] Loss_D: -0.0476 (0.2192) Loss_G: -0.1130 (0.0906) D(x): 0.5582 D(G(z)): 0.4400 / 0.4548 Acc: 37.5000 (33.5974)\n",
      "[12/25][247/782] Loss_D: -0.2601 (0.2192) Loss_G: -0.0727 (0.0906) D(x): 0.5680 D(G(z)): 0.4056 / 0.4316 Acc: 42.1875 (33.5983)\n",
      "[12/25][248/782] Loss_D: -0.0273 (0.2192) Loss_G: -0.1221 (0.0905) D(x): 0.5296 D(G(z)): 0.4792 / 0.4424 Acc: 42.1875 (33.5992)\n",
      "[12/25][249/782] Loss_D: -0.3648 (0.2191) Loss_G: -0.2280 (0.0905) D(x): 0.5949 D(G(z)): 0.4132 / 0.4830 Acc: 46.8750 (33.6006)\n",
      "[12/25][250/782] Loss_D: -0.0851 (0.2191) Loss_G: 0.0432 (0.0905) D(x): 0.5683 D(G(z)): 0.4752 / 0.3834 Acc: 40.6250 (33.6013)\n",
      "[12/25][251/782] Loss_D: -0.0723 (0.2190) Loss_G: -0.0634 (0.0905) D(x): 0.5249 D(G(z)): 0.4011 / 0.4247 Acc: 35.9375 (33.6015)\n",
      "[12/25][252/782] Loss_D: -0.2980 (0.2190) Loss_G: -0.0780 (0.0905) D(x): 0.5603 D(G(z)): 0.4347 / 0.4265 Acc: 54.6875 (33.6037)\n",
      "[12/25][253/782] Loss_D: -0.2489 (0.2189) Loss_G: 0.1534 (0.0905) D(x): 0.5226 D(G(z)): 0.4256 / 0.3607 Acc: 56.2500 (33.6061)\n",
      "[12/25][254/782] Loss_D: -0.3112 (0.2189) Loss_G: -0.2334 (0.0904) D(x): 0.5546 D(G(z)): 0.4124 / 0.5038 Acc: 51.5625 (33.6079)\n",
      "[12/25][255/782] Loss_D: -0.1592 (0.2188) Loss_G: -0.1391 (0.0904) D(x): 0.6060 D(G(z)): 0.5274 / 0.4499 Acc: 50.0000 (33.6096)\n",
      "[12/25][256/782] Loss_D: -0.1387 (0.2188) Loss_G: 0.0645 (0.0904) D(x): 0.5619 D(G(z)): 0.4987 / 0.3747 Acc: 51.5625 (33.6115)\n",
      "[12/25][257/782] Loss_D: -0.2261 (0.2188) Loss_G: -0.0685 (0.0904) D(x): 0.4884 D(G(z)): 0.3654 / 0.4379 Acc: 50.0000 (33.6132)\n",
      "[12/25][258/782] Loss_D: 0.0593 (0.2187) Loss_G: -0.1034 (0.0904) D(x): 0.5097 D(G(z)): 0.4678 / 0.4533 Acc: 35.9375 (33.6134)\n",
      "[12/25][259/782] Loss_D: -0.1012 (0.2187) Loss_G: -0.0983 (0.0904) D(x): 0.5813 D(G(z)): 0.5052 / 0.4361 Acc: 43.7500 (33.6145)\n",
      "[12/25][260/782] Loss_D: -0.1449 (0.2187) Loss_G: -0.2108 (0.0903) D(x): 0.4996 D(G(z)): 0.4435 / 0.4830 Acc: 50.0000 (33.6162)\n",
      "[12/25][261/782] Loss_D: -0.0646 (0.2186) Loss_G: -0.2660 (0.0903) D(x): 0.5076 D(G(z)): 0.4523 / 0.5088 Acc: 46.8750 (33.6176)\n",
      "[12/25][262/782] Loss_D: -0.0773 (0.2186) Loss_G: -0.1286 (0.0903) D(x): 0.5145 D(G(z)): 0.4302 / 0.4551 Acc: 40.6250 (33.6183)\n",
      "[12/25][263/782] Loss_D: -0.0198 (0.2186) Loss_G: -0.2050 (0.0902) D(x): 0.5339 D(G(z)): 0.5325 / 0.4888 Acc: 51.5625 (33.6201)\n",
      "[12/25][264/782] Loss_D: -0.0498 (0.2186) Loss_G: -0.0760 (0.0902) D(x): 0.5672 D(G(z)): 0.5046 / 0.4298 Acc: 39.0625 (33.6207)\n",
      "[12/25][265/782] Loss_D: -0.1583 (0.2185) Loss_G: -0.0441 (0.0902) D(x): 0.5086 D(G(z)): 0.4209 / 0.4262 Acc: 50.0000 (33.6224)\n",
      "[12/25][266/782] Loss_D: -0.1525 (0.2185) Loss_G: -0.1784 (0.0902) D(x): 0.5675 D(G(z)): 0.4796 / 0.4847 Acc: 46.8750 (33.6238)\n",
      "[12/25][267/782] Loss_D: 0.0479 (0.2185) Loss_G: 0.0390 (0.0902) D(x): 0.4587 D(G(z)): 0.4779 / 0.4100 Acc: 48.4375 (33.6253)\n",
      "[12/25][268/782] Loss_D: -0.0074 (0.2184) Loss_G: -0.2201 (0.0901) D(x): 0.5022 D(G(z)): 0.4592 / 0.4843 Acc: 40.6250 (33.6260)\n",
      "[12/25][269/782] Loss_D: -0.1185 (0.2184) Loss_G: -0.0897 (0.0901) D(x): 0.5643 D(G(z)): 0.4486 / 0.4318 Acc: 43.7500 (33.6271)\n",
      "[12/25][270/782] Loss_D: 0.1707 (0.2184) Loss_G: -0.1654 (0.0901) D(x): 0.4754 D(G(z)): 0.4921 / 0.4619 Acc: 32.8125 (33.6270)\n",
      "[12/25][271/782] Loss_D: -0.1630 (0.2184) Loss_G: -0.1853 (0.0901) D(x): 0.5589 D(G(z)): 0.4737 / 0.4774 Acc: 48.4375 (33.6285)\n",
      "[12/25][272/782] Loss_D: -0.0593 (0.2183) Loss_G: -0.0906 (0.0900) D(x): 0.5271 D(G(z)): 0.4608 / 0.4345 Acc: 40.6250 (33.6293)\n",
      "[12/25][273/782] Loss_D: -0.0152 (0.2183) Loss_G: 0.1749 (0.0901) D(x): 0.5758 D(G(z)): 0.5114 / 0.3412 Acc: 37.5000 (33.6297)\n",
      "[12/25][274/782] Loss_D: -0.0885 (0.2183) Loss_G: -0.1540 (0.0900) D(x): 0.4810 D(G(z)): 0.4155 / 0.4700 Acc: 43.7500 (33.6307)\n",
      "[12/25][275/782] Loss_D: -0.0587 (0.2182) Loss_G: -0.0641 (0.0900) D(x): 0.5036 D(G(z)): 0.4608 / 0.4225 Acc: 43.7500 (33.6318)\n",
      "[12/25][276/782] Loss_D: -0.0645 (0.2182) Loss_G: -0.1689 (0.0900) D(x): 0.5476 D(G(z)): 0.5216 / 0.4816 Acc: 46.8750 (33.6331)\n",
      "[12/25][277/782] Loss_D: -0.1333 (0.2182) Loss_G: -0.2695 (0.0899) D(x): 0.5602 D(G(z)): 0.4565 / 0.5146 Acc: 40.6250 (33.6339)\n",
      "[12/25][278/782] Loss_D: -0.1644 (0.2181) Loss_G: -0.1397 (0.0899) D(x): 0.5292 D(G(z)): 0.4673 / 0.4513 Acc: 51.5625 (33.6357)\n",
      "[12/25][279/782] Loss_D: -0.1229 (0.2181) Loss_G: -0.2001 (0.0899) D(x): 0.5227 D(G(z)): 0.3918 / 0.5234 Acc: 42.1875 (33.6366)\n",
      "[12/25][280/782] Loss_D: 0.0241 (0.2181) Loss_G: -0.1778 (0.0899) D(x): 0.5620 D(G(z)): 0.4955 / 0.4786 Acc: 35.9375 (33.6368)\n",
      "[12/25][281/782] Loss_D: -0.0716 (0.2180) Loss_G: -0.2085 (0.0898) D(x): 0.5647 D(G(z)): 0.5116 / 0.4802 Acc: 43.7500 (33.6379)\n",
      "[12/25][282/782] Loss_D: -0.0359 (0.2180) Loss_G: -0.1103 (0.0898) D(x): 0.5735 D(G(z)): 0.5174 / 0.4350 Acc: 40.6250 (33.6386)\n",
      "[12/25][283/782] Loss_D: -0.0651 (0.2180) Loss_G: -0.1353 (0.0898) D(x): 0.5097 D(G(z)): 0.4299 / 0.4524 Acc: 43.7500 (33.6396)\n",
      "[12/25][284/782] Loss_D: -0.0021 (0.2180) Loss_G: -0.0928 (0.0898) D(x): 0.4760 D(G(z)): 0.4515 / 0.4435 Acc: 45.3125 (33.6409)\n",
      "[12/25][285/782] Loss_D: -0.0489 (0.2179) Loss_G: -0.2079 (0.0897) D(x): 0.5477 D(G(z)): 0.5104 / 0.4759 Acc: 43.7500 (33.6419)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/25][286/782] Loss_D: -0.1502 (0.2179) Loss_G: -0.1643 (0.0897) D(x): 0.5827 D(G(z)): 0.4885 / 0.4665 Acc: 45.3125 (33.6431)\n",
      "[12/25][287/782] Loss_D: -0.0423 (0.2179) Loss_G: 0.0117 (0.0897) D(x): 0.5472 D(G(z)): 0.5023 / 0.4181 Acc: 45.3125 (33.6443)\n",
      "[12/25][288/782] Loss_D: -0.0075 (0.2179) Loss_G: -0.0289 (0.0897) D(x): 0.5234 D(G(z)): 0.5072 / 0.4028 Acc: 46.8750 (33.6457)\n",
      "[12/25][289/782] Loss_D: -0.1068 (0.2178) Loss_G: 0.0250 (0.0897) D(x): 0.4597 D(G(z)): 0.4025 / 0.3999 Acc: 51.5625 (33.6475)\n",
      "[12/25][290/782] Loss_D: 0.0633 (0.2178) Loss_G: -0.0466 (0.0897) D(x): 0.4620 D(G(z)): 0.4448 / 0.4287 Acc: 37.5000 (33.6479)\n",
      "[12/25][291/782] Loss_D: -0.1786 (0.2178) Loss_G: -0.2816 (0.0896) D(x): 0.5694 D(G(z)): 0.4865 / 0.5090 Acc: 53.1250 (33.6499)\n",
      "[12/25][292/782] Loss_D: 0.0024 (0.2177) Loss_G: -0.0461 (0.0896) D(x): 0.6065 D(G(z)): 0.5442 / 0.4215 Acc: 37.5000 (33.6503)\n",
      "[12/25][293/782] Loss_D: 0.0364 (0.2177) Loss_G: 0.1622 (0.0896) D(x): 0.5106 D(G(z)): 0.5056 / 0.3480 Acc: 45.3125 (33.6515)\n",
      "[12/25][294/782] Loss_D: 0.0631 (0.2177) Loss_G: 0.0204 (0.0896) D(x): 0.4313 D(G(z)): 0.4004 / 0.3988 Acc: 39.0625 (33.6521)\n",
      "[12/25][295/782] Loss_D: 0.0778 (0.2177) Loss_G: -0.2307 (0.0896) D(x): 0.4659 D(G(z)): 0.4658 / 0.4856 Acc: 40.6250 (33.6528)\n",
      "[12/25][296/782] Loss_D: -0.0379 (0.2177) Loss_G: -0.1721 (0.0896) D(x): 0.5262 D(G(z)): 0.4639 / 0.4744 Acc: 43.7500 (33.6539)\n",
      "[12/25][297/782] Loss_D: -0.1421 (0.2176) Loss_G: -0.1558 (0.0895) D(x): 0.5502 D(G(z)): 0.4811 / 0.4724 Acc: 50.0000 (33.6556)\n",
      "[12/25][298/782] Loss_D: -0.1335 (0.2176) Loss_G: -0.0239 (0.0895) D(x): 0.5828 D(G(z)): 0.4837 / 0.4091 Acc: 43.7500 (33.6566)\n",
      "[12/25][299/782] Loss_D: -0.1820 (0.2176) Loss_G: -0.0633 (0.0895) D(x): 0.5724 D(G(z)): 0.4791 / 0.4316 Acc: 45.3125 (33.6578)\n",
      "[12/25][300/782] Loss_D: 0.1898 (0.2175) Loss_G: -0.0268 (0.0895) D(x): 0.4742 D(G(z)): 0.5113 / 0.4120 Acc: 39.0625 (33.6584)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[12/25][301/782] Loss_D: -0.0477 (0.2175) Loss_G: -0.1084 (0.0895) D(x): 0.5012 D(G(z)): 0.4640 / 0.4332 Acc: 48.4375 (33.6599)\n",
      "[12/25][302/782] Loss_D: 0.1430 (0.2175) Loss_G: 0.0486 (0.0895) D(x): 0.5196 D(G(z)): 0.5158 / 0.3903 Acc: 37.5000 (33.6603)\n",
      "[12/25][303/782] Loss_D: 0.2735 (0.2175) Loss_G: -0.2208 (0.0894) D(x): 0.4710 D(G(z)): 0.5506 / 0.4912 Acc: 48.4375 (33.6618)\n",
      "[12/25][304/782] Loss_D: 0.1187 (0.2175) Loss_G: -0.0946 (0.0894) D(x): 0.4586 D(G(z)): 0.4710 / 0.4353 Acc: 43.7500 (33.6629)\n",
      "[12/25][305/782] Loss_D: -0.1711 (0.2175) Loss_G: -0.1293 (0.0894) D(x): 0.5085 D(G(z)): 0.4380 / 0.4740 Acc: 51.5625 (33.6647)\n",
      "[12/25][306/782] Loss_D: -0.0518 (0.2174) Loss_G: -0.1869 (0.0894) D(x): 0.5165 D(G(z)): 0.5062 / 0.4820 Acc: 54.6875 (33.6669)\n",
      "[12/25][307/782] Loss_D: 0.3032 (0.2175) Loss_G: -0.0860 (0.0894) D(x): 0.5245 D(G(z)): 0.6077 / 0.4653 Acc: 43.7500 (33.6679)\n",
      "[12/25][308/782] Loss_D: 0.2656 (0.2175) Loss_G: -0.0363 (0.0893) D(x): 0.4895 D(G(z)): 0.5238 / 0.4275 Acc: 42.1875 (33.6688)\n",
      "[12/25][309/782] Loss_D: 0.1306 (0.2174) Loss_G: -0.1247 (0.0893) D(x): 0.4565 D(G(z)): 0.4759 / 0.4679 Acc: 45.3125 (33.6700)\n",
      "[12/25][310/782] Loss_D: 0.0504 (0.2174) Loss_G: -0.0900 (0.0893) D(x): 0.5333 D(G(z)): 0.4773 / 0.4479 Acc: 35.9375 (33.6702)\n",
      "[12/25][311/782] Loss_D: 0.0994 (0.2174) Loss_G: -0.0702 (0.0893) D(x): 0.4816 D(G(z)): 0.4624 / 0.4196 Acc: 43.7500 (33.6713)\n",
      "[12/25][312/782] Loss_D: -0.0336 (0.2174) Loss_G: 0.0013 (0.0893) D(x): 0.5388 D(G(z)): 0.4350 / 0.4044 Acc: 39.0625 (33.6718)\n",
      "[12/25][313/782] Loss_D: -0.0707 (0.2174) Loss_G: -0.1804 (0.0892) D(x): 0.5435 D(G(z)): 0.4673 / 0.4839 Acc: 39.0625 (33.6724)\n",
      "[12/25][314/782] Loss_D: -0.1666 (0.2173) Loss_G: -0.0737 (0.0892) D(x): 0.5451 D(G(z)): 0.4505 / 0.4260 Acc: 50.0000 (33.6741)\n",
      "[12/25][315/782] Loss_D: -0.1331 (0.2173) Loss_G: -0.0452 (0.0892) D(x): 0.5273 D(G(z)): 0.4293 / 0.4233 Acc: 43.7500 (33.6751)\n",
      "[12/25][316/782] Loss_D: -0.1519 (0.2172) Loss_G: 0.0081 (0.0892) D(x): 0.5215 D(G(z)): 0.4857 / 0.4037 Acc: 57.8125 (33.6776)\n",
      "[12/25][317/782] Loss_D: -0.2648 (0.2172) Loss_G: -0.0273 (0.0892) D(x): 0.5657 D(G(z)): 0.4437 / 0.4245 Acc: 54.6875 (33.6798)\n",
      "[12/25][318/782] Loss_D: -0.2150 (0.2172) Loss_G: 0.0397 (0.0892) D(x): 0.5618 D(G(z)): 0.4347 / 0.3999 Acc: 46.8750 (33.6811)\n",
      "[12/25][319/782] Loss_D: -0.0376 (0.2171) Loss_G: -0.1339 (0.0892) D(x): 0.5452 D(G(z)): 0.4341 / 0.4579 Acc: 34.3750 (33.6812)\n",
      "[12/25][320/782] Loss_D: -0.1659 (0.2171) Loss_G: -0.0658 (0.0891) D(x): 0.5742 D(G(z)): 0.5081 / 0.4338 Acc: 53.1250 (33.6832)\n",
      "[12/25][321/782] Loss_D: -0.0853 (0.2171) Loss_G: 0.0014 (0.0891) D(x): 0.5426 D(G(z)): 0.4625 / 0.4010 Acc: 42.1875 (33.6841)\n",
      "[12/25][322/782] Loss_D: -0.1336 (0.2170) Loss_G: 0.0515 (0.0891) D(x): 0.5659 D(G(z)): 0.4860 / 0.3825 Acc: 48.4375 (33.6856)\n",
      "[12/25][323/782] Loss_D: -0.1270 (0.2170) Loss_G: -0.1050 (0.0891) D(x): 0.5454 D(G(z)): 0.4288 / 0.4459 Acc: 40.6250 (33.6863)\n",
      "[12/25][324/782] Loss_D: -0.1178 (0.2170) Loss_G: 0.1015 (0.0891) D(x): 0.5372 D(G(z)): 0.4680 / 0.3764 Acc: 50.0000 (33.6880)\n",
      "[12/25][325/782] Loss_D: -0.1414 (0.2169) Loss_G: -0.0503 (0.0891) D(x): 0.5299 D(G(z)): 0.4461 / 0.4288 Acc: 48.4375 (33.6895)\n",
      "[12/25][326/782] Loss_D: -0.0620 (0.2169) Loss_G: -0.1091 (0.0891) D(x): 0.5431 D(G(z)): 0.4810 / 0.4472 Acc: 43.7500 (33.6905)\n",
      "[12/25][327/782] Loss_D: 0.0584 (0.2169) Loss_G: 0.0137 (0.0891) D(x): 0.5294 D(G(z)): 0.4754 / 0.3897 Acc: 32.8125 (33.6904)\n",
      "[12/25][328/782] Loss_D: -0.2103 (0.2168) Loss_G: -0.0543 (0.0891) D(x): 0.5452 D(G(z)): 0.4595 / 0.4257 Acc: 53.1250 (33.6924)\n",
      "[12/25][329/782] Loss_D: -0.0777 (0.2168) Loss_G: -0.1257 (0.0890) D(x): 0.5596 D(G(z)): 0.4473 / 0.4450 Acc: 34.3750 (33.6925)\n",
      "[12/25][330/782] Loss_D: -0.1549 (0.2168) Loss_G: -0.1206 (0.0890) D(x): 0.5600 D(G(z)): 0.4459 / 0.4539 Acc: 46.8750 (33.6939)\n",
      "[12/25][331/782] Loss_D: -0.1568 (0.2167) Loss_G: -0.0482 (0.0890) D(x): 0.5550 D(G(z)): 0.4829 / 0.4246 Acc: 51.5625 (33.6957)\n",
      "[12/25][332/782] Loss_D: -0.0686 (0.2167) Loss_G: 0.0064 (0.0890) D(x): 0.5465 D(G(z)): 0.4505 / 0.4007 Acc: 42.1875 (33.6966)\n",
      "[12/25][333/782] Loss_D: 0.0458 (0.2167) Loss_G: -0.1173 (0.0890) D(x): 0.4910 D(G(z)): 0.4610 / 0.4594 Acc: 40.6250 (33.6973)\n",
      "[12/25][334/782] Loss_D: 0.0004 (0.2166) Loss_G: -0.2215 (0.0889) D(x): 0.5396 D(G(z)): 0.4765 / 0.5052 Acc: 42.1875 (33.6982)\n",
      "[12/25][335/782] Loss_D: 0.1503 (0.2166) Loss_G: -0.0740 (0.0889) D(x): 0.5479 D(G(z)): 0.5320 / 0.4442 Acc: 34.3750 (33.6982)\n",
      "[12/25][336/782] Loss_D: 0.0159 (0.2166) Loss_G: -0.1797 (0.0889) D(x): 0.4915 D(G(z)): 0.4485 / 0.4862 Acc: 39.0625 (33.6988)\n",
      "[12/25][337/782] Loss_D: 0.0795 (0.2166) Loss_G: -0.0870 (0.0889) D(x): 0.5465 D(G(z)): 0.4697 / 0.4451 Acc: 26.5625 (33.6981)\n",
      "[12/25][338/782] Loss_D: -0.0460 (0.2166) Loss_G: 0.0212 (0.0889) D(x): 0.5255 D(G(z)): 0.4655 / 0.4019 Acc: 37.5000 (33.6984)\n",
      "[12/25][339/782] Loss_D: -0.0277 (0.2166) Loss_G: -0.0834 (0.0889) D(x): 0.5041 D(G(z)): 0.4639 / 0.4499 Acc: 45.3125 (33.6996)\n",
      "[12/25][340/782] Loss_D: 0.0231 (0.2165) Loss_G: -0.0653 (0.0888) D(x): 0.5397 D(G(z)): 0.4935 / 0.4412 Acc: 43.7500 (33.7007)\n",
      "[12/25][341/782] Loss_D: 0.0164 (0.2165) Loss_G: -0.0444 (0.0888) D(x): 0.4877 D(G(z)): 0.4508 / 0.4454 Acc: 39.0625 (33.7012)\n",
      "[12/25][342/782] Loss_D: -0.0820 (0.2165) Loss_G: -0.0390 (0.0888) D(x): 0.4849 D(G(z)): 0.4317 / 0.4182 Acc: 51.5625 (33.7031)\n",
      "[12/25][343/782] Loss_D: -0.0573 (0.2165) Loss_G: -0.1205 (0.0888) D(x): 0.5452 D(G(z)): 0.4711 / 0.4550 Acc: 43.7500 (33.7041)\n",
      "[12/25][344/782] Loss_D: -0.1397 (0.2164) Loss_G: -0.2028 (0.0888) D(x): 0.5551 D(G(z)): 0.4492 / 0.4703 Acc: 46.8750 (33.7054)\n",
      "[12/25][345/782] Loss_D: 0.0132 (0.2164) Loss_G: -0.2189 (0.0887) D(x): 0.5414 D(G(z)): 0.5346 / 0.4829 Acc: 50.0000 (33.7071)\n",
      "[12/25][346/782] Loss_D: -0.1526 (0.2164) Loss_G: -0.0415 (0.0887) D(x): 0.5821 D(G(z)): 0.4732 / 0.4055 Acc: 45.3125 (33.7083)\n",
      "[12/25][347/782] Loss_D: 0.1335 (0.2164) Loss_G: -0.1174 (0.0887) D(x): 0.5244 D(G(z)): 0.5307 / 0.4498 Acc: 42.1875 (33.7092)\n",
      "[12/25][348/782] Loss_D: -0.1646 (0.2163) Loss_G: -0.0463 (0.0887) D(x): 0.4657 D(G(z)): 0.3947 / 0.4122 Acc: 54.6875 (33.7113)\n",
      "[12/25][349/782] Loss_D: 0.1042 (0.2163) Loss_G: -0.1332 (0.0887) D(x): 0.4908 D(G(z)): 0.4695 / 0.4594 Acc: 43.7500 (33.7124)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/25][350/782] Loss_D: -0.0484 (0.2163) Loss_G: -0.2045 (0.0886) D(x): 0.5850 D(G(z)): 0.4993 / 0.4851 Acc: 39.0625 (33.7129)\n",
      "[12/25][351/782] Loss_D: -0.0989 (0.2162) Loss_G: 0.0101 (0.0886) D(x): 0.5729 D(G(z)): 0.5041 / 0.3965 Acc: 46.8750 (33.7143)\n",
      "[12/25][352/782] Loss_D: -0.0345 (0.2162) Loss_G: -0.0101 (0.0886) D(x): 0.5277 D(G(z)): 0.4350 / 0.3955 Acc: 34.3750 (33.7143)\n",
      "[12/25][353/782] Loss_D: -0.2160 (0.2162) Loss_G: -0.2175 (0.0886) D(x): 0.5284 D(G(z)): 0.4292 / 0.4781 Acc: 53.1250 (33.7163)\n",
      "[12/25][354/782] Loss_D: -0.1280 (0.2161) Loss_G: -0.1526 (0.0886) D(x): 0.5420 D(G(z)): 0.4526 / 0.4604 Acc: 40.6250 (33.7170)\n",
      "[12/25][355/782] Loss_D: -0.0895 (0.2161) Loss_G: -0.1191 (0.0885) D(x): 0.5148 D(G(z)): 0.4135 / 0.4505 Acc: 40.6250 (33.7178)\n",
      "[12/25][356/782] Loss_D: -0.3175 (0.2161) Loss_G: -0.0818 (0.0885) D(x): 0.5815 D(G(z)): 0.4193 / 0.4250 Acc: 50.0000 (33.7194)\n",
      "[12/25][357/782] Loss_D: -0.1152 (0.2160) Loss_G: -0.2270 (0.0885) D(x): 0.5385 D(G(z)): 0.4560 / 0.5116 Acc: 46.8750 (33.7208)\n",
      "[12/25][358/782] Loss_D: -0.0288 (0.2160) Loss_G: -0.0427 (0.0885) D(x): 0.5586 D(G(z)): 0.4489 / 0.4182 Acc: 35.9375 (33.7210)\n",
      "[12/25][359/782] Loss_D: -0.1791 (0.2160) Loss_G: -0.1460 (0.0884) D(x): 0.5541 D(G(z)): 0.4391 / 0.4591 Acc: 45.3125 (33.7222)\n",
      "[12/25][360/782] Loss_D: 0.1048 (0.2159) Loss_G: -0.3067 (0.0884) D(x): 0.4513 D(G(z)): 0.4910 / 0.5460 Acc: 56.2500 (33.7245)\n",
      "[12/25][361/782] Loss_D: 0.0023 (0.2159) Loss_G: 0.0271 (0.0884) D(x): 0.5578 D(G(z)): 0.5207 / 0.4052 Acc: 48.4375 (33.7260)\n",
      "[12/25][362/782] Loss_D: 0.0890 (0.2159) Loss_G: -0.1972 (0.0884) D(x): 0.4865 D(G(z)): 0.5044 / 0.4767 Acc: 43.7500 (33.7270)\n",
      "[12/25][363/782] Loss_D: -0.1595 (0.2159) Loss_G: -0.2243 (0.0883) D(x): 0.5239 D(G(z)): 0.5071 / 0.4909 Acc: 60.9375 (33.7298)\n",
      "[12/25][364/782] Loss_D: 0.1300 (0.2159) Loss_G: -0.1393 (0.0883) D(x): 0.5089 D(G(z)): 0.4950 / 0.4787 Acc: 32.8125 (33.7297)\n",
      "[12/25][365/782] Loss_D: 0.1389 (0.2158) Loss_G: -0.2270 (0.0883) D(x): 0.5398 D(G(z)): 0.5507 / 0.4968 Acc: 39.0625 (33.7303)\n",
      "[12/25][366/782] Loss_D: 0.0195 (0.2158) Loss_G: -0.0064 (0.0883) D(x): 0.5365 D(G(z)): 0.4961 / 0.4311 Acc: 42.1875 (33.7312)\n",
      "[12/25][367/782] Loss_D: 0.0602 (0.2158) Loss_G: -0.1629 (0.0882) D(x): 0.5083 D(G(z)): 0.5101 / 0.4588 Acc: 42.1875 (33.7320)\n",
      "[12/25][368/782] Loss_D: 0.0945 (0.2158) Loss_G: -0.1670 (0.0882) D(x): 0.4319 D(G(z)): 0.4328 / 0.4573 Acc: 37.5000 (33.7324)\n",
      "[12/25][369/782] Loss_D: -0.1307 (0.2158) Loss_G: -0.0683 (0.0882) D(x): 0.5563 D(G(z)): 0.4692 / 0.4270 Acc: 51.5625 (33.7342)\n",
      "[12/25][370/782] Loss_D: -0.0574 (0.2157) Loss_G: -0.1590 (0.0882) D(x): 0.5375 D(G(z)): 0.4975 / 0.4697 Acc: 46.8750 (33.7356)\n",
      "[12/25][371/782] Loss_D: -0.1751 (0.2157) Loss_G: 0.0195 (0.0882) D(x): 0.5777 D(G(z)): 0.4474 / 0.3997 Acc: 45.3125 (33.7368)\n",
      "[12/25][372/782] Loss_D: -0.0980 (0.2157) Loss_G: 0.0484 (0.0882) D(x): 0.4921 D(G(z)): 0.4134 / 0.3875 Acc: 50.0000 (33.7384)\n",
      "[12/25][373/782] Loss_D: -0.1129 (0.2156) Loss_G: -0.0940 (0.0881) D(x): 0.5338 D(G(z)): 0.4289 / 0.4328 Acc: 39.0625 (33.7390)\n",
      "[12/25][374/782] Loss_D: -0.0191 (0.2156) Loss_G: 0.0257 (0.0881) D(x): 0.5789 D(G(z)): 0.4897 / 0.4108 Acc: 32.8125 (33.7389)\n",
      "[12/25][375/782] Loss_D: -0.0730 (0.2156) Loss_G: -0.0742 (0.0881) D(x): 0.5669 D(G(z)): 0.4620 / 0.4453 Acc: 43.7500 (33.7399)\n",
      "[12/25][376/782] Loss_D: -0.1687 (0.2155) Loss_G: -0.1222 (0.0881) D(x): 0.5391 D(G(z)): 0.4081 / 0.4592 Acc: 43.7500 (33.7409)\n",
      "[12/25][377/782] Loss_D: -0.1609 (0.2155) Loss_G: -0.1330 (0.0881) D(x): 0.5778 D(G(z)): 0.4400 / 0.4533 Acc: 40.6250 (33.7416)\n",
      "[12/25][378/782] Loss_D: -0.0353 (0.2155) Loss_G: -0.1768 (0.0881) D(x): 0.5405 D(G(z)): 0.4907 / 0.4737 Acc: 42.1875 (33.7425)\n",
      "[12/25][379/782] Loss_D: 0.0268 (0.2155) Loss_G: -0.0925 (0.0880) D(x): 0.5322 D(G(z)): 0.4461 / 0.4383 Acc: 32.8125 (33.7424)\n",
      "[12/25][380/782] Loss_D: -0.1389 (0.2154) Loss_G: -0.0914 (0.0880) D(x): 0.5155 D(G(z)): 0.4474 / 0.4498 Acc: 50.0000 (33.7441)\n",
      "[12/25][381/782] Loss_D: -0.0253 (0.2154) Loss_G: -0.1887 (0.0880) D(x): 0.5393 D(G(z)): 0.5102 / 0.4688 Acc: 48.4375 (33.7456)\n",
      "[12/25][382/782] Loss_D: -0.0343 (0.2154) Loss_G: -0.0664 (0.0880) D(x): 0.5457 D(G(z)): 0.5015 / 0.4286 Acc: 45.3125 (33.7468)\n",
      "[12/25][383/782] Loss_D: 0.0674 (0.2154) Loss_G: -0.0825 (0.0880) D(x): 0.4754 D(G(z)): 0.4540 / 0.4429 Acc: 35.9375 (33.7470)\n",
      "[12/25][384/782] Loss_D: 0.1049 (0.2153) Loss_G: -0.0738 (0.0879) D(x): 0.4622 D(G(z)): 0.4478 / 0.4424 Acc: 40.6250 (33.7477)\n",
      "[12/25][385/782] Loss_D: -0.1372 (0.2153) Loss_G: -0.1785 (0.0879) D(x): 0.5439 D(G(z)): 0.4721 / 0.4886 Acc: 51.5625 (33.7495)\n",
      "[12/25][386/782] Loss_D: -0.1389 (0.2153) Loss_G: -0.0809 (0.0879) D(x): 0.5750 D(G(z)): 0.4874 / 0.4496 Acc: 48.4375 (33.7510)\n",
      "[12/25][387/782] Loss_D: -0.0598 (0.2152) Loss_G: -0.0708 (0.0879) D(x): 0.5588 D(G(z)): 0.5232 / 0.4355 Acc: 46.8750 (33.7524)\n",
      "[12/25][388/782] Loss_D: -0.1839 (0.2152) Loss_G: -0.0979 (0.0879) D(x): 0.5172 D(G(z)): 0.4289 / 0.4387 Acc: 56.2500 (33.7547)\n",
      "[12/25][389/782] Loss_D: 0.0740 (0.2152) Loss_G: 0.0296 (0.0879) D(x): 0.5117 D(G(z)): 0.4925 / 0.4110 Acc: 40.6250 (33.7554)\n",
      "[12/25][390/782] Loss_D: -0.0020 (0.2152) Loss_G: -0.2209 (0.0878) D(x): 0.4354 D(G(z)): 0.4209 / 0.5013 Acc: 54.6875 (33.7575)\n",
      "[12/25][391/782] Loss_D: -0.0642 (0.2151) Loss_G: -0.1545 (0.0878) D(x): 0.5629 D(G(z)): 0.4921 / 0.4647 Acc: 45.3125 (33.7587)\n",
      "[12/25][392/782] Loss_D: 0.0148 (0.2151) Loss_G: -0.2069 (0.0878) D(x): 0.5138 D(G(z)): 0.4591 / 0.5059 Acc: 42.1875 (33.7596)\n",
      "[12/25][393/782] Loss_D: -0.1905 (0.2151) Loss_G: -0.1393 (0.0877) D(x): 0.5588 D(G(z)): 0.4400 / 0.4601 Acc: 43.7500 (33.7606)\n",
      "[12/25][394/782] Loss_D: -0.0863 (0.2150) Loss_G: -0.0886 (0.0877) D(x): 0.5278 D(G(z)): 0.4592 / 0.4424 Acc: 48.4375 (33.7621)\n",
      "[12/25][395/782] Loss_D: -0.0184 (0.2150) Loss_G: -0.0782 (0.0877) D(x): 0.5258 D(G(z)): 0.4448 / 0.4375 Acc: 39.0625 (33.7626)\n",
      "[12/25][396/782] Loss_D: -0.3188 (0.2150) Loss_G: -0.0586 (0.0877) D(x): 0.5701 D(G(z)): 0.4496 / 0.4374 Acc: 62.5000 (33.7656)\n",
      "[12/25][397/782] Loss_D: -0.2791 (0.2149) Loss_G: -0.1258 (0.0877) D(x): 0.5371 D(G(z)): 0.4105 / 0.4564 Acc: 51.5625 (33.7674)\n",
      "[12/25][398/782] Loss_D: -0.0623 (0.2149) Loss_G: -0.1693 (0.0876) D(x): 0.5618 D(G(z)): 0.4802 / 0.4575 Acc: 40.6250 (33.7681)\n",
      "[12/25][399/782] Loss_D: -0.0917 (0.2149) Loss_G: -0.1513 (0.0876) D(x): 0.5168 D(G(z)): 0.4627 / 0.4522 Acc: 48.4375 (33.7696)\n",
      "[12/25][400/782] Loss_D: -0.2873 (0.2148) Loss_G: -0.1360 (0.0876) D(x): 0.5409 D(G(z)): 0.4232 / 0.4567 Acc: 57.8125 (33.7720)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[12/25][401/782] Loss_D: -0.1561 (0.2148) Loss_G: -0.0042 (0.0876) D(x): 0.5503 D(G(z)): 0.4885 / 0.4242 Acc: 53.1250 (33.7740)\n",
      "[12/25][402/782] Loss_D: -0.0986 (0.2147) Loss_G: -0.1266 (0.0876) D(x): 0.5147 D(G(z)): 0.4646 / 0.4521 Acc: 48.4375 (33.7755)\n",
      "[12/25][403/782] Loss_D: -0.1779 (0.2147) Loss_G: -0.0888 (0.0875) D(x): 0.5556 D(G(z)): 0.4466 / 0.4364 Acc: 42.1875 (33.7764)\n",
      "[12/25][404/782] Loss_D: -0.1201 (0.2147) Loss_G: -0.1009 (0.0875) D(x): 0.5273 D(G(z)): 0.4601 / 0.4407 Acc: 51.5625 (33.7782)\n",
      "[12/25][405/782] Loss_D: -0.1561 (0.2146) Loss_G: -0.1634 (0.0875) D(x): 0.5076 D(G(z)): 0.4488 / 0.4630 Acc: 54.6875 (33.7803)\n",
      "[12/25][406/782] Loss_D: -0.0235 (0.2146) Loss_G: -0.1358 (0.0875) D(x): 0.5654 D(G(z)): 0.5021 / 0.4606 Acc: 39.0625 (33.7809)\n",
      "[12/25][407/782] Loss_D: -0.0633 (0.2146) Loss_G: -0.0934 (0.0875) D(x): 0.5193 D(G(z)): 0.4481 / 0.4556 Acc: 46.8750 (33.7822)\n",
      "[12/25][408/782] Loss_D: -0.0314 (0.2145) Loss_G: -0.0717 (0.0874) D(x): 0.5608 D(G(z)): 0.5280 / 0.4439 Acc: 48.4375 (33.7837)\n",
      "[12/25][409/782] Loss_D: -0.1626 (0.2145) Loss_G: 0.0100 (0.0874) D(x): 0.5251 D(G(z)): 0.4122 / 0.3956 Acc: 43.7500 (33.7847)\n",
      "[12/25][410/782] Loss_D: -0.1849 (0.2145) Loss_G: 0.0592 (0.0874) D(x): 0.5682 D(G(z)): 0.4451 / 0.3792 Acc: 43.7500 (33.7857)\n",
      "[12/25][411/782] Loss_D: -0.1127 (0.2144) Loss_G: -0.0353 (0.0874) D(x): 0.5175 D(G(z)): 0.4285 / 0.4235 Acc: 43.7500 (33.7867)\n",
      "[12/25][412/782] Loss_D: -0.0919 (0.2144) Loss_G: -0.1686 (0.0874) D(x): 0.5028 D(G(z)): 0.4277 / 0.4710 Acc: 43.7500 (33.7878)\n",
      "[12/25][413/782] Loss_D: 0.0505 (0.2144) Loss_G: -0.2291 (0.0874) D(x): 0.5806 D(G(z)): 0.5040 / 0.4980 Acc: 31.2500 (33.7875)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/25][414/782] Loss_D: -0.1108 (0.2143) Loss_G: -0.0467 (0.0873) D(x): 0.5126 D(G(z)): 0.4643 / 0.4386 Acc: 53.1250 (33.7895)\n",
      "[12/25][415/782] Loss_D: -0.0915 (0.2143) Loss_G: -0.2259 (0.0873) D(x): 0.5587 D(G(z)): 0.4855 / 0.5135 Acc: 42.1875 (33.7903)\n",
      "[12/25][416/782] Loss_D: 0.1088 (0.2143) Loss_G: -0.0659 (0.0873) D(x): 0.5208 D(G(z)): 0.5114 / 0.4342 Acc: 40.6250 (33.7910)\n",
      "[12/25][417/782] Loss_D: 0.0439 (0.2143) Loss_G: -0.0269 (0.0873) D(x): 0.4761 D(G(z)): 0.4663 / 0.4260 Acc: 45.3125 (33.7922)\n",
      "[12/25][418/782] Loss_D: -0.1310 (0.2143) Loss_G: -0.0709 (0.0873) D(x): 0.5700 D(G(z)): 0.4911 / 0.4420 Acc: 46.8750 (33.7935)\n",
      "[12/25][419/782] Loss_D: -0.0960 (0.2142) Loss_G: -0.1561 (0.0872) D(x): 0.5551 D(G(z)): 0.4893 / 0.4644 Acc: 46.8750 (33.7949)\n",
      "[12/25][420/782] Loss_D: 0.0759 (0.2142) Loss_G: 0.0090 (0.0872) D(x): 0.5048 D(G(z)): 0.4536 / 0.4115 Acc: 32.8125 (33.7948)\n",
      "[12/25][421/782] Loss_D: 0.1919 (0.2142) Loss_G: -0.1504 (0.0872) D(x): 0.4426 D(G(z)): 0.4590 / 0.4749 Acc: 37.5000 (33.7952)\n",
      "[12/25][422/782] Loss_D: -0.0238 (0.2142) Loss_G: -0.1595 (0.0872) D(x): 0.5936 D(G(z)): 0.4845 / 0.4711 Acc: 31.2500 (33.7949)\n",
      "[12/25][423/782] Loss_D: 0.0271 (0.2142) Loss_G: -0.1055 (0.0872) D(x): 0.5119 D(G(z)): 0.4902 / 0.4467 Acc: 40.6250 (33.7956)\n",
      "[12/25][424/782] Loss_D: 0.0500 (0.2141) Loss_G: -0.0844 (0.0872) D(x): 0.4576 D(G(z)): 0.4601 / 0.4381 Acc: 45.3125 (33.7968)\n",
      "[12/25][425/782] Loss_D: -0.0797 (0.2141) Loss_G: -0.0125 (0.0871) D(x): 0.5975 D(G(z)): 0.4817 / 0.4212 Acc: 34.3750 (33.7968)\n",
      "[12/25][426/782] Loss_D: 0.1237 (0.2141) Loss_G: -0.1590 (0.0871) D(x): 0.4455 D(G(z)): 0.4207 / 0.4905 Acc: 34.3750 (33.7969)\n",
      "[12/25][427/782] Loss_D: -0.0289 (0.2141) Loss_G: -0.1468 (0.0871) D(x): 0.5272 D(G(z)): 0.4704 / 0.4606 Acc: 42.1875 (33.7977)\n",
      "[12/25][428/782] Loss_D: -0.0334 (0.2141) Loss_G: -0.2699 (0.0871) D(x): 0.5213 D(G(z)): 0.5074 / 0.5375 Acc: 50.0000 (33.7994)\n",
      "[12/25][429/782] Loss_D: -0.2728 (0.2140) Loss_G: -0.0442 (0.0870) D(x): 0.5961 D(G(z)): 0.4619 / 0.4163 Acc: 53.1250 (33.8014)\n",
      "[12/25][430/782] Loss_D: -0.0814 (0.2140) Loss_G: -0.0339 (0.0870) D(x): 0.5095 D(G(z)): 0.4241 / 0.4372 Acc: 43.7500 (33.8024)\n",
      "[12/25][431/782] Loss_D: -0.0835 (0.2139) Loss_G: -0.0881 (0.0870) D(x): 0.5537 D(G(z)): 0.4769 / 0.4389 Acc: 43.7500 (33.8034)\n",
      "[12/25][432/782] Loss_D: -0.1674 (0.2139) Loss_G: -0.0353 (0.0870) D(x): 0.5929 D(G(z)): 0.4836 / 0.4248 Acc: 48.4375 (33.8049)\n",
      "[12/25][433/782] Loss_D: -0.0311 (0.2139) Loss_G: -0.0769 (0.0870) D(x): 0.4448 D(G(z)): 0.3898 / 0.4245 Acc: 42.1875 (33.8057)\n",
      "[12/25][434/782] Loss_D: -0.0669 (0.2139) Loss_G: -0.0754 (0.0870) D(x): 0.5950 D(G(z)): 0.5200 / 0.4510 Acc: 45.3125 (33.8069)\n",
      "[12/25][435/782] Loss_D: -0.2326 (0.2138) Loss_G: -0.0845 (0.0870) D(x): 0.5493 D(G(z)): 0.4521 / 0.4292 Acc: 54.6875 (33.8090)\n",
      "[12/25][436/782] Loss_D: -0.2476 (0.2138) Loss_G: -0.1193 (0.0869) D(x): 0.5159 D(G(z)): 0.3977 / 0.4422 Acc: 54.6875 (33.8112)\n",
      "[12/25][437/782] Loss_D: -0.1730 (0.2137) Loss_G: -0.0855 (0.0869) D(x): 0.5803 D(G(z)): 0.4701 / 0.4498 Acc: 48.4375 (33.8126)\n",
      "[12/25][438/782] Loss_D: -0.1011 (0.2137) Loss_G: -0.2470 (0.0869) D(x): 0.5316 D(G(z)): 0.4534 / 0.5049 Acc: 46.8750 (33.8140)\n",
      "[12/25][439/782] Loss_D: -0.0210 (0.2137) Loss_G: -0.1412 (0.0869) D(x): 0.5043 D(G(z)): 0.4363 / 0.4586 Acc: 42.1875 (33.8148)\n",
      "[12/25][440/782] Loss_D: -0.1931 (0.2136) Loss_G: -0.1855 (0.0868) D(x): 0.5324 D(G(z)): 0.4531 / 0.4897 Acc: 53.1250 (33.8168)\n",
      "[12/25][441/782] Loss_D: -0.1867 (0.2136) Loss_G: -0.2519 (0.0868) D(x): 0.5358 D(G(z)): 0.4351 / 0.5034 Acc: 50.0000 (33.8184)\n",
      "[12/25][442/782] Loss_D: 0.0598 (0.2136) Loss_G: -0.1155 (0.0868) D(x): 0.5742 D(G(z)): 0.5520 / 0.4421 Acc: 42.1875 (33.8193)\n",
      "[12/25][443/782] Loss_D: -0.1545 (0.2135) Loss_G: -0.0444 (0.0868) D(x): 0.5870 D(G(z)): 0.4648 / 0.4403 Acc: 40.6250 (33.8200)\n",
      "[12/25][444/782] Loss_D: -0.2114 (0.2135) Loss_G: -0.0398 (0.0867) D(x): 0.5510 D(G(z)): 0.4914 / 0.4269 Acc: 65.6250 (33.8232)\n",
      "[12/25][445/782] Loss_D: -0.0749 (0.2135) Loss_G: -0.0459 (0.0867) D(x): 0.5007 D(G(z)): 0.4693 / 0.4292 Acc: 51.5625 (33.8250)\n",
      "[12/25][446/782] Loss_D: 0.0516 (0.2134) Loss_G: -0.0396 (0.0867) D(x): 0.4423 D(G(z)): 0.4112 / 0.4245 Acc: 40.6250 (33.8257)\n",
      "[12/25][447/782] Loss_D: 0.1042 (0.2134) Loss_G: -0.1183 (0.0867) D(x): 0.5178 D(G(z)): 0.4998 / 0.4622 Acc: 35.9375 (33.8259)\n",
      "[12/25][448/782] Loss_D: -0.1798 (0.2134) Loss_G: -0.1612 (0.0867) D(x): 0.5305 D(G(z)): 0.4257 / 0.4590 Acc: 50.0000 (33.8276)\n",
      "[12/25][449/782] Loss_D: -0.1178 (0.2134) Loss_G: -0.1717 (0.0866) D(x): 0.5343 D(G(z)): 0.4116 / 0.4584 Acc: 40.6250 (33.8283)\n",
      "[12/25][450/782] Loss_D: -0.0931 (0.2133) Loss_G: -0.2469 (0.0866) D(x): 0.5933 D(G(z)): 0.4879 / 0.5085 Acc: 39.0625 (33.8288)\n",
      "[12/25][451/782] Loss_D: -0.1484 (0.2133) Loss_G: -0.1262 (0.0866) D(x): 0.5830 D(G(z)): 0.4761 / 0.4890 Acc: 48.4375 (33.8303)\n",
      "[12/25][452/782] Loss_D: -0.0545 (0.2133) Loss_G: -0.0713 (0.0866) D(x): 0.5170 D(G(z)): 0.4204 / 0.4277 Acc: 39.0625 (33.8308)\n",
      "[12/25][453/782] Loss_D: 0.0658 (0.2132) Loss_G: -0.1085 (0.0866) D(x): 0.5392 D(G(z)): 0.5285 / 0.4403 Acc: 43.7500 (33.8318)\n",
      "[12/25][454/782] Loss_D: -0.2154 (0.2132) Loss_G: -0.1151 (0.0865) D(x): 0.5441 D(G(z)): 0.4378 / 0.4518 Acc: 53.1250 (33.8338)\n",
      "[12/25][455/782] Loss_D: -0.2183 (0.2132) Loss_G: -0.0317 (0.0865) D(x): 0.5839 D(G(z)): 0.4897 / 0.4191 Acc: 57.8125 (33.8362)\n",
      "[12/25][456/782] Loss_D: -0.0724 (0.2131) Loss_G: -0.0749 (0.0865) D(x): 0.5458 D(G(z)): 0.4828 / 0.4243 Acc: 43.7500 (33.8372)\n",
      "[12/25][457/782] Loss_D: -0.0013 (0.2131) Loss_G: -0.1965 (0.0865) D(x): 0.4543 D(G(z)): 0.3978 / 0.4746 Acc: 42.1875 (33.8381)\n",
      "[12/25][458/782] Loss_D: -0.0615 (0.2131) Loss_G: -0.1257 (0.0865) D(x): 0.5877 D(G(z)): 0.5104 / 0.4476 Acc: 40.6250 (33.8388)\n",
      "[12/25][459/782] Loss_D: -0.0103 (0.2131) Loss_G: -0.1868 (0.0864) D(x): 0.4992 D(G(z)): 0.4323 / 0.4878 Acc: 45.3125 (33.8399)\n",
      "[12/25][460/782] Loss_D: -0.1419 (0.2130) Loss_G: -0.1380 (0.0864) D(x): 0.5354 D(G(z)): 0.4646 / 0.4625 Acc: 50.0000 (33.8416)\n",
      "[12/25][461/782] Loss_D: -0.0675 (0.2130) Loss_G: 0.0827 (0.0864) D(x): 0.5679 D(G(z)): 0.4821 / 0.3759 Acc: 35.9375 (33.8418)\n",
      "[12/25][462/782] Loss_D: -0.0675 (0.2130) Loss_G: -0.1077 (0.0864) D(x): 0.5161 D(G(z)): 0.4563 / 0.4443 Acc: 46.8750 (33.8431)\n",
      "[12/25][463/782] Loss_D: -0.1616 (0.2129) Loss_G: -0.0583 (0.0864) D(x): 0.4875 D(G(z)): 0.4049 / 0.4313 Acc: 48.4375 (33.8446)\n",
      "[12/25][464/782] Loss_D: -0.1630 (0.2129) Loss_G: -0.1560 (0.0863) D(x): 0.5566 D(G(z)): 0.4554 / 0.4633 Acc: 46.8750 (33.8459)\n",
      "[12/25][465/782] Loss_D: -0.1675 (0.2129) Loss_G: -0.1263 (0.0863) D(x): 0.5687 D(G(z)): 0.4246 / 0.4640 Acc: 39.0625 (33.8464)\n",
      "[12/25][466/782] Loss_D: -0.3016 (0.2128) Loss_G: -0.1787 (0.0863) D(x): 0.5311 D(G(z)): 0.4161 / 0.4897 Acc: 59.3750 (33.8490)\n",
      "[12/25][467/782] Loss_D: 0.0651 (0.2128) Loss_G: -0.0495 (0.0863) D(x): 0.5376 D(G(z)): 0.4947 / 0.4283 Acc: 37.5000 (33.8494)\n",
      "[12/25][468/782] Loss_D: -0.1623 (0.2127) Loss_G: 0.1125 (0.0863) D(x): 0.5272 D(G(z)): 0.4371 / 0.3676 Acc: 53.1250 (33.8514)\n",
      "[12/25][469/782] Loss_D: -0.2027 (0.2127) Loss_G: -0.0163 (0.0863) D(x): 0.5338 D(G(z)): 0.4246 / 0.4116 Acc: 51.5625 (33.8532)\n",
      "[12/25][470/782] Loss_D: -0.0544 (0.2127) Loss_G: -0.1575 (0.0863) D(x): 0.5514 D(G(z)): 0.4901 / 0.4614 Acc: 40.6250 (33.8538)\n",
      "[12/25][471/782] Loss_D: 0.1314 (0.2127) Loss_G: -0.0550 (0.0862) D(x): 0.5162 D(G(z)): 0.5130 / 0.4354 Acc: 40.6250 (33.8545)\n",
      "[12/25][472/782] Loss_D: -0.1433 (0.2126) Loss_G: -0.0745 (0.0862) D(x): 0.5122 D(G(z)): 0.4273 / 0.4456 Acc: 51.5625 (33.8563)\n",
      "[12/25][473/782] Loss_D: -0.1058 (0.2126) Loss_G: -0.1608 (0.0862) D(x): 0.5819 D(G(z)): 0.4842 / 0.4731 Acc: 40.6250 (33.8570)\n",
      "[12/25][474/782] Loss_D: -0.0761 (0.2126) Loss_G: 0.0473 (0.0862) D(x): 0.5421 D(G(z)): 0.4808 / 0.3856 Acc: 46.8750 (33.8583)\n",
      "[12/25][475/782] Loss_D: -0.0621 (0.2125) Loss_G: 0.0535 (0.0862) D(x): 0.4801 D(G(z)): 0.4207 / 0.4061 Acc: 46.8750 (33.8597)\n",
      "[12/25][476/782] Loss_D: 0.0589 (0.2125) Loss_G: -0.2415 (0.0862) D(x): 0.5274 D(G(z)): 0.4677 / 0.4997 Acc: 31.2500 (33.8594)\n",
      "[12/25][477/782] Loss_D: 0.1582 (0.2125) Loss_G: -0.0888 (0.0861) D(x): 0.5022 D(G(z)): 0.4974 / 0.4530 Acc: 39.0625 (33.8599)\n",
      "[12/25][478/782] Loss_D: -0.1599 (0.2125) Loss_G: -0.2138 (0.0861) D(x): 0.5469 D(G(z)): 0.4885 / 0.4892 Acc: 54.6875 (33.8620)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/25][479/782] Loss_D: -0.0560 (0.2125) Loss_G: -0.0232 (0.0861) D(x): 0.5901 D(G(z)): 0.5028 / 0.4235 Acc: 46.8750 (33.8634)\n",
      "[12/25][480/782] Loss_D: -0.1553 (0.2124) Loss_G: -0.1135 (0.0861) D(x): 0.5213 D(G(z)): 0.4424 / 0.4396 Acc: 46.8750 (33.8647)\n",
      "[12/25][481/782] Loss_D: -0.1321 (0.2124) Loss_G: -0.1017 (0.0861) D(x): 0.5356 D(G(z)): 0.4513 / 0.4424 Acc: 45.3125 (33.8658)\n",
      "[12/25][482/782] Loss_D: -0.0619 (0.2124) Loss_G: -0.0571 (0.0860) D(x): 0.5298 D(G(z)): 0.4552 / 0.4280 Acc: 46.8750 (33.8672)\n",
      "[12/25][483/782] Loss_D: -0.1103 (0.2123) Loss_G: -0.0966 (0.0860) D(x): 0.4922 D(G(z)): 0.4283 / 0.4597 Acc: 50.0000 (33.8688)\n",
      "[12/25][484/782] Loss_D: 0.0666 (0.2123) Loss_G: -0.1042 (0.0860) D(x): 0.5626 D(G(z)): 0.5581 / 0.4531 Acc: 42.1875 (33.8696)\n",
      "[12/25][485/782] Loss_D: 0.1253 (0.2123) Loss_G: -0.1863 (0.0860) D(x): 0.4528 D(G(z)): 0.5098 / 0.4759 Acc: 51.5625 (33.8714)\n",
      "[12/25][486/782] Loss_D: -0.2950 (0.2122) Loss_G: -0.0523 (0.0860) D(x): 0.5901 D(G(z)): 0.4247 / 0.4326 Acc: 48.4375 (33.8729)\n",
      "[12/25][487/782] Loss_D: 0.1127 (0.2122) Loss_G: -0.1544 (0.0859) D(x): 0.4795 D(G(z)): 0.4254 / 0.4532 Acc: 32.8125 (33.8728)\n",
      "[12/25][488/782] Loss_D: -0.2149 (0.2122) Loss_G: -0.0311 (0.0859) D(x): 0.5461 D(G(z)): 0.4072 / 0.4281 Acc: 43.7500 (33.8738)\n",
      "[12/25][489/782] Loss_D: 0.0591 (0.2122) Loss_G: -0.1065 (0.0859) D(x): 0.5244 D(G(z)): 0.5187 / 0.4367 Acc: 48.4375 (33.8753)\n",
      "[12/25][490/782] Loss_D: -0.1114 (0.2121) Loss_G: -0.0791 (0.0859) D(x): 0.5582 D(G(z)): 0.4590 / 0.4339 Acc: 45.3125 (33.8764)\n",
      "[12/25][491/782] Loss_D: -0.1340 (0.2121) Loss_G: 0.0639 (0.0859) D(x): 0.5673 D(G(z)): 0.4487 / 0.4010 Acc: 43.7500 (33.8774)\n",
      "[12/25][492/782] Loss_D: -0.0208 (0.2121) Loss_G: -0.2100 (0.0859) D(x): 0.4844 D(G(z)): 0.4158 / 0.4809 Acc: 40.6250 (33.8781)\n",
      "[12/25][493/782] Loss_D: -0.2088 (0.2120) Loss_G: -0.2009 (0.0858) D(x): 0.5539 D(G(z)): 0.4558 / 0.4912 Acc: 51.5625 (33.8799)\n",
      "[12/25][494/782] Loss_D: -0.0307 (0.2120) Loss_G: -0.1377 (0.0858) D(x): 0.5258 D(G(z)): 0.5016 / 0.4506 Acc: 48.4375 (33.8814)\n",
      "[12/25][495/782] Loss_D: 0.0275 (0.2120) Loss_G: -0.0686 (0.0858) D(x): 0.5544 D(G(z)): 0.5354 / 0.4230 Acc: 45.3125 (33.8825)\n",
      "[12/25][496/782] Loss_D: 0.1932 (0.2120) Loss_G: -0.2485 (0.0858) D(x): 0.5142 D(G(z)): 0.5339 / 0.5009 Acc: 32.8125 (33.8824)\n",
      "[12/25][497/782] Loss_D: -0.3286 (0.2119) Loss_G: -0.1178 (0.0857) D(x): 0.5941 D(G(z)): 0.3940 / 0.4471 Acc: 43.7500 (33.8834)\n",
      "[12/25][498/782] Loss_D: -0.1686 (0.2119) Loss_G: -0.0258 (0.0857) D(x): 0.5238 D(G(z)): 0.3876 / 0.4084 Acc: 42.1875 (33.8843)\n",
      "[12/25][499/782] Loss_D: -0.1048 (0.2119) Loss_G: -0.1197 (0.0857) D(x): 0.5909 D(G(z)): 0.4840 / 0.4474 Acc: 42.1875 (33.8851)\n",
      "[12/25][500/782] Loss_D: -0.0060 (0.2119) Loss_G: -0.0183 (0.0857) D(x): 0.5296 D(G(z)): 0.4776 / 0.4109 Acc: 34.3750 (33.8851)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[12/25][501/782] Loss_D: -0.1024 (0.2118) Loss_G: -0.1250 (0.0857) D(x): 0.5293 D(G(z)): 0.4627 / 0.4556 Acc: 43.7500 (33.8861)\n",
      "[12/25][502/782] Loss_D: -0.1102 (0.2118) Loss_G: -0.3058 (0.0856) D(x): 0.5452 D(G(z)): 0.4642 / 0.5350 Acc: 45.3125 (33.8873)\n",
      "[12/25][503/782] Loss_D: 0.1613 (0.2118) Loss_G: -0.0916 (0.0856) D(x): 0.4995 D(G(z)): 0.5114 / 0.4373 Acc: 42.1875 (33.8881)\n",
      "[12/25][504/782] Loss_D: 0.0251 (0.2118) Loss_G: 0.0086 (0.0856) D(x): 0.5292 D(G(z)): 0.5037 / 0.3943 Acc: 42.1875 (33.8890)\n",
      "[12/25][505/782] Loss_D: -0.0083 (0.2117) Loss_G: -0.1460 (0.0856) D(x): 0.5169 D(G(z)): 0.4698 / 0.4557 Acc: 42.1875 (33.8898)\n",
      "[12/25][506/782] Loss_D: -0.0742 (0.2117) Loss_G: -0.2950 (0.0855) D(x): 0.5023 D(G(z)): 0.4555 / 0.5173 Acc: 50.0000 (33.8914)\n",
      "[12/25][507/782] Loss_D: -0.0584 (0.2117) Loss_G: -0.2095 (0.0855) D(x): 0.5437 D(G(z)): 0.5059 / 0.4740 Acc: 50.0000 (33.8931)\n",
      "[12/25][508/782] Loss_D: -0.2710 (0.2116) Loss_G: -0.0713 (0.0855) D(x): 0.6074 D(G(z)): 0.4583 / 0.4241 Acc: 45.3125 (33.8942)\n",
      "[12/25][509/782] Loss_D: -0.0921 (0.2116) Loss_G: 0.0243 (0.0855) D(x): 0.5566 D(G(z)): 0.4802 / 0.4036 Acc: 43.7500 (33.8952)\n",
      "[12/25][510/782] Loss_D: -0.1197 (0.2116) Loss_G: -0.0324 (0.0855) D(x): 0.5057 D(G(z)): 0.4778 / 0.4135 Acc: 53.1250 (33.8972)\n",
      "[12/25][511/782] Loss_D: -0.1181 (0.2115) Loss_G: -0.1374 (0.0855) D(x): 0.4673 D(G(z)): 0.4075 / 0.4714 Acc: 50.0000 (33.8988)\n",
      "[12/25][512/782] Loss_D: 0.0179 (0.2115) Loss_G: -0.2101 (0.0854) D(x): 0.4674 D(G(z)): 0.4501 / 0.4868 Acc: 45.3125 (33.9000)\n",
      "[12/25][513/782] Loss_D: 0.1195 (0.2115) Loss_G: -0.1055 (0.0854) D(x): 0.5139 D(G(z)): 0.5110 / 0.4529 Acc: 40.6250 (33.9006)\n",
      "[12/25][514/782] Loss_D: -0.0833 (0.2115) Loss_G: -0.2013 (0.0854) D(x): 0.5164 D(G(z)): 0.4783 / 0.4856 Acc: 51.5625 (33.9024)\n",
      "[12/25][515/782] Loss_D: 0.0868 (0.2115) Loss_G: -0.1138 (0.0854) D(x): 0.5594 D(G(z)): 0.5131 / 0.4513 Acc: 34.3750 (33.9025)\n",
      "[12/25][516/782] Loss_D: -0.0141 (0.2114) Loss_G: -0.2179 (0.0853) D(x): 0.4676 D(G(z)): 0.4256 / 0.4871 Acc: 40.6250 (33.9031)\n",
      "[12/25][517/782] Loss_D: -0.0601 (0.2114) Loss_G: -0.2581 (0.0853) D(x): 0.5376 D(G(z)): 0.4717 / 0.4941 Acc: 42.1875 (33.9040)\n",
      "[12/25][518/782] Loss_D: 0.1224 (0.2114) Loss_G: -0.1423 (0.0853) D(x): 0.5087 D(G(z)): 0.5261 / 0.4577 Acc: 39.0625 (33.9045)\n",
      "[12/25][519/782] Loss_D: -0.1542 (0.2114) Loss_G: -0.1758 (0.0852) D(x): 0.5549 D(G(z)): 0.4448 / 0.4742 Acc: 40.6250 (33.9052)\n",
      "[12/25][520/782] Loss_D: -0.2385 (0.2113) Loss_G: -0.2115 (0.0852) D(x): 0.5498 D(G(z)): 0.4547 / 0.4782 Acc: 59.3750 (33.9077)\n",
      "[12/25][521/782] Loss_D: -0.0636 (0.2113) Loss_G: -0.1648 (0.0852) D(x): 0.5166 D(G(z)): 0.4961 / 0.4624 Acc: 51.5625 (33.9095)\n",
      "[12/25][522/782] Loss_D: -0.0681 (0.2113) Loss_G: -0.0852 (0.0852) D(x): 0.5154 D(G(z)): 0.4785 / 0.4356 Acc: 51.5625 (33.9113)\n",
      "[12/25][523/782] Loss_D: -0.1023 (0.2112) Loss_G: 0.0649 (0.0852) D(x): 0.5735 D(G(z)): 0.4470 / 0.3877 Acc: 35.9375 (33.9115)\n",
      "[12/25][524/782] Loss_D: 0.0256 (0.2112) Loss_G: -0.2327 (0.0851) D(x): 0.4790 D(G(z)): 0.4256 / 0.5028 Acc: 42.1875 (33.9124)\n",
      "[12/25][525/782] Loss_D: -0.0033 (0.2112) Loss_G: -0.2270 (0.0851) D(x): 0.4674 D(G(z)): 0.4587 / 0.4972 Acc: 51.5625 (33.9141)\n",
      "[12/25][526/782] Loss_D: -0.1095 (0.2112) Loss_G: -0.2536 (0.0851) D(x): 0.6013 D(G(z)): 0.5061 / 0.4977 Acc: 40.6250 (33.9148)\n",
      "[12/25][527/782] Loss_D: 0.0424 (0.2112) Loss_G: -0.1556 (0.0851) D(x): 0.5832 D(G(z)): 0.5710 / 0.4709 Acc: 45.3125 (33.9160)\n",
      "[12/25][528/782] Loss_D: -0.1084 (0.2111) Loss_G: -0.0507 (0.0850) D(x): 0.4873 D(G(z)): 0.4612 / 0.4384 Acc: 54.6875 (33.9181)\n",
      "[12/25][529/782] Loss_D: 0.0893 (0.2111) Loss_G: -0.0714 (0.0850) D(x): 0.4821 D(G(z)): 0.4934 / 0.4226 Acc: 42.1875 (33.9189)\n",
      "[12/25][530/782] Loss_D: -0.0926 (0.2111) Loss_G: -0.1051 (0.0850) D(x): 0.5465 D(G(z)): 0.4508 / 0.4325 Acc: 39.0625 (33.9194)\n",
      "[12/25][531/782] Loss_D: -0.1845 (0.2110) Loss_G: -0.0584 (0.0850) D(x): 0.5339 D(G(z)): 0.4594 / 0.4240 Acc: 54.6875 (33.9215)\n",
      "[12/25][532/782] Loss_D: -0.0497 (0.2110) Loss_G: -0.0834 (0.0850) D(x): 0.4688 D(G(z)): 0.4493 / 0.4350 Acc: 53.1250 (33.9234)\n",
      "[12/25][533/782] Loss_D: -0.0826 (0.2110) Loss_G: -0.2262 (0.0849) D(x): 0.4949 D(G(z)): 0.4367 / 0.4816 Acc: 48.4375 (33.9249)\n",
      "[12/25][534/782] Loss_D: -0.1194 (0.2109) Loss_G: -0.1459 (0.0849) D(x): 0.5742 D(G(z)): 0.5053 / 0.4571 Acc: 50.0000 (33.9265)\n",
      "[12/25][535/782] Loss_D: -0.1085 (0.2109) Loss_G: -0.0424 (0.0849) D(x): 0.5871 D(G(z)): 0.4743 / 0.4237 Acc: 37.5000 (33.9269)\n",
      "[12/25][536/782] Loss_D: -0.0934 (0.2109) Loss_G: 0.1025 (0.0849) D(x): 0.4945 D(G(z)): 0.4076 / 0.3673 Acc: 40.6250 (33.9276)\n",
      "[12/25][537/782] Loss_D: 0.0063 (0.2109) Loss_G: -0.1859 (0.0849) D(x): 0.5347 D(G(z)): 0.4678 / 0.4858 Acc: 40.6250 (33.9282)\n",
      "[12/25][538/782] Loss_D: -0.1339 (0.2108) Loss_G: -0.0530 (0.0849) D(x): 0.5402 D(G(z)): 0.4776 / 0.4241 Acc: 46.8750 (33.9295)\n",
      "[12/25][539/782] Loss_D: -0.0611 (0.2108) Loss_G: -0.1338 (0.0848) D(x): 0.5704 D(G(z)): 0.4947 / 0.4779 Acc: 40.6250 (33.9302)\n",
      "[12/25][540/782] Loss_D: -0.0543 (0.2108) Loss_G: -0.1441 (0.0848) D(x): 0.5313 D(G(z)): 0.4592 / 0.4610 Acc: 45.3125 (33.9314)\n",
      "[12/25][541/782] Loss_D: -0.2079 (0.2107) Loss_G: 0.0196 (0.0848) D(x): 0.5455 D(G(z)): 0.4159 / 0.3918 Acc: 45.3125 (33.9325)\n",
      "[12/25][542/782] Loss_D: 0.0387 (0.2107) Loss_G: -0.1721 (0.0848) D(x): 0.5004 D(G(z)): 0.4523 / 0.4920 Acc: 40.6250 (33.9332)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/25][543/782] Loss_D: -0.1224 (0.2107) Loss_G: 0.0350 (0.0848) D(x): 0.5699 D(G(z)): 0.4549 / 0.3995 Acc: 42.1875 (33.9340)\n",
      "[12/25][544/782] Loss_D: -0.1906 (0.2106) Loss_G: -0.0766 (0.0848) D(x): 0.5991 D(G(z)): 0.4482 / 0.4545 Acc: 39.0625 (33.9345)\n",
      "[12/25][545/782] Loss_D: -0.1374 (0.2106) Loss_G: 0.0370 (0.0848) D(x): 0.5851 D(G(z)): 0.4741 / 0.3948 Acc: 39.0625 (33.9350)\n",
      "[12/25][546/782] Loss_D: -0.1767 (0.2106) Loss_G: -0.1482 (0.0847) D(x): 0.5340 D(G(z)): 0.4441 / 0.4638 Acc: 50.0000 (33.9367)\n",
      "[12/25][547/782] Loss_D: -0.2548 (0.2105) Loss_G: -0.1472 (0.0847) D(x): 0.5429 D(G(z)): 0.4222 / 0.4523 Acc: 50.0000 (33.9383)\n",
      "[12/25][548/782] Loss_D: -0.0772 (0.2105) Loss_G: -0.1419 (0.0847) D(x): 0.5088 D(G(z)): 0.4194 / 0.4521 Acc: 34.3750 (33.9383)\n",
      "[12/25][549/782] Loss_D: 0.0367 (0.2105) Loss_G: -0.2227 (0.0847) D(x): 0.5537 D(G(z)): 0.5394 / 0.4956 Acc: 42.1875 (33.9392)\n",
      "[12/25][550/782] Loss_D: 0.0164 (0.2105) Loss_G: -0.0696 (0.0846) D(x): 0.5351 D(G(z)): 0.4646 / 0.4288 Acc: 35.9375 (33.9394)\n",
      "[12/25][551/782] Loss_D: -0.0655 (0.2104) Loss_G: 0.0598 (0.0846) D(x): 0.5552 D(G(z)): 0.4959 / 0.3805 Acc: 42.1875 (33.9402)\n",
      "[12/25][552/782] Loss_D: 0.0127 (0.2104) Loss_G: -0.0707 (0.0846) D(x): 0.4919 D(G(z)): 0.4558 / 0.4508 Acc: 42.1875 (33.9410)\n",
      "[12/25][553/782] Loss_D: -0.1618 (0.2104) Loss_G: -0.1041 (0.0846) D(x): 0.4920 D(G(z)): 0.4439 / 0.4515 Acc: 59.3750 (33.9436)\n",
      "[12/25][554/782] Loss_D: -0.0654 (0.2103) Loss_G: -0.0454 (0.0846) D(x): 0.5561 D(G(z)): 0.4811 / 0.4179 Acc: 40.6250 (33.9442)\n",
      "[12/25][555/782] Loss_D: -0.0292 (0.2103) Loss_G: -0.1611 (0.0846) D(x): 0.5087 D(G(z)): 0.4673 / 0.4700 Acc: 46.8750 (33.9455)\n",
      "[12/25][556/782] Loss_D: -0.0377 (0.2103) Loss_G: -0.2538 (0.0845) D(x): 0.5070 D(G(z)): 0.4981 / 0.5077 Acc: 51.5625 (33.9473)\n",
      "[12/25][557/782] Loss_D: 0.1467 (0.2103) Loss_G: -0.1543 (0.0845) D(x): 0.5167 D(G(z)): 0.5335 / 0.4564 Acc: 43.7500 (33.9483)\n",
      "[12/25][558/782] Loss_D: -0.1135 (0.2103) Loss_G: -0.0052 (0.0845) D(x): 0.5522 D(G(z)): 0.4629 / 0.4035 Acc: 43.7500 (33.9493)\n",
      "[12/25][559/782] Loss_D: -0.1525 (0.2102) Loss_G: -0.1476 (0.0845) D(x): 0.5342 D(G(z)): 0.4554 / 0.4537 Acc: 50.0000 (33.9509)\n",
      "[12/25][560/782] Loss_D: -0.0812 (0.2102) Loss_G: -0.2306 (0.0844) D(x): 0.4944 D(G(z)): 0.4406 / 0.4975 Acc: 53.1250 (33.9528)\n",
      "[12/25][561/782] Loss_D: -0.1279 (0.2102) Loss_G: -0.1033 (0.0844) D(x): 0.5529 D(G(z)): 0.5170 / 0.4336 Acc: 56.2500 (33.9551)\n",
      "[12/25][562/782] Loss_D: -0.2632 (0.2101) Loss_G: -0.0082 (0.0844) D(x): 0.5685 D(G(z)): 0.4724 / 0.4011 Acc: 54.6875 (33.9572)\n",
      "[12/25][563/782] Loss_D: 0.1483 (0.2101) Loss_G: -0.1262 (0.0844) D(x): 0.4219 D(G(z)): 0.4277 / 0.4651 Acc: 39.0625 (33.9577)\n",
      "[12/25][564/782] Loss_D: -0.1747 (0.2101) Loss_G: -0.2650 (0.0844) D(x): 0.5245 D(G(z)): 0.4475 / 0.5052 Acc: 48.4375 (33.9591)\n",
      "[12/25][565/782] Loss_D: -0.0950 (0.2100) Loss_G: -0.1182 (0.0843) D(x): 0.6456 D(G(z)): 0.5304 / 0.4570 Acc: 42.1875 (33.9600)\n",
      "[12/25][566/782] Loss_D: -0.0044 (0.2100) Loss_G: -0.1922 (0.0843) D(x): 0.5076 D(G(z)): 0.4840 / 0.4772 Acc: 50.0000 (33.9616)\n",
      "[12/25][567/782] Loss_D: 0.1338 (0.2100) Loss_G: -0.0966 (0.0843) D(x): 0.5020 D(G(z)): 0.5229 / 0.4494 Acc: 40.6250 (33.9622)\n",
      "[12/25][568/782] Loss_D: -0.0053 (0.2100) Loss_G: -0.1099 (0.0843) D(x): 0.4962 D(G(z)): 0.4447 / 0.4396 Acc: 35.9375 (33.9624)\n",
      "[12/25][569/782] Loss_D: -0.0519 (0.2100) Loss_G: -0.1686 (0.0843) D(x): 0.5340 D(G(z)): 0.4711 / 0.4874 Acc: 42.1875 (33.9633)\n",
      "[12/25][570/782] Loss_D: 0.2192 (0.2100) Loss_G: -0.1714 (0.0842) D(x): 0.5048 D(G(z)): 0.5320 / 0.4740 Acc: 34.3750 (33.9633)\n",
      "[12/25][571/782] Loss_D: -0.0896 (0.2099) Loss_G: -0.1012 (0.0842) D(x): 0.5542 D(G(z)): 0.4631 / 0.4336 Acc: 39.0625 (33.9638)\n",
      "[12/25][572/782] Loss_D: 0.0316 (0.2099) Loss_G: -0.1507 (0.0842) D(x): 0.5292 D(G(z)): 0.4749 / 0.4841 Acc: 40.6250 (33.9645)\n",
      "[12/25][573/782] Loss_D: -0.0152 (0.2099) Loss_G: -0.1987 (0.0842) D(x): 0.5125 D(G(z)): 0.4754 / 0.4759 Acc: 42.1875 (33.9653)\n",
      "[12/25][574/782] Loss_D: -0.1055 (0.2099) Loss_G: 0.0151 (0.0841) D(x): 0.5381 D(G(z)): 0.4325 / 0.3891 Acc: 37.5000 (33.9657)\n",
      "[12/25][575/782] Loss_D: 0.0415 (0.2098) Loss_G: -0.0727 (0.0841) D(x): 0.5120 D(G(z)): 0.4528 / 0.4202 Acc: 31.2500 (33.9654)\n",
      "[12/25][576/782] Loss_D: -0.2132 (0.2098) Loss_G: -0.0721 (0.0841) D(x): 0.5446 D(G(z)): 0.4216 / 0.4432 Acc: 48.4375 (33.9668)\n",
      "[12/25][577/782] Loss_D: -0.0472 (0.2098) Loss_G: -0.0645 (0.0841) D(x): 0.4914 D(G(z)): 0.4432 / 0.4392 Acc: 43.7500 (33.9678)\n",
      "[12/25][578/782] Loss_D: -0.1411 (0.2097) Loss_G: 0.0479 (0.0841) D(x): 0.5816 D(G(z)): 0.4458 / 0.3922 Acc: 34.3750 (33.9679)\n",
      "[12/25][579/782] Loss_D: -0.0842 (0.2097) Loss_G: -0.0768 (0.0841) D(x): 0.5342 D(G(z)): 0.4300 / 0.4390 Acc: 37.5000 (33.9682)\n",
      "[12/25][580/782] Loss_D: -0.1316 (0.2097) Loss_G: 0.0247 (0.0841) D(x): 0.5314 D(G(z)): 0.4756 / 0.3953 Acc: 51.5625 (33.9700)\n",
      "[12/25][581/782] Loss_D: 0.0098 (0.2096) Loss_G: -0.0392 (0.0841) D(x): 0.5093 D(G(z)): 0.4664 / 0.4108 Acc: 40.6250 (33.9707)\n",
      "[12/25][582/782] Loss_D: -0.0935 (0.2096) Loss_G: 0.0176 (0.0841) D(x): 0.5282 D(G(z)): 0.4459 / 0.4067 Acc: 48.4375 (33.9721)\n",
      "[12/25][583/782] Loss_D: -0.4971 (0.2095) Loss_G: -0.0335 (0.0840) D(x): 0.5872 D(G(z)): 0.4123 / 0.4143 Acc: 65.6250 (33.9753)\n",
      "[12/25][584/782] Loss_D: -0.1127 (0.2095) Loss_G: -0.1713 (0.0840) D(x): 0.5402 D(G(z)): 0.4598 / 0.4981 Acc: 46.8750 (33.9766)\n",
      "[12/25][585/782] Loss_D: -0.0810 (0.2095) Loss_G: -0.0567 (0.0840) D(x): 0.5727 D(G(z)): 0.4962 / 0.4308 Acc: 43.7500 (33.9776)\n",
      "[12/25][586/782] Loss_D: -0.2040 (0.2094) Loss_G: -0.1690 (0.0840) D(x): 0.5498 D(G(z)): 0.4573 / 0.4679 Acc: 50.0000 (33.9792)\n",
      "[12/25][587/782] Loss_D: -0.1387 (0.2094) Loss_G: -0.0229 (0.0840) D(x): 0.5700 D(G(z)): 0.4336 / 0.4128 Acc: 39.0625 (33.9797)\n",
      "[12/25][588/782] Loss_D: -0.0694 (0.2094) Loss_G: -0.1631 (0.0839) D(x): 0.5054 D(G(z)): 0.4698 / 0.4657 Acc: 48.4375 (33.9811)\n",
      "[12/25][589/782] Loss_D: -0.0449 (0.2094) Loss_G: -0.1158 (0.0839) D(x): 0.5521 D(G(z)): 0.4684 / 0.4461 Acc: 39.0625 (33.9816)\n",
      "[12/25][590/782] Loss_D: -0.1714 (0.2093) Loss_G: -0.1935 (0.0839) D(x): 0.5216 D(G(z)): 0.4500 / 0.4640 Acc: 53.1250 (33.9836)\n",
      "[12/25][591/782] Loss_D: -0.0693 (0.2093) Loss_G: -0.1314 (0.0839) D(x): 0.5421 D(G(z)): 0.5044 / 0.4535 Acc: 50.0000 (33.9852)\n",
      "[12/25][592/782] Loss_D: 0.0779 (0.2093) Loss_G: -0.2240 (0.0838) D(x): 0.5130 D(G(z)): 0.4936 / 0.4876 Acc: 40.6250 (33.9858)\n",
      "[12/25][593/782] Loss_D: -0.1686 (0.2092) Loss_G: -0.0820 (0.0838) D(x): 0.5450 D(G(z)): 0.4901 / 0.4433 Acc: 56.2500 (33.9881)\n",
      "[12/25][594/782] Loss_D: -0.1290 (0.2092) Loss_G: -0.0643 (0.0838) D(x): 0.5215 D(G(z)): 0.4493 / 0.4189 Acc: 46.8750 (33.9893)\n",
      "[12/25][595/782] Loss_D: -0.1454 (0.2092) Loss_G: -0.1631 (0.0838) D(x): 0.5235 D(G(z)): 0.4491 / 0.4790 Acc: 46.8750 (33.9906)\n",
      "[12/25][596/782] Loss_D: -0.0681 (0.2091) Loss_G: -0.1123 (0.0838) D(x): 0.5615 D(G(z)): 0.4917 / 0.4374 Acc: 45.3125 (33.9918)\n",
      "[12/25][597/782] Loss_D: -0.0903 (0.2091) Loss_G: -0.2041 (0.0837) D(x): 0.5445 D(G(z)): 0.4319 / 0.4890 Acc: 40.6250 (33.9924)\n",
      "[12/25][598/782] Loss_D: -0.1126 (0.2091) Loss_G: -0.1293 (0.0837) D(x): 0.5234 D(G(z)): 0.4246 / 0.4607 Acc: 40.6250 (33.9931)\n",
      "[12/25][599/782] Loss_D: -0.0670 (0.2091) Loss_G: -0.1004 (0.0837) D(x): 0.5523 D(G(z)): 0.4988 / 0.4349 Acc: 45.3125 (33.9942)\n",
      "[12/25][600/782] Loss_D: -0.1729 (0.2090) Loss_G: -0.0384 (0.0837) D(x): 0.5531 D(G(z)): 0.5013 / 0.4112 Acc: 53.1250 (33.9962)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[12/25][601/782] Loss_D: -0.1336 (0.2090) Loss_G: 0.0256 (0.0837) D(x): 0.5470 D(G(z)): 0.4321 / 0.4045 Acc: 40.6250 (33.9968)\n",
      "[12/25][602/782] Loss_D: -0.0113 (0.2090) Loss_G: -0.1439 (0.0837) D(x): 0.5119 D(G(z)): 0.4454 / 0.4661 Acc: 40.6250 (33.9975)\n",
      "[12/25][603/782] Loss_D: -0.2049 (0.2089) Loss_G: -0.2369 (0.0836) D(x): 0.5524 D(G(z)): 0.4416 / 0.4982 Acc: 46.8750 (33.9988)\n",
      "[12/25][604/782] Loss_D: 0.0008 (0.2089) Loss_G: -0.1842 (0.0836) D(x): 0.5046 D(G(z)): 0.4754 / 0.4799 Acc: 46.8750 (34.0001)\n",
      "[12/25][605/782] Loss_D: -0.0305 (0.2089) Loss_G: 0.0177 (0.0836) D(x): 0.5893 D(G(z)): 0.5499 / 0.3851 Acc: 46.8750 (34.0013)\n",
      "[12/25][606/782] Loss_D: -0.0315 (0.2088) Loss_G: -0.1842 (0.0836) D(x): 0.5125 D(G(z)): 0.4734 / 0.4674 Acc: 45.3125 (34.0025)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/25][607/782] Loss_D: 0.0294 (0.2088) Loss_G: -0.1841 (0.0835) D(x): 0.4419 D(G(z)): 0.4245 / 0.4816 Acc: 46.8750 (34.0038)\n",
      "[12/25][608/782] Loss_D: -0.0237 (0.2088) Loss_G: -0.2462 (0.0835) D(x): 0.5704 D(G(z)): 0.4862 / 0.5265 Acc: 43.7500 (34.0047)\n",
      "[12/25][609/782] Loss_D: -0.1299 (0.2088) Loss_G: -0.1253 (0.0835) D(x): 0.5810 D(G(z)): 0.5068 / 0.4659 Acc: 53.1250 (34.0067)\n",
      "[12/25][610/782] Loss_D: -0.0813 (0.2087) Loss_G: 0.0095 (0.0835) D(x): 0.5144 D(G(z)): 0.4302 / 0.3913 Acc: 40.6250 (34.0073)\n",
      "[12/25][611/782] Loss_D: -0.1349 (0.2087) Loss_G: 0.0152 (0.0835) D(x): 0.5218 D(G(z)): 0.4503 / 0.4083 Acc: 48.4375 (34.0088)\n",
      "[12/25][612/782] Loss_D: -0.0505 (0.2087) Loss_G: -0.2371 (0.0834) D(x): 0.4817 D(G(z)): 0.4146 / 0.4936 Acc: 43.7500 (34.0097)\n",
      "[12/25][613/782] Loss_D: -0.1294 (0.2086) Loss_G: -0.2540 (0.0834) D(x): 0.5472 D(G(z)): 0.4721 / 0.5033 Acc: 50.0000 (34.0113)\n",
      "[12/25][614/782] Loss_D: -0.0617 (0.2086) Loss_G: -0.1168 (0.0834) D(x): 0.5417 D(G(z)): 0.4649 / 0.4553 Acc: 40.6250 (34.0120)\n",
      "[12/25][615/782] Loss_D: -0.1040 (0.2086) Loss_G: -0.1685 (0.0834) D(x): 0.5071 D(G(z)): 0.4944 / 0.4617 Acc: 54.6875 (34.0141)\n",
      "[12/25][616/782] Loss_D: -0.1155 (0.2086) Loss_G: -0.1217 (0.0833) D(x): 0.5581 D(G(z)): 0.4754 / 0.4452 Acc: 43.7500 (34.0150)\n",
      "[12/25][617/782] Loss_D: -0.0656 (0.2085) Loss_G: -0.1078 (0.0833) D(x): 0.4663 D(G(z)): 0.4437 / 0.4376 Acc: 51.5625 (34.0168)\n",
      "[12/25][618/782] Loss_D: -0.0800 (0.2085) Loss_G: -0.1604 (0.0833) D(x): 0.5837 D(G(z)): 0.5133 / 0.4620 Acc: 42.1875 (34.0176)\n",
      "[12/25][619/782] Loss_D: 0.0388 (0.2085) Loss_G: -0.1124 (0.0833) D(x): 0.4989 D(G(z)): 0.4988 / 0.4345 Acc: 40.6250 (34.0183)\n",
      "[12/25][620/782] Loss_D: 0.2127 (0.2085) Loss_G: -0.0371 (0.0833) D(x): 0.4575 D(G(z)): 0.4995 / 0.4355 Acc: 39.0625 (34.0188)\n",
      "[12/25][621/782] Loss_D: -0.2190 (0.2084) Loss_G: -0.0931 (0.0832) D(x): 0.5441 D(G(z)): 0.4513 / 0.4431 Acc: 50.0000 (34.0204)\n",
      "[12/25][622/782] Loss_D: -0.1237 (0.2084) Loss_G: -0.1147 (0.0832) D(x): 0.5321 D(G(z)): 0.4764 / 0.4755 Acc: 51.5625 (34.0221)\n",
      "[12/25][623/782] Loss_D: 0.1942 (0.2084) Loss_G: -0.0523 (0.0832) D(x): 0.4806 D(G(z)): 0.5334 / 0.4206 Acc: 43.7500 (34.0231)\n",
      "[12/25][624/782] Loss_D: -0.1275 (0.2084) Loss_G: 0.0976 (0.0832) D(x): 0.5787 D(G(z)): 0.4506 / 0.3598 Acc: 34.3750 (34.0231)\n",
      "[12/25][625/782] Loss_D: -0.1791 (0.2083) Loss_G: -0.0745 (0.0832) D(x): 0.5267 D(G(z)): 0.4184 / 0.4397 Acc: 46.8750 (34.0244)\n",
      "[12/25][626/782] Loss_D: -0.0115 (0.2083) Loss_G: -0.2171 (0.0832) D(x): 0.4351 D(G(z)): 0.4020 / 0.5085 Acc: 54.6875 (34.0265)\n",
      "[12/25][627/782] Loss_D: -0.0002 (0.2083) Loss_G: -0.1589 (0.0831) D(x): 0.5896 D(G(z)): 0.5392 / 0.4652 Acc: 45.3125 (34.0276)\n",
      "[12/25][628/782] Loss_D: -0.1641 (0.2083) Loss_G: -0.0633 (0.0831) D(x): 0.5354 D(G(z)): 0.4226 / 0.4268 Acc: 40.6250 (34.0283)\n",
      "[12/25][629/782] Loss_D: -0.0747 (0.2082) Loss_G: -0.1633 (0.0831) D(x): 0.5385 D(G(z)): 0.4421 / 0.4649 Acc: 42.1875 (34.0291)\n",
      "[12/25][630/782] Loss_D: -0.1020 (0.2082) Loss_G: -0.0740 (0.0831) D(x): 0.5773 D(G(z)): 0.4523 / 0.4255 Acc: 32.8125 (34.0290)\n",
      "[12/25][631/782] Loss_D: -0.2088 (0.2082) Loss_G: -0.0489 (0.0831) D(x): 0.5813 D(G(z)): 0.4715 / 0.4334 Acc: 45.3125 (34.0301)\n",
      "[12/25][632/782] Loss_D: -0.1492 (0.2081) Loss_G: -0.0908 (0.0831) D(x): 0.5457 D(G(z)): 0.4548 / 0.4311 Acc: 45.3125 (34.0312)\n",
      "[12/25][633/782] Loss_D: 0.1204 (0.2081) Loss_G: -0.1001 (0.0830) D(x): 0.4811 D(G(z)): 0.4506 / 0.4609 Acc: 34.3750 (34.0312)\n",
      "[12/25][634/782] Loss_D: -0.0670 (0.2081) Loss_G: -0.2977 (0.0830) D(x): 0.4951 D(G(z)): 0.4846 / 0.5177 Acc: 56.2500 (34.0335)\n",
      "[12/25][635/782] Loss_D: -0.1024 (0.2081) Loss_G: -0.0561 (0.0830) D(x): 0.5633 D(G(z)): 0.4755 / 0.4361 Acc: 45.3125 (34.0346)\n",
      "[12/25][636/782] Loss_D: -0.1231 (0.2080) Loss_G: -0.0588 (0.0830) D(x): 0.5582 D(G(z)): 0.4867 / 0.4116 Acc: 48.4375 (34.0360)\n",
      "[12/25][637/782] Loss_D: -0.0657 (0.2080) Loss_G: -0.0474 (0.0830) D(x): 0.5112 D(G(z)): 0.4607 / 0.4276 Acc: 46.8750 (34.0373)\n",
      "[12/25][638/782] Loss_D: -0.0625 (0.2080) Loss_G: -0.0013 (0.0830) D(x): 0.5811 D(G(z)): 0.4916 / 0.4270 Acc: 42.1875 (34.0381)\n",
      "[12/25][639/782] Loss_D: 0.1438 (0.2080) Loss_G: 0.0344 (0.0830) D(x): 0.4443 D(G(z)): 0.4364 / 0.3983 Acc: 37.5000 (34.0385)\n",
      "[12/25][640/782] Loss_D: -0.0695 (0.2079) Loss_G: -0.2364 (0.0829) D(x): 0.5179 D(G(z)): 0.4520 / 0.4995 Acc: 42.1875 (34.0393)\n",
      "[12/25][641/782] Loss_D: 0.0029 (0.2079) Loss_G: -0.1517 (0.0829) D(x): 0.4949 D(G(z)): 0.4938 / 0.4551 Acc: 50.0000 (34.0409)\n",
      "[12/25][642/782] Loss_D: 0.0638 (0.2079) Loss_G: -0.1863 (0.0829) D(x): 0.5245 D(G(z)): 0.5086 / 0.5010 Acc: 42.1875 (34.0417)\n",
      "[12/25][643/782] Loss_D: -0.1822 (0.2079) Loss_G: -0.1960 (0.0828) D(x): 0.5348 D(G(z)): 0.4645 / 0.4804 Acc: 57.8125 (34.0441)\n",
      "[12/25][644/782] Loss_D: -0.1030 (0.2078) Loss_G: -0.2207 (0.0828) D(x): 0.5839 D(G(z)): 0.4847 / 0.4972 Acc: 42.1875 (34.0449)\n",
      "[12/25][645/782] Loss_D: -0.1719 (0.2078) Loss_G: -0.0719 (0.0828) D(x): 0.5928 D(G(z)): 0.4851 / 0.4347 Acc: 45.3125 (34.0460)\n",
      "[12/25][646/782] Loss_D: 0.0039 (0.2078) Loss_G: -0.1598 (0.0828) D(x): 0.4725 D(G(z)): 0.4315 / 0.4643 Acc: 45.3125 (34.0471)\n",
      "[12/25][647/782] Loss_D: -0.0682 (0.2077) Loss_G: -0.0106 (0.0828) D(x): 0.5130 D(G(z)): 0.4805 / 0.4212 Acc: 48.4375 (34.0485)\n",
      "[12/25][648/782] Loss_D: -0.0428 (0.2077) Loss_G: -0.1678 (0.0827) D(x): 0.5189 D(G(z)): 0.4740 / 0.4696 Acc: 46.8750 (34.0498)\n",
      "[12/25][649/782] Loss_D: 0.0237 (0.2077) Loss_G: 0.0889 (0.0827) D(x): 0.5460 D(G(z)): 0.5016 / 0.3729 Acc: 40.6250 (34.0505)\n",
      "[12/25][650/782] Loss_D: -0.2677 (0.2076) Loss_G: -0.0006 (0.0827) D(x): 0.6520 D(G(z)): 0.4480 / 0.4072 Acc: 37.5000 (34.0508)\n",
      "[12/25][651/782] Loss_D: -0.1435 (0.2076) Loss_G: 0.1235 (0.0827) D(x): 0.5602 D(G(z)): 0.4201 / 0.3643 Acc: 40.6250 (34.0515)\n",
      "[12/25][652/782] Loss_D: 0.0701 (0.2076) Loss_G: -0.1617 (0.0827) D(x): 0.4756 D(G(z)): 0.4460 / 0.4645 Acc: 34.3750 (34.0515)\n",
      "[12/25][653/782] Loss_D: -0.3206 (0.2075) Loss_G: 0.1262 (0.0827) D(x): 0.5566 D(G(z)): 0.3812 / 0.3663 Acc: 48.4375 (34.0529)\n",
      "[12/25][654/782] Loss_D: 0.1341 (0.2075) Loss_G: -0.1283 (0.0827) D(x): 0.4918 D(G(z)): 0.4904 / 0.4474 Acc: 37.5000 (34.0533)\n",
      "[12/25][655/782] Loss_D: -0.0660 (0.2075) Loss_G: -0.0395 (0.0827) D(x): 0.5307 D(G(z)): 0.4474 / 0.4239 Acc: 42.1875 (34.0541)\n",
      "[12/25][656/782] Loss_D: -0.1245 (0.2075) Loss_G: -0.1443 (0.0827) D(x): 0.5282 D(G(z)): 0.4327 / 0.4530 Acc: 42.1875 (34.0549)\n",
      "[12/25][657/782] Loss_D: -0.2436 (0.2074) Loss_G: -0.0644 (0.0826) D(x): 0.5851 D(G(z)): 0.4542 / 0.4306 Acc: 48.4375 (34.0563)\n",
      "[12/25][658/782] Loss_D: 0.0272 (0.2074) Loss_G: -0.1057 (0.0826) D(x): 0.5113 D(G(z)): 0.4543 / 0.4411 Acc: 39.0625 (34.0568)\n",
      "[12/25][659/782] Loss_D: -0.0953 (0.2074) Loss_G: -0.0850 (0.0826) D(x): 0.5246 D(G(z)): 0.4051 / 0.4297 Acc: 34.3750 (34.0569)\n",
      "[12/25][660/782] Loss_D: -0.1949 (0.2073) Loss_G: -0.0063 (0.0826) D(x): 0.5653 D(G(z)): 0.4559 / 0.4215 Acc: 51.5625 (34.0586)\n",
      "[12/25][661/782] Loss_D: -0.0120 (0.2073) Loss_G: -0.2381 (0.0826) D(x): 0.4957 D(G(z)): 0.4562 / 0.5066 Acc: 43.7500 (34.0596)\n",
      "[12/25][662/782] Loss_D: -0.0561 (0.2073) Loss_G: -0.1491 (0.0825) D(x): 0.5395 D(G(z)): 0.4850 / 0.4545 Acc: 45.3125 (34.0607)\n",
      "[12/25][663/782] Loss_D: 0.0450 (0.2073) Loss_G: -0.0428 (0.0825) D(x): 0.5111 D(G(z)): 0.5017 / 0.4261 Acc: 48.4375 (34.0621)\n",
      "[12/25][664/782] Loss_D: -0.0146 (0.2073) Loss_G: 0.0560 (0.0825) D(x): 0.4831 D(G(z)): 0.4384 / 0.4165 Acc: 48.4375 (34.0636)\n",
      "[12/25][665/782] Loss_D: -0.0410 (0.2072) Loss_G: -0.0702 (0.0825) D(x): 0.5448 D(G(z)): 0.4737 / 0.4328 Acc: 42.1875 (34.0644)\n",
      "[12/25][666/782] Loss_D: 0.1242 (0.2072) Loss_G: -0.1516 (0.0825) D(x): 0.5261 D(G(z)): 0.5070 / 0.4673 Acc: 40.6250 (34.0650)\n",
      "[12/25][667/782] Loss_D: 0.0107 (0.2072) Loss_G: -0.2186 (0.0825) D(x): 0.5000 D(G(z)): 0.4581 / 0.5020 Acc: 45.3125 (34.0661)\n",
      "[12/25][668/782] Loss_D: -0.0532 (0.2072) Loss_G: -0.0618 (0.0824) D(x): 0.5292 D(G(z)): 0.4871 / 0.4267 Acc: 45.3125 (34.0673)\n",
      "[12/25][669/782] Loss_D: -0.1774 (0.2071) Loss_G: -0.0456 (0.0824) D(x): 0.5652 D(G(z)): 0.4543 / 0.4464 Acc: 46.8750 (34.0685)\n",
      "[12/25][670/782] Loss_D: -0.0953 (0.2071) Loss_G: -0.0336 (0.0824) D(x): 0.5332 D(G(z)): 0.4633 / 0.4227 Acc: 51.5625 (34.0703)\n",
      "[12/25][671/782] Loss_D: -0.1226 (0.2071) Loss_G: -0.0631 (0.0824) D(x): 0.5300 D(G(z)): 0.4724 / 0.4340 Acc: 48.4375 (34.0717)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/25][672/782] Loss_D: -0.1253 (0.2070) Loss_G: -0.0936 (0.0824) D(x): 0.5317 D(G(z)): 0.4464 / 0.4453 Acc: 43.7500 (34.0727)\n",
      "[12/25][673/782] Loss_D: 0.0426 (0.2070) Loss_G: -0.1288 (0.0824) D(x): 0.5248 D(G(z)): 0.4822 / 0.4574 Acc: 40.6250 (34.0733)\n",
      "[12/25][674/782] Loss_D: -0.0397 (0.2070) Loss_G: -0.0880 (0.0824) D(x): 0.5104 D(G(z)): 0.4621 / 0.4341 Acc: 43.7500 (34.0743)\n",
      "[12/25][675/782] Loss_D: -0.0108 (0.2070) Loss_G: -0.3224 (0.0823) D(x): 0.5204 D(G(z)): 0.5002 / 0.5425 Acc: 46.8750 (34.0755)\n",
      "[12/25][676/782] Loss_D: -0.1406 (0.2069) Loss_G: -0.1229 (0.0823) D(x): 0.5546 D(G(z)): 0.4682 / 0.4554 Acc: 50.0000 (34.0771)\n",
      "[12/25][677/782] Loss_D: 0.1244 (0.2069) Loss_G: -0.2642 (0.0823) D(x): 0.4941 D(G(z)): 0.4745 / 0.5234 Acc: 39.0625 (34.0776)\n",
      "[12/25][678/782] Loss_D: 0.0422 (0.2069) Loss_G: -0.1075 (0.0822) D(x): 0.5662 D(G(z)): 0.5289 / 0.4566 Acc: 39.0625 (34.0781)\n",
      "[12/25][679/782] Loss_D: -0.1426 (0.2069) Loss_G: -0.0300 (0.0822) D(x): 0.5225 D(G(z)): 0.4116 / 0.4159 Acc: 43.7500 (34.0791)\n",
      "[12/25][680/782] Loss_D: -0.0902 (0.2069) Loss_G: -0.0909 (0.0822) D(x): 0.5272 D(G(z)): 0.4176 / 0.4538 Acc: 37.5000 (34.0794)\n",
      "[12/25][681/782] Loss_D: 0.0575 (0.2068) Loss_G: -0.1961 (0.0822) D(x): 0.5182 D(G(z)): 0.5324 / 0.4765 Acc: 48.4375 (34.0808)\n",
      "[12/25][682/782] Loss_D: -0.2334 (0.2068) Loss_G: -0.1019 (0.0822) D(x): 0.5600 D(G(z)): 0.4760 / 0.4387 Acc: 54.6875 (34.0829)\n",
      "[12/25][683/782] Loss_D: -0.0583 (0.2068) Loss_G: -0.0512 (0.0821) D(x): 0.5550 D(G(z)): 0.4688 / 0.4306 Acc: 37.5000 (34.0832)\n",
      "[12/25][684/782] Loss_D: -0.2057 (0.2067) Loss_G: -0.1265 (0.0821) D(x): 0.5801 D(G(z)): 0.4653 / 0.4450 Acc: 50.0000 (34.0848)\n",
      "[12/25][685/782] Loss_D: -0.2219 (0.2067) Loss_G: -0.0762 (0.0821) D(x): 0.5299 D(G(z)): 0.4320 / 0.4281 Acc: 50.0000 (34.0864)\n",
      "[12/25][686/782] Loss_D: -0.1395 (0.2067) Loss_G: -0.2953 (0.0821) D(x): 0.5181 D(G(z)): 0.4287 / 0.5151 Acc: 45.3125 (34.0875)\n",
      "[12/25][687/782] Loss_D: -0.0082 (0.2066) Loss_G: -0.1193 (0.0821) D(x): 0.5531 D(G(z)): 0.4781 / 0.4541 Acc: 37.5000 (34.0878)\n",
      "[12/25][688/782] Loss_D: -0.1204 (0.2066) Loss_G: -0.0764 (0.0820) D(x): 0.6107 D(G(z)): 0.5005 / 0.4238 Acc: 35.9375 (34.0880)\n",
      "[12/25][689/782] Loss_D: -0.0361 (0.2066) Loss_G: -0.0964 (0.0820) D(x): 0.5081 D(G(z)): 0.4713 / 0.4321 Acc: 42.1875 (34.0888)\n",
      "[12/25][690/782] Loss_D: -0.2263 (0.2065) Loss_G: -0.0602 (0.0820) D(x): 0.5447 D(G(z)): 0.4435 / 0.4238 Acc: 56.2500 (34.0910)\n",
      "[12/25][691/782] Loss_D: -0.0964 (0.2065) Loss_G: -0.1665 (0.0820) D(x): 0.5293 D(G(z)): 0.4861 / 0.4887 Acc: 48.4375 (34.0925)\n",
      "[12/25][692/782] Loss_D: -0.0402 (0.2065) Loss_G: -0.1819 (0.0820) D(x): 0.4968 D(G(z)): 0.4880 / 0.4632 Acc: 48.4375 (34.0939)\n",
      "[12/25][693/782] Loss_D: -0.0263 (0.2065) Loss_G: -0.2018 (0.0819) D(x): 0.5228 D(G(z)): 0.4264 / 0.4902 Acc: 37.5000 (34.0942)\n",
      "[12/25][694/782] Loss_D: -0.0853 (0.2064) Loss_G: -0.2112 (0.0819) D(x): 0.5280 D(G(z)): 0.4731 / 0.5006 Acc: 50.0000 (34.0958)\n",
      "[12/25][695/782] Loss_D: 0.0853 (0.2064) Loss_G: -0.1783 (0.0819) D(x): 0.5291 D(G(z)): 0.5389 / 0.4703 Acc: 45.3125 (34.0969)\n",
      "[12/25][696/782] Loss_D: -0.1035 (0.2064) Loss_G: -0.1642 (0.0818) D(x): 0.5447 D(G(z)): 0.4702 / 0.4665 Acc: 51.5625 (34.0986)\n",
      "[12/25][697/782] Loss_D: -0.2574 (0.2063) Loss_G: 0.0007 (0.0818) D(x): 0.5638 D(G(z)): 0.4393 / 0.4023 Acc: 50.0000 (34.1002)\n",
      "[12/25][698/782] Loss_D: -0.1796 (0.2063) Loss_G: -0.0606 (0.0818) D(x): 0.5291 D(G(z)): 0.4759 / 0.4263 Acc: 62.5000 (34.1030)\n",
      "[12/25][699/782] Loss_D: -0.0663 (0.2063) Loss_G: -0.1348 (0.0818) D(x): 0.5537 D(G(z)): 0.4665 / 0.4627 Acc: 42.1875 (34.1038)\n",
      "[12/25][700/782] Loss_D: 0.0301 (0.2063) Loss_G: -0.0583 (0.0818) D(x): 0.4725 D(G(z)): 0.4617 / 0.4357 Acc: 45.3125 (34.1050)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[12/25][701/782] Loss_D: -0.0534 (0.2062) Loss_G: -0.1104 (0.0818) D(x): 0.5237 D(G(z)): 0.4535 / 0.4565 Acc: 45.3125 (34.1061)\n",
      "[12/25][702/782] Loss_D: -0.2976 (0.2062) Loss_G: -0.2312 (0.0817) D(x): 0.5928 D(G(z)): 0.4761 / 0.4982 Acc: 57.8125 (34.1084)\n",
      "[12/25][703/782] Loss_D: -0.0877 (0.2062) Loss_G: -0.0266 (0.0817) D(x): 0.5053 D(G(z)): 0.3805 / 0.4167 Acc: 34.3750 (34.1084)\n",
      "[12/25][704/782] Loss_D: -0.1348 (0.2061) Loss_G: -0.0723 (0.0817) D(x): 0.6231 D(G(z)): 0.4899 / 0.4518 Acc: 43.7500 (34.1094)\n",
      "[12/25][705/782] Loss_D: -0.0818 (0.2061) Loss_G: 0.0337 (0.0817) D(x): 0.5102 D(G(z)): 0.4333 / 0.3938 Acc: 46.8750 (34.1107)\n",
      "[12/25][706/782] Loss_D: 0.0221 (0.2061) Loss_G: -0.0351 (0.0817) D(x): 0.4478 D(G(z)): 0.4371 / 0.4150 Acc: 45.3125 (34.1118)\n",
      "[12/25][707/782] Loss_D: -0.1027 (0.2060) Loss_G: -0.2211 (0.0817) D(x): 0.5056 D(G(z)): 0.4680 / 0.4941 Acc: 56.2500 (34.1140)\n",
      "[12/25][708/782] Loss_D: -0.0921 (0.2060) Loss_G: -0.0467 (0.0817) D(x): 0.6004 D(G(z)): 0.5265 / 0.4244 Acc: 48.4375 (34.1154)\n",
      "[12/25][709/782] Loss_D: -0.2996 (0.2060) Loss_G: 0.0993 (0.0817) D(x): 0.5942 D(G(z)): 0.4842 / 0.3793 Acc: 57.8125 (34.1177)\n",
      "[12/25][710/782] Loss_D: -0.1187 (0.2059) Loss_G: -0.0043 (0.0817) D(x): 0.5165 D(G(z)): 0.3868 / 0.4119 Acc: 37.5000 (34.1181)\n",
      "[12/25][711/782] Loss_D: -0.0902 (0.2059) Loss_G: -0.0250 (0.0816) D(x): 0.5106 D(G(z)): 0.4562 / 0.4170 Acc: 46.8750 (34.1193)\n",
      "[12/25][712/782] Loss_D: -0.1808 (0.2059) Loss_G: 0.0075 (0.0816) D(x): 0.5564 D(G(z)): 0.4422 / 0.4288 Acc: 45.3125 (34.1204)\n",
      "[12/25][713/782] Loss_D: -0.0072 (0.2058) Loss_G: -0.0661 (0.0816) D(x): 0.5331 D(G(z)): 0.4421 / 0.4349 Acc: 35.9375 (34.1206)\n",
      "[12/25][714/782] Loss_D: -0.0970 (0.2058) Loss_G: -0.1235 (0.0816) D(x): 0.5313 D(G(z)): 0.4579 / 0.4561 Acc: 50.0000 (34.1222)\n",
      "[12/25][715/782] Loss_D: -0.2116 (0.2058) Loss_G: 0.0185 (0.0816) D(x): 0.5878 D(G(z)): 0.4697 / 0.3991 Acc: 48.4375 (34.1236)\n",
      "[12/25][716/782] Loss_D: 0.0305 (0.2058) Loss_G: -0.0366 (0.0816) D(x): 0.5092 D(G(z)): 0.5269 / 0.4108 Acc: 50.0000 (34.1252)\n",
      "[12/25][717/782] Loss_D: -0.2096 (0.2057) Loss_G: -0.0993 (0.0816) D(x): 0.5566 D(G(z)): 0.4263 / 0.4565 Acc: 48.4375 (34.1266)\n",
      "[12/25][718/782] Loss_D: -0.0368 (0.2057) Loss_G: -0.2027 (0.0815) D(x): 0.5054 D(G(z)): 0.4611 / 0.4814 Acc: 48.4375 (34.1280)\n",
      "[12/25][719/782] Loss_D: -0.0457 (0.2057) Loss_G: -0.1192 (0.0815) D(x): 0.5429 D(G(z)): 0.4617 / 0.4557 Acc: 35.9375 (34.1282)\n",
      "[12/25][720/782] Loss_D: 0.0119 (0.2056) Loss_G: -0.0825 (0.0815) D(x): 0.5331 D(G(z)): 0.4762 / 0.4483 Acc: 45.3125 (34.1293)\n",
      "[12/25][721/782] Loss_D: -0.1179 (0.2056) Loss_G: -0.1983 (0.0815) D(x): 0.5577 D(G(z)): 0.5082 / 0.4892 Acc: 51.5625 (34.1310)\n",
      "[12/25][722/782] Loss_D: 0.1823 (0.2056) Loss_G: -0.0781 (0.0815) D(x): 0.5455 D(G(z)): 0.5272 / 0.4412 Acc: 29.6875 (34.1306)\n",
      "[12/25][723/782] Loss_D: 0.0293 (0.2056) Loss_G: -0.1010 (0.0814) D(x): 0.4538 D(G(z)): 0.4322 / 0.4401 Acc: 45.3125 (34.1317)\n",
      "[12/25][724/782] Loss_D: -0.1446 (0.2056) Loss_G: -0.0974 (0.0814) D(x): 0.5371 D(G(z)): 0.4357 / 0.4711 Acc: 51.5625 (34.1334)\n",
      "[12/25][725/782] Loss_D: 0.0478 (0.2055) Loss_G: -0.2345 (0.0814) D(x): 0.5159 D(G(z)): 0.4502 / 0.5027 Acc: 32.8125 (34.1333)\n",
      "[12/25][726/782] Loss_D: 0.0411 (0.2055) Loss_G: -0.2670 (0.0814) D(x): 0.5161 D(G(z)): 0.4751 / 0.5122 Acc: 39.0625 (34.1338)\n",
      "[12/25][727/782] Loss_D: 0.0164 (0.2055) Loss_G: -0.1229 (0.0813) D(x): 0.5532 D(G(z)): 0.4961 / 0.4601 Acc: 37.5000 (34.1341)\n",
      "[12/25][728/782] Loss_D: 0.0223 (0.2055) Loss_G: -0.1772 (0.0813) D(x): 0.5278 D(G(z)): 0.4722 / 0.4669 Acc: 39.0625 (34.1346)\n",
      "[12/25][729/782] Loss_D: -0.0626 (0.2055) Loss_G: -0.0784 (0.0813) D(x): 0.5403 D(G(z)): 0.4640 / 0.4292 Acc: 39.0625 (34.1351)\n",
      "[12/25][730/782] Loss_D: -0.1231 (0.2054) Loss_G: -0.1474 (0.0813) D(x): 0.5212 D(G(z)): 0.4431 / 0.4543 Acc: 50.0000 (34.1366)\n",
      "[12/25][731/782] Loss_D: -0.0116 (0.2054) Loss_G: -0.2518 (0.0812) D(x): 0.4827 D(G(z)): 0.4782 / 0.4974 Acc: 50.0000 (34.1382)\n",
      "[12/25][732/782] Loss_D: -0.1345 (0.2054) Loss_G: -0.1113 (0.0812) D(x): 0.5866 D(G(z)): 0.4778 / 0.4449 Acc: 40.6250 (34.1389)\n",
      "[12/25][733/782] Loss_D: -0.0463 (0.2054) Loss_G: -0.1353 (0.0812) D(x): 0.5240 D(G(z)): 0.4523 / 0.4575 Acc: 45.3125 (34.1400)\n",
      "[12/25][734/782] Loss_D: 0.0911 (0.2053) Loss_G: -0.2189 (0.0812) D(x): 0.4923 D(G(z)): 0.4863 / 0.4886 Acc: 39.0625 (34.1404)\n",
      "[12/25][735/782] Loss_D: 0.0389 (0.2053) Loss_G: -0.1602 (0.0811) D(x): 0.5124 D(G(z)): 0.4824 / 0.4769 Acc: 40.6250 (34.1411)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/25][736/782] Loss_D: -0.1707 (0.2053) Loss_G: -0.0586 (0.0811) D(x): 0.5748 D(G(z)): 0.4255 / 0.4324 Acc: 43.7500 (34.1420)\n",
      "[12/25][737/782] Loss_D: -0.1807 (0.2052) Loss_G: -0.0616 (0.0811) D(x): 0.5706 D(G(z)): 0.5030 / 0.4289 Acc: 57.8125 (34.1444)\n",
      "[12/25][738/782] Loss_D: -0.0791 (0.2052) Loss_G: -0.0783 (0.0811) D(x): 0.5747 D(G(z)): 0.5045 / 0.4299 Acc: 42.1875 (34.1452)\n",
      "[12/25][739/782] Loss_D: 0.0025 (0.2052) Loss_G: 0.0091 (0.0811) D(x): 0.4766 D(G(z)): 0.4734 / 0.4119 Acc: 46.8750 (34.1464)\n",
      "[12/25][740/782] Loss_D: -0.0736 (0.2052) Loss_G: -0.0582 (0.0811) D(x): 0.5459 D(G(z)): 0.4591 / 0.4321 Acc: 45.3125 (34.1475)\n",
      "[12/25][741/782] Loss_D: 0.1114 (0.2052) Loss_G: -0.0802 (0.0811) D(x): 0.4963 D(G(z)): 0.5278 / 0.4387 Acc: 50.0000 (34.1491)\n",
      "[12/25][742/782] Loss_D: -0.0627 (0.2051) Loss_G: 0.0111 (0.0811) D(x): 0.5123 D(G(z)): 0.4595 / 0.4096 Acc: 51.5625 (34.1508)\n",
      "[12/25][743/782] Loss_D: -0.1780 (0.2051) Loss_G: -0.0409 (0.0810) D(x): 0.5277 D(G(z)): 0.4552 / 0.4131 Acc: 51.5625 (34.1525)\n",
      "[12/25][744/782] Loss_D: -0.0685 (0.2051) Loss_G: -0.2649 (0.0810) D(x): 0.5086 D(G(z)): 0.4875 / 0.5122 Acc: 53.1250 (34.1544)\n",
      "[12/25][745/782] Loss_D: 0.0771 (0.2051) Loss_G: -0.2199 (0.0810) D(x): 0.5515 D(G(z)): 0.5199 / 0.4977 Acc: 42.1875 (34.1552)\n",
      "[12/25][746/782] Loss_D: -0.0548 (0.2050) Loss_G: -0.1622 (0.0810) D(x): 0.5228 D(G(z)): 0.4788 / 0.4638 Acc: 45.3125 (34.1563)\n",
      "[12/25][747/782] Loss_D: 0.1287 (0.2050) Loss_G: -0.1096 (0.0809) D(x): 0.4521 D(G(z)): 0.5130 / 0.4465 Acc: 50.0000 (34.1579)\n",
      "[12/25][748/782] Loss_D: 0.0712 (0.2050) Loss_G: -0.1253 (0.0809) D(x): 0.4764 D(G(z)): 0.5071 / 0.4581 Acc: 46.8750 (34.1591)\n",
      "[12/25][749/782] Loss_D: 0.0108 (0.2050) Loss_G: -0.0434 (0.0809) D(x): 0.5217 D(G(z)): 0.4798 / 0.4260 Acc: 46.8750 (34.1604)\n",
      "[12/25][750/782] Loss_D: 0.0531 (0.2050) Loss_G: -0.2863 (0.0809) D(x): 0.4575 D(G(z)): 0.4828 / 0.5163 Acc: 48.4375 (34.1618)\n",
      "[12/25][751/782] Loss_D: -0.1750 (0.2049) Loss_G: -0.1489 (0.0808) D(x): 0.5381 D(G(z)): 0.4134 / 0.4695 Acc: 45.3125 (34.1629)\n",
      "[12/25][752/782] Loss_D: 0.0102 (0.2049) Loss_G: -0.1109 (0.0808) D(x): 0.5551 D(G(z)): 0.4833 / 0.4693 Acc: 39.0625 (34.1634)\n",
      "[12/25][753/782] Loss_D: -0.2446 (0.2049) Loss_G: 0.1454 (0.0808) D(x): 0.6108 D(G(z)): 0.4575 / 0.3590 Acc: 43.7500 (34.1643)\n",
      "[12/25][754/782] Loss_D: -0.2484 (0.2048) Loss_G: -0.0627 (0.0808) D(x): 0.5069 D(G(z)): 0.3881 / 0.4265 Acc: 48.4375 (34.1657)\n",
      "[12/25][755/782] Loss_D: -0.2911 (0.2048) Loss_G: -0.1922 (0.0808) D(x): 0.5494 D(G(z)): 0.3909 / 0.4787 Acc: 53.1250 (34.1676)\n",
      "[12/25][756/782] Loss_D: 0.0070 (0.2048) Loss_G: 0.0051 (0.0808) D(x): 0.5822 D(G(z)): 0.5193 / 0.4075 Acc: 40.6250 (34.1682)\n",
      "[12/25][757/782] Loss_D: -0.0449 (0.2047) Loss_G: -0.1016 (0.0808) D(x): 0.5248 D(G(z)): 0.4325 / 0.4447 Acc: 35.9375 (34.1684)\n",
      "[12/25][758/782] Loss_D: -0.0799 (0.2047) Loss_G: -0.0372 (0.0808) D(x): 0.6081 D(G(z)): 0.4961 / 0.4233 Acc: 42.1875 (34.1692)\n",
      "[12/25][759/782] Loss_D: -0.1388 (0.2047) Loss_G: -0.0390 (0.0807) D(x): 0.5258 D(G(z)): 0.4158 / 0.4234 Acc: 46.8750 (34.1704)\n",
      "[12/25][760/782] Loss_D: -0.1946 (0.2046) Loss_G: -0.1459 (0.0807) D(x): 0.4972 D(G(z)): 0.3828 / 0.4630 Acc: 45.3125 (34.1715)\n",
      "[12/25][761/782] Loss_D: -0.1140 (0.2046) Loss_G: -0.0841 (0.0807) D(x): 0.5875 D(G(z)): 0.4830 / 0.4458 Acc: 42.1875 (34.1723)\n",
      "[12/25][762/782] Loss_D: 0.0346 (0.2046) Loss_G: 0.0021 (0.0807) D(x): 0.5113 D(G(z)): 0.4846 / 0.4007 Acc: 43.7500 (34.1733)\n",
      "[12/25][763/782] Loss_D: 0.0730 (0.2046) Loss_G: -0.0920 (0.0807) D(x): 0.4974 D(G(z)): 0.4914 / 0.4487 Acc: 40.6250 (34.1739)\n",
      "[12/25][764/782] Loss_D: -0.0616 (0.2046) Loss_G: -0.1961 (0.0807) D(x): 0.5250 D(G(z)): 0.4420 / 0.4957 Acc: 40.6250 (34.1745)\n",
      "[12/25][765/782] Loss_D: 0.0031 (0.2045) Loss_G: -0.1522 (0.0806) D(x): 0.4711 D(G(z)): 0.4519 / 0.4681 Acc: 48.4375 (34.1760)\n",
      "[12/25][766/782] Loss_D: 0.0045 (0.2045) Loss_G: -0.0135 (0.0806) D(x): 0.5730 D(G(z)): 0.4850 / 0.4232 Acc: 35.9375 (34.1761)\n",
      "[12/25][767/782] Loss_D: -0.0803 (0.2045) Loss_G: -0.1747 (0.0806) D(x): 0.5160 D(G(z)): 0.4770 / 0.4856 Acc: 54.6875 (34.1781)\n",
      "[12/25][768/782] Loss_D: 0.0056 (0.2045) Loss_G: -0.2068 (0.0806) D(x): 0.5256 D(G(z)): 0.4779 / 0.4715 Acc: 39.0625 (34.1786)\n",
      "[12/25][769/782] Loss_D: -0.0685 (0.2044) Loss_G: -0.2080 (0.0805) D(x): 0.5155 D(G(z)): 0.4951 / 0.4800 Acc: 48.4375 (34.1800)\n",
      "[12/25][770/782] Loss_D: -0.0607 (0.2044) Loss_G: -0.0966 (0.0805) D(x): 0.5587 D(G(z)): 0.4406 / 0.4392 Acc: 34.3750 (34.1801)\n",
      "[12/25][771/782] Loss_D: 0.1199 (0.2044) Loss_G: -0.1022 (0.0805) D(x): 0.5376 D(G(z)): 0.5146 / 0.4444 Acc: 32.8125 (34.1799)\n",
      "[12/25][772/782] Loss_D: 0.0681 (0.2044) Loss_G: -0.0134 (0.0805) D(x): 0.5174 D(G(z)): 0.5297 / 0.4141 Acc: 48.4375 (34.1813)\n",
      "[12/25][773/782] Loss_D: 0.2045 (0.2044) Loss_G: -0.1199 (0.0805) D(x): 0.4107 D(G(z)): 0.4843 / 0.4619 Acc: 53.1250 (34.1832)\n",
      "[12/25][774/782] Loss_D: 0.0314 (0.2044) Loss_G: -0.2049 (0.0804) D(x): 0.5056 D(G(z)): 0.4984 / 0.4898 Acc: 50.0000 (34.1847)\n",
      "[12/25][775/782] Loss_D: -0.1096 (0.2043) Loss_G: -0.1332 (0.0804) D(x): 0.5658 D(G(z)): 0.4862 / 0.4503 Acc: 45.3125 (34.1858)\n",
      "[12/25][776/782] Loss_D: -0.0680 (0.2043) Loss_G: -0.1642 (0.0804) D(x): 0.5476 D(G(z)): 0.4797 / 0.4618 Acc: 48.4375 (34.1872)\n",
      "[12/25][777/782] Loss_D: -0.0547 (0.2043) Loss_G: -0.1134 (0.0804) D(x): 0.5624 D(G(z)): 0.5210 / 0.4607 Acc: 48.4375 (34.1886)\n",
      "[12/25][778/782] Loss_D: -0.0231 (0.2043) Loss_G: -0.2753 (0.0803) D(x): 0.5487 D(G(z)): 0.4814 / 0.5341 Acc: 43.7500 (34.1896)\n",
      "[12/25][779/782] Loss_D: -0.0847 (0.2042) Loss_G: -0.1746 (0.0803) D(x): 0.5055 D(G(z)): 0.4536 / 0.4845 Acc: 51.5625 (34.1913)\n",
      "[12/25][780/782] Loss_D: -0.0725 (0.2042) Loss_G: -0.2830 (0.0803) D(x): 0.5463 D(G(z)): 0.5004 / 0.5222 Acc: 51.5625 (34.1930)\n",
      "[12/25][781/782] Loss_D: 0.0725 (0.2042) Loss_G: 0.0406 (0.0803) D(x): 0.5604 D(G(z)): 0.5358 / 0.4076 Acc: 62.5000 (34.1958)\n",
      "[13/25][0/782] Loss_D: -0.0300 (0.2042) Loss_G: -0.0344 (0.0803) D(x): 0.5328 D(G(z)): 0.4530 / 0.4128 Acc: 42.1875 (34.1966)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[13/25][1/782] Loss_D: -0.0656 (0.2041) Loss_G: -0.2535 (0.0802) D(x): 0.5610 D(G(z)): 0.4899 / 0.5135 Acc: 48.4375 (34.1980)\n",
      "[13/25][2/782] Loss_D: -0.1278 (0.2041) Loss_G: -0.0595 (0.0802) D(x): 0.6226 D(G(z)): 0.4925 / 0.4369 Acc: 42.1875 (34.1988)\n",
      "[13/25][3/782] Loss_D: 0.0595 (0.2041) Loss_G: 0.0552 (0.0802) D(x): 0.5103 D(G(z)): 0.4574 / 0.3814 Acc: 40.6250 (34.1994)\n",
      "[13/25][4/782] Loss_D: 0.0311 (0.2041) Loss_G: -0.0614 (0.0802) D(x): 0.5051 D(G(z)): 0.3905 / 0.4339 Acc: 34.3750 (34.1994)\n",
      "[13/25][5/782] Loss_D: -0.1813 (0.2040) Loss_G: -0.2259 (0.0802) D(x): 0.5581 D(G(z)): 0.4569 / 0.4910 Acc: 53.1250 (34.2013)\n",
      "[13/25][6/782] Loss_D: -0.1814 (0.2040) Loss_G: -0.1931 (0.0801) D(x): 0.5909 D(G(z)): 0.5109 / 0.4971 Acc: 54.6875 (34.2033)\n",
      "[13/25][7/782] Loss_D: 0.0370 (0.2040) Loss_G: -0.0225 (0.0801) D(x): 0.5287 D(G(z)): 0.5231 / 0.4189 Acc: 45.3125 (34.2044)\n",
      "[13/25][8/782] Loss_D: -0.0910 (0.2040) Loss_G: -0.2171 (0.0801) D(x): 0.4816 D(G(z)): 0.4118 / 0.5012 Acc: 50.0000 (34.2059)\n",
      "[13/25][9/782] Loss_D: -0.0845 (0.2039) Loss_G: -0.1448 (0.0801) D(x): 0.5646 D(G(z)): 0.5026 / 0.4708 Acc: 48.4375 (34.2073)\n",
      "[13/25][10/782] Loss_D: -0.0908 (0.2039) Loss_G: 0.0311 (0.0801) D(x): 0.5382 D(G(z)): 0.4673 / 0.3990 Acc: 43.7500 (34.2083)\n",
      "[13/25][11/782] Loss_D: 0.1546 (0.2039) Loss_G: 0.0768 (0.0801) D(x): 0.4578 D(G(z)): 0.4591 / 0.3654 Acc: 32.8125 (34.2081)\n",
      "[13/25][12/782] Loss_D: 0.0944 (0.2039) Loss_G: -0.0406 (0.0801) D(x): 0.4489 D(G(z)): 0.4503 / 0.4302 Acc: 43.7500 (34.2091)\n",
      "[13/25][13/782] Loss_D: -0.1558 (0.2039) Loss_G: -0.2467 (0.0800) D(x): 0.5033 D(G(z)): 0.4435 / 0.4967 Acc: 53.1250 (34.2109)\n",
      "[13/25][14/782] Loss_D: -0.0583 (0.2038) Loss_G: -0.1345 (0.0800) D(x): 0.5838 D(G(z)): 0.4803 / 0.4549 Acc: 34.3750 (34.2109)\n",
      "[13/25][15/782] Loss_D: -0.0604 (0.2038) Loss_G: -0.1186 (0.0800) D(x): 0.5496 D(G(z)): 0.4791 / 0.4585 Acc: 42.1875 (34.2117)\n",
      "[13/25][16/782] Loss_D: 0.0042 (0.2038) Loss_G: -0.0595 (0.0800) D(x): 0.5225 D(G(z)): 0.4835 / 0.4216 Acc: 42.1875 (34.2125)\n",
      "[13/25][17/782] Loss_D: -0.0539 (0.2038) Loss_G: -0.0977 (0.0800) D(x): 0.4920 D(G(z)): 0.4618 / 0.4527 Acc: 50.0000 (34.2141)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/25][18/782] Loss_D: -0.0906 (0.2037) Loss_G: -0.1415 (0.0799) D(x): 0.5153 D(G(z)): 0.4383 / 0.4450 Acc: 43.7500 (34.2150)\n",
      "[13/25][19/782] Loss_D: -0.1984 (0.2037) Loss_G: -0.0543 (0.0799) D(x): 0.5424 D(G(z)): 0.4843 / 0.4175 Acc: 59.3750 (34.2175)\n",
      "[13/25][20/782] Loss_D: 0.0251 (0.2037) Loss_G: -0.2032 (0.0799) D(x): 0.5101 D(G(z)): 0.5011 / 0.4772 Acc: 48.4375 (34.2189)\n",
      "[13/25][21/782] Loss_D: -0.1204 (0.2036) Loss_G: -0.0454 (0.0799) D(x): 0.5665 D(G(z)): 0.4473 / 0.4090 Acc: 39.0625 (34.2193)\n",
      "[13/25][22/782] Loss_D: -0.0957 (0.2036) Loss_G: 0.1477 (0.0799) D(x): 0.4899 D(G(z)): 0.4253 / 0.3582 Acc: 46.8750 (34.2206)\n",
      "[13/25][23/782] Loss_D: -0.2114 (0.2036) Loss_G: -0.1291 (0.0799) D(x): 0.5432 D(G(z)): 0.4088 / 0.4577 Acc: 43.7500 (34.2215)\n",
      "[13/25][24/782] Loss_D: -0.0836 (0.2035) Loss_G: -0.1817 (0.0799) D(x): 0.5816 D(G(z)): 0.4818 / 0.4879 Acc: 42.1875 (34.2223)\n",
      "[13/25][25/782] Loss_D: -0.2355 (0.2035) Loss_G: -0.0500 (0.0798) D(x): 0.5590 D(G(z)): 0.4530 / 0.4112 Acc: 46.8750 (34.2235)\n",
      "[13/25][26/782] Loss_D: -0.1746 (0.2035) Loss_G: 0.0791 (0.0798) D(x): 0.5862 D(G(z)): 0.4701 / 0.4033 Acc: 51.5625 (34.2252)\n",
      "[13/25][27/782] Loss_D: -0.2421 (0.2034) Loss_G: -0.0351 (0.0798) D(x): 0.5332 D(G(z)): 0.4011 / 0.4110 Acc: 45.3125 (34.2263)\n",
      "[13/25][28/782] Loss_D: -0.2014 (0.2034) Loss_G: -0.0715 (0.0798) D(x): 0.5104 D(G(z)): 0.4526 / 0.4184 Acc: 57.8125 (34.2286)\n",
      "[13/25][29/782] Loss_D: -0.1624 (0.2033) Loss_G: -0.1305 (0.0798) D(x): 0.5080 D(G(z)): 0.4281 / 0.4477 Acc: 50.0000 (34.2302)\n",
      "[13/25][30/782] Loss_D: 0.0181 (0.2033) Loss_G: -0.1306 (0.0798) D(x): 0.5701 D(G(z)): 0.5196 / 0.4634 Acc: 40.6250 (34.2308)\n",
      "[13/25][31/782] Loss_D: -0.2371 (0.2033) Loss_G: -0.1053 (0.0798) D(x): 0.5475 D(G(z)): 0.4690 / 0.4388 Acc: 57.8125 (34.2331)\n",
      "[13/25][32/782] Loss_D: -0.0438 (0.2033) Loss_G: -0.0710 (0.0797) D(x): 0.5432 D(G(z)): 0.4856 / 0.4505 Acc: 39.0625 (34.2336)\n",
      "[13/25][33/782] Loss_D: -0.0296 (0.2032) Loss_G: -0.0794 (0.0797) D(x): 0.5321 D(G(z)): 0.4676 / 0.4266 Acc: 40.6250 (34.2342)\n",
      "[13/25][34/782] Loss_D: 0.0097 (0.2032) Loss_G: -0.1421 (0.0797) D(x): 0.5681 D(G(z)): 0.5278 / 0.4614 Acc: 42.1875 (34.2350)\n",
      "[13/25][35/782] Loss_D: -0.2312 (0.2032) Loss_G: -0.0801 (0.0797) D(x): 0.5053 D(G(z)): 0.4087 / 0.4457 Acc: 51.5625 (34.2367)\n",
      "[13/25][36/782] Loss_D: -0.0703 (0.2031) Loss_G: -0.0261 (0.0797) D(x): 0.5319 D(G(z)): 0.5082 / 0.4053 Acc: 48.4375 (34.2381)\n",
      "[13/25][37/782] Loss_D: -0.1629 (0.2031) Loss_G: -0.0519 (0.0797) D(x): 0.5080 D(G(z)): 0.4174 / 0.4341 Acc: 48.4375 (34.2395)\n",
      "[13/25][38/782] Loss_D: -0.2240 (0.2031) Loss_G: -0.2139 (0.0796) D(x): 0.4978 D(G(z)): 0.4328 / 0.5049 Acc: 60.9375 (34.2421)\n",
      "[13/25][39/782] Loss_D: 0.1253 (0.2031) Loss_G: -0.2588 (0.0796) D(x): 0.5368 D(G(z)): 0.5468 / 0.5125 Acc: 43.7500 (34.2430)\n",
      "[13/25][40/782] Loss_D: -0.0372 (0.2030) Loss_G: -0.0753 (0.0796) D(x): 0.5250 D(G(z)): 0.5195 / 0.4594 Acc: 51.5625 (34.2447)\n",
      "[13/25][41/782] Loss_D: -0.1168 (0.2030) Loss_G: -0.0033 (0.0796) D(x): 0.5769 D(G(z)): 0.5190 / 0.4140 Acc: 48.4375 (34.2461)\n",
      "[13/25][42/782] Loss_D: -0.0986 (0.2030) Loss_G: -0.0326 (0.0796) D(x): 0.4943 D(G(z)): 0.4403 / 0.4127 Acc: 46.8750 (34.2474)\n",
      "[13/25][43/782] Loss_D: 0.0429 (0.2030) Loss_G: -0.1606 (0.0795) D(x): 0.4968 D(G(z)): 0.4759 / 0.4506 Acc: 39.0625 (34.2478)\n",
      "[13/25][44/782] Loss_D: 0.1701 (0.2030) Loss_G: -0.1342 (0.0795) D(x): 0.4817 D(G(z)): 0.4678 / 0.4827 Acc: 37.5000 (34.2481)\n",
      "[13/25][45/782] Loss_D: -0.0608 (0.2029) Loss_G: -0.2889 (0.0795) D(x): 0.5456 D(G(z)): 0.5204 / 0.5275 Acc: 50.0000 (34.2497)\n",
      "[13/25][46/782] Loss_D: 0.0199 (0.2029) Loss_G: -0.1132 (0.0795) D(x): 0.5049 D(G(z)): 0.4604 / 0.4484 Acc: 43.7500 (34.2506)\n",
      "[13/25][47/782] Loss_D: -0.0592 (0.2029) Loss_G: -0.1363 (0.0794) D(x): 0.5215 D(G(z)): 0.4486 / 0.4525 Acc: 37.5000 (34.2509)\n",
      "[13/25][48/782] Loss_D: 0.0262 (0.2029) Loss_G: -0.1273 (0.0794) D(x): 0.5101 D(G(z)): 0.4803 / 0.4517 Acc: 39.0625 (34.2514)\n",
      "[13/25][49/782] Loss_D: 0.0229 (0.2029) Loss_G: -0.0783 (0.0794) D(x): 0.5066 D(G(z)): 0.4770 / 0.4245 Acc: 43.7500 (34.2523)\n",
      "[13/25][50/782] Loss_D: -0.0953 (0.2028) Loss_G: -0.1732 (0.0794) D(x): 0.5268 D(G(z)): 0.4371 / 0.4799 Acc: 45.3125 (34.2534)\n",
      "[13/25][51/782] Loss_D: -0.1319 (0.2028) Loss_G: -0.1072 (0.0794) D(x): 0.5501 D(G(z)): 0.4513 / 0.4476 Acc: 40.6250 (34.2540)\n",
      "[13/25][52/782] Loss_D: -0.2267 (0.2027) Loss_G: 0.0735 (0.0794) D(x): 0.5513 D(G(z)): 0.4304 / 0.3898 Acc: 53.1250 (34.2559)\n",
      "[13/25][53/782] Loss_D: -0.1405 (0.2027) Loss_G: -0.1318 (0.0793) D(x): 0.5380 D(G(z)): 0.4615 / 0.4542 Acc: 54.6875 (34.2579)\n",
      "[13/25][54/782] Loss_D: -0.1222 (0.2027) Loss_G: -0.0720 (0.0793) D(x): 0.5206 D(G(z)): 0.4430 / 0.4354 Acc: 48.4375 (34.2593)\n",
      "[13/25][55/782] Loss_D: 0.0908 (0.2027) Loss_G: -0.1032 (0.0793) D(x): 0.5172 D(G(z)): 0.4977 / 0.4474 Acc: 40.6250 (34.2599)\n",
      "[13/25][56/782] Loss_D: -0.2202 (0.2026) Loss_G: -0.0317 (0.0793) D(x): 0.5941 D(G(z)): 0.4753 / 0.4133 Acc: 48.4375 (34.2613)\n",
      "[13/25][57/782] Loss_D: -0.1743 (0.2026) Loss_G: 0.0075 (0.0793) D(x): 0.5774 D(G(z)): 0.4807 / 0.4020 Acc: 46.8750 (34.2625)\n",
      "[13/25][58/782] Loss_D: -0.1445 (0.2026) Loss_G: -0.0899 (0.0793) D(x): 0.5048 D(G(z)): 0.3991 / 0.4306 Acc: 48.4375 (34.2639)\n",
      "[13/25][59/782] Loss_D: -0.2305 (0.2025) Loss_G: 0.0824 (0.0793) D(x): 0.6002 D(G(z)): 0.4568 / 0.3845 Acc: 48.4375 (34.2653)\n",
      "[13/25][60/782] Loss_D: -0.1638 (0.2025) Loss_G: -0.0640 (0.0793) D(x): 0.5457 D(G(z)): 0.4586 / 0.4293 Acc: 46.8750 (34.2665)\n",
      "[13/25][61/782] Loss_D: -0.0970 (0.2025) Loss_G: -0.0583 (0.0793) D(x): 0.5035 D(G(z)): 0.4624 / 0.4301 Acc: 51.5625 (34.2682)\n",
      "[13/25][62/782] Loss_D: 0.1948 (0.2025) Loss_G: -0.3032 (0.0792) D(x): 0.4641 D(G(z)): 0.5054 / 0.5236 Acc: 40.6250 (34.2688)\n",
      "[13/25][63/782] Loss_D: 0.0953 (0.2024) Loss_G: -0.2314 (0.0792) D(x): 0.5312 D(G(z)): 0.5292 / 0.4887 Acc: 43.7500 (34.2698)\n",
      "[13/25][64/782] Loss_D: 0.0698 (0.2024) Loss_G: 0.0021 (0.0792) D(x): 0.5164 D(G(z)): 0.4839 / 0.3905 Acc: 35.9375 (34.2699)\n",
      "[13/25][65/782] Loss_D: -0.0432 (0.2024) Loss_G: -0.1189 (0.0792) D(x): 0.5033 D(G(z)): 0.4703 / 0.4573 Acc: 46.8750 (34.2712)\n",
      "[13/25][66/782] Loss_D: 0.0165 (0.2024) Loss_G: -0.1399 (0.0791) D(x): 0.4709 D(G(z)): 0.4734 / 0.4571 Acc: 46.8750 (34.2724)\n",
      "[13/25][67/782] Loss_D: 0.0188 (0.2024) Loss_G: -0.1522 (0.0791) D(x): 0.4961 D(G(z)): 0.4952 / 0.4526 Acc: 50.0000 (34.2739)\n",
      "[13/25][68/782] Loss_D: -0.1345 (0.2023) Loss_G: -0.0524 (0.0791) D(x): 0.5676 D(G(z)): 0.4574 / 0.4559 Acc: 43.7500 (34.2749)\n",
      "[13/25][69/782] Loss_D: -0.2368 (0.2023) Loss_G: -0.0466 (0.0791) D(x): 0.5258 D(G(z)): 0.4224 / 0.4482 Acc: 54.6875 (34.2768)\n",
      "[13/25][70/782] Loss_D: -0.0451 (0.2023) Loss_G: -0.2117 (0.0791) D(x): 0.5499 D(G(z)): 0.5107 / 0.4870 Acc: 43.7500 (34.2778)\n",
      "[13/25][71/782] Loss_D: -0.1840 (0.2022) Loss_G: -0.1155 (0.0790) D(x): 0.5619 D(G(z)): 0.4786 / 0.4343 Acc: 46.8750 (34.2790)\n",
      "[13/25][72/782] Loss_D: -0.0922 (0.2022) Loss_G: -0.1097 (0.0790) D(x): 0.4855 D(G(z)): 0.4488 / 0.4382 Acc: 53.1250 (34.2808)\n",
      "[13/25][73/782] Loss_D: -0.3014 (0.2022) Loss_G: -0.1507 (0.0790) D(x): 0.5418 D(G(z)): 0.4460 / 0.4513 Acc: 59.3750 (34.2833)\n",
      "[13/25][74/782] Loss_D: -0.2120 (0.2021) Loss_G: 0.0028 (0.0790) D(x): 0.6000 D(G(z)): 0.4761 / 0.4024 Acc: 45.3125 (34.2844)\n",
      "[13/25][75/782] Loss_D: 0.1228 (0.2021) Loss_G: -0.0883 (0.0790) D(x): 0.5159 D(G(z)): 0.4436 / 0.4467 Acc: 20.3125 (34.2830)\n",
      "[13/25][76/782] Loss_D: -0.1089 (0.2021) Loss_G: -0.1725 (0.0790) D(x): 0.4981 D(G(z)): 0.4583 / 0.4797 Acc: 56.2500 (34.2852)\n",
      "[13/25][77/782] Loss_D: -0.0039 (0.2021) Loss_G: -0.1405 (0.0789) D(x): 0.5515 D(G(z)): 0.4813 / 0.4749 Acc: 35.9375 (34.2853)\n",
      "[13/25][78/782] Loss_D: -0.1464 (0.2020) Loss_G: -0.0275 (0.0789) D(x): 0.5570 D(G(z)): 0.4871 / 0.4160 Acc: 48.4375 (34.2867)\n",
      "[13/25][79/782] Loss_D: -0.0664 (0.2020) Loss_G: -0.2569 (0.0789) D(x): 0.5101 D(G(z)): 0.4318 / 0.5016 Acc: 40.6250 (34.2873)\n",
      "[13/25][80/782] Loss_D: 0.0072 (0.2020) Loss_G: -0.2801 (0.0789) D(x): 0.5776 D(G(z)): 0.5488 / 0.5137 Acc: 45.3125 (34.2884)\n",
      "[13/25][81/782] Loss_D: -0.1788 (0.2019) Loss_G: 0.2381 (0.0789) D(x): 0.5696 D(G(z)): 0.4785 / 0.3241 Acc: 48.4375 (34.2898)\n",
      "[13/25][82/782] Loss_D: -0.2014 (0.2019) Loss_G: -0.1184 (0.0788) D(x): 0.5210 D(G(z)): 0.4348 / 0.4542 Acc: 51.5625 (34.2915)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/25][83/782] Loss_D: -0.1988 (0.2019) Loss_G: -0.2256 (0.0788) D(x): 0.4862 D(G(z)): 0.4084 / 0.4969 Acc: 53.1250 (34.2933)\n",
      "[13/25][84/782] Loss_D: 0.0134 (0.2018) Loss_G: -0.2556 (0.0788) D(x): 0.5129 D(G(z)): 0.5059 / 0.5147 Acc: 48.4375 (34.2947)\n",
      "[13/25][85/782] Loss_D: 0.0250 (0.2018) Loss_G: -0.1289 (0.0788) D(x): 0.5200 D(G(z)): 0.4946 / 0.4577 Acc: 45.3125 (34.2957)\n",
      "[13/25][86/782] Loss_D: -0.1761 (0.2018) Loss_G: -0.1875 (0.0787) D(x): 0.5906 D(G(z)): 0.4961 / 0.4715 Acc: 46.8750 (34.2970)\n",
      "[13/25][87/782] Loss_D: -0.0699 (0.2018) Loss_G: -0.0885 (0.0787) D(x): 0.5315 D(G(z)): 0.4567 / 0.4474 Acc: 40.6250 (34.2976)\n",
      "[13/25][88/782] Loss_D: -0.0485 (0.2017) Loss_G: -0.2046 (0.0787) D(x): 0.5229 D(G(z)): 0.4683 / 0.4783 Acc: 48.4375 (34.2990)\n",
      "[13/25][89/782] Loss_D: 0.0125 (0.2017) Loss_G: -0.1333 (0.0787) D(x): 0.5068 D(G(z)): 0.4556 / 0.4524 Acc: 45.3125 (34.3000)\n",
      "[13/25][90/782] Loss_D: -0.0989 (0.2017) Loss_G: -0.1987 (0.0786) D(x): 0.4911 D(G(z)): 0.4757 / 0.4705 Acc: 53.1250 (34.3019)\n",
      "[13/25][91/782] Loss_D: -0.0245 (0.2017) Loss_G: -0.1755 (0.0786) D(x): 0.5827 D(G(z)): 0.5165 / 0.4819 Acc: 39.0625 (34.3023)\n",
      "[13/25][92/782] Loss_D: -0.1364 (0.2016) Loss_G: -0.0914 (0.0786) D(x): 0.5446 D(G(z)): 0.4674 / 0.4306 Acc: 46.8750 (34.3036)\n",
      "[13/25][93/782] Loss_D: -0.1173 (0.2016) Loss_G: -0.0945 (0.0786) D(x): 0.5580 D(G(z)): 0.4628 / 0.4368 Acc: 42.1875 (34.3043)\n",
      "[13/25][94/782] Loss_D: -0.1526 (0.2016) Loss_G: -0.1647 (0.0786) D(x): 0.5246 D(G(z)): 0.4264 / 0.4664 Acc: 42.1875 (34.3051)\n",
      "[13/25][95/782] Loss_D: -0.2066 (0.2015) Loss_G: 0.0576 (0.0786) D(x): 0.6094 D(G(z)): 0.4650 / 0.3926 Acc: 40.6250 (34.3057)\n",
      "[13/25][96/782] Loss_D: -0.0478 (0.2015) Loss_G: 0.0387 (0.0786) D(x): 0.5447 D(G(z)): 0.5037 / 0.3790 Acc: 45.3125 (34.3068)\n",
      "[13/25][97/782] Loss_D: -0.0390 (0.2015) Loss_G: -0.0355 (0.0785) D(x): 0.4748 D(G(z)): 0.3946 / 0.4159 Acc: 39.0625 (34.3073)\n",
      "[13/25][98/782] Loss_D: 0.1250 (0.2015) Loss_G: -0.1862 (0.0785) D(x): 0.5264 D(G(z)): 0.5210 / 0.4640 Acc: 39.0625 (34.3077)\n",
      "[13/25][99/782] Loss_D: -0.0710 (0.2014) Loss_G: -0.0989 (0.0785) D(x): 0.5454 D(G(z)): 0.4601 / 0.4334 Acc: 39.0625 (34.3082)\n",
      "[13/25][100/782] Loss_D: -0.1686 (0.2014) Loss_G: -0.1071 (0.0785) D(x): 0.6115 D(G(z)): 0.5056 / 0.4543 Acc: 46.8750 (34.3094)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[13/25][101/782] Loss_D: -0.0918 (0.2014) Loss_G: -0.0074 (0.0785) D(x): 0.4979 D(G(z)): 0.4181 / 0.4137 Acc: 40.6250 (34.3100)\n",
      "[13/25][102/782] Loss_D: -0.0712 (0.2014) Loss_G: 0.1060 (0.0785) D(x): 0.5011 D(G(z)): 0.4577 / 0.3663 Acc: 46.8750 (34.3112)\n",
      "[13/25][103/782] Loss_D: -0.1209 (0.2013) Loss_G: -0.1249 (0.0785) D(x): 0.4894 D(G(z)): 0.4370 / 0.4613 Acc: 54.6875 (34.3132)\n",
      "[13/25][104/782] Loss_D: 0.0379 (0.2013) Loss_G: -0.1327 (0.0784) D(x): 0.5150 D(G(z)): 0.4907 / 0.4503 Acc: 50.0000 (34.3148)\n",
      "[13/25][105/782] Loss_D: -0.0949 (0.2013) Loss_G: -0.1766 (0.0784) D(x): 0.5690 D(G(z)): 0.4960 / 0.4701 Acc: 42.1875 (34.3155)\n",
      "[13/25][106/782] Loss_D: -0.0908 (0.2013) Loss_G: 0.0851 (0.0784) D(x): 0.5888 D(G(z)): 0.5280 / 0.3783 Acc: 46.8750 (34.3167)\n",
      "[13/25][107/782] Loss_D: -0.0317 (0.2012) Loss_G: 0.0146 (0.0784) D(x): 0.5365 D(G(z)): 0.4481 / 0.3926 Acc: 39.0625 (34.3172)\n",
      "[13/25][108/782] Loss_D: 0.1060 (0.2012) Loss_G: -0.0895 (0.0784) D(x): 0.4191 D(G(z)): 0.4187 / 0.4345 Acc: 48.4375 (34.3186)\n",
      "[13/25][109/782] Loss_D: -0.0350 (0.2012) Loss_G: -0.3333 (0.0784) D(x): 0.4823 D(G(z)): 0.4001 / 0.5607 Acc: 40.6250 (34.3192)\n",
      "[13/25][110/782] Loss_D: -0.0160 (0.2012) Loss_G: -0.2823 (0.0783) D(x): 0.5207 D(G(z)): 0.5008 / 0.5204 Acc: 46.8750 (34.3204)\n",
      "[13/25][111/782] Loss_D: -0.0495 (0.2012) Loss_G: -0.2666 (0.0783) D(x): 0.5526 D(G(z)): 0.5129 / 0.5052 Acc: 50.0000 (34.3219)\n",
      "[13/25][112/782] Loss_D: 0.0414 (0.2011) Loss_G: 0.0880 (0.0783) D(x): 0.5488 D(G(z)): 0.5561 / 0.3934 Acc: 54.6875 (34.3239)\n",
      "[13/25][113/782] Loss_D: -0.1415 (0.2011) Loss_G: -0.0437 (0.0783) D(x): 0.5549 D(G(z)): 0.4444 / 0.4209 Acc: 42.1875 (34.3247)\n",
      "[13/25][114/782] Loss_D: -0.0588 (0.2011) Loss_G: -0.0289 (0.0783) D(x): 0.5332 D(G(z)): 0.4434 / 0.4240 Acc: 42.1875 (34.3255)\n",
      "[13/25][115/782] Loss_D: -0.1828 (0.2010) Loss_G: -0.1578 (0.0782) D(x): 0.4918 D(G(z)): 0.4192 / 0.4710 Acc: 54.6875 (34.3274)\n",
      "[13/25][116/782] Loss_D: -0.1887 (0.2010) Loss_G: -0.2011 (0.0782) D(x): 0.5408 D(G(z)): 0.4033 / 0.4887 Acc: 43.7500 (34.3284)\n",
      "[13/25][117/782] Loss_D: -0.3842 (0.2009) Loss_G: -0.2566 (0.0782) D(x): 0.5941 D(G(z)): 0.4168 / 0.5163 Acc: 53.1250 (34.3302)\n",
      "[13/25][118/782] Loss_D: -0.1379 (0.2009) Loss_G: -0.2481 (0.0782) D(x): 0.5911 D(G(z)): 0.5072 / 0.4972 Acc: 46.8750 (34.3314)\n",
      "[13/25][119/782] Loss_D: 0.0220 (0.2009) Loss_G: -0.1721 (0.0781) D(x): 0.5207 D(G(z)): 0.5085 / 0.4599 Acc: 46.8750 (34.3326)\n",
      "[13/25][120/782] Loss_D: 0.0698 (0.2009) Loss_G: -0.0406 (0.0781) D(x): 0.5337 D(G(z)): 0.5335 / 0.4226 Acc: 43.7500 (34.3335)\n",
      "[13/25][121/782] Loss_D: -0.0445 (0.2009) Loss_G: 0.0097 (0.0781) D(x): 0.5126 D(G(z)): 0.4194 / 0.4010 Acc: 39.0625 (34.3340)\n",
      "[13/25][122/782] Loss_D: 0.0387 (0.2008) Loss_G: -0.0620 (0.0781) D(x): 0.4975 D(G(z)): 0.4536 / 0.4241 Acc: 35.9375 (34.3341)\n",
      "[13/25][123/782] Loss_D: -0.1746 (0.2008) Loss_G: -0.0387 (0.0781) D(x): 0.4925 D(G(z)): 0.4150 / 0.4114 Acc: 53.1250 (34.3360)\n",
      "[13/25][124/782] Loss_D: 0.1008 (0.2008) Loss_G: -0.1841 (0.0781) D(x): 0.5292 D(G(z)): 0.5408 / 0.4747 Acc: 45.3125 (34.3370)\n",
      "[13/25][125/782] Loss_D: -0.1821 (0.2008) Loss_G: -0.1058 (0.0780) D(x): 0.5543 D(G(z)): 0.4192 / 0.4400 Acc: 45.3125 (34.3381)\n",
      "[13/25][126/782] Loss_D: 0.0057 (0.2007) Loss_G: -0.0742 (0.0780) D(x): 0.5181 D(G(z)): 0.4952 / 0.4319 Acc: 43.7500 (34.3390)\n",
      "[13/25][127/782] Loss_D: -0.0831 (0.2007) Loss_G: 0.0352 (0.0780) D(x): 0.5665 D(G(z)): 0.5041 / 0.4027 Acc: 50.0000 (34.3405)\n",
      "[13/25][128/782] Loss_D: -0.0757 (0.2007) Loss_G: -0.0762 (0.0780) D(x): 0.4981 D(G(z)): 0.4196 / 0.4219 Acc: 42.1875 (34.3413)\n",
      "[13/25][129/782] Loss_D: -0.0715 (0.2007) Loss_G: -0.0513 (0.0780) D(x): 0.5011 D(G(z)): 0.4401 / 0.4343 Acc: 46.8750 (34.3425)\n",
      "[13/25][130/782] Loss_D: -0.3218 (0.2006) Loss_G: -0.0918 (0.0780) D(x): 0.5956 D(G(z)): 0.4032 / 0.4320 Acc: 43.7500 (34.3434)\n",
      "[13/25][131/782] Loss_D: -0.3573 (0.2006) Loss_G: -0.0017 (0.0780) D(x): 0.6210 D(G(z)): 0.4524 / 0.4076 Acc: 54.6875 (34.3454)\n",
      "[13/25][132/782] Loss_D: -0.3451 (0.2005) Loss_G: -0.0076 (0.0780) D(x): 0.5744 D(G(z)): 0.4659 / 0.4006 Acc: 59.3750 (34.3478)\n",
      "[13/25][133/782] Loss_D: 0.1274 (0.2005) Loss_G: -0.0189 (0.0780) D(x): 0.4404 D(G(z)): 0.4795 / 0.4133 Acc: 45.3125 (34.3489)\n",
      "[13/25][134/782] Loss_D: 0.0949 (0.2005) Loss_G: -0.2769 (0.0779) D(x): 0.4837 D(G(z)): 0.4608 / 0.5164 Acc: 39.0625 (34.3494)\n",
      "[13/25][135/782] Loss_D: 0.1002 (0.2005) Loss_G: -0.2600 (0.0779) D(x): 0.5185 D(G(z)): 0.5036 / 0.5059 Acc: 40.6250 (34.3500)\n",
      "[13/25][136/782] Loss_D: -0.0472 (0.2004) Loss_G: -0.1986 (0.0779) D(x): 0.5872 D(G(z)): 0.5512 / 0.4973 Acc: 51.5625 (34.3516)\n",
      "[13/25][137/782] Loss_D: 0.0040 (0.2004) Loss_G: -0.1303 (0.0778) D(x): 0.4833 D(G(z)): 0.4620 / 0.4657 Acc: 45.3125 (34.3527)\n",
      "[13/25][138/782] Loss_D: -0.0640 (0.2004) Loss_G: -0.1020 (0.0778) D(x): 0.5334 D(G(z)): 0.4563 / 0.4396 Acc: 43.7500 (34.3536)\n",
      "[13/25][139/782] Loss_D: -0.0115 (0.2004) Loss_G: 0.0613 (0.0778) D(x): 0.5337 D(G(z)): 0.4608 / 0.3843 Acc: 42.1875 (34.3544)\n",
      "[13/25][140/782] Loss_D: -0.2282 (0.2003) Loss_G: -0.0889 (0.0778) D(x): 0.5273 D(G(z)): 0.4349 / 0.4523 Acc: 53.1250 (34.3562)\n",
      "[13/25][141/782] Loss_D: -0.0549 (0.2003) Loss_G: -0.1268 (0.0778) D(x): 0.5031 D(G(z)): 0.4420 / 0.4503 Acc: 43.7500 (34.3571)\n",
      "[13/25][142/782] Loss_D: -0.1015 (0.2003) Loss_G: -0.3237 (0.0777) D(x): 0.5895 D(G(z)): 0.4946 / 0.5272 Acc: 43.7500 (34.3580)\n",
      "[13/25][143/782] Loss_D: 0.2465 (0.2003) Loss_G: -0.1097 (0.0777) D(x): 0.5553 D(G(z)): 0.5335 / 0.4456 Acc: 25.0000 (34.3571)\n",
      "[13/25][144/782] Loss_D: 0.1740 (0.2003) Loss_G: -0.0877 (0.0777) D(x): 0.4590 D(G(z)): 0.4903 / 0.4428 Acc: 45.3125 (34.3582)\n",
      "[13/25][145/782] Loss_D: -0.1312 (0.2003) Loss_G: -0.1514 (0.0777) D(x): 0.5294 D(G(z)): 0.4664 / 0.4500 Acc: 51.5625 (34.3598)\n",
      "[13/25][146/782] Loss_D: 0.0280 (0.2002) Loss_G: -0.1728 (0.0777) D(x): 0.4900 D(G(z)): 0.4455 / 0.4743 Acc: 37.5000 (34.3602)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/25][147/782] Loss_D: -0.1480 (0.2002) Loss_G: -0.1164 (0.0776) D(x): 0.6027 D(G(z)): 0.5217 / 0.4383 Acc: 48.4375 (34.3615)\n",
      "[13/25][148/782] Loss_D: -0.1795 (0.2002) Loss_G: -0.0594 (0.0776) D(x): 0.5454 D(G(z)): 0.4004 / 0.4230 Acc: 39.0625 (34.3620)\n",
      "[13/25][149/782] Loss_D: -0.0667 (0.2001) Loss_G: -0.2402 (0.0776) D(x): 0.5633 D(G(z)): 0.4732 / 0.4957 Acc: 40.6250 (34.3626)\n",
      "[13/25][150/782] Loss_D: -0.1428 (0.2001) Loss_G: -0.2252 (0.0776) D(x): 0.5013 D(G(z)): 0.4495 / 0.4885 Acc: 50.0000 (34.3641)\n",
      "[13/25][151/782] Loss_D: 0.0424 (0.2001) Loss_G: -0.2437 (0.0775) D(x): 0.6296 D(G(z)): 0.5690 / 0.4973 Acc: 35.9375 (34.3642)\n",
      "[13/25][152/782] Loss_D: -0.0433 (0.2001) Loss_G: 0.0230 (0.0775) D(x): 0.5034 D(G(z)): 0.4627 / 0.3916 Acc: 45.3125 (34.3653)\n",
      "[13/25][153/782] Loss_D: -0.0179 (0.2001) Loss_G: -0.0005 (0.0775) D(x): 0.4843 D(G(z)): 0.4428 / 0.3962 Acc: 48.4375 (34.3667)\n",
      "[13/25][154/782] Loss_D: 0.0713 (0.2000) Loss_G: -0.2256 (0.0775) D(x): 0.4855 D(G(z)): 0.4257 / 0.4958 Acc: 29.6875 (34.3662)\n",
      "[13/25][155/782] Loss_D: -0.0418 (0.2000) Loss_G: -0.1167 (0.0775) D(x): 0.5628 D(G(z)): 0.5060 / 0.4398 Acc: 40.6250 (34.3668)\n",
      "[13/25][156/782] Loss_D: 0.0560 (0.2000) Loss_G: -0.2209 (0.0774) D(x): 0.5097 D(G(z)): 0.4992 / 0.4817 Acc: 39.0625 (34.3673)\n",
      "[13/25][157/782] Loss_D: -0.0232 (0.2000) Loss_G: -0.1227 (0.0774) D(x): 0.5736 D(G(z)): 0.5033 / 0.4445 Acc: 39.0625 (34.3677)\n",
      "[13/25][158/782] Loss_D: -0.0835 (0.2000) Loss_G: -0.2444 (0.0774) D(x): 0.5228 D(G(z)): 0.4577 / 0.5128 Acc: 48.4375 (34.3691)\n",
      "[13/25][159/782] Loss_D: 0.0053 (0.1999) Loss_G: -0.1585 (0.0774) D(x): 0.5259 D(G(z)): 0.4597 / 0.4798 Acc: 35.9375 (34.3692)\n",
      "[13/25][160/782] Loss_D: -0.0556 (0.1999) Loss_G: -0.1614 (0.0774) D(x): 0.5172 D(G(z)): 0.4476 / 0.4507 Acc: 39.0625 (34.3697)\n",
      "[13/25][161/782] Loss_D: -0.2744 (0.1999) Loss_G: -0.1799 (0.0773) D(x): 0.5187 D(G(z)): 0.4367 / 0.4664 Acc: 57.8125 (34.3720)\n",
      "[13/25][162/782] Loss_D: 0.0307 (0.1998) Loss_G: -0.0516 (0.0773) D(x): 0.5319 D(G(z)): 0.5044 / 0.4220 Acc: 45.3125 (34.3730)\n",
      "[13/25][163/782] Loss_D: -0.1713 (0.1998) Loss_G: -0.0161 (0.0773) D(x): 0.5618 D(G(z)): 0.4302 / 0.4113 Acc: 40.6250 (34.3736)\n",
      "[13/25][164/782] Loss_D: -0.0040 (0.1998) Loss_G: -0.1484 (0.0773) D(x): 0.5134 D(G(z)): 0.4525 / 0.4559 Acc: 37.5000 (34.3739)\n",
      "[13/25][165/782] Loss_D: -0.0290 (0.1998) Loss_G: -0.0094 (0.0773) D(x): 0.5120 D(G(z)): 0.4643 / 0.4083 Acc: 40.6250 (34.3745)\n",
      "[13/25][166/782] Loss_D: -0.4186 (0.1997) Loss_G: -0.1860 (0.0773) D(x): 0.5862 D(G(z)): 0.4176 / 0.4596 Acc: 59.3750 (34.3770)\n",
      "[13/25][167/782] Loss_D: -0.1997 (0.1997) Loss_G: -0.0156 (0.0772) D(x): 0.5705 D(G(z)): 0.4428 / 0.4095 Acc: 43.7500 (34.3779)\n",
      "[13/25][168/782] Loss_D: -0.0073 (0.1997) Loss_G: -0.0194 (0.0772) D(x): 0.5668 D(G(z)): 0.4777 / 0.4015 Acc: 35.9375 (34.3780)\n",
      "[13/25][169/782] Loss_D: -0.1859 (0.1996) Loss_G: -0.0926 (0.0772) D(x): 0.5237 D(G(z)): 0.4230 / 0.4379 Acc: 50.0000 (34.3795)\n",
      "[13/25][170/782] Loss_D: -0.2700 (0.1996) Loss_G: -0.1143 (0.0772) D(x): 0.5167 D(G(z)): 0.4213 / 0.4631 Acc: 57.8125 (34.3818)\n",
      "[13/25][171/782] Loss_D: -0.0592 (0.1995) Loss_G: -0.0233 (0.0772) D(x): 0.5608 D(G(z)): 0.4628 / 0.4198 Acc: 37.5000 (34.3821)\n",
      "[13/25][172/782] Loss_D: -0.0187 (0.1995) Loss_G: -0.1992 (0.0772) D(x): 0.5552 D(G(z)): 0.5048 / 0.4891 Acc: 42.1875 (34.3829)\n",
      "[13/25][173/782] Loss_D: -0.2064 (0.1995) Loss_G: 0.0293 (0.0772) D(x): 0.5935 D(G(z)): 0.4853 / 0.3889 Acc: 53.1250 (34.3847)\n",
      "[13/25][174/782] Loss_D: 0.0286 (0.1995) Loss_G: 0.1079 (0.0772) D(x): 0.4709 D(G(z)): 0.4538 / 0.3732 Acc: 45.3125 (34.3857)\n",
      "[13/25][175/782] Loss_D: -0.1387 (0.1994) Loss_G: -0.1949 (0.0771) D(x): 0.4847 D(G(z)): 0.4015 / 0.4807 Acc: 48.4375 (34.3871)\n",
      "[13/25][176/782] Loss_D: -0.1885 (0.1994) Loss_G: -0.1591 (0.0771) D(x): 0.5710 D(G(z)): 0.4749 / 0.4759 Acc: 51.5625 (34.3887)\n",
      "[13/25][177/782] Loss_D: -0.1968 (0.1994) Loss_G: -0.2327 (0.0771) D(x): 0.5943 D(G(z)): 0.5069 / 0.4867 Acc: 46.8750 (34.3900)\n",
      "[13/25][178/782] Loss_D: -0.1110 (0.1993) Loss_G: -0.0254 (0.0771) D(x): 0.5595 D(G(z)): 0.4982 / 0.4037 Acc: 48.4375 (34.3913)\n",
      "[13/25][179/782] Loss_D: 0.0491 (0.1993) Loss_G: -0.1503 (0.0770) D(x): 0.4719 D(G(z)): 0.4602 / 0.4689 Acc: 46.8750 (34.3925)\n",
      "[13/25][180/782] Loss_D: -0.0198 (0.1993) Loss_G: -0.1691 (0.0770) D(x): 0.4874 D(G(z)): 0.4845 / 0.4662 Acc: 53.1250 (34.3943)\n",
      "[13/25][181/782] Loss_D: -0.1061 (0.1993) Loss_G: -0.0982 (0.0770) D(x): 0.5971 D(G(z)): 0.5023 / 0.4284 Acc: 42.1875 (34.3951)\n",
      "[13/25][182/782] Loss_D: -0.1064 (0.1992) Loss_G: -0.1118 (0.0770) D(x): 0.4979 D(G(z)): 0.4583 / 0.4554 Acc: 56.2500 (34.3972)\n",
      "[13/25][183/782] Loss_D: 0.1224 (0.1992) Loss_G: -0.2182 (0.0770) D(x): 0.4464 D(G(z)): 0.4703 / 0.4806 Acc: 43.7500 (34.3981)\n",
      "[13/25][184/782] Loss_D: -0.2784 (0.1992) Loss_G: -0.0199 (0.0770) D(x): 0.5908 D(G(z)): 0.4633 / 0.4111 Acc: 50.0000 (34.3996)\n",
      "[13/25][185/782] Loss_D: -0.1110 (0.1991) Loss_G: -0.0920 (0.0769) D(x): 0.5070 D(G(z)): 0.4333 / 0.4271 Acc: 48.4375 (34.4010)\n",
      "[13/25][186/782] Loss_D: 0.0406 (0.1991) Loss_G: -0.0893 (0.0769) D(x): 0.4922 D(G(z)): 0.4404 / 0.4572 Acc: 40.6250 (34.4016)\n",
      "[13/25][187/782] Loss_D: -0.1532 (0.1991) Loss_G: -0.1615 (0.0769) D(x): 0.5575 D(G(z)): 0.5077 / 0.4659 Acc: 56.2500 (34.4037)\n",
      "[13/25][188/782] Loss_D: -0.2177 (0.1991) Loss_G: -0.1077 (0.0769) D(x): 0.5995 D(G(z)): 0.4605 / 0.4486 Acc: 48.4375 (34.4050)\n",
      "[13/25][189/782] Loss_D: -0.1795 (0.1990) Loss_G: -0.1336 (0.0769) D(x): 0.5505 D(G(z)): 0.4565 / 0.4616 Acc: 53.1250 (34.4068)\n",
      "[13/25][190/782] Loss_D: 0.2347 (0.1990) Loss_G: -0.0486 (0.0768) D(x): 0.4926 D(G(z)): 0.5576 / 0.4339 Acc: 43.7500 (34.4077)\n",
      "[13/25][191/782] Loss_D: -0.0993 (0.1990) Loss_G: 0.0697 (0.0768) D(x): 0.4797 D(G(z)): 0.3877 / 0.3893 Acc: 43.7500 (34.4086)\n",
      "[13/25][192/782] Loss_D: -0.1720 (0.1990) Loss_G: -0.0617 (0.0768) D(x): 0.5769 D(G(z)): 0.4816 / 0.4323 Acc: 46.8750 (34.4098)\n",
      "[13/25][193/782] Loss_D: 0.0692 (0.1989) Loss_G: -0.3672 (0.0768) D(x): 0.4795 D(G(z)): 0.4532 / 0.5785 Acc: 43.7500 (34.4107)\n",
      "[13/25][194/782] Loss_D: 0.0150 (0.1989) Loss_G: -0.2895 (0.0768) D(x): 0.5040 D(G(z)): 0.4672 / 0.5381 Acc: 42.1875 (34.4115)\n",
      "[13/25][195/782] Loss_D: -0.1160 (0.1989) Loss_G: -0.2333 (0.0767) D(x): 0.5605 D(G(z)): 0.5421 / 0.4919 Acc: 62.5000 (34.4142)\n",
      "[13/25][196/782] Loss_D: -0.0681 (0.1989) Loss_G: 0.1989 (0.0767) D(x): 0.6145 D(G(z)): 0.5385 / 0.3340 Acc: 48.4375 (34.4156)\n",
      "[13/25][197/782] Loss_D: 0.0923 (0.1989) Loss_G: 0.0191 (0.0767) D(x): 0.4599 D(G(z)): 0.4386 / 0.4026 Acc: 39.0625 (34.4160)\n",
      "[13/25][198/782] Loss_D: -0.0499 (0.1988) Loss_G: 0.1043 (0.0767) D(x): 0.5129 D(G(z)): 0.4221 / 0.3870 Acc: 40.6250 (34.4166)\n",
      "[13/25][199/782] Loss_D: -0.0301 (0.1988) Loss_G: -0.0216 (0.0767) D(x): 0.4894 D(G(z)): 0.3777 / 0.4065 Acc: 34.3750 (34.4166)\n",
      "[13/25][200/782] Loss_D: -0.1964 (0.1988) Loss_G: -0.1507 (0.0767) D(x): 0.5724 D(G(z)): 0.4817 / 0.4681 Acc: 54.6875 (34.4186)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[13/25][201/782] Loss_D: -0.2634 (0.1987) Loss_G: 0.0036 (0.0767) D(x): 0.6166 D(G(z)): 0.4615 / 0.3986 Acc: 42.1875 (34.4193)\n",
      "[13/25][202/782] Loss_D: -0.0905 (0.1987) Loss_G: 0.0427 (0.0767) D(x): 0.5127 D(G(z)): 0.4529 / 0.3921 Acc: 51.5625 (34.4210)\n",
      "[13/25][203/782] Loss_D: -0.1790 (0.1987) Loss_G: -0.1415 (0.0767) D(x): 0.4682 D(G(z)): 0.3660 / 0.4538 Acc: 50.0000 (34.4225)\n",
      "[13/25][204/782] Loss_D: -0.1156 (0.1986) Loss_G: -0.2454 (0.0766) D(x): 0.5620 D(G(z)): 0.4935 / 0.5053 Acc: 45.3125 (34.4235)\n",
      "[13/25][205/782] Loss_D: -0.1463 (0.1986) Loss_G: -0.1294 (0.0766) D(x): 0.5549 D(G(z)): 0.4626 / 0.4660 Acc: 43.7500 (34.4244)\n",
      "[13/25][206/782] Loss_D: -0.0886 (0.1986) Loss_G: -0.0013 (0.0766) D(x): 0.5975 D(G(z)): 0.5225 / 0.4130 Acc: 42.1875 (34.4252)\n",
      "[13/25][207/782] Loss_D: -0.1541 (0.1985) Loss_G: -0.0142 (0.0766) D(x): 0.6017 D(G(z)): 0.5104 / 0.3983 Acc: 48.4375 (34.4265)\n",
      "[13/25][208/782] Loss_D: 0.0227 (0.1985) Loss_G: -0.0602 (0.0766) D(x): 0.4465 D(G(z)): 0.3958 / 0.4263 Acc: 42.1875 (34.4273)\n",
      "[13/25][209/782] Loss_D: 0.1555 (0.1985) Loss_G: -0.0466 (0.0766) D(x): 0.5087 D(G(z)): 0.4998 / 0.4404 Acc: 34.3750 (34.4273)\n",
      "[13/25][210/782] Loss_D: -0.0980 (0.1985) Loss_G: -0.0784 (0.0766) D(x): 0.5759 D(G(z)): 0.4969 / 0.4303 Acc: 45.3125 (34.4283)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/25][211/782] Loss_D: 0.1439 (0.1985) Loss_G: -0.1312 (0.0765) D(x): 0.4691 D(G(z)): 0.4737 / 0.4422 Acc: 37.5000 (34.4286)\n",
      "[13/25][212/782] Loss_D: -0.0724 (0.1985) Loss_G: -0.0206 (0.0765) D(x): 0.5132 D(G(z)): 0.4724 / 0.4246 Acc: 51.5625 (34.4302)\n",
      "[13/25][213/782] Loss_D: 0.0403 (0.1985) Loss_G: -0.0913 (0.0765) D(x): 0.5028 D(G(z)): 0.5401 / 0.4355 Acc: 56.2500 (34.4324)\n",
      "[13/25][214/782] Loss_D: 0.0101 (0.1984) Loss_G: -0.1372 (0.0765) D(x): 0.4908 D(G(z)): 0.4725 / 0.4510 Acc: 45.3125 (34.4334)\n",
      "[13/25][215/782] Loss_D: -0.1631 (0.1984) Loss_G: -0.1286 (0.0765) D(x): 0.5173 D(G(z)): 0.4215 / 0.4488 Acc: 46.8750 (34.4346)\n",
      "[13/25][216/782] Loss_D: 0.0223 (0.1984) Loss_G: -0.0828 (0.0765) D(x): 0.5088 D(G(z)): 0.4557 / 0.4553 Acc: 42.1875 (34.4353)\n",
      "[13/25][217/782] Loss_D: -0.1193 (0.1984) Loss_G: -0.1556 (0.0764) D(x): 0.5352 D(G(z)): 0.4316 / 0.4794 Acc: 40.6250 (34.4359)\n",
      "[13/25][218/782] Loss_D: 0.0275 (0.1983) Loss_G: -0.1152 (0.0764) D(x): 0.5282 D(G(z)): 0.4887 / 0.4480 Acc: 40.6250 (34.4365)\n",
      "[13/25][219/782] Loss_D: 0.0593 (0.1983) Loss_G: -0.0714 (0.0764) D(x): 0.4996 D(G(z)): 0.4970 / 0.4383 Acc: 45.3125 (34.4376)\n",
      "[13/25][220/782] Loss_D: -0.2414 (0.1983) Loss_G: -0.1550 (0.0764) D(x): 0.5469 D(G(z)): 0.4267 / 0.4708 Acc: 53.1250 (34.4394)\n",
      "[13/25][221/782] Loss_D: -0.2899 (0.1982) Loss_G: -0.2318 (0.0764) D(x): 0.5704 D(G(z)): 0.4476 / 0.4972 Acc: 53.1250 (34.4412)\n",
      "[13/25][222/782] Loss_D: -0.1444 (0.1982) Loss_G: -0.1422 (0.0763) D(x): 0.5446 D(G(z)): 0.4472 / 0.4639 Acc: 42.1875 (34.4419)\n",
      "[13/25][223/782] Loss_D: 0.1689 (0.1982) Loss_G: -0.0601 (0.0763) D(x): 0.4885 D(G(z)): 0.4847 / 0.4534 Acc: 34.3750 (34.4419)\n",
      "[13/25][224/782] Loss_D: 0.0694 (0.1982) Loss_G: -0.1734 (0.0763) D(x): 0.5444 D(G(z)): 0.4789 / 0.4740 Acc: 34.3750 (34.4419)\n",
      "[13/25][225/782] Loss_D: -0.0898 (0.1982) Loss_G: -0.1212 (0.0763) D(x): 0.5549 D(G(z)): 0.4910 / 0.4521 Acc: 48.4375 (34.4433)\n",
      "[13/25][226/782] Loss_D: -0.0644 (0.1981) Loss_G: -0.1885 (0.0763) D(x): 0.4882 D(G(z)): 0.4329 / 0.4702 Acc: 46.8750 (34.4445)\n",
      "[13/25][227/782] Loss_D: -0.0639 (0.1981) Loss_G: -0.1272 (0.0762) D(x): 0.5560 D(G(z)): 0.4909 / 0.4602 Acc: 42.1875 (34.4452)\n",
      "[13/25][228/782] Loss_D: -0.0221 (0.1981) Loss_G: -0.1183 (0.0762) D(x): 0.5323 D(G(z)): 0.5029 / 0.4438 Acc: 46.8750 (34.4464)\n",
      "[13/25][229/782] Loss_D: -0.1414 (0.1981) Loss_G: 0.0035 (0.0762) D(x): 0.4974 D(G(z)): 0.4287 / 0.3914 Acc: 46.8750 (34.4476)\n",
      "[13/25][230/782] Loss_D: -0.2227 (0.1980) Loss_G: -0.0295 (0.0762) D(x): 0.5336 D(G(z)): 0.4575 / 0.4121 Acc: 56.2500 (34.4497)\n",
      "[13/25][231/782] Loss_D: -0.0954 (0.1980) Loss_G: -0.1488 (0.0762) D(x): 0.5106 D(G(z)): 0.4196 / 0.4581 Acc: 43.7500 (34.4506)\n",
      "[13/25][232/782] Loss_D: -0.1415 (0.1979) Loss_G: -0.0694 (0.0762) D(x): 0.6086 D(G(z)): 0.4856 / 0.4225 Acc: 39.0625 (34.4510)\n",
      "[13/25][233/782] Loss_D: -0.3058 (0.1979) Loss_G: 0.0575 (0.0762) D(x): 0.6346 D(G(z)): 0.4433 / 0.3974 Acc: 45.3125 (34.4521)\n",
      "[13/25][234/782] Loss_D: -0.0311 (0.1979) Loss_G: -0.1733 (0.0761) D(x): 0.4990 D(G(z)): 0.4392 / 0.4591 Acc: 43.7500 (34.4530)\n",
      "[13/25][235/782] Loss_D: -0.3484 (0.1978) Loss_G: 0.0308 (0.0761) D(x): 0.6171 D(G(z)): 0.3969 / 0.3852 Acc: 42.1875 (34.4537)\n",
      "[13/25][236/782] Loss_D: -0.2089 (0.1978) Loss_G: 0.1862 (0.0761) D(x): 0.5744 D(G(z)): 0.4216 / 0.3471 Acc: 40.6250 (34.4543)\n",
      "[13/25][237/782] Loss_D: -0.1926 (0.1977) Loss_G: 0.0547 (0.0761) D(x): 0.5657 D(G(z)): 0.4852 / 0.4002 Acc: 53.1250 (34.4561)\n",
      "[13/25][238/782] Loss_D: 0.1867 (0.1977) Loss_G: -0.1643 (0.0761) D(x): 0.5037 D(G(z)): 0.5053 / 0.4638 Acc: 34.3750 (34.4561)\n",
      "[13/25][239/782] Loss_D: -0.0190 (0.1977) Loss_G: -0.1621 (0.0761) D(x): 0.5262 D(G(z)): 0.4434 / 0.4718 Acc: 39.0625 (34.4565)\n",
      "[13/25][240/782] Loss_D: -0.2183 (0.1977) Loss_G: -0.1388 (0.0761) D(x): 0.6155 D(G(z)): 0.5087 / 0.4610 Acc: 53.1250 (34.4583)\n",
      "[13/25][241/782] Loss_D: -0.1018 (0.1977) Loss_G: 0.1104 (0.0761) D(x): 0.5265 D(G(z)): 0.4752 / 0.3612 Acc: 50.0000 (34.4598)\n",
      "[13/25][242/782] Loss_D: 0.1563 (0.1977) Loss_G: -0.1003 (0.0761) D(x): 0.4618 D(G(z)): 0.4672 / 0.4429 Acc: 37.5000 (34.4601)\n",
      "[13/25][243/782] Loss_D: -0.1047 (0.1976) Loss_G: -0.1520 (0.0760) D(x): 0.5125 D(G(z)): 0.4667 / 0.4609 Acc: 57.8125 (34.4624)\n",
      "[13/25][244/782] Loss_D: 0.1553 (0.1976) Loss_G: -0.2426 (0.0760) D(x): 0.4384 D(G(z)): 0.4810 / 0.5027 Acc: 43.7500 (34.4632)\n",
      "[13/25][245/782] Loss_D: -0.1924 (0.1976) Loss_G: -0.1986 (0.0760) D(x): 0.5146 D(G(z)): 0.4926 / 0.4805 Acc: 64.0625 (34.4661)\n",
      "[13/25][246/782] Loss_D: -0.0755 (0.1976) Loss_G: -0.2421 (0.0759) D(x): 0.5674 D(G(z)): 0.5709 / 0.4979 Acc: 57.8125 (34.4683)\n",
      "[13/25][247/782] Loss_D: 0.0481 (0.1975) Loss_G: -0.1667 (0.0759) D(x): 0.5000 D(G(z)): 0.4496 / 0.4610 Acc: 35.9375 (34.4685)\n",
      "[13/25][248/782] Loss_D: -0.1049 (0.1975) Loss_G: 0.0354 (0.0759) D(x): 0.5649 D(G(z)): 0.4686 / 0.3881 Acc: 46.8750 (34.4697)\n",
      "[13/25][249/782] Loss_D: 0.1952 (0.1975) Loss_G: -0.1715 (0.0759) D(x): 0.4572 D(G(z)): 0.4961 / 0.4769 Acc: 35.9375 (34.4698)\n",
      "[13/25][250/782] Loss_D: 0.1843 (0.1975) Loss_G: -0.3181 (0.0759) D(x): 0.4685 D(G(z)): 0.4876 / 0.5329 Acc: 42.1875 (34.4705)\n",
      "[13/25][251/782] Loss_D: -0.1537 (0.1975) Loss_G: -0.1650 (0.0758) D(x): 0.5751 D(G(z)): 0.5053 / 0.4780 Acc: 50.0000 (34.4720)\n",
      "[13/25][252/782] Loss_D: 0.0490 (0.1975) Loss_G: -0.1713 (0.0758) D(x): 0.5377 D(G(z)): 0.5023 / 0.4734 Acc: 37.5000 (34.4723)\n",
      "[13/25][253/782] Loss_D: -0.1764 (0.1974) Loss_G: -0.1369 (0.0758) D(x): 0.5362 D(G(z)): 0.4276 / 0.4602 Acc: 46.8750 (34.4735)\n",
      "[13/25][254/782] Loss_D: 0.0410 (0.1974) Loss_G: -0.2350 (0.0758) D(x): 0.5273 D(G(z)): 0.4860 / 0.4871 Acc: 37.5000 (34.4738)\n",
      "[13/25][255/782] Loss_D: -0.1334 (0.1974) Loss_G: 0.1003 (0.0758) D(x): 0.5974 D(G(z)): 0.5169 / 0.3672 Acc: 50.0000 (34.4753)\n",
      "[13/25][256/782] Loss_D: 0.1751 (0.1974) Loss_G: -0.1364 (0.0757) D(x): 0.4217 D(G(z)): 0.4097 / 0.4515 Acc: 34.3750 (34.4753)\n",
      "[13/25][257/782] Loss_D: -0.0958 (0.1974) Loss_G: -0.2641 (0.0757) D(x): 0.5339 D(G(z)): 0.4804 / 0.5132 Acc: 53.1250 (34.4771)\n",
      "[13/25][258/782] Loss_D: -0.0814 (0.1973) Loss_G: 0.0376 (0.0757) D(x): 0.5636 D(G(z)): 0.4604 / 0.3821 Acc: 39.0625 (34.4775)\n",
      "[13/25][259/782] Loss_D: -0.1988 (0.1973) Loss_G: 0.0034 (0.0757) D(x): 0.6024 D(G(z)): 0.4762 / 0.4134 Acc: 45.3125 (34.4786)\n",
      "[13/25][260/782] Loss_D: -0.2141 (0.1972) Loss_G: 0.0385 (0.0757) D(x): 0.5571 D(G(z)): 0.3973 / 0.3838 Acc: 39.0625 (34.4790)\n",
      "[13/25][261/782] Loss_D: -0.1215 (0.1972) Loss_G: 0.0116 (0.0757) D(x): 0.5499 D(G(z)): 0.4575 / 0.4004 Acc: 43.7500 (34.4799)\n",
      "[13/25][262/782] Loss_D: -0.2226 (0.1972) Loss_G: 0.0237 (0.0757) D(x): 0.5582 D(G(z)): 0.4061 / 0.3907 Acc: 43.7500 (34.4808)\n",
      "[13/25][263/782] Loss_D: -0.2852 (0.1971) Loss_G: -0.0308 (0.0757) D(x): 0.5688 D(G(z)): 0.4192 / 0.4172 Acc: 48.4375 (34.4821)\n",
      "[13/25][264/782] Loss_D: -0.0674 (0.1971) Loss_G: -0.0280 (0.0757) D(x): 0.5442 D(G(z)): 0.4974 / 0.4098 Acc: 46.8750 (34.4833)\n",
      "[13/25][265/782] Loss_D: -0.1938 (0.1971) Loss_G: -0.0220 (0.0757) D(x): 0.5511 D(G(z)): 0.4473 / 0.4255 Acc: 48.4375 (34.4846)\n",
      "[13/25][266/782] Loss_D: 0.0113 (0.1971) Loss_G: -0.0398 (0.0756) D(x): 0.5033 D(G(z)): 0.4478 / 0.4264 Acc: 46.8750 (34.4858)\n",
      "[13/25][267/782] Loss_D: 0.2307 (0.1971) Loss_G: -0.1989 (0.0756) D(x): 0.4926 D(G(z)): 0.5030 / 0.4912 Acc: 37.5000 (34.4861)\n",
      "[13/25][268/782] Loss_D: 0.1770 (0.1971) Loss_G: -0.1421 (0.0756) D(x): 0.4804 D(G(z)): 0.4640 / 0.4632 Acc: 29.6875 (34.4857)\n",
      "[13/25][269/782] Loss_D: -0.1319 (0.1970) Loss_G: -0.1661 (0.0756) D(x): 0.5168 D(G(z)): 0.4593 / 0.4666 Acc: 53.1250 (34.4874)\n",
      "[13/25][270/782] Loss_D: -0.0676 (0.1970) Loss_G: -0.0263 (0.0756) D(x): 0.5572 D(G(z)): 0.4950 / 0.4084 Acc: 48.4375 (34.4888)\n",
      "[13/25][271/782] Loss_D: -0.0718 (0.1970) Loss_G: -0.1018 (0.0755) D(x): 0.5397 D(G(z)): 0.4217 / 0.4505 Acc: 35.9375 (34.4889)\n",
      "[13/25][272/782] Loss_D: -0.0321 (0.1969) Loss_G: -0.1255 (0.0755) D(x): 0.5309 D(G(z)): 0.4994 / 0.4545 Acc: 45.3125 (34.4900)\n",
      "[13/25][273/782] Loss_D: -0.2008 (0.1969) Loss_G: -0.1287 (0.0755) D(x): 0.5659 D(G(z)): 0.4600 / 0.4472 Acc: 51.5625 (34.4916)\n",
      "[13/25][274/782] Loss_D: 0.1167 (0.1969) Loss_G: -0.0626 (0.0755) D(x): 0.4731 D(G(z)): 0.4421 / 0.4223 Acc: 37.5000 (34.4919)\n",
      "[13/25][275/782] Loss_D: -0.2838 (0.1969) Loss_G: 0.0050 (0.0755) D(x): 0.5749 D(G(z)): 0.4393 / 0.4081 Acc: 51.5625 (34.4935)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/25][276/782] Loss_D: -0.1040 (0.1968) Loss_G: -0.2277 (0.0755) D(x): 0.5209 D(G(z)): 0.4460 / 0.4908 Acc: 51.5625 (34.4951)\n",
      "[13/25][277/782] Loss_D: -0.2782 (0.1968) Loss_G: -0.0635 (0.0754) D(x): 0.5694 D(G(z)): 0.4295 / 0.4334 Acc: 48.4375 (34.4965)\n",
      "[13/25][278/782] Loss_D: -0.1521 (0.1967) Loss_G: 0.0214 (0.0754) D(x): 0.5477 D(G(z)): 0.4474 / 0.3829 Acc: 43.7500 (34.4974)\n",
      "[13/25][279/782] Loss_D: 0.1372 (0.1967) Loss_G: -0.1153 (0.0754) D(x): 0.5197 D(G(z)): 0.4949 / 0.4267 Acc: 32.8125 (34.4972)\n",
      "[13/25][280/782] Loss_D: -0.2018 (0.1967) Loss_G: -0.0804 (0.0754) D(x): 0.5597 D(G(z)): 0.4342 / 0.4325 Acc: 45.3125 (34.4982)\n",
      "[13/25][281/782] Loss_D: -0.1547 (0.1967) Loss_G: -0.1633 (0.0754) D(x): 0.5516 D(G(z)): 0.4537 / 0.4774 Acc: 45.3125 (34.4993)\n",
      "[13/25][282/782] Loss_D: -0.1099 (0.1966) Loss_G: -0.1662 (0.0754) D(x): 0.5241 D(G(z)): 0.4254 / 0.4579 Acc: 43.7500 (34.5002)\n",
      "[13/25][283/782] Loss_D: 0.0197 (0.1966) Loss_G: 0.0176 (0.0754) D(x): 0.6146 D(G(z)): 0.4937 / 0.4010 Acc: 26.5625 (34.4994)\n",
      "[13/25][284/782] Loss_D: -0.0949 (0.1966) Loss_G: 0.1366 (0.0754) D(x): 0.5598 D(G(z)): 0.4066 / 0.3599 Acc: 29.6875 (34.4989)\n",
      "[13/25][285/782] Loss_D: -0.0926 (0.1966) Loss_G: -0.0433 (0.0754) D(x): 0.5027 D(G(z)): 0.4134 / 0.4102 Acc: 43.7500 (34.4998)\n",
      "[13/25][286/782] Loss_D: -0.2447 (0.1965) Loss_G: -0.1726 (0.0753) D(x): 0.5182 D(G(z)): 0.4003 / 0.4754 Acc: 51.5625 (34.5015)\n",
      "[13/25][287/782] Loss_D: -0.0501 (0.1965) Loss_G: -0.2452 (0.0753) D(x): 0.5653 D(G(z)): 0.4969 / 0.4975 Acc: 42.1875 (34.5022)\n",
      "[13/25][288/782] Loss_D: 0.0350 (0.1965) Loss_G: -0.1732 (0.0753) D(x): 0.5576 D(G(z)): 0.5272 / 0.4680 Acc: 39.0625 (34.5026)\n",
      "[13/25][289/782] Loss_D: -0.0669 (0.1965) Loss_G: 0.1032 (0.0753) D(x): 0.5409 D(G(z)): 0.5275 / 0.3701 Acc: 53.1250 (34.5044)\n",
      "[13/25][290/782] Loss_D: 0.0237 (0.1964) Loss_G: -0.0994 (0.0753) D(x): 0.4752 D(G(z)): 0.4117 / 0.4365 Acc: 40.6250 (34.5050)\n",
      "[13/25][291/782] Loss_D: -0.2360 (0.1964) Loss_G: -0.1159 (0.0752) D(x): 0.5338 D(G(z)): 0.3930 / 0.4447 Acc: 46.8750 (34.5062)\n",
      "[13/25][292/782] Loss_D: -0.1879 (0.1964) Loss_G: -0.1846 (0.0752) D(x): 0.5448 D(G(z)): 0.4660 / 0.4611 Acc: 54.6875 (34.5081)\n",
      "[13/25][293/782] Loss_D: -0.1165 (0.1963) Loss_G: -0.2287 (0.0752) D(x): 0.5672 D(G(z)): 0.4461 / 0.5255 Acc: 43.7500 (34.5090)\n",
      "[13/25][294/782] Loss_D: -0.1805 (0.1963) Loss_G: -0.0356 (0.0752) D(x): 0.6055 D(G(z)): 0.4470 / 0.4140 Acc: 35.9375 (34.5091)\n",
      "[13/25][295/782] Loss_D: -0.3575 (0.1962) Loss_G: -0.0190 (0.0752) D(x): 0.5614 D(G(z)): 0.3764 / 0.4100 Acc: 48.4375 (34.5105)\n",
      "[13/25][296/782] Loss_D: -0.1292 (0.1962) Loss_G: -0.2020 (0.0751) D(x): 0.5749 D(G(z)): 0.4830 / 0.4808 Acc: 43.7500 (34.5113)\n",
      "[13/25][297/782] Loss_D: 0.0250 (0.1962) Loss_G: -0.0640 (0.0751) D(x): 0.5351 D(G(z)): 0.4758 / 0.4323 Acc: 42.1875 (34.5121)\n",
      "[13/25][298/782] Loss_D: -0.1334 (0.1962) Loss_G: -0.0300 (0.0751) D(x): 0.5283 D(G(z)): 0.4070 / 0.4043 Acc: 39.0625 (34.5125)\n",
      "[13/25][299/782] Loss_D: -0.0888 (0.1961) Loss_G: 0.0050 (0.0751) D(x): 0.5937 D(G(z)): 0.5062 / 0.4111 Acc: 42.1875 (34.5132)\n",
      "[13/25][300/782] Loss_D: -0.1364 (0.1961) Loss_G: -0.0241 (0.0751) D(x): 0.5472 D(G(z)): 0.4591 / 0.4282 Acc: 46.8750 (34.5144)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[13/25][301/782] Loss_D: -0.0738 (0.1961) Loss_G: -0.0352 (0.0751) D(x): 0.5029 D(G(z)): 0.3824 / 0.4118 Acc: 32.8125 (34.5143)\n",
      "[13/25][302/782] Loss_D: 0.0002 (0.1961) Loss_G: -0.1633 (0.0751) D(x): 0.5498 D(G(z)): 0.5377 / 0.4782 Acc: 45.3125 (34.5153)\n",
      "[13/25][303/782] Loss_D: -0.0175 (0.1960) Loss_G: 0.1106 (0.0751) D(x): 0.5607 D(G(z)): 0.5265 / 0.3680 Acc: 48.4375 (34.5166)\n",
      "[13/25][304/782] Loss_D: -0.1183 (0.1960) Loss_G: -0.0646 (0.0751) D(x): 0.5085 D(G(z)): 0.4655 / 0.4286 Acc: 54.6875 (34.5186)\n",
      "[13/25][305/782] Loss_D: -0.0262 (0.1960) Loss_G: -0.0165 (0.0751) D(x): 0.4960 D(G(z)): 0.4753 / 0.4066 Acc: 48.4375 (34.5199)\n",
      "[13/25][306/782] Loss_D: -0.1504 (0.1960) Loss_G: -0.0278 (0.0750) D(x): 0.5273 D(G(z)): 0.4358 / 0.4219 Acc: 46.8750 (34.5211)\n",
      "[13/25][307/782] Loss_D: 0.0114 (0.1959) Loss_G: -0.2701 (0.0750) D(x): 0.4601 D(G(z)): 0.4239 / 0.5325 Acc: 42.1875 (34.5218)\n",
      "[13/25][308/782] Loss_D: 0.2525 (0.1959) Loss_G: -0.1635 (0.0750) D(x): 0.5257 D(G(z)): 0.5471 / 0.4872 Acc: 34.3750 (34.5218)\n",
      "[13/25][309/782] Loss_D: 0.0618 (0.1959) Loss_G: -0.0945 (0.0750) D(x): 0.5876 D(G(z)): 0.5628 / 0.4475 Acc: 40.6250 (34.5224)\n",
      "[13/25][310/782] Loss_D: -0.4370 (0.1959) Loss_G: 0.0452 (0.0750) D(x): 0.5719 D(G(z)): 0.3909 / 0.3861 Acc: 57.8125 (34.5246)\n",
      "[13/25][311/782] Loss_D: -0.1278 (0.1958) Loss_G: -0.0349 (0.0750) D(x): 0.4776 D(G(z)): 0.4121 / 0.4147 Acc: 50.0000 (34.5261)\n",
      "[13/25][312/782] Loss_D: -0.2974 (0.1958) Loss_G: -0.2222 (0.0749) D(x): 0.5474 D(G(z)): 0.4078 / 0.4943 Acc: 50.0000 (34.5275)\n",
      "[13/25][313/782] Loss_D: -0.1063 (0.1958) Loss_G: -0.1802 (0.0749) D(x): 0.5681 D(G(z)): 0.4899 / 0.4691 Acc: 40.6250 (34.5281)\n",
      "[13/25][314/782] Loss_D: -0.2576 (0.1957) Loss_G: -0.2743 (0.0749) D(x): 0.5681 D(G(z)): 0.4308 / 0.5059 Acc: 46.8750 (34.5293)\n",
      "[13/25][315/782] Loss_D: -0.1511 (0.1957) Loss_G: -0.0703 (0.0749) D(x): 0.5467 D(G(z)): 0.4530 / 0.4213 Acc: 42.1875 (34.5300)\n",
      "[13/25][316/782] Loss_D: -0.2632 (0.1956) Loss_G: 0.0550 (0.0749) D(x): 0.5372 D(G(z)): 0.4306 / 0.3886 Acc: 54.6875 (34.5320)\n",
      "[13/25][317/782] Loss_D: -0.0097 (0.1956) Loss_G: -0.1270 (0.0748) D(x): 0.5154 D(G(z)): 0.4771 / 0.4479 Acc: 43.7500 (34.5328)\n",
      "[13/25][318/782] Loss_D: -0.0057 (0.1956) Loss_G: -0.2225 (0.0748) D(x): 0.6045 D(G(z)): 0.5430 / 0.4945 Acc: 46.8750 (34.5340)\n",
      "[13/25][319/782] Loss_D: -0.1992 (0.1956) Loss_G: -0.0306 (0.0748) D(x): 0.5578 D(G(z)): 0.4428 / 0.4153 Acc: 43.7500 (34.5349)\n",
      "[13/25][320/782] Loss_D: -0.1691 (0.1955) Loss_G: -0.1796 (0.0748) D(x): 0.4630 D(G(z)): 0.3720 / 0.4736 Acc: 53.1250 (34.5367)\n",
      "[13/25][321/782] Loss_D: 0.0107 (0.1955) Loss_G: -0.1826 (0.0747) D(x): 0.5386 D(G(z)): 0.4757 / 0.4792 Acc: 35.9375 (34.5368)\n",
      "[13/25][322/782] Loss_D: 0.0685 (0.1955) Loss_G: -0.1686 (0.0747) D(x): 0.5769 D(G(z)): 0.5631 / 0.4719 Acc: 43.7500 (34.5377)\n",
      "[13/25][323/782] Loss_D: -0.0368 (0.1955) Loss_G: -0.0586 (0.0747) D(x): 0.5076 D(G(z)): 0.4581 / 0.4438 Acc: 48.4375 (34.5390)\n",
      "[13/25][324/782] Loss_D: -0.0219 (0.1955) Loss_G: -0.0771 (0.0747) D(x): 0.4639 D(G(z)): 0.3943 / 0.4326 Acc: 42.1875 (34.5397)\n",
      "[13/25][325/782] Loss_D: 0.0315 (0.1954) Loss_G: -0.1963 (0.0747) D(x): 0.4886 D(G(z)): 0.4967 / 0.4749 Acc: 48.4375 (34.5410)\n",
      "[13/25][326/782] Loss_D: -0.1300 (0.1954) Loss_G: -0.0252 (0.0747) D(x): 0.5614 D(G(z)): 0.4704 / 0.4154 Acc: 48.4375 (34.5424)\n",
      "[13/25][327/782] Loss_D: -0.0726 (0.1954) Loss_G: -0.2645 (0.0746) D(x): 0.4979 D(G(z)): 0.4794 / 0.5405 Acc: 57.8125 (34.5446)\n",
      "[13/25][328/782] Loss_D: 0.0109 (0.1954) Loss_G: 0.0110 (0.0746) D(x): 0.5690 D(G(z)): 0.5070 / 0.3945 Acc: 37.5000 (34.5449)\n",
      "[13/25][329/782] Loss_D: -0.0104 (0.1954) Loss_G: 0.1405 (0.0746) D(x): 0.5200 D(G(z)): 0.4787 / 0.3594 Acc: 42.1875 (34.5456)\n",
      "[13/25][330/782] Loss_D: -0.2205 (0.1953) Loss_G: 0.1331 (0.0746) D(x): 0.5310 D(G(z)): 0.3687 / 0.3705 Acc: 42.1875 (34.5463)\n",
      "[13/25][331/782] Loss_D: -0.0506 (0.1953) Loss_G: -0.1554 (0.0746) D(x): 0.4865 D(G(z)): 0.4771 / 0.4767 Acc: 56.2500 (34.5484)\n",
      "[13/25][332/782] Loss_D: -0.2276 (0.1953) Loss_G: -0.0923 (0.0746) D(x): 0.5722 D(G(z)): 0.4570 / 0.4382 Acc: 50.0000 (34.5499)\n",
      "[13/25][333/782] Loss_D: -0.4080 (0.1952) Loss_G: 0.1801 (0.0746) D(x): 0.6266 D(G(z)): 0.4644 / 0.3492 Acc: 59.3750 (34.5522)\n",
      "[13/25][334/782] Loss_D: -0.0248 (0.1952) Loss_G: 0.1200 (0.0746) D(x): 0.5194 D(G(z)): 0.4435 / 0.3700 Acc: 35.9375 (34.5524)\n",
      "[13/25][335/782] Loss_D: -0.1666 (0.1951) Loss_G: 0.0100 (0.0746) D(x): 0.5596 D(G(z)): 0.3946 / 0.3928 Acc: 32.8125 (34.5522)\n",
      "[13/25][336/782] Loss_D: -0.1969 (0.1951) Loss_G: 0.0084 (0.0746) D(x): 0.5448 D(G(z)): 0.4412 / 0.4108 Acc: 51.5625 (34.5538)\n",
      "[13/25][337/782] Loss_D: -0.0388 (0.1951) Loss_G: -0.1047 (0.0746) D(x): 0.5115 D(G(z)): 0.4710 / 0.4403 Acc: 51.5625 (34.5554)\n",
      "[13/25][338/782] Loss_D: -0.1571 (0.1950) Loss_G: -0.0437 (0.0746) D(x): 0.5476 D(G(z)): 0.4762 / 0.4141 Acc: 46.8750 (34.5566)\n",
      "[13/25][339/782] Loss_D: -0.0980 (0.1950) Loss_G: -0.0448 (0.0746) D(x): 0.5312 D(G(z)): 0.4542 / 0.4267 Acc: 51.5625 (34.5582)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/25][340/782] Loss_D: -0.0421 (0.1950) Loss_G: -0.0236 (0.0746) D(x): 0.6117 D(G(z)): 0.5003 / 0.4196 Acc: 35.9375 (34.5584)\n",
      "[13/25][341/782] Loss_D: -0.0145 (0.1950) Loss_G: 0.1053 (0.0746) D(x): 0.4923 D(G(z)): 0.4821 / 0.3798 Acc: 48.4375 (34.5597)\n",
      "[13/25][342/782] Loss_D: -0.2300 (0.1949) Loss_G: -0.0476 (0.0745) D(x): 0.4833 D(G(z)): 0.4057 / 0.4270 Acc: 56.2500 (34.5617)\n",
      "[13/25][343/782] Loss_D: -0.1166 (0.1949) Loss_G: -0.2085 (0.0745) D(x): 0.4853 D(G(z)): 0.4813 / 0.4898 Acc: 62.5000 (34.5644)\n",
      "[13/25][344/782] Loss_D: -0.1852 (0.1949) Loss_G: -0.0196 (0.0745) D(x): 0.5950 D(G(z)): 0.4935 / 0.4154 Acc: 51.5625 (34.5660)\n",
      "[13/25][345/782] Loss_D: -0.1626 (0.1948) Loss_G: -0.1329 (0.0745) D(x): 0.5360 D(G(z)): 0.4326 / 0.4677 Acc: 45.3125 (34.5670)\n",
      "[13/25][346/782] Loss_D: -0.0432 (0.1948) Loss_G: -0.2060 (0.0745) D(x): 0.5640 D(G(z)): 0.4967 / 0.4746 Acc: 42.1875 (34.5678)\n",
      "[13/25][347/782] Loss_D: -0.0184 (0.1948) Loss_G: -0.0706 (0.0744) D(x): 0.5443 D(G(z)): 0.5019 / 0.4350 Acc: 48.4375 (34.5691)\n",
      "[13/25][348/782] Loss_D: 0.0386 (0.1948) Loss_G: -0.0956 (0.0744) D(x): 0.5023 D(G(z)): 0.4847 / 0.4674 Acc: 48.4375 (34.5704)\n",
      "[13/25][349/782] Loss_D: 0.0605 (0.1948) Loss_G: -0.1938 (0.0744) D(x): 0.4570 D(G(z)): 0.4302 / 0.4879 Acc: 45.3125 (34.5714)\n",
      "[13/25][350/782] Loss_D: -0.0282 (0.1947) Loss_G: -0.1941 (0.0744) D(x): 0.4968 D(G(z)): 0.4592 / 0.4821 Acc: 45.3125 (34.5724)\n",
      "[13/25][351/782] Loss_D: 0.0866 (0.1947) Loss_G: -0.2854 (0.0743) D(x): 0.5835 D(G(z)): 0.5395 / 0.5527 Acc: 35.9375 (34.5726)\n",
      "[13/25][352/782] Loss_D: -0.0761 (0.1947) Loss_G: -0.0513 (0.0743) D(x): 0.5450 D(G(z)): 0.4818 / 0.4283 Acc: 43.7500 (34.5735)\n",
      "[13/25][353/782] Loss_D: -0.1563 (0.1947) Loss_G: -0.1464 (0.0743) D(x): 0.4956 D(G(z)): 0.4021 / 0.4703 Acc: 50.0000 (34.5749)\n",
      "[13/25][354/782] Loss_D: -0.0564 (0.1947) Loss_G: -0.2117 (0.0743) D(x): 0.5797 D(G(z)): 0.4916 / 0.4934 Acc: 43.7500 (34.5758)\n",
      "[13/25][355/782] Loss_D: 0.1633 (0.1946) Loss_G: -0.0900 (0.0743) D(x): 0.5259 D(G(z)): 0.5169 / 0.4512 Acc: 34.3750 (34.5758)\n",
      "[13/25][356/782] Loss_D: -0.0717 (0.1946) Loss_G: -0.0960 (0.0743) D(x): 0.4616 D(G(z)): 0.3977 / 0.4381 Acc: 48.4375 (34.5771)\n",
      "[13/25][357/782] Loss_D: -0.1902 (0.1946) Loss_G: -0.1603 (0.0742) D(x): 0.5297 D(G(z)): 0.4090 / 0.4707 Acc: 48.4375 (34.5784)\n",
      "[13/25][358/782] Loss_D: -0.1995 (0.1945) Loss_G: -0.1387 (0.0742) D(x): 0.5905 D(G(z)): 0.5066 / 0.4613 Acc: 56.2500 (34.5805)\n",
      "[13/25][359/782] Loss_D: -0.2863 (0.1945) Loss_G: -0.1246 (0.0742) D(x): 0.6210 D(G(z)): 0.4662 / 0.4585 Acc: 50.0000 (34.5819)\n",
      "[13/25][360/782] Loss_D: -0.1303 (0.1945) Loss_G: -0.0050 (0.0742) D(x): 0.4887 D(G(z)): 0.4213 / 0.3948 Acc: 54.6875 (34.5838)\n",
      "[13/25][361/782] Loss_D: -0.0864 (0.1944) Loss_G: -0.0818 (0.0742) D(x): 0.5202 D(G(z)): 0.4536 / 0.4314 Acc: 45.3125 (34.5849)\n",
      "[13/25][362/782] Loss_D: -0.0034 (0.1944) Loss_G: -0.2668 (0.0741) D(x): 0.4393 D(G(z)): 0.4116 / 0.5247 Acc: 48.4375 (34.5862)\n",
      "[13/25][363/782] Loss_D: 0.0953 (0.1944) Loss_G: -0.1641 (0.0741) D(x): 0.5635 D(G(z)): 0.5724 / 0.4729 Acc: 48.4375 (34.5875)\n",
      "[13/25][364/782] Loss_D: -0.0868 (0.1944) Loss_G: -0.0030 (0.0741) D(x): 0.6070 D(G(z)): 0.5661 / 0.4086 Acc: 54.6875 (34.5894)\n",
      "[13/25][365/782] Loss_D: -0.2006 (0.1944) Loss_G: -0.0420 (0.0741) D(x): 0.5669 D(G(z)): 0.4276 / 0.4316 Acc: 45.3125 (34.5904)\n",
      "[13/25][366/782] Loss_D: -0.0368 (0.1943) Loss_G: -0.1079 (0.0741) D(x): 0.5237 D(G(z)): 0.4789 / 0.4554 Acc: 45.3125 (34.5914)\n",
      "[13/25][367/782] Loss_D: -0.0435 (0.1943) Loss_G: -0.1251 (0.0741) D(x): 0.4839 D(G(z)): 0.4121 / 0.4500 Acc: 39.0625 (34.5919)\n",
      "[13/25][368/782] Loss_D: 0.0037 (0.1943) Loss_G: -0.0572 (0.0740) D(x): 0.5198 D(G(z)): 0.4662 / 0.4226 Acc: 40.6250 (34.5924)\n",
      "[13/25][369/782] Loss_D: -0.0557 (0.1943) Loss_G: -0.1148 (0.0740) D(x): 0.5218 D(G(z)): 0.4438 / 0.4624 Acc: 40.6250 (34.5930)\n",
      "[13/25][370/782] Loss_D: -0.1455 (0.1942) Loss_G: -0.2119 (0.0740) D(x): 0.5313 D(G(z)): 0.4666 / 0.4924 Acc: 51.5625 (34.5946)\n",
      "[13/25][371/782] Loss_D: -0.0373 (0.1942) Loss_G: -0.1901 (0.0740) D(x): 0.5395 D(G(z)): 0.4633 / 0.4827 Acc: 40.6250 (34.5952)\n",
      "[13/25][372/782] Loss_D: 0.0129 (0.1942) Loss_G: -0.2224 (0.0739) D(x): 0.5483 D(G(z)): 0.5258 / 0.4959 Acc: 50.0000 (34.5966)\n",
      "[13/25][373/782] Loss_D: -0.1441 (0.1942) Loss_G: -0.0422 (0.0739) D(x): 0.5270 D(G(z)): 0.4245 / 0.4371 Acc: 45.3125 (34.5977)\n",
      "[13/25][374/782] Loss_D: -0.1433 (0.1941) Loss_G: -0.1728 (0.0739) D(x): 0.5480 D(G(z)): 0.4323 / 0.4686 Acc: 42.1875 (34.5984)\n",
      "[13/25][375/782] Loss_D: 0.0534 (0.1941) Loss_G: -0.0950 (0.0739) D(x): 0.5058 D(G(z)): 0.5154 / 0.4367 Acc: 43.7500 (34.5993)\n",
      "[13/25][376/782] Loss_D: 0.0331 (0.1941) Loss_G: 0.0252 (0.0739) D(x): 0.5286 D(G(z)): 0.5067 / 0.4116 Acc: 40.6250 (34.5998)\n",
      "[13/25][377/782] Loss_D: -0.1533 (0.1941) Loss_G: 0.0220 (0.0739) D(x): 0.4935 D(G(z)): 0.4459 / 0.3981 Acc: 57.8125 (34.6020)\n",
      "[13/25][378/782] Loss_D: -0.1101 (0.1940) Loss_G: 0.0191 (0.0739) D(x): 0.5189 D(G(z)): 0.4266 / 0.3940 Acc: 46.8750 (34.6032)\n",
      "[13/25][379/782] Loss_D: -0.0221 (0.1940) Loss_G: -0.0467 (0.0739) D(x): 0.5204 D(G(z)): 0.4492 / 0.4383 Acc: 37.5000 (34.6035)\n",
      "[13/25][380/782] Loss_D: -0.0537 (0.1940) Loss_G: -0.1185 (0.0739) D(x): 0.5478 D(G(z)): 0.4530 / 0.4459 Acc: 35.9375 (34.6036)\n",
      "[13/25][381/782] Loss_D: -0.0861 (0.1940) Loss_G: -0.0392 (0.0738) D(x): 0.5830 D(G(z)): 0.5141 / 0.4222 Acc: 43.7500 (34.6045)\n",
      "[13/25][382/782] Loss_D: -0.1137 (0.1939) Loss_G: 0.1910 (0.0739) D(x): 0.5259 D(G(z)): 0.4625 / 0.3390 Acc: 50.0000 (34.6059)\n",
      "[13/25][383/782] Loss_D: -0.1720 (0.1939) Loss_G: -0.0417 (0.0738) D(x): 0.5482 D(G(z)): 0.4606 / 0.4364 Acc: 51.5625 (34.6075)\n",
      "[13/25][384/782] Loss_D: -0.2256 (0.1939) Loss_G: 0.0115 (0.0738) D(x): 0.5175 D(G(z)): 0.4037 / 0.3907 Acc: 50.0000 (34.6090)\n",
      "[13/25][385/782] Loss_D: -0.2224 (0.1938) Loss_G: -0.0657 (0.0738) D(x): 0.5255 D(G(z)): 0.4518 / 0.4326 Acc: 59.3750 (34.6113)\n",
      "[13/25][386/782] Loss_D: -0.2574 (0.1938) Loss_G: -0.0201 (0.0738) D(x): 0.5533 D(G(z)): 0.4223 / 0.4248 Acc: 48.4375 (34.6126)\n",
      "[13/25][387/782] Loss_D: -0.2390 (0.1937) Loss_G: -0.1581 (0.0738) D(x): 0.5798 D(G(z)): 0.4534 / 0.4589 Acc: 48.4375 (34.6139)\n",
      "[13/25][388/782] Loss_D: -0.1987 (0.1937) Loss_G: -0.1185 (0.0738) D(x): 0.5610 D(G(z)): 0.4675 / 0.4437 Acc: 53.1250 (34.6157)\n",
      "[13/25][389/782] Loss_D: -0.2048 (0.1937) Loss_G: -0.0079 (0.0738) D(x): 0.5407 D(G(z)): 0.4491 / 0.4060 Acc: 53.1250 (34.6175)\n",
      "[13/25][390/782] Loss_D: -0.0828 (0.1936) Loss_G: -0.1614 (0.0737) D(x): 0.5032 D(G(z)): 0.4519 / 0.4757 Acc: 46.8750 (34.6186)\n",
      "[13/25][391/782] Loss_D: -0.1232 (0.1936) Loss_G: -0.1097 (0.0737) D(x): 0.5873 D(G(z)): 0.5198 / 0.4366 Acc: 51.5625 (34.6202)\n",
      "[13/25][392/782] Loss_D: -0.1018 (0.1936) Loss_G: -0.0141 (0.0737) D(x): 0.5297 D(G(z)): 0.4823 / 0.4265 Acc: 48.4375 (34.6215)\n",
      "[13/25][393/782] Loss_D: -0.1440 (0.1936) Loss_G: -0.0591 (0.0737) D(x): 0.5694 D(G(z)): 0.4643 / 0.4308 Acc: 45.3125 (34.6225)\n",
      "[13/25][394/782] Loss_D: 0.0267 (0.1935) Loss_G: -0.0398 (0.0737) D(x): 0.4703 D(G(z)): 0.4053 / 0.4214 Acc: 35.9375 (34.6227)\n",
      "[13/25][395/782] Loss_D: 0.1812 (0.1935) Loss_G: -0.1409 (0.0737) D(x): 0.4628 D(G(z)): 0.5151 / 0.4604 Acc: 40.6250 (34.6232)\n",
      "[13/25][396/782] Loss_D: 0.0695 (0.1935) Loss_G: -0.0689 (0.0737) D(x): 0.5665 D(G(z)): 0.5356 / 0.4299 Acc: 39.0625 (34.6237)\n",
      "[13/25][397/782] Loss_D: 0.1642 (0.1935) Loss_G: -0.1132 (0.0736) D(x): 0.4937 D(G(z)): 0.5489 / 0.4519 Acc: 46.8750 (34.6248)\n",
      "[13/25][398/782] Loss_D: 0.0686 (0.1935) Loss_G: -0.0701 (0.0736) D(x): 0.4891 D(G(z)): 0.4665 / 0.4259 Acc: 43.7500 (34.6257)\n",
      "[13/25][399/782] Loss_D: -0.0058 (0.1935) Loss_G: -0.0443 (0.0736) D(x): 0.4693 D(G(z)): 0.4377 / 0.4201 Acc: 45.3125 (34.6267)\n",
      "[13/25][400/782] Loss_D: -0.1730 (0.1935) Loss_G: -0.1507 (0.0736) D(x): 0.5204 D(G(z)): 0.3940 / 0.4596 Acc: 46.8750 (34.6279)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[13/25][401/782] Loss_D: -0.0841 (0.1934) Loss_G: -0.0263 (0.0736) D(x): 0.5769 D(G(z)): 0.5176 / 0.4052 Acc: 50.0000 (34.6293)\n",
      "[13/25][402/782] Loss_D: -0.0753 (0.1934) Loss_G: -0.1603 (0.0736) D(x): 0.5429 D(G(z)): 0.4928 / 0.4640 Acc: 48.4375 (34.6306)\n",
      "[13/25][403/782] Loss_D: -0.1440 (0.1934) Loss_G: -0.0147 (0.0736) D(x): 0.5305 D(G(z)): 0.4227 / 0.4098 Acc: 42.1875 (34.6313)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/25][404/782] Loss_D: -0.0262 (0.1934) Loss_G: -0.2439 (0.0735) D(x): 0.5105 D(G(z)): 0.4434 / 0.4970 Acc: 40.6250 (34.6319)\n",
      "[13/25][405/782] Loss_D: -0.1608 (0.1933) Loss_G: -0.2741 (0.0735) D(x): 0.5545 D(G(z)): 0.4815 / 0.5104 Acc: 54.6875 (34.6338)\n",
      "[13/25][406/782] Loss_D: -0.2264 (0.1933) Loss_G: 0.1036 (0.0735) D(x): 0.6075 D(G(z)): 0.4874 / 0.3774 Acc: 48.4375 (34.6351)\n",
      "[13/25][407/782] Loss_D: 0.0357 (0.1933) Loss_G: 0.0968 (0.0735) D(x): 0.5200 D(G(z)): 0.4758 / 0.3818 Acc: 40.6250 (34.6357)\n",
      "[13/25][408/782] Loss_D: -0.2004 (0.1932) Loss_G: -0.0093 (0.0735) D(x): 0.5323 D(G(z)): 0.3805 / 0.4304 Acc: 42.1875 (34.6364)\n",
      "[13/25][409/782] Loss_D: -0.1326 (0.1932) Loss_G: -0.1100 (0.0735) D(x): 0.5416 D(G(z)): 0.4417 / 0.4406 Acc: 43.7500 (34.6372)\n",
      "[13/25][410/782] Loss_D: -0.1512 (0.1932) Loss_G: -0.3042 (0.0734) D(x): 0.5619 D(G(z)): 0.4314 / 0.5174 Acc: 40.6250 (34.6378)\n",
      "[13/25][411/782] Loss_D: -0.0464 (0.1931) Loss_G: -0.0895 (0.0734) D(x): 0.5581 D(G(z)): 0.4756 / 0.4409 Acc: 40.6250 (34.6384)\n",
      "[13/25][412/782] Loss_D: 0.0394 (0.1931) Loss_G: -0.2384 (0.0734) D(x): 0.4914 D(G(z)): 0.4663 / 0.4998 Acc: 40.6250 (34.6389)\n",
      "[13/25][413/782] Loss_D: 0.0290 (0.1931) Loss_G: -0.2531 (0.0734) D(x): 0.4745 D(G(z)): 0.4577 / 0.4952 Acc: 48.4375 (34.6402)\n",
      "[13/25][414/782] Loss_D: -0.1701 (0.1931) Loss_G: -0.0878 (0.0733) D(x): 0.5465 D(G(z)): 0.4740 / 0.4478 Acc: 48.4375 (34.6415)\n",
      "[13/25][415/782] Loss_D: -0.2333 (0.1930) Loss_G: -0.1578 (0.0733) D(x): 0.5513 D(G(z)): 0.4803 / 0.4666 Acc: 60.9375 (34.6440)\n",
      "[13/25][416/782] Loss_D: -0.1169 (0.1930) Loss_G: -0.1626 (0.0733) D(x): 0.5569 D(G(z)): 0.4653 / 0.4677 Acc: 46.8750 (34.6452)\n",
      "[13/25][417/782] Loss_D: -0.0831 (0.1930) Loss_G: -0.0968 (0.0733) D(x): 0.5136 D(G(z)): 0.4178 / 0.4322 Acc: 37.5000 (34.6455)\n",
      "[13/25][418/782] Loss_D: -0.0741 (0.1930) Loss_G: -0.2305 (0.0733) D(x): 0.5103 D(G(z)): 0.4541 / 0.4959 Acc: 46.8750 (34.6466)\n",
      "[13/25][419/782] Loss_D: 0.0960 (0.1929) Loss_G: -0.3089 (0.0732) D(x): 0.5821 D(G(z)): 0.5036 / 0.5290 Acc: 29.6875 (34.6461)\n",
      "[13/25][420/782] Loss_D: 0.0665 (0.1929) Loss_G: -0.1165 (0.0732) D(x): 0.5095 D(G(z)): 0.4621 / 0.4325 Acc: 35.9375 (34.6463)\n",
      "[13/25][421/782] Loss_D: -0.0729 (0.1929) Loss_G: -0.0527 (0.0732) D(x): 0.5165 D(G(z)): 0.4311 / 0.4253 Acc: 39.0625 (34.6467)\n",
      "[13/25][422/782] Loss_D: -0.3128 (0.1929) Loss_G: -0.2548 (0.0732) D(x): 0.5783 D(G(z)): 0.4586 / 0.4992 Acc: 57.8125 (34.6489)\n",
      "[13/25][423/782] Loss_D: 0.1138 (0.1929) Loss_G: -0.1168 (0.0731) D(x): 0.4983 D(G(z)): 0.5325 / 0.4451 Acc: 46.8750 (34.6500)\n",
      "[13/25][424/782] Loss_D: 0.0001 (0.1928) Loss_G: -0.1988 (0.0731) D(x): 0.4922 D(G(z)): 0.4680 / 0.4705 Acc: 43.7500 (34.6509)\n",
      "[13/25][425/782] Loss_D: -0.3084 (0.1928) Loss_G: -0.1709 (0.0731) D(x): 0.5431 D(G(z)): 0.4609 / 0.4622 Acc: 62.5000 (34.6535)\n",
      "[13/25][426/782] Loss_D: -0.1268 (0.1928) Loss_G: -0.1743 (0.0731) D(x): 0.5307 D(G(z)): 0.4826 / 0.4787 Acc: 53.1250 (34.6553)\n",
      "[13/25][427/782] Loss_D: -0.0578 (0.1927) Loss_G: -0.0887 (0.0731) D(x): 0.5410 D(G(z)): 0.4788 / 0.4405 Acc: 40.6250 (34.6558)\n",
      "[13/25][428/782] Loss_D: -0.0076 (0.1927) Loss_G: 0.0234 (0.0731) D(x): 0.4934 D(G(z)): 0.4483 / 0.3974 Acc: 40.6250 (34.6564)\n",
      "[13/25][429/782] Loss_D: -0.0142 (0.1927) Loss_G: -0.1027 (0.0730) D(x): 0.5254 D(G(z)): 0.5040 / 0.4472 Acc: 48.4375 (34.6577)\n",
      "[13/25][430/782] Loss_D: 0.0493 (0.1927) Loss_G: -0.1492 (0.0730) D(x): 0.4875 D(G(z)): 0.4703 / 0.4556 Acc: 40.6250 (34.6582)\n",
      "[13/25][431/782] Loss_D: -0.0442 (0.1927) Loss_G: -0.1808 (0.0730) D(x): 0.5172 D(G(z)): 0.4570 / 0.4660 Acc: 46.8750 (34.6594)\n",
      "[13/25][432/782] Loss_D: -0.0152 (0.1926) Loss_G: -0.1492 (0.0730) D(x): 0.5728 D(G(z)): 0.5317 / 0.4616 Acc: 45.3125 (34.6604)\n",
      "[13/25][433/782] Loss_D: -0.0408 (0.1926) Loss_G: -0.0988 (0.0730) D(x): 0.4845 D(G(z)): 0.4369 / 0.4440 Acc: 45.3125 (34.6614)\n",
      "[13/25][434/782] Loss_D: -0.1518 (0.1926) Loss_G: -0.2189 (0.0729) D(x): 0.4787 D(G(z)): 0.4462 / 0.4889 Acc: 56.2500 (34.6634)\n",
      "[13/25][435/782] Loss_D: -0.0119 (0.1926) Loss_G: -0.1375 (0.0729) D(x): 0.5424 D(G(z)): 0.5140 / 0.4512 Acc: 46.8750 (34.6646)\n",
      "[13/25][436/782] Loss_D: -0.0510 (0.1925) Loss_G: -0.1610 (0.0729) D(x): 0.5731 D(G(z)): 0.5106 / 0.4574 Acc: 40.6250 (34.6652)\n",
      "[13/25][437/782] Loss_D: -0.1230 (0.1925) Loss_G: -0.0910 (0.0729) D(x): 0.5030 D(G(z)): 0.4287 / 0.4517 Acc: 46.8750 (34.6663)\n",
      "[13/25][438/782] Loss_D: -0.0920 (0.1925) Loss_G: -0.1372 (0.0728) D(x): 0.5436 D(G(z)): 0.4835 / 0.4715 Acc: 46.8750 (34.6675)\n",
      "[13/25][439/782] Loss_D: 0.0162 (0.1925) Loss_G: -0.0782 (0.0728) D(x): 0.5303 D(G(z)): 0.4614 / 0.4442 Acc: 34.3750 (34.6674)\n",
      "[13/25][440/782] Loss_D: 0.0094 (0.1925) Loss_G: -0.0446 (0.0728) D(x): 0.5245 D(G(z)): 0.5213 / 0.4196 Acc: 51.5625 (34.6690)\n",
      "[13/25][441/782] Loss_D: -0.0538 (0.1924) Loss_G: -0.2134 (0.0728) D(x): 0.5024 D(G(z)): 0.4727 / 0.4771 Acc: 48.4375 (34.6703)\n",
      "[13/25][442/782] Loss_D: -0.1970 (0.1924) Loss_G: -0.0273 (0.0728) D(x): 0.5506 D(G(z)): 0.4516 / 0.4031 Acc: 53.1250 (34.6721)\n",
      "[13/25][443/782] Loss_D: 0.0417 (0.1924) Loss_G: -0.0376 (0.0728) D(x): 0.5348 D(G(z)): 0.4975 / 0.4210 Acc: 42.1875 (34.6728)\n",
      "[13/25][444/782] Loss_D: -0.1666 (0.1923) Loss_G: -0.1778 (0.0728) D(x): 0.5514 D(G(z)): 0.4747 / 0.4708 Acc: 46.8750 (34.6739)\n",
      "[13/25][445/782] Loss_D: 0.0787 (0.1923) Loss_G: 0.0429 (0.0728) D(x): 0.4819 D(G(z)): 0.4354 / 0.3943 Acc: 35.9375 (34.6740)\n",
      "[13/25][446/782] Loss_D: -0.1643 (0.1923) Loss_G: -0.0721 (0.0727) D(x): 0.5562 D(G(z)): 0.4575 / 0.4398 Acc: 46.8750 (34.6752)\n",
      "[13/25][447/782] Loss_D: -0.1799 (0.1923) Loss_G: -0.0604 (0.0727) D(x): 0.5814 D(G(z)): 0.4704 / 0.4313 Acc: 46.8750 (34.6763)\n",
      "[13/25][448/782] Loss_D: -0.0830 (0.1922) Loss_G: -0.0677 (0.0727) D(x): 0.4805 D(G(z)): 0.4248 / 0.4292 Acc: 48.4375 (34.6776)\n",
      "[13/25][449/782] Loss_D: -0.3054 (0.1922) Loss_G: -0.1623 (0.0727) D(x): 0.6156 D(G(z)): 0.4778 / 0.4605 Acc: 51.5625 (34.6792)\n",
      "[13/25][450/782] Loss_D: -0.3387 (0.1921) Loss_G: 0.0839 (0.0727) D(x): 0.6033 D(G(z)): 0.4202 / 0.3718 Acc: 51.5625 (34.6808)\n",
      "[13/25][451/782] Loss_D: -0.4170 (0.1921) Loss_G: 0.1376 (0.0727) D(x): 0.6092 D(G(z)): 0.3988 / 0.3627 Acc: 48.4375 (34.6821)\n",
      "[13/25][452/782] Loss_D: -0.1638 (0.1921) Loss_G: -0.0371 (0.0727) D(x): 0.4889 D(G(z)): 0.4099 / 0.4163 Acc: 50.0000 (34.6836)\n",
      "[13/25][453/782] Loss_D: -0.1358 (0.1920) Loss_G: -0.1031 (0.0727) D(x): 0.5645 D(G(z)): 0.4343 / 0.4499 Acc: 35.9375 (34.6837)\n",
      "[13/25][454/782] Loss_D: -0.2327 (0.1920) Loss_G: 0.0594 (0.0727) D(x): 0.5404 D(G(z)): 0.4141 / 0.3750 Acc: 46.8750 (34.6848)\n",
      "[13/25][455/782] Loss_D: -0.2197 (0.1919) Loss_G: -0.2459 (0.0726) D(x): 0.5845 D(G(z)): 0.4515 / 0.4874 Acc: 43.7500 (34.6857)\n",
      "[13/25][456/782] Loss_D: -0.1562 (0.1919) Loss_G: -0.1126 (0.0726) D(x): 0.5202 D(G(z)): 0.4737 / 0.4526 Acc: 57.8125 (34.6879)\n",
      "[13/25][457/782] Loss_D: -0.1367 (0.1919) Loss_G: -0.1924 (0.0726) D(x): 0.5238 D(G(z)): 0.4390 / 0.4713 Acc: 43.7500 (34.6887)\n",
      "[13/25][458/782] Loss_D: -0.0624 (0.1919) Loss_G: -0.0846 (0.0726) D(x): 0.5045 D(G(z)): 0.4572 / 0.4444 Acc: 50.0000 (34.6901)\n",
      "[13/25][459/782] Loss_D: 0.0433 (0.1918) Loss_G: 0.1202 (0.0726) D(x): 0.5219 D(G(z)): 0.5339 / 0.3585 Acc: 50.0000 (34.6916)\n",
      "[13/25][460/782] Loss_D: -0.1519 (0.1918) Loss_G: -0.2284 (0.0726) D(x): 0.5267 D(G(z)): 0.4338 / 0.5044 Acc: 46.8750 (34.6927)\n",
      "[13/25][461/782] Loss_D: -0.3385 (0.1918) Loss_G: -0.0677 (0.0725) D(x): 0.5895 D(G(z)): 0.4488 / 0.4345 Acc: 54.6875 (34.6946)\n",
      "[13/25][462/782] Loss_D: -0.1439 (0.1917) Loss_G: -0.0935 (0.0725) D(x): 0.5835 D(G(z)): 0.4514 / 0.4304 Acc: 35.9375 (34.6947)\n",
      "[13/25][463/782] Loss_D: -0.0890 (0.1917) Loss_G: -0.1269 (0.0725) D(x): 0.5060 D(G(z)): 0.4468 / 0.4745 Acc: 45.3125 (34.6957)\n",
      "[13/25][464/782] Loss_D: 0.0063 (0.1917) Loss_G: -0.0484 (0.0725) D(x): 0.5308 D(G(z)): 0.4976 / 0.4158 Acc: 37.5000 (34.6960)\n",
      "[13/25][465/782] Loss_D: -0.1661 (0.1916) Loss_G: 0.0028 (0.0725) D(x): 0.5719 D(G(z)): 0.5109 / 0.3923 Acc: 57.8125 (34.6982)\n",
      "[13/25][466/782] Loss_D: -0.1555 (0.1916) Loss_G: 0.0233 (0.0725) D(x): 0.4924 D(G(z)): 0.4250 / 0.3967 Acc: 51.5625 (34.6998)\n",
      "[13/25][467/782] Loss_D: -0.0777 (0.1916) Loss_G: -0.2558 (0.0725) D(x): 0.5078 D(G(z)): 0.4261 / 0.4997 Acc: 39.0625 (34.7002)\n",
      "[13/25][468/782] Loss_D: 0.1326 (0.1916) Loss_G: -0.2823 (0.0724) D(x): 0.4657 D(G(z)): 0.5000 / 0.5207 Acc: 45.3125 (34.7012)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/25][469/782] Loss_D: -0.1943 (0.1915) Loss_G: -0.0580 (0.0724) D(x): 0.5404 D(G(z)): 0.3944 / 0.4155 Acc: 40.6250 (34.7017)\n",
      "[13/25][470/782] Loss_D: -0.1925 (0.1915) Loss_G: -0.1329 (0.0724) D(x): 0.6048 D(G(z)): 0.4661 / 0.4602 Acc: 43.7500 (34.7026)\n",
      "[13/25][471/782] Loss_D: -0.1632 (0.1915) Loss_G: -0.0850 (0.0724) D(x): 0.5524 D(G(z)): 0.4353 / 0.4457 Acc: 43.7500 (34.7034)\n",
      "[13/25][472/782] Loss_D: -0.0322 (0.1915) Loss_G: -0.0665 (0.0724) D(x): 0.5198 D(G(z)): 0.4859 / 0.4370 Acc: 45.3125 (34.7044)\n",
      "[13/25][473/782] Loss_D: -0.0012 (0.1914) Loss_G: -0.0989 (0.0723) D(x): 0.5513 D(G(z)): 0.5251 / 0.4406 Acc: 45.3125 (34.7054)\n",
      "[13/25][474/782] Loss_D: -0.1255 (0.1914) Loss_G: -0.1131 (0.0723) D(x): 0.4884 D(G(z)): 0.3949 / 0.4497 Acc: 48.4375 (34.7067)\n",
      "[13/25][475/782] Loss_D: -0.1805 (0.1914) Loss_G: -0.1753 (0.0723) D(x): 0.5586 D(G(z)): 0.4636 / 0.4629 Acc: 46.8750 (34.7078)\n",
      "[13/25][476/782] Loss_D: -0.2149 (0.1913) Loss_G: 0.0211 (0.0723) D(x): 0.5820 D(G(z)): 0.4661 / 0.4150 Acc: 48.4375 (34.7091)\n",
      "[13/25][477/782] Loss_D: -0.2210 (0.1913) Loss_G: 0.0173 (0.0723) D(x): 0.5447 D(G(z)): 0.4029 / 0.3932 Acc: 46.8750 (34.7103)\n",
      "[13/25][478/782] Loss_D: -0.1426 (0.1913) Loss_G: 0.1045 (0.0723) D(x): 0.5424 D(G(z)): 0.4161 / 0.3620 Acc: 35.9375 (34.7104)\n",
      "[13/25][479/782] Loss_D: -0.3138 (0.1912) Loss_G: -0.0985 (0.0723) D(x): 0.6401 D(G(z)): 0.4983 / 0.4308 Acc: 51.5625 (34.7120)\n",
      "[13/25][480/782] Loss_D: -0.1580 (0.1912) Loss_G: -0.0538 (0.0723) D(x): 0.5004 D(G(z)): 0.4140 / 0.4208 Acc: 46.8750 (34.7131)\n",
      "[13/25][481/782] Loss_D: 0.0411 (0.1912) Loss_G: -0.1020 (0.0723) D(x): 0.5035 D(G(z)): 0.4297 / 0.4548 Acc: 29.6875 (34.7127)\n",
      "[13/25][482/782] Loss_D: -0.2345 (0.1911) Loss_G: -0.0509 (0.0722) D(x): 0.5716 D(G(z)): 0.4789 / 0.4276 Acc: 54.6875 (34.7145)\n",
      "[13/25][483/782] Loss_D: -0.1209 (0.1911) Loss_G: -0.0086 (0.0722) D(x): 0.5925 D(G(z)): 0.4894 / 0.4019 Acc: 42.1875 (34.7152)\n",
      "[13/25][484/782] Loss_D: -0.0715 (0.1911) Loss_G: -0.0643 (0.0722) D(x): 0.4661 D(G(z)): 0.4363 / 0.4202 Acc: 50.0000 (34.7167)\n",
      "[13/25][485/782] Loss_D: 0.0013 (0.1911) Loss_G: -0.1447 (0.0722) D(x): 0.4818 D(G(z)): 0.4661 / 0.4680 Acc: 46.8750 (34.7178)\n",
      "[13/25][486/782] Loss_D: 0.0909 (0.1911) Loss_G: -0.1503 (0.0722) D(x): 0.4978 D(G(z)): 0.4869 / 0.4813 Acc: 40.6250 (34.7184)\n",
      "[13/25][487/782] Loss_D: 0.0489 (0.1910) Loss_G: -0.3001 (0.0721) D(x): 0.5278 D(G(z)): 0.5242 / 0.5307 Acc: 45.3125 (34.7194)\n",
      "[13/25][488/782] Loss_D: -0.1297 (0.1910) Loss_G: -0.0560 (0.0721) D(x): 0.5467 D(G(z)): 0.4972 / 0.4237 Acc: 51.5625 (34.7209)\n",
      "[13/25][489/782] Loss_D: 0.0176 (0.1910) Loss_G: -0.1268 (0.0721) D(x): 0.5141 D(G(z)): 0.4897 / 0.4428 Acc: 45.3125 (34.7219)\n",
      "[13/25][490/782] Loss_D: 0.0456 (0.1910) Loss_G: -0.0707 (0.0721) D(x): 0.4883 D(G(z)): 0.4489 / 0.4431 Acc: 42.1875 (34.7226)\n",
      "[13/25][491/782] Loss_D: -0.0944 (0.1910) Loss_G: 0.0705 (0.0721) D(x): 0.5360 D(G(z)): 0.4486 / 0.3749 Acc: 45.3125 (34.7236)\n",
      "[13/25][492/782] Loss_D: -0.0627 (0.1909) Loss_G: -0.0053 (0.0721) D(x): 0.5129 D(G(z)): 0.4616 / 0.4191 Acc: 45.3125 (34.7246)\n",
      "[13/25][493/782] Loss_D: -0.0059 (0.1909) Loss_G: -0.2424 (0.0721) D(x): 0.4826 D(G(z)): 0.4463 / 0.5074 Acc: 45.3125 (34.7256)\n",
      "[13/25][494/782] Loss_D: 0.0181 (0.1909) Loss_G: -0.1976 (0.0720) D(x): 0.5890 D(G(z)): 0.5366 / 0.4760 Acc: 40.6250 (34.7262)\n",
      "[13/25][495/782] Loss_D: -0.0649 (0.1909) Loss_G: -0.1572 (0.0720) D(x): 0.5488 D(G(z)): 0.4895 / 0.4491 Acc: 42.1875 (34.7269)\n",
      "[13/25][496/782] Loss_D: 0.0400 (0.1909) Loss_G: -0.0796 (0.0720) D(x): 0.4982 D(G(z)): 0.4661 / 0.4456 Acc: 45.3125 (34.7279)\n",
      "[13/25][497/782] Loss_D: -0.2365 (0.1908) Loss_G: -0.0760 (0.0720) D(x): 0.5465 D(G(z)): 0.4280 / 0.4402 Acc: 48.4375 (34.7291)\n",
      "[13/25][498/782] Loss_D: -0.0070 (0.1908) Loss_G: 0.0966 (0.0720) D(x): 0.5422 D(G(z)): 0.4809 / 0.3999 Acc: 42.1875 (34.7298)\n",
      "[13/25][499/782] Loss_D: -0.0018 (0.1908) Loss_G: -0.2121 (0.0720) D(x): 0.5325 D(G(z)): 0.5080 / 0.5151 Acc: 50.0000 (34.7313)\n",
      "[13/25][500/782] Loss_D: -0.0845 (0.1908) Loss_G: -0.0992 (0.0720) D(x): 0.5213 D(G(z)): 0.4781 / 0.4439 Acc: 46.8750 (34.7324)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[13/25][501/782] Loss_D: -0.0053 (0.1907) Loss_G: -0.0853 (0.0719) D(x): 0.5145 D(G(z)): 0.4638 / 0.4659 Acc: 48.4375 (34.7337)\n",
      "[13/25][502/782] Loss_D: -0.1635 (0.1907) Loss_G: -0.0962 (0.0719) D(x): 0.5194 D(G(z)): 0.4694 / 0.4396 Acc: 54.6875 (34.7356)\n",
      "[13/25][503/782] Loss_D: -0.0157 (0.1907) Loss_G: -0.1927 (0.0719) D(x): 0.5254 D(G(z)): 0.4352 / 0.4829 Acc: 35.9375 (34.7357)\n",
      "[13/25][504/782] Loss_D: -0.0262 (0.1907) Loss_G: -0.2232 (0.0719) D(x): 0.5571 D(G(z)): 0.5035 / 0.4861 Acc: 45.3125 (34.7367)\n",
      "[13/25][505/782] Loss_D: -0.1168 (0.1906) Loss_G: -0.1908 (0.0718) D(x): 0.5273 D(G(z)): 0.4757 / 0.4813 Acc: 51.5625 (34.7382)\n",
      "[13/25][506/782] Loss_D: -0.1073 (0.1906) Loss_G: -0.0204 (0.0718) D(x): 0.5665 D(G(z)): 0.4975 / 0.4028 Acc: 48.4375 (34.7395)\n",
      "[13/25][507/782] Loss_D: -0.1636 (0.1906) Loss_G: -0.0189 (0.0718) D(x): 0.5170 D(G(z)): 0.4380 / 0.4083 Acc: 53.1250 (34.7413)\n",
      "[13/25][508/782] Loss_D: -0.0727 (0.1905) Loss_G: -0.0935 (0.0718) D(x): 0.4642 D(G(z)): 0.4623 / 0.4407 Acc: 54.6875 (34.7431)\n",
      "[13/25][509/782] Loss_D: -0.0650 (0.1905) Loss_G: -0.2154 (0.0718) D(x): 0.5562 D(G(z)): 0.4957 / 0.4958 Acc: 42.1875 (34.7438)\n",
      "[13/25][510/782] Loss_D: -0.0680 (0.1905) Loss_G: -0.1051 (0.0718) D(x): 0.5520 D(G(z)): 0.4904 / 0.4711 Acc: 43.7500 (34.7447)\n",
      "[13/25][511/782] Loss_D: -0.0388 (0.1905) Loss_G: -0.1178 (0.0717) D(x): 0.5477 D(G(z)): 0.4851 / 0.4460 Acc: 39.0625 (34.7451)\n",
      "[13/25][512/782] Loss_D: -0.3119 (0.1904) Loss_G: 0.1260 (0.0718) D(x): 0.6198 D(G(z)): 0.4509 / 0.3547 Acc: 48.4375 (34.7463)\n",
      "[13/25][513/782] Loss_D: -0.1159 (0.1904) Loss_G: -0.0222 (0.0717) D(x): 0.5381 D(G(z)): 0.4438 / 0.4041 Acc: 42.1875 (34.7470)\n",
      "[13/25][514/782] Loss_D: 0.0330 (0.1904) Loss_G: -0.0710 (0.0717) D(x): 0.4729 D(G(z)): 0.4087 / 0.4542 Acc: 40.6250 (34.7476)\n",
      "[13/25][515/782] Loss_D: -0.1565 (0.1904) Loss_G: -0.1529 (0.0717) D(x): 0.5369 D(G(z)): 0.4689 / 0.4587 Acc: 53.1250 (34.7493)\n",
      "[13/25][516/782] Loss_D: 0.0614 (0.1903) Loss_G: -0.1737 (0.0717) D(x): 0.5512 D(G(z)): 0.5357 / 0.4841 Acc: 39.0625 (34.7497)\n",
      "[13/25][517/782] Loss_D: -0.0213 (0.1903) Loss_G: -0.0467 (0.0717) D(x): 0.5663 D(G(z)): 0.5138 / 0.4380 Acc: 43.7500 (34.7506)\n",
      "[13/25][518/782] Loss_D: -0.2225 (0.1903) Loss_G: -0.0153 (0.0717) D(x): 0.5801 D(G(z)): 0.4643 / 0.4223 Acc: 50.0000 (34.7520)\n",
      "[13/25][519/782] Loss_D: -0.0375 (0.1903) Loss_G: -0.0646 (0.0717) D(x): 0.4641 D(G(z)): 0.4122 / 0.4337 Acc: 50.0000 (34.7534)\n",
      "[13/25][520/782] Loss_D: -0.2846 (0.1902) Loss_G: -0.1575 (0.0716) D(x): 0.5485 D(G(z)): 0.4156 / 0.4754 Acc: 51.5625 (34.7550)\n",
      "[13/25][521/782] Loss_D: 0.2102 (0.1902) Loss_G: -0.2099 (0.0716) D(x): 0.4350 D(G(z)): 0.5170 / 0.4951 Acc: 48.4375 (34.7563)\n",
      "[13/25][522/782] Loss_D: 0.0104 (0.1902) Loss_G: -0.2063 (0.0716) D(x): 0.5699 D(G(z)): 0.5637 / 0.4813 Acc: 45.3125 (34.7573)\n",
      "[13/25][523/782] Loss_D: -0.1865 (0.1902) Loss_G: 0.1483 (0.0716) D(x): 0.6173 D(G(z)): 0.4720 / 0.3616 Acc: 46.8750 (34.7584)\n",
      "[13/25][524/782] Loss_D: 0.0453 (0.1902) Loss_G: -0.0910 (0.0716) D(x): 0.4102 D(G(z)): 0.3842 / 0.4451 Acc: 45.3125 (34.7594)\n",
      "[13/25][525/782] Loss_D: -0.2052 (0.1901) Loss_G: -0.1103 (0.0716) D(x): 0.5298 D(G(z)): 0.4226 / 0.4502 Acc: 50.0000 (34.7608)\n",
      "[13/25][526/782] Loss_D: -0.2697 (0.1901) Loss_G: -0.0109 (0.0716) D(x): 0.6016 D(G(z)): 0.4483 / 0.3986 Acc: 46.8750 (34.7619)\n",
      "[13/25][527/782] Loss_D: -0.1511 (0.1900) Loss_G: 0.0855 (0.0716) D(x): 0.5384 D(G(z)): 0.4412 / 0.3723 Acc: 45.3125 (34.7629)\n",
      "[13/25][528/782] Loss_D: -0.1633 (0.1900) Loss_G: -0.0939 (0.0715) D(x): 0.5664 D(G(z)): 0.4758 / 0.4416 Acc: 46.8750 (34.7641)\n",
      "[13/25][529/782] Loss_D: -0.2137 (0.1900) Loss_G: 0.0265 (0.0715) D(x): 0.5796 D(G(z)): 0.4518 / 0.3988 Acc: 50.0000 (34.7655)\n",
      "[13/25][530/782] Loss_D: -0.2013 (0.1899) Loss_G: -0.0517 (0.0715) D(x): 0.5151 D(G(z)): 0.4243 / 0.4300 Acc: 51.5625 (34.7670)\n",
      "[13/25][531/782] Loss_D: -0.0635 (0.1899) Loss_G: -0.1816 (0.0715) D(x): 0.4485 D(G(z)): 0.3923 / 0.4899 Acc: 46.8750 (34.7682)\n",
      "[13/25][532/782] Loss_D: 0.0639 (0.1899) Loss_G: -0.1275 (0.0715) D(x): 0.6290 D(G(z)): 0.5549 / 0.4568 Acc: 31.2500 (34.7679)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/25][533/782] Loss_D: -0.1574 (0.1899) Loss_G: -0.0863 (0.0715) D(x): 0.5099 D(G(z)): 0.4292 / 0.4502 Acc: 51.5625 (34.7694)\n",
      "[13/25][534/782] Loss_D: 0.2050 (0.1899) Loss_G: -0.2486 (0.0714) D(x): 0.4436 D(G(z)): 0.4958 / 0.5184 Acc: 43.7500 (34.7703)\n",
      "[13/25][535/782] Loss_D: -0.2703 (0.1898) Loss_G: -0.1069 (0.0714) D(x): 0.5364 D(G(z)): 0.4164 / 0.4442 Acc: 48.4375 (34.7715)\n",
      "[13/25][536/782] Loss_D: -0.3157 (0.1898) Loss_G: -0.1380 (0.0714) D(x): 0.6005 D(G(z)): 0.3840 / 0.4471 Acc: 37.5000 (34.7718)\n",
      "[13/25][537/782] Loss_D: -0.2275 (0.1897) Loss_G: -0.1780 (0.0714) D(x): 0.5872 D(G(z)): 0.4671 / 0.4696 Acc: 53.1250 (34.7735)\n",
      "[13/25][538/782] Loss_D: -0.1219 (0.1897) Loss_G: -0.0222 (0.0714) D(x): 0.5176 D(G(z)): 0.4818 / 0.4202 Acc: 53.1250 (34.7752)\n",
      "[13/25][539/782] Loss_D: 0.0065 (0.1897) Loss_G: -0.0088 (0.0714) D(x): 0.5095 D(G(z)): 0.4723 / 0.4245 Acc: 42.1875 (34.7759)\n",
      "[13/25][540/782] Loss_D: 0.0927 (0.1897) Loss_G: -0.1796 (0.0713) D(x): 0.5104 D(G(z)): 0.5008 / 0.4855 Acc: 46.8750 (34.7770)\n",
      "[13/25][541/782] Loss_D: -0.1729 (0.1897) Loss_G: -0.2009 (0.0713) D(x): 0.5344 D(G(z)): 0.4322 / 0.4787 Acc: 43.7500 (34.7779)\n",
      "[13/25][542/782] Loss_D: -0.0779 (0.1896) Loss_G: -0.0640 (0.0713) D(x): 0.5598 D(G(z)): 0.4838 / 0.4256 Acc: 43.7500 (34.7787)\n",
      "[13/25][543/782] Loss_D: -0.0876 (0.1896) Loss_G: -0.0445 (0.0713) D(x): 0.5840 D(G(z)): 0.4861 / 0.4373 Acc: 42.1875 (34.7794)\n",
      "[13/25][544/782] Loss_D: -0.0941 (0.1896) Loss_G: -0.0361 (0.0713) D(x): 0.5050 D(G(z)): 0.4769 / 0.4236 Acc: 53.1250 (34.7811)\n",
      "[13/25][545/782] Loss_D: -0.0034 (0.1896) Loss_G: -0.0576 (0.0713) D(x): 0.4320 D(G(z)): 0.3977 / 0.4310 Acc: 50.0000 (34.7825)\n",
      "[13/25][546/782] Loss_D: 0.2147 (0.1896) Loss_G: -0.1921 (0.0712) D(x): 0.5383 D(G(z)): 0.5759 / 0.4885 Acc: 40.6250 (34.7831)\n",
      "[13/25][547/782] Loss_D: 0.0161 (0.1895) Loss_G: -0.0465 (0.0712) D(x): 0.5530 D(G(z)): 0.5099 / 0.4255 Acc: 39.0625 (34.7835)\n",
      "[13/25][548/782] Loss_D: -0.0790 (0.1895) Loss_G: -0.1122 (0.0712) D(x): 0.4971 D(G(z)): 0.4376 / 0.4431 Acc: 43.7500 (34.7843)\n",
      "[13/25][549/782] Loss_D: 0.0667 (0.1895) Loss_G: -0.1807 (0.0712) D(x): 0.5132 D(G(z)): 0.5154 / 0.4605 Acc: 48.4375 (34.7856)\n",
      "[13/25][550/782] Loss_D: -0.2659 (0.1895) Loss_G: 0.0052 (0.0712) D(x): 0.5641 D(G(z)): 0.4100 / 0.3995 Acc: 46.8750 (34.7867)\n",
      "[13/25][551/782] Loss_D: -0.3076 (0.1894) Loss_G: -0.0501 (0.0712) D(x): 0.5487 D(G(z)): 0.4217 / 0.4229 Acc: 53.1250 (34.7884)\n",
      "[13/25][552/782] Loss_D: -0.1931 (0.1894) Loss_G: 0.0480 (0.0712) D(x): 0.5321 D(G(z)): 0.4246 / 0.4025 Acc: 48.4375 (34.7897)\n",
      "[13/25][553/782] Loss_D: -0.1904 (0.1893) Loss_G: -0.1036 (0.0712) D(x): 0.5800 D(G(z)): 0.4825 / 0.4462 Acc: 54.6875 (34.7916)\n",
      "[13/25][554/782] Loss_D: 0.0265 (0.1893) Loss_G: 0.0583 (0.0711) D(x): 0.5572 D(G(z)): 0.5019 / 0.3807 Acc: 39.0625 (34.7920)\n",
      "[13/25][555/782] Loss_D: -0.0711 (0.1893) Loss_G: 0.0946 (0.0712) D(x): 0.4531 D(G(z)): 0.4495 / 0.3725 Acc: 65.6250 (34.7948)\n",
      "[13/25][556/782] Loss_D: -0.1119 (0.1893) Loss_G: -0.0908 (0.0711) D(x): 0.5289 D(G(z)): 0.4313 / 0.4314 Acc: 40.6250 (34.7954)\n",
      "[13/25][557/782] Loss_D: -0.2303 (0.1892) Loss_G: -0.1320 (0.0711) D(x): 0.5507 D(G(z)): 0.4304 / 0.4601 Acc: 53.1250 (34.7971)\n",
      "[13/25][558/782] Loss_D: -0.2690 (0.1892) Loss_G: -0.1559 (0.0711) D(x): 0.6182 D(G(z)): 0.5066 / 0.4675 Acc: 53.1250 (34.7988)\n",
      "[13/25][559/782] Loss_D: -0.2365 (0.1892) Loss_G: -0.0646 (0.0711) D(x): 0.5761 D(G(z)): 0.4501 / 0.4304 Acc: 48.4375 (34.8001)\n",
      "[13/25][560/782] Loss_D: -0.2862 (0.1891) Loss_G: -0.1102 (0.0711) D(x): 0.5520 D(G(z)): 0.3878 / 0.4329 Acc: 46.8750 (34.8012)\n",
      "[13/25][561/782] Loss_D: -0.1694 (0.1891) Loss_G: -0.0766 (0.0711) D(x): 0.5194 D(G(z)): 0.3859 / 0.4454 Acc: 39.0625 (34.8016)\n",
      "[13/25][562/782] Loss_D: -0.2677 (0.1890) Loss_G: -0.1623 (0.0710) D(x): 0.6212 D(G(z)): 0.4773 / 0.4522 Acc: 50.0000 (34.8030)\n",
      "[13/25][563/782] Loss_D: 0.0411 (0.1890) Loss_G: 0.0345 (0.0710) D(x): 0.5219 D(G(z)): 0.5026 / 0.3964 Acc: 45.3125 (34.8040)\n",
      "[13/25][564/782] Loss_D: -0.0186 (0.1890) Loss_G: -0.0439 (0.0710) D(x): 0.4984 D(G(z)): 0.4224 / 0.4172 Acc: 42.1875 (34.8047)\n",
      "[13/25][565/782] Loss_D: -0.1141 (0.1890) Loss_G: -0.0034 (0.0710) D(x): 0.5234 D(G(z)): 0.4240 / 0.3950 Acc: 39.0625 (34.8051)\n",
      "[13/25][566/782] Loss_D: -0.1066 (0.1889) Loss_G: -0.1522 (0.0710) D(x): 0.5750 D(G(z)): 0.4723 / 0.4623 Acc: 42.1875 (34.8058)\n",
      "[13/25][567/782] Loss_D: -0.0962 (0.1889) Loss_G: -0.0110 (0.0710) D(x): 0.5439 D(G(z)): 0.4767 / 0.4138 Acc: 46.8750 (34.8069)\n",
      "[13/25][568/782] Loss_D: -0.1524 (0.1889) Loss_G: -0.1850 (0.0710) D(x): 0.5126 D(G(z)): 0.4165 / 0.4734 Acc: 48.4375 (34.8082)\n",
      "[13/25][569/782] Loss_D: 0.0209 (0.1889) Loss_G: -0.2061 (0.0709) D(x): 0.5390 D(G(z)): 0.5246 / 0.4794 Acc: 45.3125 (34.8091)\n",
      "[13/25][570/782] Loss_D: -0.1511 (0.1888) Loss_G: -0.1563 (0.0709) D(x): 0.4963 D(G(z)): 0.4638 / 0.4577 Acc: 54.6875 (34.8110)\n",
      "[13/25][571/782] Loss_D: -0.0166 (0.1888) Loss_G: 0.0240 (0.0709) D(x): 0.4887 D(G(z)): 0.4694 / 0.4058 Acc: 50.0000 (34.8124)\n",
      "[13/25][572/782] Loss_D: -0.2041 (0.1888) Loss_G: -0.1181 (0.0709) D(x): 0.5724 D(G(z)): 0.4838 / 0.4529 Acc: 54.6875 (34.8143)\n",
      "[13/25][573/782] Loss_D: -0.1588 (0.1888) Loss_G: -0.2052 (0.0709) D(x): 0.5106 D(G(z)): 0.4036 / 0.4830 Acc: 46.8750 (34.8154)\n",
      "[13/25][574/782] Loss_D: -0.2084 (0.1887) Loss_G: 0.0170 (0.0709) D(x): 0.5833 D(G(z)): 0.4702 / 0.4065 Acc: 50.0000 (34.8168)\n",
      "[13/25][575/782] Loss_D: -0.4008 (0.1887) Loss_G: -0.0963 (0.0708) D(x): 0.5882 D(G(z)): 0.3890 / 0.4310 Acc: 45.3125 (34.8178)\n",
      "[13/25][576/782] Loss_D: -0.0344 (0.1886) Loss_G: -0.1970 (0.0708) D(x): 0.5139 D(G(z)): 0.4451 / 0.4807 Acc: 45.3125 (34.8187)\n",
      "[13/25][577/782] Loss_D: -0.1708 (0.1886) Loss_G: -0.1625 (0.0708) D(x): 0.5606 D(G(z)): 0.4674 / 0.4713 Acc: 51.5625 (34.8203)\n",
      "[13/25][578/782] Loss_D: -0.2709 (0.1886) Loss_G: -0.2052 (0.0708) D(x): 0.5835 D(G(z)): 0.4387 / 0.4767 Acc: 46.8750 (34.8214)\n",
      "[13/25][579/782] Loss_D: -0.0991 (0.1885) Loss_G: -0.0350 (0.0708) D(x): 0.5405 D(G(z)): 0.4997 / 0.4355 Acc: 50.0000 (34.8228)\n",
      "[13/25][580/782] Loss_D: 0.0489 (0.1885) Loss_G: -0.1339 (0.0707) D(x): 0.5060 D(G(z)): 0.5055 / 0.4536 Acc: 43.7500 (34.8237)\n",
      "[13/25][581/782] Loss_D: 0.0343 (0.1885) Loss_G: -0.1955 (0.0707) D(x): 0.5067 D(G(z)): 0.5064 / 0.4736 Acc: 46.8750 (34.8248)\n",
      "[13/25][582/782] Loss_D: 0.0804 (0.1885) Loss_G: -0.0668 (0.0707) D(x): 0.4845 D(G(z)): 0.5005 / 0.4299 Acc: 43.7500 (34.8256)\n",
      "[13/25][583/782] Loss_D: 0.0249 (0.1885) Loss_G: -0.1744 (0.0707) D(x): 0.4568 D(G(z)): 0.4551 / 0.4726 Acc: 46.8750 (34.8267)\n",
      "[13/25][584/782] Loss_D: -0.0158 (0.1885) Loss_G: -0.1399 (0.0707) D(x): 0.5867 D(G(z)): 0.5417 / 0.4707 Acc: 51.5625 (34.8283)\n",
      "[13/25][585/782] Loss_D: 0.2722 (0.1885) Loss_G: -0.0548 (0.0707) D(x): 0.4486 D(G(z)): 0.5264 / 0.4219 Acc: 42.1875 (34.8290)\n",
      "[13/25][586/782] Loss_D: -0.2384 (0.1884) Loss_G: 0.0424 (0.0706) D(x): 0.5367 D(G(z)): 0.4184 / 0.3776 Acc: 48.4375 (34.8303)\n",
      "[13/25][587/782] Loss_D: -0.2223 (0.1884) Loss_G: 0.0067 (0.0706) D(x): 0.5825 D(G(z)): 0.4473 / 0.3896 Acc: 42.1875 (34.8309)\n",
      "[13/25][588/782] Loss_D: -0.1458 (0.1884) Loss_G: -0.1383 (0.0706) D(x): 0.4778 D(G(z)): 0.4256 / 0.4565 Acc: 59.3750 (34.8332)\n",
      "[13/25][589/782] Loss_D: -0.0575 (0.1883) Loss_G: -0.1607 (0.0706) D(x): 0.5682 D(G(z)): 0.4866 / 0.4535 Acc: 39.0625 (34.8336)\n",
      "[13/25][590/782] Loss_D: -0.0143 (0.1883) Loss_G: -0.2140 (0.0706) D(x): 0.5108 D(G(z)): 0.4843 / 0.4882 Acc: 46.8750 (34.8347)\n",
      "[13/25][591/782] Loss_D: -0.1884 (0.1883) Loss_G: -0.1733 (0.0706) D(x): 0.4875 D(G(z)): 0.4174 / 0.4622 Acc: 56.2500 (34.8367)\n",
      "[13/25][592/782] Loss_D: -0.1144 (0.1883) Loss_G: -0.1845 (0.0705) D(x): 0.5661 D(G(z)): 0.4795 / 0.4773 Acc: 46.8750 (34.8378)\n",
      "[13/25][593/782] Loss_D: -0.2471 (0.1882) Loss_G: -0.0741 (0.0705) D(x): 0.5926 D(G(z)): 0.4575 / 0.4412 Acc: 53.1250 (34.8395)\n",
      "[13/25][594/782] Loss_D: -0.1967 (0.1882) Loss_G: 0.1215 (0.0705) D(x): 0.5571 D(G(z)): 0.4791 / 0.3550 Acc: 51.5625 (34.8411)\n",
      "[13/25][595/782] Loss_D: -0.1909 (0.1881) Loss_G: 0.0914 (0.0705) D(x): 0.5335 D(G(z)): 0.3802 / 0.3736 Acc: 40.6250 (34.8416)\n",
      "[13/25][596/782] Loss_D: -0.2158 (0.1881) Loss_G: -0.1292 (0.0705) D(x): 0.5680 D(G(z)): 0.4698 / 0.4562 Acc: 48.4375 (34.8429)\n",
      "[13/25][597/782] Loss_D: 0.0540 (0.1881) Loss_G: -0.1794 (0.0705) D(x): 0.4820 D(G(z)): 0.4740 / 0.4798 Acc: 43.7500 (34.8437)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/25][598/782] Loss_D: -0.0421 (0.1881) Loss_G: 0.0657 (0.0705) D(x): 0.5946 D(G(z)): 0.5295 / 0.3859 Acc: 45.3125 (34.8447)\n",
      "[13/25][599/782] Loss_D: 0.0142 (0.1881) Loss_G: 0.0398 (0.0705) D(x): 0.5196 D(G(z)): 0.4783 / 0.4015 Acc: 40.6250 (34.8452)\n",
      "[13/25][600/782] Loss_D: -0.0549 (0.1880) Loss_G: -0.0370 (0.0705) D(x): 0.5325 D(G(z)): 0.4540 / 0.4206 Acc: 40.6250 (34.8458)\n",
      "Label for eval = [2 5 9 8 7 2 8 1 8 7 5 9 8 3 5 4 9 8 7 5 7 3 0 9 7 9 4 2 7 9 0 5 6 0 1 2 2\n",
      " 0 0 9 4 0 0 6 1 2 1 5 3 6 9 8 1 1 7 4 3 8 1 6 7 8 6 5]\n",
      "[13/25][601/782] Loss_D: -0.0455 (0.1880) Loss_G: -0.2073 (0.0704) D(x): 0.5138 D(G(z)): 0.3835 / 0.4923 Acc: 34.3750 (34.8457)\n",
      "[13/25][602/782] Loss_D: 0.0026 (0.1880) Loss_G: -0.0516 (0.0704) D(x): 0.5820 D(G(z)): 0.5029 / 0.4341 Acc: 42.1875 (34.8464)\n",
      "[13/25][603/782] Loss_D: -0.1013 (0.1880) Loss_G: 0.0725 (0.0704) D(x): 0.6127 D(G(z)): 0.4776 / 0.3714 Acc: 39.0625 (34.8468)\n",
      "[13/25][604/782] Loss_D: -0.0702 (0.1879) Loss_G: 0.0783 (0.0704) D(x): 0.4738 D(G(z)): 0.4539 / 0.3668 Acc: 50.0000 (34.8482)\n",
      "[13/25][605/782] Loss_D: 0.0117 (0.1879) Loss_G: -0.1072 (0.0704) D(x): 0.4306 D(G(z)): 0.3844 / 0.4365 Acc: 39.0625 (34.8486)\n",
      "[13/25][606/782] Loss_D: -0.1898 (0.1879) Loss_G: -0.1870 (0.0704) D(x): 0.5472 D(G(z)): 0.4466 / 0.4877 Acc: 50.0000 (34.8500)\n",
      "[13/25][607/782] Loss_D: -0.0169 (0.1879) Loss_G: -0.3129 (0.0704) D(x): 0.5939 D(G(z)): 0.5424 / 0.5461 Acc: 46.8750 (34.8511)\n",
      "[13/25][608/782] Loss_D: -0.0724 (0.1879) Loss_G: 0.0131 (0.0703) D(x): 0.5827 D(G(z)): 0.4919 / 0.4082 Acc: 42.1875 (34.8518)\n",
      "[13/25][609/782] Loss_D: -0.0719 (0.1878) Loss_G: -0.0616 (0.0703) D(x): 0.5511 D(G(z)): 0.5041 / 0.4234 Acc: 46.8750 (34.8529)\n",
      "[13/25][610/782] Loss_D: -0.1769 (0.1878) Loss_G: 0.0106 (0.0703) D(x): 0.5062 D(G(z)): 0.4066 / 0.4016 Acc: 50.0000 (34.8543)\n",
      "[13/25][611/782] Loss_D: -0.1590 (0.1878) Loss_G: -0.1102 (0.0703) D(x): 0.5528 D(G(z)): 0.4756 / 0.4547 Acc: 53.1250 (34.8560)\n",
      "[13/25][612/782] Loss_D: 0.0530 (0.1878) Loss_G: -0.0181 (0.0703) D(x): 0.4701 D(G(z)): 0.4222 / 0.4221 Acc: 39.0625 (34.8564)\n",
      "[13/25][613/782] Loss_D: -0.1112 (0.1877) Loss_G: 0.0079 (0.0703) D(x): 0.5501 D(G(z)): 0.4829 / 0.4122 Acc: 50.0000 (34.8578)\n",
      "[13/25][614/782] Loss_D: -0.1380 (0.1877) Loss_G: 0.0390 (0.0703) D(x): 0.5647 D(G(z)): 0.4708 / 0.4058 Acc: 43.7500 (34.8586)\n",
      "[13/25][615/782] Loss_D: -0.3286 (0.1876) Loss_G: 0.0795 (0.0703) D(x): 0.5799 D(G(z)): 0.4335 / 0.3940 Acc: 56.2500 (34.8606)\n",
      "[13/25][616/782] Loss_D: -0.1974 (0.1876) Loss_G: -0.0148 (0.0703) D(x): 0.5056 D(G(z)): 0.4643 / 0.3968 Acc: 60.9375 (34.8630)\n",
      "[13/25][617/782] Loss_D: -0.0613 (0.1876) Loss_G: -0.0327 (0.0703) D(x): 0.5246 D(G(z)): 0.4467 / 0.4093 Acc: 43.7500 (34.8639)\n",
      "[13/25][618/782] Loss_D: -0.1627 (0.1876) Loss_G: -0.0167 (0.0703) D(x): 0.5555 D(G(z)): 0.4427 / 0.4066 Acc: 48.4375 (34.8651)\n",
      "[13/25][619/782] Loss_D: -0.1824 (0.1875) Loss_G: 0.1036 (0.0703) D(x): 0.5921 D(G(z)): 0.4862 / 0.3723 Acc: 48.4375 (34.8664)\n",
      "[13/25][620/782] Loss_D: -0.0074 (0.1875) Loss_G: 0.0023 (0.0703) D(x): 0.5100 D(G(z)): 0.4718 / 0.3971 Acc: 43.7500 (34.8672)\n",
      "[13/25][621/782] Loss_D: -0.1511 (0.1875) Loss_G: -0.0530 (0.0703) D(x): 0.5515 D(G(z)): 0.4919 / 0.4421 Acc: 56.2500 (34.8692)\n",
      "[13/25][622/782] Loss_D: 0.0713 (0.1875) Loss_G: -0.1681 (0.0702) D(x): 0.5060 D(G(z)): 0.4727 / 0.4713 Acc: 39.0625 (34.8696)\n",
      "[13/25][623/782] Loss_D: -0.0812 (0.1874) Loss_G: 0.0201 (0.0702) D(x): 0.5307 D(G(z)): 0.5290 / 0.4048 Acc: 57.8125 (34.8717)\n",
      "[13/25][624/782] Loss_D: -0.0430 (0.1874) Loss_G: -0.0987 (0.0702) D(x): 0.4325 D(G(z)): 0.3981 / 0.4388 Acc: 51.5625 (34.8732)\n",
      "[13/25][625/782] Loss_D: -0.1473 (0.1874) Loss_G: -0.1080 (0.0702) D(x): 0.5147 D(G(z)): 0.4191 / 0.4329 Acc: 51.5625 (34.8748)\n",
      "[13/25][626/782] Loss_D: 0.1956 (0.1874) Loss_G: -0.1039 (0.0702) D(x): 0.5436 D(G(z)): 0.5659 / 0.4463 Acc: 37.5000 (34.8750)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-555:\n",
      "Process Process-572:\n",
      "Process Process-570:\n",
      "Process Process-561:\n",
      "Process Process-557:\n",
      "Process Process-562:\n",
      "Process Process-566:\n",
      "Process Process-567:\n",
      "Process Process-571:\n",
      "Process Process-556:\n",
      "Process Process-552:\n",
      "Process Process-576:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Process-549:\n",
      "Process Process-575:\n",
      "Process Process-569:\n",
      "Process Process-548:\n",
      "Process Process-546:\n",
      "Process Process-551:\n",
      "Process Process-563:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Process-574:\n",
      "Process Process-565:\n",
      "Traceback (most recent call last):\n",
      "Process Process-568:\n",
      "Process Process-545:\n",
      "Process Process-553:\n",
      "Process Process-573:\n",
      "Process Process-550:\n",
      "Process Process-558:\n",
      "Process Process-554:\n",
      "Process Process-547:\n",
      "Process Process-560:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Process-559:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "Process Process-564:\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7faf879e1b00>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 347, in __del__\n",
      "    def __del__(self):\n",
      "  File \"/home/rajaswa-pc/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 178, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 7624) exited unexpectedly with exit code 1.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-2eff43f89d4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0maux_errD_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maux_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maux_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0merrD_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdis_errD_real\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0maux_errD_real\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0merrD_real\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mD_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdis_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(niter):\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        # train with real\n",
    "        netD.zero_grad()\n",
    "        real_cpu, label = data\n",
    "        batch_size = real_cpu.size(0)\n",
    "        if cuda:\n",
    "            real_cpu = real_cpu.cuda()\n",
    "        input.data.resize_as_(real_cpu).copy_(real_cpu)\n",
    "        dis_label.data.resize_(batch_size).fill_(real_label)\n",
    "        aux_label.data.resize_(batch_size).copy_(label)\n",
    "        dis_output, aux_output = netD(input)\n",
    "\n",
    "        dis_errD_real = dis_criterion(dis_output, dis_label)\n",
    "        aux_errD_real = aux_criterion(aux_output, aux_label)\n",
    "        errD_real = dis_errD_real + aux_errD_real\n",
    "        errD_real.backward()\n",
    "        D_x = dis_output.data.mean()\n",
    "\n",
    "        # compute the current classification accuracy\n",
    "        accuracy = compute_acc(aux_output, aux_label)\n",
    "\n",
    "        # train with fake\n",
    "        noise.data.resize_(batch_size, nz, 1, 1).normal_(0, 1)\n",
    "        label = np.random.randint(0, num_classes, batch_size)\n",
    "        noise_ = np.random.normal(0, 1, (batch_size, nz))\n",
    "        class_onehot = np.zeros((batch_size, num_classes))\n",
    "        class_onehot[np.arange(batch_size), label] = 1\n",
    "        noise_[np.arange(batch_size), :num_classes] = class_onehot[np.arange(batch_size)]\n",
    "        noise_ = (torch.from_numpy(noise_))\n",
    "        noise.data.copy_(noise_.view(batch_size, nz, 1, 1))\n",
    "        aux_label.data.resize_(batch_size).copy_(torch.from_numpy(label))\n",
    "\n",
    "        fake = netG(noise)\n",
    "        dis_label.data.fill_(fake_label)\n",
    "        dis_output, aux_output = netD(fake.detach())\n",
    "        dis_errD_fake = dis_criterion(dis_output, dis_label)\n",
    "        aux_errD_fake = aux_criterion(aux_output, aux_label)\n",
    "        errD_fake = dis_errD_fake + aux_errD_fake\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = dis_output.data.mean()\n",
    "        errD = errD_real + errD_fake\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        netG.zero_grad()\n",
    "        dis_label.data.fill_(real_label)  # fake labels are real for generator cost\n",
    "        dis_output, aux_output = netD(fake)\n",
    "        dis_errG = dis_criterion(dis_output, dis_label)\n",
    "        aux_errG = aux_criterion(aux_output, aux_label)\n",
    "        errG = dis_errG + aux_errG\n",
    "        errG.backward()\n",
    "        D_G_z2 = dis_output.data.mean()\n",
    "        optimizerG.step()\n",
    "\n",
    "        # compute the average loss\n",
    "        curr_iter = epoch * len(dataloader) + i\n",
    "        all_loss_G = avg_loss_G * curr_iter\n",
    "        all_loss_D = avg_loss_D * curr_iter\n",
    "        all_loss_A = avg_loss_A * curr_iter\n",
    "        all_loss_G += errG.data[0]\n",
    "        all_loss_D += errD.data[0]\n",
    "        all_loss_A += accuracy\n",
    "        avg_loss_G = all_loss_G / (curr_iter + 1)\n",
    "        avg_loss_D = all_loss_D / (curr_iter + 1)\n",
    "        avg_loss_A = all_loss_A / (curr_iter + 1)\n",
    "\n",
    "        print('[%d/%d][%d/%d] Loss_D: %.4f (%.4f) Loss_G: %.4f (%.4f) D(x): %.4f D(G(z)): %.4f / %.4f Acc: %.4f (%.4f)'\n",
    "              % (epoch, niter, i, len(dataloader),\n",
    "                 errD.data[0], avg_loss_D, errG.data[0], avg_loss_G, D_x, D_G_z1, D_G_z2, accuracy, avg_loss_A))\n",
    "        if i % 100 == 0:\n",
    "            vutils.save_image(\n",
    "                real_cpu, '%s/real_samples.png' % outf)\n",
    "            print('Label for eval = {}'.format(eval_label))\n",
    "            fake = netG(eval_noise)\n",
    "            vutils.save_image(\n",
    "                fake.data,\n",
    "                '%s/fake_samples_epoch_%03d.png' % (outf, epoch)\n",
    "            )\n",
    "\n",
    "    # do checkpointing\n",
    "    torch.save(netG.state_dict(), '%s/netG_epoch_%d.pth' % (outf, epoch))\n",
    "    torch.save(netD.state_dict(), '%s/netD_epoch_%d.pth' % (outf, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
